[
  {
    "objectID": "exam-02-practice.html",
    "href": "exam-02-practice.html",
    "title": "Exam 02 practice",
    "section": "",
    "text": "Important\n\n\n\nThis page contains practice problems to help prepare for Exam 02. This set of practice problems is not comprehensive. You should review these study tips as you prepare for the exam.\n\nThere is no answer key for these problems. You may ask questions in office hours and on Ed Discussion."
  },
  {
    "objectID": "exam-02-practice.html#exercise-1",
    "href": "exam-02-practice.html#exercise-1",
    "title": "Exam 02 practice",
    "section": "Exercise 1",
    "text": "Exercise 1\nGiven the simple linear regression model\n\\[y_i = \\beta_0 + \\beta_1x_i + \\epsilon_i, \\hspace{10mm} \\epsilon_i \\sim N(0, \\sigma^2_{\\epsilon})\\]\nWrite the likelihood function and use it to show that the maximum likelihood estimators (MLEs) of \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\sigma^2_{\\epsilon}\\) are of the form shown on this slide."
  },
  {
    "objectID": "exam-02-practice.html#exercise-2",
    "href": "exam-02-practice.html#exercise-2",
    "title": "Exam 02 practice",
    "section": "Exercise 2",
    "text": "Exercise 2\nGiven the linear regression model\n\\[\n\\mathbf{y}  = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon} \\hspace{10mm} \\boldsymbol{\\epsilon} \\sim N(\\mathbf{0}, \\sigma^2_{\\epsilon}\\mathbf{I})\n\\]\nWrite the likelihood function and use it to show that the maximum likelihood estimators (MLEs) of \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2_{\\epsilon}\\) are\n\\[\n\\tilde{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y} \\hspace{10mm} \\tilde{\\sigma}^2_{\\epsilon} = \\frac{1}{n}(\\mathbf{y} - \\mathbf{X}\\tilde{\\boldsymbol{\\beta}})^T(\\mathbf{y} - \\mathbf{X}\\tilde{\\boldsymbol{\\beta}})\n\\]"
  },
  {
    "objectID": "exam-02-practice.html#exercise-3",
    "href": "exam-02-practice.html#exercise-3",
    "title": "Exam 02 practice",
    "section": "Exercise 3",
    "text": "Exercise 3\nGiven the logistic regression model\n\\[\n\\log\\Big(\\frac{\\pi}{1-\\pi}\\Big) = \\mathbf{X}\\boldsymbol{\\beta}\n\\]\n\nWrite the likelihood function\nRework the derivation from the November 7 lecture to show the derivative solved to find the MLEs is of the form on this slide. (You can check your answer using the board work posted in Canvas)."
  },
  {
    "objectID": "exam-02-practice.html#exercise-4",
    "href": "exam-02-practice.html#exercise-4",
    "title": "Exam 02 practice",
    "section": "Exercise 4",
    "text": "Exercise 4\nSuppose \\(Y_1, \\ldots, Y_n\\) are an independent and identically distributed (iid) sample from some distribution\n\\[f_Y(y) = \\theta(1 - \\theta)^{y-1}\\]\nsuch that \\(y\\) takes on positive integer values and \\(0 &lt; \\theta &lt; 1\\). Show that the MLE for \\(\\theta^{-1}\\) is \\(\\frac{1}{n}\\sum_{i=1}^n y_i\\) ."
  },
  {
    "objectID": "exam-02-practice.html#exercise-5",
    "href": "exam-02-practice.html#exercise-5",
    "title": "Exam 02 practice",
    "section": "Exercise 5",
    "text": "Exercise 5\nRework Exercises 1 - 3 in HW 03."
  },
  {
    "objectID": "exam-02-practice.html#exercise-6",
    "href": "exam-02-practice.html#exercise-6",
    "title": "Exam 02 practice",
    "section": "Exercise 6",
    "text": "Exercise 6\nSuppose we fit a linear model with a log transformation on the response variable, i.e.,\n\\[\n\\widehat{\\log(y_i)} = \\hat{\\beta}_0 + \\hat{\\beta}_1x_1 + \\dots + \\hat{\\beta}_p x_p\n\\]\n\nShow mathematically why the slope for \\(x_j\\) and intercept are interpreted in terms of \\(y\\) as shown on this slide.\nShow how \\(y\\) is expected to change if \\(x_j\\) increases by \\(t\\) units."
  },
  {
    "objectID": "exam-02-practice.html#exercise-7",
    "href": "exam-02-practice.html#exercise-7",
    "title": "Exam 02 practice",
    "section": "Exercise 7",
    "text": "Exercise 7\nSuppose we fit a linear model with a log transformation on one predictor variable, i.e.,\n\\[\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1\\log (x_1) + \\dots + \\hat{\\beta}_p x_p\n\\]\n\nShow mathematically why the slope and intercept are interpreted similarly as shown on this slide when \\(x\\) is multiplied by a factor \\(C\\).\nExplain why we need “holding all else constant” in this interpretation but not for the one shown in the lecture slides."
  },
  {
    "objectID": "exam-02-practice.html#exercise-8",
    "href": "exam-02-practice.html#exercise-8",
    "title": "Exam 02 practice",
    "section": "Exercise 8",
    "text": "Exercise 8\nRework Exercise 4 in HW 03."
  },
  {
    "objectID": "exam-02-practice.html#exercise-9",
    "href": "exam-02-practice.html#exercise-9",
    "title": "Exam 02 practice",
    "section": "Exercise 9",
    "text": "Exercise 9\nRecall that for the linear regression, the variance of the estimated coefficients are the diagonal elements of \\(Var(\\hat{\\boldsymbol{\\beta}}) = \\hat{\\sigma}^2_{\\epsilon}(\\mathbf{X}^T\\mathbf{X})^{-1}\\). One of the effects of multicollinearity is that the model coefficients will have large variances. Explain why."
  },
  {
    "objectID": "exam-02-practice.html#exercise-10",
    "href": "exam-02-practice.html#exercise-10",
    "title": "Exam 02 practice",
    "section": "Exercise 10",
    "text": "Exercise 10\nSuppose you fit a simple linear regression model.\n\nDraw a scatterplot that contains an observation with large leverage but low Cook’s distance.\nDraw a scatterplot that contains an observation with large leverage and high Cook’s distance.\nDraw a scatterplot that contains an observation with a large studentized residual."
  },
  {
    "objectID": "exam-02-practice.html#exercise-11",
    "href": "exam-02-practice.html#exercise-11",
    "title": "Exam 02 practice",
    "section": "Exercise 11",
    "text": "Exercise 11\n\nWhat is an advantage of examining a plot of studentized residuals vs. fitted values rather than using the raw residuals?\nExplain what is measured by Cook’s distance. You don’t need to memorize the formula but rather describe what the formula is quantifying for each observation. Click here for the formula (slide also contains the solution)."
  },
  {
    "objectID": "exam-02-practice.html#exercise-12",
    "href": "exam-02-practice.html#exercise-12",
    "title": "Exam 02 practice",
    "section": "Exercise 12",
    "text": "Exercise 12\nConsider the hypotheses being tested in the Nested F Test on this slide. The output produced by the anova() function for the Nested F test is shown here. Explain how each value in the table is computed."
  },
  {
    "objectID": "exam-02-practice.html#exercise-13",
    "href": "exam-02-practice.html#exercise-13",
    "title": "Exam 02 practice",
    "section": "Exercise 13",
    "text": "Exercise 13\n\nWhat is an advantage of using a Nested F test instead of AIC (or BIC) to compare linear regression models?\nWhat is an advantage of using AIC (or BIC) instead of a Nested F test to compare linear regression models?"
  },
  {
    "objectID": "exam-02-practice.html#exercise-141",
    "href": "exam-02-practice.html#exercise-141",
    "title": "Exam 02 practice",
    "section": "Exercise 141",
    "text": "Exercise 141\n\nOn average, what fraction of people with an odds of 0.37 of defaulting on their credit card payment will in fact default?\nSuppose an individual has a 16% chance of defaulting on their credit card payment. What are the odds they will default?"
  },
  {
    "objectID": "exam-02-practice.html#exercise-15",
    "href": "exam-02-practice.html#exercise-15",
    "title": "Exam 02 practice",
    "section": "Exercise 15",
    "text": "Exercise 15\nRecall the model using age and education to predict odds of being high risk for heart disease.\n\nShow mathematically why the interpretation for the slope for age in terms of the log-odds is in the form shown on this slide.\nShow mathematically why the interpretation for the slope of age in terms of the odds is in the form shown on this slide."
  },
  {
    "objectID": "exam-02-practice.html#exercise-16",
    "href": "exam-02-practice.html#exercise-16",
    "title": "Exam 02 practice",
    "section": "Exercise 16",
    "text": "Exercise 16\nRecall the model using age and education to predict odds of being high risk for heart disease.\n\nShow mathematically why the interpretation for the slope for education4 in terms of the log-odds is in the form shown on this slide.\nShow mathematically why the interpretation for the slope of education4in terms of the odds is in the form shown on this slide."
  },
  {
    "objectID": "exam-02-practice.html#exercise-17",
    "href": "exam-02-practice.html#exercise-17",
    "title": "Exam 02 practice",
    "section": "Exercise 17",
    "text": "Exercise 17\nExplain why the slope of the logistic regression model is called the Adjusted Odds Ratio (or just Odds Ratio if there is one predictor)."
  },
  {
    "objectID": "exam-02-practice.html#exercise-18",
    "href": "exam-02-practice.html#exercise-18",
    "title": "Exam 02 practice",
    "section": "Exercise 18",
    "text": "Exercise 18\n\nDraw an example of an ROC curve such that the AUC is about 0.55\nDraw an example of an ROC curve such that the AUC is about 0.9.\nExplain what each point on an ROC curve represents."
  },
  {
    "objectID": "exam-02-practice.html#exercise-19",
    "href": "exam-02-practice.html#exercise-19",
    "title": "Exam 02 practice",
    "section": "Exercise 19",
    "text": "Exercise 19\nConsider the drop-in-deviance test from lecture testing whether education should be added to a model that already includes age, totChol, and currentSmoker to predict the odds a person is high risk for heart disease.\nThe anova() output for the drop-in-deviance test is shown on this slide. Explain how each value in the table is computed."
  },
  {
    "objectID": "exam-02-practice.html#exercise-20",
    "href": "exam-02-practice.html#exercise-20",
    "title": "Exam 02 practice",
    "section": "Exercise 20",
    "text": "Exercise 20\nRecall this empirical logit plot to check the linearity condition for the model using age , sex, and years of experience to predict access to PPE for employees at food establishments in Summer 2020.\nThere is a point on the plot around (20, -0.5). Explain what these coordinates mean in the context of the data."
  },
  {
    "objectID": "exam-02-practice.html#relevant-assignments-and-aes",
    "href": "exam-02-practice.html#relevant-assignments-and-aes",
    "title": "Exam 02 practice",
    "section": "Relevant assignments and AEs",
    "text": "Relevant assignments and AEs\nThe following assignments and AEs cover Exam 02 content. Ask yourself “why” questions as your review your answers, process, and derivations on these assignments. It may also be helpful to explain your process to others.\n\nHW 03, HW 04\nLab 04, Lab 05, Lab 06\nAE 05, AE 06, AE 07, AE 08"
  },
  {
    "objectID": "exam-02-practice.html#footnotes",
    "href": "exam-02-practice.html#footnotes",
    "title": "Exam 02 practice",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFrom Introduction to Statistical Learning.↩︎"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Final project",
    "section": "",
    "text": "Research topics due Tuesday, February 11\nProject proposal due Tuesday, February 25\nExploratory data analysis due Thursday, March 20\nPresentation + Presentation comments Friday, March 28 (in lab)\nAnalysis draft + peer review Friday, April 11 (peer review in lab)\nWritten report due Monday, April 28\nProject highlights due Wednesday, April 30\nReproducibility + organization due Wednesday, April 30\nFinal project survey due Thursday, May 1",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#project-milestones",
    "href": "project.html#project-milestones",
    "title": "Final project",
    "section": "",
    "text": "Research topics due Tuesday, February 11\nProject proposal due Tuesday, February 25\nExploratory data analysis due Thursday, March 20\nPresentation + Presentation comments Friday, March 28 (in lab)\nAnalysis draft + peer review Friday, April 11 (peer review in lab)\nWritten report due Monday, April 28\nProject highlights due Wednesday, April 30\nReproducibility + organization due Wednesday, April 30\nFinal project survey due Thursday, May 1",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#introduction",
    "href": "project.html#introduction",
    "title": "Final project",
    "section": "Introduction",
    "text": "Introduction\nTL;DR: Pick a data set and do a regression analysis. That is your final project.\nThe goal of the final project is for you to use regression analysis to analyze a data set of your own choosing. The data set may already exist or you may collect your own data by scraping the web.\nChoose the data based on your group’s interests or work you all have done in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like!) and apply them to a data set to analyze it in a meaningful way.\nAll analyses must be done in RStudio using Quarto and GitHub, and your analysis and written report must be reproducible.\n\nLogistics\nYou will work on the project with your lab groups. The primary deliverables for the project are\n\nan in-person presentation about the exploratory data analysis and initial modeling\na written, reproducible final report detailing your analysis\na summary of your project highlights to share with the class\na GitHub repository containing all work from the project\n\nThere are intermediate milestones and peer review assignments throughout the semester to help you work towards the primary deliverables.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#research-topics",
    "href": "project.html#research-topics",
    "title": "Final project",
    "section": "Research topics",
    "text": "Research topics\nThe goal of this milestone is to discuss topics and develop potential research questions your team is interested in investigating for the project. You are only developing ideas at this point; you do not need to have a data set identified right now.\nDevelop three potential research topics. Include the following for each topic:\n\nA brief description of the topic\nA statement about your motivation for investigating this topic\nThe potential audience(s), i.e., who might be most interested in this research?\nTwo or three potential research questions you could analyze about this topic. (Note: These are draft questions at this point. You will finalize the questions in the next stage of the project.)\nIdeas about the type of data you might use to answer this question or potential data sets you’re interested in using. (Note: The goal is to generate ideas at this point, so it is fine if you have not identified any particular data sets at this point.)\n\n\nSubmission\nWrite your responses in research-topics.qmd in your team’s project GitHub repo. Push the qmd and rendered pdf documents to GitHub by the deadline, Tuesday, February 11 at 11:59pm. There is no Gradescope submission.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#project-proposal",
    "href": "project.html#project-proposal",
    "title": "Final project",
    "section": "Project proposal",
    "text": "Project proposal\nThe purpose of the project proposal is for your team to identify the data set you’re interested in analyzing to investigate one of your potential research topics. You will also do some preliminary exploration of the response variable and begin thinking about the modeling strategy. If you’re unsure where to find data, you can use the list of potential data sources on the Tips + resources page as a starting point.\n\n\n\n\n\n\nImportant\n\n\n\nYou must use the data set(s) in the proposal for the final project, unless instructed otherwise when given feedback.\n\n\nThe data set must meet the following criteria:\n\nAt least 500 observations\nAt least 10 columns, such that at least 6 of the columns are useful and unique predictor variables.\n\ne.g., identifier variables such as “name”, “ID number”, etc. are not useful predictor variables.\ne.g., if you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique predictors.\n\nAt least one variable that can be identified as a reasonable response variable.\n\nThe response variable can be quantitative or categorical.\n\nA mix of quantitative and categorical variables that can be used as predictors.\nMay not be data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\n\n\n\n\n\n\nTypes of data sets to avoid\n\n\n\n\nData that are likely violate the independence condition. Therefore, avoid data with repeated measures, data collected over time, etc.\nData sets in which there is no information about how the data were originally collected\nData sets in which there are missing or unclear definitions about the observations and/or variables\n\n\n\nAsk a member of the teaching team if you’re unsure whether your data set meets the criteria.\nThe proposal will include the following sections:\n\nSection 1: Introduction\n\n\n\n\n\n\nTip\n\n\n\nReuse and iterate on the work from the Research Topics milestone.\n\n\n\nAn introduction to the subject matter you’re investigating (citing any relevant literature)\nStatement of a well-developed research question.\nThe motivation for your research question and why it is important\nYour team’s hypotheses regarding the research question\n\nThis is a narrative about what you think regarding the research question, not formal statistical hypotheses.\n\n\n\n\nSection 2: Data description\n\nThe source of the data set\nA description of when and how the data were originally collected (by the original data curator, not necessarily how you found the data)\nA description of the observations and general characteristics being measured\n\n\n\nSection 3: Data processing\n\nDescription of data processing you need to do to prepare for analysis, such as joining multiple data sets, handling missing data, etc.\nVisualizations, summary statistics, and narrative to describe the distribution of the response variable.\n\n\n\nSection 4: Analysis approach\n\na description of the potential predictor variables of interest\nregression model technique (multiple linear regression for quantitative response variable or logistic regression for a categorical response variable)\n\n\n\nData dictionary (aka code book)\nSubmit a data dictionary for all the variables in your data set in the README of the data folder. You do not need to include the data dictionary in the PDF document.\n\n\nSubmission\nWrite your narrative and analysis for Sections 1 - 4 in the proposal.qmd file in your team’s GitHub repo. Put the data set and the data dictionary in the data folder in the repo. Push the qmd and rendered pdf documents to GitHub by the deadline, Tuesday, February 25 at 11:59pm.\n\n\nGrading\nThe anticipated length, including all graphs, tables, narrative, etc., is 2 -4 pages.\nThe proposal is worth 5 points and will be graded based on accurately and comprehensively addressing the criteria stated above. Points will be assigned based on a holistic review of the project proposal.\n\nExcellent (5 points) : All required elements are completed and are accurate. The data set meets the requirements (or the team has otherwise discussed the data with Professor Tackett) and the data do not pose obvious violations to the modeling assumptions. There is a thoughtful and comprehensive description of the data, any data processing, and exploration of the response variable as described above. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nStrong (3 - 4 points): Requirements are mostly met, but there are some elements that are incomplete or inaccurate. Some minor revision of the work required before team is ready for modeling.\nSatisfactory (2 points): Requirements partially met, but there are some elements that are incomplete and/or inaccurate. Major revision of the work required before team is ready for modeling.\nNeeds Improvement (1 point): Requirements are largely unmet, and there arem major elements that are incomplete and/or inaccurate. Substantial revisions of the work required before team is ready for modeling.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#eda",
    "href": "project.html#eda",
    "title": "Final project",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\n\n\n\n\n\nTip\n\n\n\nReuse and iterate on the work from the previous milestones.\n\n\nThe purpose of this milestone is begin exploring the data and get early feedback on your data and analysis. You will submit a draft of the beginning of your report that includes the introduction and exploratory data analysis, with an emphasis on the EDA. It will also help you prepare for the presentation of the exploratory data analysis results.\nBelow is a brief description of the sections to include in this step:\n\nIntroduction\nThis section includes an introduction to the project motivation, background, data, and research question.\n\n\nExploratory data analysis\nThis section includes the following:\n\nDescription of the data set and key variables.\nExploratory data analysis of the response variable and key predictor variables. This includes visualizations, summary statistics, and narrative\n\nUnivariate EDA of the response and key predictor variables.\nBivariate EDA of the response and key predictor variables\nPotential interaction effects\n\n\n\n\nSubmission\nWrite your draft introduction and exploratory data analysis in the written-report.qmd file in your team’s GitHub repo. Push the qmd and rendered pdf documents to GitHub by the deadline.\n\n\nGrading\nThe anticipated length, including all graphs, tables, narrative, etc. with code, warnings, and messages suppressed is about 4 - 6 pages (It is OK to be over this page limit at this stage in the project.)\n\n\n\n\n\n\nTip\n\n\n\nYou can save space by suppressing code, warnings, and messages by including the following in the YAML:\nexecute:\n  echo: false\n  message: false\n  warning: false\n\n\nThe exploratory data analysis is worth 10 points and will be graded based on accurately and comprehensively addressing the criteria stated above, along with incorporating the feedback from the proposal. Points will be assigned based on a holistic review of the exploratory data analysis.\n\nExcellent (9 - 10 points) : All required elements are completed and are accurate. There is a thorough exploration of the data as described above, and the team has demonstrated a careful and thoughtful approach exploring the data and preparing it for analysis. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nStrong: (7 - 8 points): Requirements are mostly met, but there are some elements that are incomplete or inaccurate. Some revision of the work required before team is ready for modeling.\nSatisfactory (5 - 6 points): Requirements partially met, but there are some elements that are incomplete and/or inaccurate. Major revision of the work required before team is ready for modeling.\nNeeds Improvement (4 or fewer points points): Requirements are largely unmet, and there are large elements that are incomplete and/or inaccurate. Substantial revisions of the work required before team is ready for modeling.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#presentation",
    "href": "project.html#presentation",
    "title": "Final project",
    "section": "Presentation",
    "text": "Presentation\n\n\n\n\n\n\nImportant\n\n\n\nPresentations will take place in class during labs. Presentation order will be announced in advance.\n\n\nYour team will do an in-person presentation that summarizes and showcases the work you’ve done on the project thus far. Because the presentations will take place while you’re still working on the project, it will also be an opportunity to receive feedback and suggestions as well as provide feedback to other teams. The presentation will focus on introducing the subject matter and research question, showcase key results from the exploratory data analysis, and discuss primary modeling strategies and/or results. The presentation should be supported by slides that serve as a brief visual addition to the presentation. The presentation and slides will be graded for content and clarity.\nYou can create your slides with any software you like (e.g., Keynote, PowerPoint, Google Slides, etc.). You can also use Quarto to make your slides! While we won’t be covering making slides with Quarto in the class, we would be happy to help you with it in office hours. It’s no different than writing other documents with Quarto, so the learning curve will not be steep!\nThe presentation is expected to be between 5 to 6 minutes. It may not exceed 6 minutes, due to the limited time during lab.\nEvery team member is expected to speak in the presentation. Part of the grade will be whether every team member had a meaningful speaking role in the presentation.\n\nSlides\nThe slide deck should have no more than 6 content slides + 1 title slide to ensure you have enough time to discuss each slide. s Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the subject, motivation, and research question\nSlide 2: Introduce the data set\nSlide 3 - 4: Highlights from the EDA (be sure to include EDA for the response variable!)\nSlide 5: Initial modeling strategies / results (if applicable)\nSlide 6: Next steps and any questions you’d like to get feedback on\n\n\n\nSubmission\nYou can submit the presentation slides in two ways:\n\nPut a PDF of the slides or Quarto slides in the presentation folder in your team’s GitHub repo.\nPut the URL to your slides in the README of the presentation folder. If you share the URL, please make sure permissions are set so Prof. Tackett can view the slides.\n\n\n\n\n\n\n\nImportant\n\n\n\nSlides must be submitted by the start of your lab on the day of presentations. We will use a classroom computer for the presentations.\n\n\n\n\nGrading\nThe presentation is worth points. It will be graded based on the following:\n\nContent: The team told a unified story that clearly introduced the subject matter, research question, and exploration of the data.\nSlides: The presentation slides were organized, included clear and informative visualizations, and were easily readable.\nPresentation: The team’s communication style was clear and professional. The team divided the time well and stayed within the 8 minute time limit, with each team member making a meaningful contribution to the presentation.\n\n80% of the presentation grade will be the average of the teaching team scores and 20% will be the average of the peer scores.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#presentation-comments",
    "href": "project.html#presentation-comments",
    "title": "Final project",
    "section": "Presentation comments",
    "text": "Presentation comments\n\n\n\n\n\n\nImportant\n\n\n\nClick here to see the teams you’re scoring and a link to the feedback form.\nThis portion of the project is worth 2 points and will be assessed individually.\n\n\nYou will provide feedback on two teams’ presentations. The assigned teams and link to the feedback form will be available in advance of the presentations. Please provide all scores and comments by the end of the lab session. There will be a few minutes between each presentation to submit scores and comments.\nThe grade will be based on submitting the scores and comments for both of your assigned teams by the end of the presentation day.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#draft-report-peer-review",
    "href": "project.html#draft-report-peer-review",
    "title": "Final project",
    "section": "Analysis + peer review",
    "text": "Analysis + peer review\nThe purpose of the draft and peer review is to give you an opportunity to get early feedback on your analysis. Therefore, the draft and peer review will focus primarily on the exploratory data analysis, modeling, and initial interpretations.\n\nDraft report\nWrite the draft in the written-report.qmd file in your project repo.\nBelow is a brief description of the sections to focus on in the draft:\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the body of the report, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, any variable transformations (if needed), and any other relevant considerations that were part of the model fitting process.\n\n\nResults\nIn this section, you will output the final model and include a brief discussion of the model assumptions, diagnostics, and any relevant model fit statistics.\nThis section also includes initial interpretations and conclusions drawn from the model.\n\n\nGrading\nThe draft will be graded based on whether there is demonstration of a reasonable attempt at each of the sections described below in the written report file in the GitHub repo by the deadline.\n\n\n\nPeer review\nCritically reviewing others’ work is a crucial part of the scientific process, and STA 221 is no exception. Each lab team will be assigned two other teams’ projects to review. Each team should push their draft to their GitHub repo by 10 am on the day their lab’s draft is due. The lab that week will be dedicated to the peer review, so your team will have time to review and provide quality feedback to two other teams.\nDuring the peer review process, you will be provided read-only access to your partner teams’ GitHub repos. Provide your review in the form of GitHub issues to your partner team’s GitHub repo using the issue template provided in the repo.\n\nSteps for peer review\n\n\n\n\n\n\nPeer review assignments\n\n\n\nClick here to see the teams you’re peer reviewing.You’ll spend about 30 minutes reviewing each project.\n\n\n\nWhen you get to lab, you should have access to the GitHub repos for the teams you’re reviewing. In GitHub, search the repositories for project, and you should see the repos for the projects you’re reviewing. You will be able to read the files in the repo and post issues, but you cannot push changes to the repo. You will have access to the repo until the deadline for the peer review.\nYou may choose to all work on both peer reviews or have some team members focus on a single peer review. Either way there will be one peer review grade assigned per team.\nFor each team you’re reviewing:\n\nOpen that team’s repo, read the project draft, and browse the rest of the repo.\nGo to the Issues tab in that repo, click on New issue, and click on Get started for the Peer Review issue. Write your responses to the prompts in the issue. You will answer the following questions:\n\nDescribe the goal of the project.\nDescribe the data set used in the project. What are the observations in the data? What is the source of the data? How were the data originally collected?\nConsider the exploratory data analysis (EDA). Describe one aspect of the EDA that is effective in helping you understand the data. Provide constructive feedback on how the team might improve the EDA.\nDescribe the statistical methods, analysis approach, and discussion of model assumptions, diagnostics, model fit.\nProvide constructive feedback on how the team might improve their analysis. Make sure your feedback includes at least one comment on the statistical modeling aspect of the project, but also feel free to comment on aspects beyond the modeling.\nProvide constructive feedback on the interpretations and initial conclusion. What is most effective in the presentation of the results? What additional detail can the team provide to make the results and conclusions easier for the reader to understand?\nWhat aspect of this project are you most interested in and think would be interesting to highlight in the written report?\nProvide constructive feedback on any issues with file and/or code organization.\n(Optional) Any further comments or feedback?\n\n\n\n\n\nGrading\nThe peer review will be graded on the extent to which each comprehensively and constructively addresses the components on the peer review form. There will be one peer review grade per team.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#written-report",
    "href": "project.html#written-report",
    "title": "Final project",
    "section": "Written report",
    "text": "Written report\n\n\n\n\n\n\nImportant\n\n\n\nYour written report must be completed in the written-report.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the code chunks are not visible and all messages and warnings are suppressed.\n\n\n\nYou will submit the PDF of your final report on GitHub.\nThe PDF you submit must match the .qmd in your GitHub repository exactly. The mandatory components of the report are below. You are free to add additional sections as necessary. The report, including tables and visualizations, must be no more than 10 pages long. There is no minimum page requirement; however, you should comprehensively address all of the analysis and report.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will overwhelmingly be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.\n\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\n\n\n\nResults\n\nDescribe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\n\n\n\nDiscussion + Conclusion\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\n\n\n\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#project-highlights",
    "href": "project.html#project-highlights",
    "title": "Final project",
    "section": "Project highlights",
    "text": "Project highlights\nThis is an opportunity to share your final analysis results with your peers! You will post highlights in Canvas discussion forum using one fo the following formats:\n\nA detailed abstract\nSlides summarizing your project results\nShort video summarizing your project results\n\nMore detail about these highlight formats and posting in Canvas to come.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#reproducibility-organization",
    "href": "project.html#reproducibility-organization",
    "title": "Final project",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nThe GitHub repo should have the following structure:\n\nREADME: Short project description and data dictionary\nwritten-report.qmd & written-report.pdf: Final written report\nproposal.qmd & proposal.pdf: Project proposal\nresearch-topics.qmd & research-topics.pdf: Proposed research questions\n/data: Folder that contains the data set for the final project.\nproject.Rproj: File specifying the RStudio project\n/presentation: Folder with the presentation slides or link to slides.\n.gitignore: File that lists all files that are in the local RStudio project but not the GitHub repo\n/.github: Folder for peer review issue template\nAny other files should be neatly organized into clearly labeled folders.\n\nUpdate the README of the project repo with your project title and team members’ names.\nPoints for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#final-project-survey",
    "href": "project.html#final-project-survey",
    "title": "Final project",
    "section": "Final project survey",
    "text": "Final project survey\nYou will complete a short survey about the project. More details to come.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#peer-teamwork-evaluation",
    "href": "project.html#peer-teamwork-evaluation",
    "title": "Final project",
    "section": "Peer teamwork evaluation",
    "text": "Peer teamwork evaluation\nThere will be an opportunity to provide feedback to Professor Tackett about each team member’s contribution to the project. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#overall-grading",
    "href": "project.html#overall-grading",
    "title": "Final project",
    "section": "Overall grading",
    "text": "Overall grading\nThe grade breakdown is as follows:\n\n\n\nTotal\n100 pts\n\n\n\n\nResearch topics\n3 pts\n\n\nProject proposal\n5 pts\n\n\nExploratory data analysis\n10 pts\n\n\nPresentation\n10 pts\n\n\nPresentation comments\n2 pts\n\n\nDraft report + peer review\n10 pts\n\n\nWritten report\n40 pts\n\n\nProject highlights\n15 pts\n\n\nReproducibility + organization\n3 pts\n\n\nProject survey\n2 pts",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#late-work-policy",
    "href": "project.html#late-work-policy",
    "title": "Final project",
    "section": "Late work policy",
    "text": "Late work policy\nThere is no late work accepted on the draft report or presentation. Other components of the project may be accepted up to 48 hours late. A 10% late deduction will apply for each 24-hour period late.\nBe sure to turn in your work early to avoid any technological mishaps.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project-tips.html",
    "href": "project-tips.html",
    "title": "Final project tips + resources",
    "section": "",
    "text": "Data sources\n\nSome resources that may be helpful as you find data:\n\nFiveThirtyEight data\nTidyTuesday\nData Is Plural\nR Data Sources for Regression Analysis\n\n\n\nOther data repositories\n\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies\n\n\n\n\nTips\n\nAsk questions if any of the expectations are unclear.\nCode: In your write up your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your Qmd file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you’re welcome to show that portion.\n\nMerge conflicts will happen, issues will arise, and that’s fine! Commit and push often, and ask questions when stuck.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nAll team members are expected to contribute equally to the completion of this assignment and group assessments will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works.\n\n\n\nFormatting + communication tips\n\nSuppress Code, Warnings, & Messages\n\nInclude the following code in a code chunk at the top of your .qmd file to suppress all code, warnings, and other messages. Use the code chunk header {r set-up, include = FALSE} to suppress this set up code.\n\nknitr::opts_chunk$set(echo = FALSE,\n                      warning = FALSE, \n                      message = FALSE)\n\nAn alternative approach is to add the following code to the YAML:\n\nexecute:\n  echo: false\n  warning: false\n  message: false\n\n\n\n\nHeaders\n\nUse headers to clearly label each section. Make sure there is a space between the last # and the title, so the header renders correctly. For example, ###Section Title will not render as header, but ### Section Title will.\n\n\n\nReferences\n\nInclude all references in a section called “References” at the end of the report.\nThis course does not have specific requirements for formatting citations and references.\n\n\n\nAppendix\n\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called “Appendix”.\nThe items in the appendix should be properly labeled.\nThe appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix.\n\n\n\nResize figures\n\nResize plots and figures, so you have more space for the narrative.\n\nResize individual figures: Use the code chunk header {r plot1, fig.height = 3, fig.width = 5}, replacing plot1 with a meaningful label and the height and width with values appropriate for your write up.\nResize all figures: Include the fig_width and fig_height options in your YAML header as shown below:\n\n\n\n---\ntitle: \"Your title\"\nauthor: \"Your names\"\nformat:\n  pdf:\n    fig-width: 7\n    fig-height: 5\n---\nReplace the height and width values with values appropriate for your write up.\n\n\nArranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\n\nIf you’re using ggplot2 functions, the patchwork package makes it easy to arrange plots in a grid. See the documentation and examples here.\nIf you’re using base R function, i.e. when using the emplogit functions, put the code par(mfrow = c(rows,columns)) before the code to make the plots. For example, par(mfrow = c(2,3)) will arrange plots in a grid with 2 rows and 3 columns.\n\n\n\nPlot titles and axis labels\nBe sure all plot titles and axis labels are visible and easy to read.\n\nUse informative titles, not variable names, for titles and axis labels.\nUse coord_flip() to flip the x and y axes on the plot. This is useful if you a bar plot with an x-axis that is difficult to read due to overlapping text.\n\n❌ NO! The x-axis is hard to read because the names overlap.\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n✅ YES! Names are readable\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\nDo a little more to make the plot look professional!\n\nInformative title and axis labels\nFlipped coordinates to make names readable\nArranged bars based on count\nCapitalized manufacturer names\nOptional: Added color - Use a coordinated color scheme throughout paper / presentation\nOptional: Applied a theme - Use same theme throughout paper / presentation\n\n\nmpg |&gt;\n  count(manufacturer) |&gt;\n  mutate(manufacturer = str_to_title(manufacturer)) |&gt;\n  ggplot(aes(x = fct_reorder(manufacturer,n), y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  coord_flip() +\n  labs(x = \"Manufacturer\", \n       y = \"Count\", \n       title = \"The most common manufacturer is Dodge\") +\n  theme_bw() \n\n\n\n\n\n\n\n\n\n\nTables and model output\n\nUse the kable function from the knitr package to neatly output all tables and model output. This will also ensure all model coefficients are displayed.\n\nUse the digits argument to display only 3 or 4 significant digits.\nUse the caption argument to add captions to your table.\n\n\n\nmodel &lt;- lm(mpg ~ hp, data = mtcars)\ntidy(model) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n30.099\n1.634\n18.421\n0\n\n\nhp\n-0.068\n0.010\n-6.742\n0\n\n\n\n\n\n\n\nGuidelines for communicating results\n\nDon’t use variable names in your narrative! Use descriptive terms, so the reader understands your narrative without relying on the data dictionary.\n\n❌ There is a negative linear relationship between mpg and hp.\n✅ There is a negative linear relationship between a car’s fuel economy (in miles per gallon) and its horsepower.\n\nKnow your audience: Your report should be written for a general audience who has an understanding of statistics at the level of STA 210.\nAvoid subject matter jargon: Don’t assume the audience knows all of the specific terminology related to your subject area. If you must use jargon, include a brief definition the first time you introduce a term.\nTell the “so what”: Your report and presentation should be more than a list of interpretations and technical definitions. Focus on what the results mean, i.e. what you want the audience to know about your topic after reading your report or viewing your presentation.\n\n❌ For every one unit increase in horsepower, we expect the miles per gallon to decrease by 0.068 units, on average.\n✅ If the priority is to have good fuel economy, then one should choose a car with lower horsepower. Based on our model, the fuel economy is expected to decrease, on average, by 0.68 miles per gallon for every 10 additional horsepower.\n\nTell a story: All visualizations, tables, model output, and narrative should tell a cohesive story!\nUse one voice: Though multiple people are writing the report, it should read as if it’s from a single author. At least one team member should read through the report before submission to ensure it reads like a cohesive document.\n\n\n\n\nAdditional resources\n\nExploring RStudio’s Visual Markdown Editor\nR for Data Science\nQuarto documentation:\n\nQuarto PDF Basics\nPresentations in Quarto\n\nData visualization\n\nggplot2 Reference\nggplot2: Elegant Graphics for Data Analysis\nData Visualization: A Practice Introduction\nPatchwork R Package",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "math-rules.html",
    "href": "math-rules.html",
    "title": "Math rules",
    "section": "",
    "text": "This page contains mathematical rules we’ll use in this course that may be beyond what is covered in a linear algebra course.",
    "crumbs": [
      "Math rules"
    ]
  },
  {
    "objectID": "math-rules.html#matrix-calculus",
    "href": "math-rules.html#matrix-calculus",
    "title": "Math rules",
    "section": "Matrix calculus",
    "text": "Matrix calculus\n\nDefinition of gradient\nLet \\(\\mathbf{x} = \\begin{bmatrix}x_1 \\\\ x_2 \\\\ \\vdots \\\\x_k\\end{bmatrix}\\)be a \\(k \\times 1\\) vector and \\(f(\\mathbf{x})\\) be a function of \\(\\mathbf{x}\\).\nThen \\(\\nabla_\\mathbf{x}f\\), the gradient of \\(f\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x}f = \\begin{bmatrix}\\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial x_k}\\end{bmatrix}\n\\]\n\n\n\nGradient of \\(\\mathbf{x}^\\mathsf{T}\\mathbf{z}\\)\nLet \\(\\mathbf{x}\\) be a \\(k \\times 1\\) vector and \\(\\mathbf{z}\\) be a \\(k \\times 1\\) vector, such that \\(\\mathbf{z}\\) is not a function of \\(\\mathbf{x}\\) .\nThe gradient of \\(\\mathbf{x}^\\mathsf{T}\\mathbf{z}\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x} \\hspace{1mm} \\mathbf{x}^\\mathsf{T}\\mathbf{z} = \\mathbf{z}\n\\]\n\n\n\nGradient of \\(\\mathbf{x}^\\mathsf{T}\\mathbf{A}\\mathbf{x}\\)\nLet \\(\\mathbf{x}\\) be a \\(k \\times 1\\) vector and \\(\\mathbf{A}\\) be a \\(k \\times k\\) matrix, such that \\(\\mathbf{A}\\) is not a function of \\(\\mathbf{x}\\) .\nThen the gradient of \\(\\mathbf{x}^\\mathsf{T}\\mathbf{A}\\mathbf{x}\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x} \\hspace{1mm} \\mathbf{x}^\\mathsf{T}\\mathbf{A}\\mathbf{x} = (\\mathbf{A}\\mathbf{x} + \\mathbf{A}^\\mathsf{T} \\mathbf{x}) = (\\mathbf{A} + \\mathbf{A}^\\mathsf{T})\\mathbf{x}\n\\]\nIf \\(\\mathbf{A}\\) is symmetric, then\n\\[\n(\\mathbf{A} + \\mathbf{A}^\\mathsf{T})\\mathbf{x} = 2\\mathbf{A}\\mathbf{x}\n\\]\n\n\n\nHessian matrix\nThe Hessian matrix, \\(\\nabla_\\mathbf{x}^2f\\) is a \\(k \\times k\\) matrix of partial second derivatives\n\\[\n\\nabla_{\\mathbf{x}}^2f = \\begin{bmatrix} \\frac{\\partial^2f}{\\partial x_1^2} & \\frac{\\partial^2f}{\\partial x_1 \\partial x_2} & \\dots & \\frac{\\partial^2f}{\\partial x_1\\partial x_k} \\\\\n\\frac{\\partial^2f}{\\partial\\ x_2 \\partial x_1} & \\frac{\\partial^2f}{\\partial x_2^2} & \\dots & \\frac{\\partial^2f}{\\partial x_2 \\partial x_k} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial^2f}{\\partial x_k\\partial x_1} & \\frac{\\partial^2f}{\\partial x_k\\partial x_2} & \\dots & \\frac{\\partial^2f}{\\partial x_k^2} \\end{bmatrix}\n\\]",
    "crumbs": [
      "Math rules"
    ]
  },
  {
    "objectID": "math-rules.html#expected-value",
    "href": "math-rules.html#expected-value",
    "title": "Math rules",
    "section": "Expected value",
    "text": "Expected value\n\nExpected value of random variable \\(X\\)\nThe expected value of a random variable \\(\\mathbf{X}\\) is a weighted average, i.e., the mean value of the possible values a random variable can take weighted by the probability of the outcomes.\nLet \\(f_X(x)\\) be the probability distribution of \\(X\\). If \\(X\\) is continuous then\n\\[\nE(X) = \\int_{-\\infty}^{\\infty}xf_X(x)dx\n\\]\nIf \\(X\\) is discrete then\n\\[\nE(X) = \\sum_{x \\in X}xf_X(x) = \\sum_{x\\in X}xP(X = x)\n\\]\n\n\n\nExpected value of vector \\(\\mathbf{z}\\)\nLet \\(\\mathbf{z} = \\begin{bmatrix}z_1 \\\\ \\vdots \\\\z_p\\end{bmatrix}\\) be a \\(p \\times 1\\) vector of random variables.\n\nThen \\(E(\\mathbf{z}) = E\\begin{bmatrix}z_1 \\\\ \\vdots \\\\ z_p\\end{bmatrix} = \\begin{bmatrix}E(z_1) \\\\ \\vdots \\\\ E(z_p)\\end{bmatrix}\\)\n\n\n\nExpected value of vector \\(\\mathbf{Az}\\)\nLet \\(\\mathbf{A}\\) be an \\(n \\times p\\) matrix of constants and \\(\\mathbf{z}\\) a \\(p \\times 1\\) vector of random variables. Then\n\\[\nE(\\mathbf{Az}) = \\mathbf{A}E(\\mathbf{z})\n\\]\n\n\n\nExpected value of \\(\\mathbf{Az} + \\mathbf{C}\\)\nLet \\(\\mathbf{A}\\) be an \\(n \\times p\\) matrix of constants, \\(\\mathbf{C}\\) a \\(n \\times 1\\) vector of constants, and \\(\\mathbf{z}\\) a \\(p \\times 1\\) vector of random variables. Then\n\\[\nE(\\mathbf{Az} + \\mathbf{C}) = E(\\mathbf{Az}) + E(\\mathbf{C}) = \\mathbf{A}E(\\mathbf{z}) + \\mathbf{C}\n\\]\n\n\nExpected value of \\(\\mathbf{AXA}\\mathsf{^T}\\)\nLet \\(\\mathbf{A}\\) be an \\(n\\times p\\) matrix of constants and \\(\\mathbf{X}\\) a \\(p \\times p\\) matrix. Then\n\\[\nE(\\mathbf{AXA}^\\mathsf{T}) = \\mathbf{A}E(\\mathbf{X})\\mathbf{A}^\\mathsf{T}\n\\]",
    "crumbs": [
      "Math rules"
    ]
  },
  {
    "objectID": "math-rules.html#variance",
    "href": "math-rules.html#variance",
    "title": "Math rules",
    "section": "Variance",
    "text": "Variance\n\nVariance of random variable \\(X\\)\nThe variance of a random variable \\(X\\) is a measure of the spread of a distribution about its mean.\n\\[\nVar(X) = E[(X - E(X))^2] = E(X^2) - E(X)^2\n\\]\n\n\n\nVariance of vector \\(\\mathbf{z}\\)\nLet \\(\\mathbf{z} = \\begin{bmatrix}z_1 \\\\ \\vdots \\\\z_p\\end{bmatrix}\\) be a \\(p \\times 1\\) vector of random variables. Then\n\\[\nVar(\\mathbf{z}) = E[(\\mathbf{z} - E(\\mathbf{z}))(\\mathbf{z} - E(\\mathbf{z}))^\\mathsf{T}]\n\\]\n\nThis produced the variance-covariance matrix\n\\(Var(\\mathbf{z}) = \\begin{bmatrix}Var(z_1) & Cov(z_1, z_2) & \\dots & Cov(z_1, z_p)\\\\ Cov(z_2, z_1) & Var(z_2) & \\dots & Cov(z_2, z_p) \\\\ \\vdots & \\vdots & \\dots & \\cdot \\\\ Cov(z_p, z_1) & Cov(z_p, z_2) & \\dots & Var(z_p)\\end{bmatrix}\\)\n\n\n\nVariance of \\(\\mathbf{Az}\\)\nLet \\(\\mathbf{A}\\) be an \\(n \\times p\\) matrix of constants and \\(\\mathbf{z}\\) a \\(p \\times 1\\) vector of random variables. Then\n\\[\n\\begin{aligned}\nVar(\\mathbf{Az}) &= E[(\\mathbf{Az} - E(\\mathbf{Az}))(\\mathbf{Az} - E(\\mathbf{Az}))^\\mathsf{T}] \\\\\n& = \\mathbf{A}Var(\\mathbf{z})\\mathbf{A}^\\mathsf{T}\n\\end{aligned}\n\\]",
    "crumbs": [
      "Math rules"
    ]
  },
  {
    "objectID": "math-rules.html#probability-distributions",
    "href": "math-rules.html#probability-distributions",
    "title": "Math rules",
    "section": "Probability distributions",
    "text": "Probability distributions\n\nMultivariate normal distribution\nLet \\(\\mathbf{z}\\) be a \\(p \\times 1\\) vector of random variables, such that \\(\\mathbf{z}\\) follows a multivariate normal distribution with mean \\(\\boldsymbol{\\mu}\\) and variance \\(\\boldsymbol{\\Sigma}\\). Then the probability density function of \\(\\mathbf{z}\\) is\n\\[f(\\mathbf{z}) = \\frac{1}{(2\\pi)^{p/2}|\\boldsymbol{\\Sigma}|^{1/2}}\\exp\\Big\\{-\\frac{1}{2}(\\mathbf{z} - \\boldsymbol{\\mu})^\\mathsf{T}\\boldsymbol{\\Sigma}^{-1}(\\mathbf{z}- \\boldsymbol{\\mu})\\Big\\}\\]\n\n\n\n\n\n\nLinear transformation of normal random variable\nSuppose \\(\\mathbf{z}\\) is a multivariate normal random variable with mean \\(\\boldsymbol{\\mu}\\) and variance \\(\\boldsymbol{\\Sigma}\\). A linear transformation of \\(\\mathbf{z}\\) is also multivariate normal, such that\n\\[\n\\mathbf{A}\\mathbf{z} + \\mathbf{B} \\sim N(\\mathbf{A}\\boldsymbol{\\mu} + \\mathbf{B}, \\mathbf{A}\\boldsymbol{\\Sigma}\\mathbf{A}^\\mathsf{T})\n\\]",
    "crumbs": [
      "Math rules"
    ]
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#announcements",
    "href": "slides/17-prop-of-estimators.html#announcements",
    "title": "Properties of estimators",
    "section": "Announcements",
    "text": "Announcements\n\nHW 03 due TODAY at 11:59pm\nProject exploratory data analysis due TODAY at 11:59pm\n\nNext project milestone: Presentations in March 28 lab\n\nStatistics experience due April 22"
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#questions-from-this-weeks-content",
    "href": "slides/17-prop-of-estimators.html#questions-from-this-weeks-content",
    "title": "Properties of estimators",
    "section": "Questions from this week’s content?",
    "text": "Questions from this week’s content?"
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#topics",
    "href": "slides/17-prop-of-estimators.html#topics",
    "title": "Properties of estimators",
    "section": "Topics",
    "text": "Topics\n\nProperties of the least squares estimator\n\n\n\n\n\n\n\nNote\n\n\nThis is not a mathematical statistics class. There are semester-long courses that will go into these topics in much more detail; we will barely scratch the surface in this course.\nOur goals are to understand\n\nEstimators have properties\nA few properties of the least squares estimator and why they are useful"
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#motivation",
    "href": "slides/17-prop-of-estimators.html#motivation",
    "title": "Properties of estimators",
    "section": "Motivation",
    "text": "Motivation\n\n\nWe have discussed how to use least squares and maximum likelihood estimation to find estimators for \\(\\beta\\)\nHow do we know whether our least squares estimator (and MLE) is a “good” estimator?\nWhen we consider what makes an estimator “good”, we’ll look at three criteria:\n\nBias\nVariance\nMean squared error"
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#bias-and-variance",
    "href": "slides/17-prop-of-estimators.html#bias-and-variance",
    "title": "Properties of estimators",
    "section": "Bias and variance",
    "text": "Bias and variance\nSuppose you are throwing darts at a target\n\n\n\n\n\n\nImage source: Analytics Vidhya\n\n\n\n\nUnbiased: Darts distributed around the target\nBiased: Darts systematically away from the target\nVariance: Darts could be widely spread (high variance) or generally clustered together (low variance)"
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#bias-and-variance-1",
    "href": "slides/17-prop-of-estimators.html#bias-and-variance-1",
    "title": "Properties of estimators",
    "section": "Bias and variance",
    "text": "Bias and variance\n\nIdeal scenario: Darts are clustered around the target (unbiased and low variance)\nWorst case scenario: Darts are widely spread out and systematically far from the target (high bias and high variance)\nAcceptable scenario: There’s some trade-off between the bias and variance. For example, it may be acceptable for the darts to be clustered around a point that is close to the target (low bias and low variance)"
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#bias-and-variance-2",
    "href": "slides/17-prop-of-estimators.html#bias-and-variance-2",
    "title": "Properties of estimators",
    "section": "Bias and variance",
    "text": "Bias and variance\n\n\nEach time we take a sample of size \\(n\\), we can find the least squares estimator (throw dart at target)\nSuppose we take many independent samples of size \\(n\\) and find the least squares estimator for each sample (throw many darts at the target). Ideally,\n\nThe estimators are centered at the true parameter (unbiased)\nThe estimators are clustered around the true parameter (unbiased with low variance)"
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#properties-of-hatboldsymbolbeta-1",
    "href": "slides/17-prop-of-estimators.html#properties-of-hatboldsymbolbeta-1",
    "title": "Properties of estimators",
    "section": "Properties of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Properties of \\(\\hat{\\boldsymbol{\\beta}}\\)\nFinite sample ( \\(n\\) ) properties\n\nUnbiased estimator\nBest Linear Unbiased Estimator (BLUE)\n\n\nAsymptotic ( \\(n \\rightarrow \\infty\\) ) properties\n\nConsistent estimator\nEfficient estimator\nAsymptotic normality"
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#unbiased-estimator",
    "href": "slides/17-prop-of-estimators.html#unbiased-estimator",
    "title": "Properties of estimators",
    "section": "Unbiased estimator",
    "text": "Unbiased estimator\nThe bias of an estimator is the difference between the estimator’s expected value and the true value of the parameter\nLet \\(\\hat{\\theta}\\) be an estimator of the parameter \\(\\theta\\). Then\n\\[\nBias(\\hat{\\theta}) = E(\\hat{\\theta}) - \\theta\n\\]\nAn estimator is unbiased if the bias is 0 and thus \\(E(\\hat{\\theta}) = \\theta\\)"
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#expected-value-of-hatboldsymbolbeta",
    "href": "slides/17-prop-of-estimators.html#expected-value-of-hatboldsymbolbeta",
    "title": "Properties of estimators",
    "section": "Expected value of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Expected value of \\(\\hat{\\boldsymbol{\\beta}}\\)\nLet’s take a look at the expected value of least-squares estimator:\n\\[\n\\begin{aligned}\nE(\\hat{\\boldsymbol{\\beta}}) &= E[(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}\\mathbf{y}] \\\\[8pt]\n& = \\class{fragment}{(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}E[\\mathbf{y}]} \\\\[8pt]\n& = \\class{fragment}{(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}\\mathbf{X}\\boldsymbol{\\beta}}\\\\[8pt]\n& = \\class{fragment}{\\boldsymbol{\\beta}}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#expected-value-of-hatboldsymbolbeta-1",
    "href": "slides/17-prop-of-estimators.html#expected-value-of-hatboldsymbolbeta-1",
    "title": "Properties of estimators",
    "section": "Expected value of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Expected value of \\(\\hat{\\boldsymbol{\\beta}}\\)\nThe least squares estimator (and MLE) \\(\\hat{\\boldsymbol{\\beta}}\\) is an unbiased estimator of \\(\\boldsymbol{\\beta}\\)\n\\[\nE(\\hat{\\boldsymbol{\\beta}}) = \\boldsymbol{\\beta}\n\\]"
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#variance-of-hatboldsymbolbeta",
    "href": "slides/17-prop-of-estimators.html#variance-of-hatboldsymbolbeta",
    "title": "Properties of estimators",
    "section": "Variance of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Variance of \\(\\hat{\\boldsymbol{\\beta}}\\)\n\\[\n\\begin{aligned}\nVar(\\hat{\\boldsymbol{\\beta}}) &= Var((\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}\\mathbf{y}) \\\\[8pt]\n& = \\class{fragment}{[(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}]Var(\\mathbf{y})[(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}]^\\mathsf{T} }\\\\[8pt]\n& = \\class{fragment}{[(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}]\\sigma^2_{\\epsilon}\\mathbf{I}[\\mathbf{X}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}]} \\\\[8pt]\n& = \\class{fragment}{\\sigma^2_{\\epsilon}[(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}\\mathbf{X}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}]} \\\\[8pt]\n& = \\class{fragment}{\\sigma^2_{\\epsilon}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}}\n\\end{aligned}\n\\]\n\nWe will show that \\(\\hat{\\boldsymbol{\\beta}}\\) is the “best” estimator (has the lowest variance) among the class of linear unbiased estimators"
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#gauss-markov-theorem-proof",
    "href": "slides/17-prop-of-estimators.html#gauss-markov-theorem-proof",
    "title": "Properties of estimators",
    "section": "Gauss-Markov Theorem Proof",
    "text": "Gauss-Markov Theorem Proof\nSuppose \\(\\hat{\\boldsymbol{\\beta}}^\\prime\\) is another linear unbiased estimator of \\(\\boldsymbol{\\beta}\\) that can be expressed as \\(\\hat{\\boldsymbol{\\beta}}^\\prime = \\mathbf{Cy}\\) , such that \\(\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}^\\prime = \\mathbf{XCy}\\)\n\nLet \\(\\mathbf{C} = (\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T} + \\mathbf{B}\\) for a non-zero matrix \\(\\mathbf{B}\\).\n\n\nWhat is the dimension of \\(\\mathbf{B}\\)?"
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#gauss-markov-theorem-proof-1",
    "href": "slides/17-prop-of-estimators.html#gauss-markov-theorem-proof-1",
    "title": "Properties of estimators",
    "section": "Gauss-Markov Theorem Proof",
    "text": "Gauss-Markov Theorem Proof\n\\[\n\\hat{\\boldsymbol{\\beta}}^\\prime = \\mathbf{Cy} = ((\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T} + \\mathbf{B})\\mathbf{y}\n\\]\nWe need to show\n\n\\(\\hat{\\boldsymbol{\\beta}}^\\prime\\) is unbiased\n\\(Var(\\hat{\\boldsymbol{\\beta}}^\\prime) &gt; Var(\\hat{\\boldsymbol{\\beta}})\\)"
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#gauss-markov-theorem-proof-2",
    "href": "slides/17-prop-of-estimators.html#gauss-markov-theorem-proof-2",
    "title": "Properties of estimators",
    "section": "Gauss-Markov Theorem Proof",
    "text": "Gauss-Markov Theorem Proof\n\\[\n\\begin{aligned}\nE(\\hat{\\boldsymbol{\\beta}}^\\prime) & = E[((\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T} + \\mathbf{B})\\mathbf{y}] \\\\\n& = E[((\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T} + \\mathbf{B})(\\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon})] \\\\\n& = E[((\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T} + \\mathbf{B})(\\mathbf{X}\\boldsymbol{\\beta})] \\\\\n& = ((\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T} + \\mathbf{B})(\\mathbf{X}\\boldsymbol{\\beta}) \\\\\n& = (\\mathbf{I} + \\mathbf{BX})\\boldsymbol{\\beta}\n\\end{aligned}\n\\]\n\n\nWhat assumption(s) of the Gauss-Markov Theorem did we use?\nWhat must be true for \\(\\hat{\\boldsymbol{\\beta}}^\\prime\\) to be unbiased?"
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#gauss-markov-theorem-proof-3",
    "href": "slides/17-prop-of-estimators.html#gauss-markov-theorem-proof-3",
    "title": "Properties of estimators",
    "section": "Gauss-Markov Theorem Proof",
    "text": "Gauss-Markov Theorem Proof\n\n\\(\\mathbf{BX}\\) must be the \\(\\mathbf{0}\\) matrix (dimension = \\((p+1) \\times (p+1)\\)) in order for \\(\\hat{\\boldsymbol{\\beta}}^\\prime\\) to be unbiased\nNow we need to find \\(Var(\\hat{\\boldsymbol{\\beta}}^\\prime)\\) and see how it compares to \\(Var(\\hat{\\boldsymbol{\\beta}})\\)"
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#gauss-markov-theorem-proof-4",
    "href": "slides/17-prop-of-estimators.html#gauss-markov-theorem-proof-4",
    "title": "Properties of estimators",
    "section": "Gauss-Markov Theorem Proof",
    "text": "Gauss-Markov Theorem Proof\n\\[\n\\begin{aligned}\nVar(\\hat{\\boldsymbol{\\beta}}^\\prime) &= Var[((\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T} + \\mathbf{B})\\mathbf{y}] \\\\[8pt]\n& = ((\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T} + \\mathbf{B})Var(\\mathbf{y})((\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T} + \\mathbf{B})^\\mathsf{T} \\\\[8pt]\n& = \\small{\\sigma^2_{\\epsilon}[(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}\\mathbf{X}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1} + (\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T} \\mathbf{B}^\\mathsf{T} + \\mathbf{BX}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1} + \\mathbf{BB}^\\mathsf{T}]}\\\\[8pt]\n& = \\sigma^2_\\epsilon(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1} + \\sigma^2_{\\epsilon}\\mathbf{BB}^\\mathsf{T}\\end{aligned}\n\\]\n\nWhat assumption(s) of the Gauss-Markov Theorem did we use?"
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#gauss-markov-theorem-proof-5",
    "href": "slides/17-prop-of-estimators.html#gauss-markov-theorem-proof-5",
    "title": "Properties of estimators",
    "section": "Gauss-Markov Theorem Proof",
    "text": "Gauss-Markov Theorem Proof\nWe have\n\\[\nVar(\\hat{\\boldsymbol{\\beta}}^\\prime) = \\sigma^2_{\\epsilon}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1} + \\sigma^2_\\epsilon \\mathbf{BB}^\\mathsf{T}\n\\]\n\nWe know that \\(\\sigma^2_{\\epsilon}\\mathbf{BB}^\\mathsf{T} \\geq \\mathbf{0}\\).\n\n\n\n\nWhen is \\(\\sigma^2_{\\epsilon}\\mathbf{BB}^\\mathsf{T} = \\mathbf{0}\\)?\n\n\n\nTherefore, we have shown that \\(Var(\\hat{\\boldsymbol{\\beta}}^\\prime) &gt; Var(\\hat{\\boldsymbol{\\beta}})\\) and have completed the proof."
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#properties-of-hatboldsymbolbeta-2",
    "href": "slides/17-prop-of-estimators.html#properties-of-hatboldsymbolbeta-2",
    "title": "Properties of estimators",
    "section": "Properties of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Properties of \\(\\hat{\\boldsymbol{\\beta}}\\)\nFinite sample ( \\(n\\) ) properties\n\nUnbiased estimator ✅\nBest Linear Unbiased Estimator (BLUE) ✅\n\n\nAsymptotic ( \\(n \\rightarrow \\infty\\) ) properties\n\nConsistent estimator\nEfficient estimator\nAsymptotic normality"
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#properties-from-the-mle",
    "href": "slides/17-prop-of-estimators.html#properties-from-the-mle",
    "title": "Properties of estimators",
    "section": "Properties from the MLE",
    "text": "Properties from the MLE\n\nRecall that the least-squares estimator \\(\\hat{\\boldsymbol{\\beta}}\\) is equal to the Maximum Likelihood Estimator \\(\\tilde{\\boldsymbol{\\beta}}\\)\nMaximum likelihood estimators have nice statistical properties and the \\(\\hat{\\boldsymbol{\\beta}}\\) inherits all of these properties\n\nConsistency\nEfficiency\nAsymptotic normality\n\n\n\n\n\n\n\n\nNote\n\n\nWe will define the properties here, and you will explore them in much more depth in STA 332: Statistical Inference"
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#mean-squared-error",
    "href": "slides/17-prop-of-estimators.html#mean-squared-error",
    "title": "Properties of estimators",
    "section": "Mean squared error",
    "text": "Mean squared error\nThe mean squared error (MSE) is the squared difference between the estimator and parameter.\n\nLet \\(\\hat{\\theta}\\) be an estimator of the parameter \\(\\theta\\). Then\n\\[\n\\begin{aligned}\nMSE(\\hat{\\theta}) &= E[(\\hat{\\theta} - \\theta)^2] \\\\\n& = E(\\hat{\\theta}^2 - 2\\hat{\\theta}\\theta + \\theta^2) \\\\\n& = E(\\hat{\\theta}^2) - 2\\theta E(\\hat{\\theta}) + \\theta^2 \\\\\n& = \\underbrace{E(\\hat{\\theta}^2) -  E(\\hat{\\theta})^2}_{Var(\\hat{\\theta})} + \\underbrace{E(\\hat{\\theta})^2 - 2\\theta E(\\hat{\\theta}) + \\theta^2}_{Bias(\\theta)^2}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#mean-squared-error-1",
    "href": "slides/17-prop-of-estimators.html#mean-squared-error-1",
    "title": "Properties of estimators",
    "section": "Mean squared error",
    "text": "Mean squared error\n\\[\nMSE(\\hat{\\theta}) = Var(\\hat{\\theta}) + Bias(\\hat{\\theta})^2\n\\]\n\n\nThe least-squares estimator \\(\\hat{\\boldsymbol{\\beta}}\\) is unbiased, so \\[MSE(\\hat{\\boldsymbol{\\beta}}) = Var(\\hat{\\boldsymbol{\\beta}})\\]"
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#consistency",
    "href": "slides/17-prop-of-estimators.html#consistency",
    "title": "Properties of estimators",
    "section": "Consistency",
    "text": "Consistency\nAn estimator \\(\\hat{\\theta}\\) is a consistent estimator of a parameter \\(\\theta\\) if it converges in probability to \\(\\theta\\). Given a sequence of estimators \\(\\hat{\\theta}_1, \\hat{\\theta}_2, . . .\\), then for every \\(\\epsilon &gt; 0\\),\n\\[\n\\displaystyle \\lim_{n\\to\\infty} P(|\\hat{\\theta}_n - \\theta| \\geq \\epsilon) = 0\n\\]\n\nThis means that as the sample size goes to \\(\\infty\\) (and thus the sample information gets better and better), the estimator will be arbitrarily close to the parameter with high probability.\n\n\nWhy is this a useful property of an estimator?"
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#consistency-1",
    "href": "slides/17-prop-of-estimators.html#consistency-1",
    "title": "Properties of estimators",
    "section": "Consistency",
    "text": "Consistency\n\n\n\n\n\nImportant\n\n\nTheorem\nAn estimator \\(\\hat{\\theta}\\) is a consistent estimator of the parameter \\(\\theta\\) if the sequence of estimators \\(\\hat{\\theta}_1, \\hat{\\theta}_2, \\ldots\\) satisfies\n\n\\(\\lim_{n \\to \\infty} Var(\\hat{\\theta}) = 0\\)\n\\(\\lim_{n \\to \\infty} Bias(\\hat{\\theta}) = 0\\)"
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#consistency-of-hatboldsymbolbeta",
    "href": "slides/17-prop-of-estimators.html#consistency-of-hatboldsymbolbeta",
    "title": "Properties of estimators",
    "section": "Consistency of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Consistency of \\(\\hat{\\boldsymbol{\\beta}}\\)\n\\(Bias(\\hat{\\boldsymbol{\\beta}}) = \\mathbf{0}\\), so \\(\\lim_{n \\to \\infty} Bias(\\hat{\\boldsymbol{\\beta}}) = \\mathbf{0}\\)\n\n\nNow we need to show that \\(\\lim_{n \\to \\infty} Var(\\hat{\\boldsymbol{\\beta}}) = \\mathbf{0}\\)\n\n\nWhat is \\(Var(\\hat{\\boldsymbol{\\beta}})\\)?\nShow \\(Var(\\hat{\\boldsymbol{\\beta}}) \\to \\mathbf{0}\\) as \\(n \\to \\infty\\).\n\n\n\n\nTherefore \\(\\hat{\\boldsymbol{\\beta}}\\) is a consistent estimator."
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#efficiency",
    "href": "slides/17-prop-of-estimators.html#efficiency",
    "title": "Properties of estimators",
    "section": "Efficiency",
    "text": "Efficiency\n\n\nAn estimator if efficient if it has the smallest variance among a class of estimators as \\(n \\rightarrow \\infty\\)\nBy the Gauss-Markov Theorem, we have shown that the least-squares estimator \\(\\hat{\\boldsymbol{\\beta}}\\) is the most efficient among linear unbiased estimators.\nMaximum Likelihood Estimators are the most efficient among all unbiased estimators.\nTherefore, \\(\\hat{\\boldsymbol{\\beta}}\\) is the most efficient among all unbiased estimators of \\(\\boldsymbol{\\beta}\\)\n\n\n\n\n\n\n\n\nNote\n\n\nProof of this in a later statistics class."
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#asymptotic-normality",
    "href": "slides/17-prop-of-estimators.html#asymptotic-normality",
    "title": "Properties of estimators",
    "section": "Asymptotic normality",
    "text": "Asymptotic normality\n\nMaximum Likelihood Estimators are asymptotically normal, meaning the distribution of an MLE is normal as \\(n \\rightarrow \\infty\\)\nTherefore, we know the distribution of \\(\\hat{\\boldsymbol{\\beta}}\\) is normal when \\(n\\) is large, regardless of the underlying data\n\n\n\n\n\n\n\nNote\n\n\nProof of this in a later statistics class."
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#recap",
    "href": "slides/17-prop-of-estimators.html#recap",
    "title": "Properties of estimators",
    "section": "Recap",
    "text": "Recap\nFinite sample ( \\(n\\) ) properties\n\nUnbiased estimator ✅\nBest Linear Unbiased Estimator (BLUE) ✅\n\n\nAsymptotic ( \\(n \\rightarrow \\infty\\) ) properties\n\nConsistent estimator ✅\nEfficient estimator ✅\nAsymptotic normality ✅"
  },
  {
    "objectID": "slides/17-prop-of-estimators.html#questions-from-this-weeks-content-1",
    "href": "slides/17-prop-of-estimators.html#questions-from-this-weeks-content-1",
    "title": "Properties of estimators",
    "section": "Questions from this week’s content?",
    "text": "Questions from this week’s content?"
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html",
    "href": "slides/17-prop-of-estimators-notes.html",
    "title": "Properties of estimators",
    "section": "",
    "text": "HW 03 due TODAY at 11:59pm\nProject exploratory data analysis due TODAY at 11:59pm\n\nNext project milestone: Presentations in March 28 lab\n\nStatistics experience due April 22"
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#announcements",
    "href": "slides/17-prop-of-estimators-notes.html#announcements",
    "title": "Properties of estimators",
    "section": "",
    "text": "HW 03 due TODAY at 11:59pm\nProject exploratory data analysis due TODAY at 11:59pm\n\nNext project milestone: Presentations in March 28 lab\n\nStatistics experience due April 22"
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#questions-from-this-weeks-content",
    "href": "slides/17-prop-of-estimators-notes.html#questions-from-this-weeks-content",
    "title": "Properties of estimators",
    "section": "Questions from this week’s content?",
    "text": "Questions from this week’s content?"
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#topics",
    "href": "slides/17-prop-of-estimators-notes.html#topics",
    "title": "Properties of estimators",
    "section": "Topics",
    "text": "Topics\n\nProperties of the least squares estimator\n\n\n\n\n\n\n\nNote\n\n\n\nThis is not a mathematical statistics class. There are semester-long courses that will go into these topics in much more detail; we will barely scratch the surface in this course.\nOur goals are to understand\n\nEstimators have properties\nA few properties of the least squares estimator and why they are useful"
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#motivation",
    "href": "slides/17-prop-of-estimators-notes.html#motivation",
    "title": "Properties of estimators",
    "section": "Motivation",
    "text": "Motivation\n\n\nWe have discussed how to use least squares and maximum likelihood estimation to find estimators for \\(\\beta\\)\nHow do we know whether our least squares estimator (and MLE) is a “good” estimator?\nWhen we consider what makes an estimator “good”, we’ll look at three criteria:\n\nBias\nVariance\nMean squared error"
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#bias-and-variance",
    "href": "slides/17-prop-of-estimators-notes.html#bias-and-variance",
    "title": "Properties of estimators",
    "section": "Bias and variance",
    "text": "Bias and variance\nSuppose you are throwing darts at a target\n. . .\n\n\n\n\n\nImage source: Analytics Vidhya\n\n\n\n\nUnbiased: Darts distributed around the target\nBiased: Darts systematically away from the target\nVariance: Darts could be widely spread (high variance) or generally clustered together (low variance)"
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#bias-and-variance-1",
    "href": "slides/17-prop-of-estimators-notes.html#bias-and-variance-1",
    "title": "Properties of estimators",
    "section": "Bias and variance",
    "text": "Bias and variance\n\nIdeal scenario: Darts are clustered around the target (unbiased and low variance)\nWorst case scenario: Darts are widely spread out and systematically far from the target (high bias and high variance)\nAcceptable scenario: There’s some trade-off between the bias and variance. For example, it may be acceptable for the darts to be clustered around a point that is close to the target (low bias and low variance)"
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#bias-and-variance-2",
    "href": "slides/17-prop-of-estimators-notes.html#bias-and-variance-2",
    "title": "Properties of estimators",
    "section": "Bias and variance",
    "text": "Bias and variance\n\n\nEach time we take a sample of size \\(n\\), we can find the least squares estimator (throw dart at target)\nSuppose we take many independent samples of size \\(n\\) and find the least squares estimator for each sample (throw many darts at the target). Ideally,\n\nThe estimators are centered at the true parameter (unbiased)\nThe estimators are clustered around the true parameter (unbiased with low variance)"
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#properties-of-hatboldsymbolbeta-1",
    "href": "slides/17-prop-of-estimators-notes.html#properties-of-hatboldsymbolbeta-1",
    "title": "Properties of estimators",
    "section": "Properties of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Properties of \\(\\hat{\\boldsymbol{\\beta}}\\)\nFinite sample ( \\(n\\) ) properties\n\nUnbiased estimator\nBest Linear Unbiased Estimator (BLUE)\n\n\nAsymptotic ( \\(n \\rightarrow \\infty\\) ) properties\n\nConsistent estimator\nEfficient estimator\nAsymptotic normality"
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#unbiased-estimator",
    "href": "slides/17-prop-of-estimators-notes.html#unbiased-estimator",
    "title": "Properties of estimators",
    "section": "Unbiased estimator",
    "text": "Unbiased estimator\nThe bias of an estimator is the difference between the estimator’s expected value and the true value of the parameter\nLet \\(\\hat{\\theta}\\) be an estimator of the parameter \\(\\theta\\). Then\n\\[\nBias(\\hat{\\theta}) = E(\\hat{\\theta}) - \\theta\n\\]\nAn estimator is unbiased if the bias is 0 and thus \\(E(\\hat{\\theta}) = \\theta\\)"
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#expected-value-of-hatboldsymbolbeta",
    "href": "slides/17-prop-of-estimators-notes.html#expected-value-of-hatboldsymbolbeta",
    "title": "Properties of estimators",
    "section": "Expected value of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Expected value of \\(\\hat{\\boldsymbol{\\beta}}\\)\nLet’s take a look at the expected value of least-squares estimator:\n\\[\n\\begin{aligned}\nE(\\hat{\\boldsymbol{\\beta}}) &= E[(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}\\mathbf{y}] \\\\[8pt]\n& = \\class{fragment}{(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}E[\\mathbf{y}]} \\\\[8pt]\n& = \\class{fragment}{(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}\\mathbf{X}\\boldsymbol{\\beta}}\\\\[8pt]\n& = \\class{fragment}{\\boldsymbol{\\beta}}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#expected-value-of-hatboldsymbolbeta-1",
    "href": "slides/17-prop-of-estimators-notes.html#expected-value-of-hatboldsymbolbeta-1",
    "title": "Properties of estimators",
    "section": "Expected value of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Expected value of \\(\\hat{\\boldsymbol{\\beta}}\\)\nThe least squares estimator (and MLE) \\(\\hat{\\boldsymbol{\\beta}}\\) is an unbiased estimator of \\(\\boldsymbol{\\beta}\\)\n\\[\nE(\\hat{\\boldsymbol{\\beta}}) = \\boldsymbol{\\beta}\n\\]"
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#variance-of-hatboldsymbolbeta",
    "href": "slides/17-prop-of-estimators-notes.html#variance-of-hatboldsymbolbeta",
    "title": "Properties of estimators",
    "section": "Variance of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Variance of \\(\\hat{\\boldsymbol{\\beta}}\\)\n\\[\n\\begin{aligned}\nVar(\\hat{\\boldsymbol{\\beta}}) &= Var((\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}\\mathbf{y}) \\\\[8pt]\n& = \\class{fragment}{[(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}]Var(\\mathbf{y})[(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}]^\\mathsf{T} }\\\\[8pt]\n& = \\class{fragment}{[(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}]\\sigma^2_{\\epsilon}\\mathbf{I}[\\mathbf{X}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}]} \\\\[8pt]\n& = \\class{fragment}{\\sigma^2_{\\epsilon}[(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}\\mathbf{X}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}]} \\\\[8pt]\n& = \\class{fragment}{\\sigma^2_{\\epsilon}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}}\n\\end{aligned}\n\\]\n. . .\nWe will show that \\(\\hat{\\boldsymbol{\\beta}}\\) is the “best” estimator (has the lowest variance) among the class of linear unbiased estimators\n\n\n\n\n\n\n\n\n\n\nGauss-Markov Theorem\n\n\n\nThe least-squares estimator of \\(\\boldsymbol{\\beta}\\) in the model \\(\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\\) is given by \\(\\hat{\\boldsymbol{\\beta}}\\). Given the errors have mean \\(\\mathbf{0}\\) and variance \\(\\sigma^2_{\\epsilon}\\mathbf{I}\\) , then \\(\\hat{\\boldsymbol{\\beta}}\\) is BLUE (best linear unbiased estimator).\n“Best” means \\(\\hat{\\boldsymbol{\\beta}}\\) has the smallest variance among all linear unbiased estimators for \\(\\boldsymbol{\\beta}\\) ."
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#gauss-markov-theorem-proof",
    "href": "slides/17-prop-of-estimators-notes.html#gauss-markov-theorem-proof",
    "title": "Properties of estimators",
    "section": "Gauss-Markov Theorem Proof",
    "text": "Gauss-Markov Theorem Proof\nSuppose \\(\\hat{\\boldsymbol{\\beta}}^\\prime\\) is another linear unbiased estimator of \\(\\boldsymbol{\\beta}\\) that can be expressed as \\(\\hat{\\boldsymbol{\\beta}}^\\prime = \\mathbf{Cy}\\) , such that \\(\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}^\\prime = \\mathbf{XCy}\\)\n\nLet \\(\\mathbf{C} = (\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T} + \\mathbf{B}\\) for a non-zero matrix \\(\\mathbf{B}\\).\n\n\nWhat is the dimension of \\(\\mathbf{B}\\)?"
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#gauss-markov-theorem-proof-1",
    "href": "slides/17-prop-of-estimators-notes.html#gauss-markov-theorem-proof-1",
    "title": "Properties of estimators",
    "section": "Gauss-Markov Theorem Proof",
    "text": "Gauss-Markov Theorem Proof\n\\[\n\\hat{\\boldsymbol{\\beta}}^\\prime = \\mathbf{Cy} = ((\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T} + \\mathbf{B})\\mathbf{y}\n\\]\nWe need to show\n\n\\(\\hat{\\boldsymbol{\\beta}}^\\prime\\) is unbiased\n\\(Var(\\hat{\\boldsymbol{\\beta}}^\\prime) &gt; Var(\\hat{\\boldsymbol{\\beta}})\\)"
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#gauss-markov-theorem-proof-2",
    "href": "slides/17-prop-of-estimators-notes.html#gauss-markov-theorem-proof-2",
    "title": "Properties of estimators",
    "section": "Gauss-Markov Theorem Proof",
    "text": "Gauss-Markov Theorem Proof\n\\[\n\\begin{aligned}\nE(\\hat{\\boldsymbol{\\beta}}^\\prime) & = E[((\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T} + \\mathbf{B})\\mathbf{y}] \\\\\n& = E[((\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T} + \\mathbf{B})(\\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon})] \\\\\n& = E[((\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T} + \\mathbf{B})(\\mathbf{X}\\boldsymbol{\\beta})] \\\\\n& = ((\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T} + \\mathbf{B})(\\mathbf{X}\\boldsymbol{\\beta}) \\\\\n& = (\\mathbf{I} + \\mathbf{BX})\\boldsymbol{\\beta}\n\\end{aligned}\n\\]\n\n\nWhat assumption(s) of the Gauss-Markov Theorem did we use?\nWhat must be true for \\(\\hat{\\boldsymbol{\\beta}}^\\prime\\) to be unbiased?"
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#gauss-markov-theorem-proof-3",
    "href": "slides/17-prop-of-estimators-notes.html#gauss-markov-theorem-proof-3",
    "title": "Properties of estimators",
    "section": "Gauss-Markov Theorem Proof",
    "text": "Gauss-Markov Theorem Proof\n\n\\(\\mathbf{BX}\\) must be the \\(\\mathbf{0}\\) matrix (dimension = \\((p+1) \\times (p+1)\\)) in order for \\(\\hat{\\boldsymbol{\\beta}}^\\prime\\) to be unbiased\nNow we need to find \\(Var(\\hat{\\boldsymbol{\\beta}}^\\prime)\\) and see how it compares to \\(Var(\\hat{\\boldsymbol{\\beta}})\\)"
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#gauss-markov-theorem-proof-4",
    "href": "slides/17-prop-of-estimators-notes.html#gauss-markov-theorem-proof-4",
    "title": "Properties of estimators",
    "section": "Gauss-Markov Theorem Proof",
    "text": "Gauss-Markov Theorem Proof\n\\[\n\\begin{aligned}\nVar(\\hat{\\boldsymbol{\\beta}}^\\prime) &= Var[((\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T} + \\mathbf{B})\\mathbf{y}] \\\\[8pt]\n& = ((\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T} + \\mathbf{B})Var(\\mathbf{y})((\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T} + \\mathbf{B})^\\mathsf{T} \\\\[8pt]\n& = \\small{\\sigma^2_{\\epsilon}[(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}\\mathbf{X}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1} + (\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T} \\mathbf{B}^\\mathsf{T} + \\mathbf{BX}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1} + \\mathbf{BB}^\\mathsf{T}]}\\\\[8pt]\n& = \\sigma^2_\\epsilon(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1} + \\sigma^2_{\\epsilon}\\mathbf{BB}^\\mathsf{T}\\end{aligned}\n\\]\n\nWhat assumption(s) of the Gauss-Markov Theorem did we use?"
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#gauss-markov-theorem-proof-5",
    "href": "slides/17-prop-of-estimators-notes.html#gauss-markov-theorem-proof-5",
    "title": "Properties of estimators",
    "section": "Gauss-Markov Theorem Proof",
    "text": "Gauss-Markov Theorem Proof\nWe have\n\\[\nVar(\\hat{\\boldsymbol{\\beta}}^\\prime) = \\sigma^2_{\\epsilon}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1} + \\sigma^2_\\epsilon \\mathbf{BB}^\\mathsf{T}\n\\]\n. . .\nWe know that \\(\\sigma^2_{\\epsilon}\\mathbf{BB}^\\mathsf{T} \\geq \\mathbf{0}\\).\n\n. . .\n\nWhen is \\(\\sigma^2_{\\epsilon}\\mathbf{BB}^\\mathsf{T} = \\mathbf{0}\\)?\n\n. . .\nTherefore, we have shown that \\(Var(\\hat{\\boldsymbol{\\beta}}^\\prime) &gt; Var(\\hat{\\boldsymbol{\\beta}})\\) and have completed the proof.\n\n\n\n\n\n\n\n\n\n\nGauss-Markov Theorem\n\n\n\nThe least-squares estimator of \\(\\boldsymbol{\\beta}\\) in the model \\(\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\\) is given by \\(\\hat{\\boldsymbol{\\beta}}\\). Given the errors have mean \\(\\mathbf{0}\\) and variance \\(\\sigma^2_{\\epsilon}\\mathbf{I}\\) , then \\(\\hat{\\boldsymbol{\\beta}}\\) is BLUE (best linear unbiased estimator).\n“Best” means \\(\\hat{\\boldsymbol{\\beta}}\\) has the smallest variance among all linear unbiased estimators for \\(\\boldsymbol{\\beta}\\) ."
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#properties-of-hatboldsymbolbeta-2",
    "href": "slides/17-prop-of-estimators-notes.html#properties-of-hatboldsymbolbeta-2",
    "title": "Properties of estimators",
    "section": "Properties of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Properties of \\(\\hat{\\boldsymbol{\\beta}}\\)\nFinite sample ( \\(n\\) ) properties\n\nUnbiased estimator ✅\nBest Linear Unbiased Estimator (BLUE) ✅\n\n\nAsymptotic ( \\(n \\rightarrow \\infty\\) ) properties\n\nConsistent estimator\nEfficient estimator\nAsymptotic normality"
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#properties-from-the-mle",
    "href": "slides/17-prop-of-estimators-notes.html#properties-from-the-mle",
    "title": "Properties of estimators",
    "section": "Properties from the MLE",
    "text": "Properties from the MLE\n\nRecall that the least-squares estimator \\(\\hat{\\boldsymbol{\\beta}}\\) is equal to the Maximum Likelihood Estimator \\(\\tilde{\\boldsymbol{\\beta}}\\)\nMaximum likelihood estimators have nice statistical properties and the \\(\\hat{\\boldsymbol{\\beta}}\\) inherits all of these properties\n\nConsistency\nEfficiency\nAsymptotic normality\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe will define the properties here, and you will explore them in much more depth in STA 332: Statistical Inference"
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#mean-squared-error",
    "href": "slides/17-prop-of-estimators-notes.html#mean-squared-error",
    "title": "Properties of estimators",
    "section": "Mean squared error",
    "text": "Mean squared error\nThe mean squared error (MSE) is the squared difference between the estimator and parameter.\n. . .\nLet \\(\\hat{\\theta}\\) be an estimator of the parameter \\(\\theta\\). Then\n\\[\n\\begin{aligned}\nMSE(\\hat{\\theta}) &= E[(\\hat{\\theta} - \\theta)^2] \\\\\n& = E(\\hat{\\theta}^2 - 2\\hat{\\theta}\\theta + \\theta^2) \\\\\n& = E(\\hat{\\theta}^2) - 2\\theta E(\\hat{\\theta}) + \\theta^2 \\\\\n& = \\underbrace{E(\\hat{\\theta}^2) -  E(\\hat{\\theta})^2}_{Var(\\hat{\\theta})} + \\underbrace{E(\\hat{\\theta})^2 - 2\\theta E(\\hat{\\theta}) + \\theta^2}_{Bias(\\theta)^2}\n\\end{aligned}\n\\]\n. . ."
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#mean-squared-error-1",
    "href": "slides/17-prop-of-estimators-notes.html#mean-squared-error-1",
    "title": "Properties of estimators",
    "section": "Mean squared error",
    "text": "Mean squared error\n\\[\nMSE(\\hat{\\theta}) = Var(\\hat{\\theta}) + Bias(\\hat{\\theta})^2\n\\]\n\n. . .\nThe least-squares estimator \\(\\hat{\\boldsymbol{\\beta}}\\) is unbiased, so \\[MSE(\\hat{\\boldsymbol{\\beta}}) = Var(\\hat{\\boldsymbol{\\beta}})\\]"
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#consistency",
    "href": "slides/17-prop-of-estimators-notes.html#consistency",
    "title": "Properties of estimators",
    "section": "Consistency",
    "text": "Consistency\nAn estimator \\(\\hat{\\theta}\\) is a consistent estimator of a parameter \\(\\theta\\) if it converges in probability to \\(\\theta\\). Given a sequence of estimators \\(\\hat{\\theta}_1, \\hat{\\theta}_2, . . .\\), then for every \\(\\epsilon &gt; 0\\),\n\\[\n\\displaystyle \\lim_{n\\to\\infty} P(|\\hat{\\theta}_n - \\theta| \\geq \\epsilon) = 0\n\\]\n. . .\nThis means that as the sample size goes to \\(\\infty\\) (and thus the sample information gets better and better), the estimator will be arbitrarily close to the parameter with high probability.\n\n\nWhy is this a useful property of an estimator?"
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#consistency-1",
    "href": "slides/17-prop-of-estimators-notes.html#consistency-1",
    "title": "Properties of estimators",
    "section": "Consistency",
    "text": "Consistency\n\n\n\n\n\n\n\n\nImportant\n\n\n\nTheorem\nAn estimator \\(\\hat{\\theta}\\) is a consistent estimator of the parameter \\(\\theta\\) if the sequence of estimators \\(\\hat{\\theta}_1, \\hat{\\theta}_2, \\ldots\\) satisfies\n\n\\(\\lim_{n \\to \\infty} Var(\\hat{\\theta}) = 0\\)\n\\(\\lim_{n \\to \\infty} Bias(\\hat{\\theta}) = 0\\)"
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#consistency-of-hatboldsymbolbeta",
    "href": "slides/17-prop-of-estimators-notes.html#consistency-of-hatboldsymbolbeta",
    "title": "Properties of estimators",
    "section": "Consistency of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Consistency of \\(\\hat{\\boldsymbol{\\beta}}\\)\n\\(Bias(\\hat{\\boldsymbol{\\beta}}) = \\mathbf{0}\\), so \\(\\lim_{n \\to \\infty} Bias(\\hat{\\boldsymbol{\\beta}}) = \\mathbf{0}\\)\n\n. . .\nNow we need to show that \\(\\lim_{n \\to \\infty} Var(\\hat{\\boldsymbol{\\beta}}) = \\mathbf{0}\\)\n\n\nWhat is \\(Var(\\hat{\\boldsymbol{\\beta}})\\)?\nShow \\(Var(\\hat{\\boldsymbol{\\beta}}) \\to \\mathbf{0}\\) as \\(n \\to \\infty\\).\n\n\n. . .\nTherefore \\(\\hat{\\boldsymbol{\\beta}}\\) is a consistent estimator."
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#efficiency",
    "href": "slides/17-prop-of-estimators-notes.html#efficiency",
    "title": "Properties of estimators",
    "section": "Efficiency",
    "text": "Efficiency\n\n\nAn estimator if efficient if it has the smallest variance among a class of estimators as \\(n \\rightarrow \\infty\\)\nBy the Gauss-Markov Theorem, we have shown that the least-squares estimator \\(\\hat{\\boldsymbol{\\beta}}\\) is the most efficient among linear unbiased estimators.\nMaximum Likelihood Estimators are the most efficient among all unbiased estimators.\nTherefore, \\(\\hat{\\boldsymbol{\\beta}}\\) is the most efficient among all unbiased estimators of \\(\\boldsymbol{\\beta}\\)\n\n\n\n\n\n\n\n\nNote\n\n\n\nProof of this in a later statistics class."
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#asymptotic-normality",
    "href": "slides/17-prop-of-estimators-notes.html#asymptotic-normality",
    "title": "Properties of estimators",
    "section": "Asymptotic normality",
    "text": "Asymptotic normality\n\nMaximum Likelihood Estimators are asymptotically normal, meaning the distribution of an MLE is normal as \\(n \\rightarrow \\infty\\)\nTherefore, we know the distribution of \\(\\hat{\\boldsymbol{\\beta}}\\) is normal when \\(n\\) is large, regardless of the underlying data\n\n\n\n\n\n\n\nNote\n\n\n\nProof of this in a later statistics class."
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#recap",
    "href": "slides/17-prop-of-estimators-notes.html#recap",
    "title": "Properties of estimators",
    "section": "Recap",
    "text": "Recap\nFinite sample ( \\(n\\) ) properties\n\nUnbiased estimator ✅\nBest Linear Unbiased Estimator (BLUE) ✅\n\n\nAsymptotic ( \\(n \\rightarrow \\infty\\) ) properties\n\nConsistent estimator ✅\nEfficient estimator ✅\nAsymptotic normality ✅"
  },
  {
    "objectID": "slides/17-prop-of-estimators-notes.html#questions-from-this-weeks-content-1",
    "href": "slides/17-prop-of-estimators-notes.html#questions-from-this-weeks-content-1",
    "title": "Properties of estimators",
    "section": "Questions from this week’s content?",
    "text": "Questions from this week’s content?"
  },
  {
    "objectID": "slides/05-mlr.html#topics",
    "href": "slides/05-mlr.html#topics",
    "title": "Multiple linear regression (MLR)",
    "section": "Topics",
    "text": "Topics\n\nIntroducing multiple linear regression\n\nExploratory data analysis for multiple linear regression\nFitting the least squares line\nInterpreting coefficients for quantitative predictors\nPrediction"
  },
  {
    "objectID": "slides/05-mlr.html#computing-setup",
    "href": "slides/05-mlr.html#computing-setup",
    "title": "Multiple linear regression (MLR)",
    "section": "Computing setup",
    "text": "Computing setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))"
  },
  {
    "objectID": "slides/05-mlr.html#data-peer-to-peer-lender",
    "href": "slides/05-mlr.html#data-peer-to-peer-lender",
    "title": "Multiple linear regression (MLR)",
    "section": "Data: Peer-to-peer lender",
    "text": "Data: Peer-to-peer lender\nToday’s data is a sample of 50 loans made through a peer-to-peer lending club. The data is in the loan50 data frame in the openintro R package.\n\n\n# A tibble: 50 × 4\n   annual_income debt_to_income verified_income interest_rate\n           &lt;dbl&gt;          &lt;dbl&gt; &lt;fct&gt;                   &lt;dbl&gt;\n 1         59000         0.558  Not Verified            10.9 \n 2         60000         1.31   Not Verified             9.92\n 3         75000         1.06   Verified                26.3 \n 4         75000         0.574  Not Verified             9.92\n 5        254000         0.238  Not Verified             9.43\n 6         67000         1.08   Source Verified          9.92\n 7         28800         0.0997 Source Verified         17.1 \n 8         80000         0.351  Not Verified             6.08\n 9         34000         0.698  Not Verified             7.97\n10         80000         0.167  Source Verified         12.6 \n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/05-mlr.html#variables",
    "href": "slides/05-mlr.html#variables",
    "title": "Multiple linear regression (MLR)",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\n\nannual_income: Annual income\ndebt_to_income: Debt-to-income ratio, i.e. the percentage of a borrower’s total debt divided by their total income\nverified_income: Whether borrower’s income source and amount have been verified (Not Verified, Source Verified, Verified)\n\n\nOutcome: interest_rate: Interest rate for the loan"
  },
  {
    "objectID": "slides/05-mlr.html#outcome-interest_rate",
    "href": "slides/05-mlr.html#outcome-interest_rate",
    "title": "Multiple linear regression (MLR)",
    "section": "Outcome: interest_rate",
    "text": "Outcome: interest_rate\n\n\n\n\n\n\nMin\nMedian\nMax\nIQR\n\n\n\n\n5.31\n9.93\n26.3\n5.755"
  },
  {
    "objectID": "slides/05-mlr.html#predictors",
    "href": "slides/05-mlr.html#predictors",
    "title": "Multiple linear regression (MLR)",
    "section": "Predictors",
    "text": "Predictors"
  },
  {
    "objectID": "slides/05-mlr.html#data-manipulation-1-rescale-income",
    "href": "slides/05-mlr.html#data-manipulation-1-rescale-income",
    "title": "Multiple linear regression (MLR)",
    "section": "Data manipulation 1: Rescale income",
    "text": "Data manipulation 1: Rescale income\n\nloan50 &lt;- loan50 |&gt;\n  mutate(annual_income_th = annual_income / 1000)\n\n\n\n\nWhy did we rescale income?"
  },
  {
    "objectID": "slides/05-mlr.html#outcome-vs.-predictors",
    "href": "slides/05-mlr.html#outcome-vs.-predictors",
    "title": "Multiple linear regression (MLR)",
    "section": "Outcome vs. predictors",
    "text": "Outcome vs. predictors\n\n\nGoal: Use these predictors in a single model to understand variability in interest rate.\n\n\n\nWhy do we want to use a single model versus 3 separate simple linear regression models?"
  },
  {
    "objectID": "slides/05-mlr.html#multiple-linear-regression-mlr-1",
    "href": "slides/05-mlr.html#multiple-linear-regression-mlr-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Multiple linear regression (MLR)",
    "text": "Multiple linear regression (MLR)\nBased on the analysis goals, we will use a multiple linear regression model of the following form\n\\[\n\\begin{aligned}\\text{interest_rate} ~ =\n\\beta_0 & + \\beta_1 ~ \\text{debt_to_income} \\\\ & + \\beta_2 ~ \\text{verified_income} \\\\ &+ \\beta_3~ \\text{annual_income_th} \\\\\n& +\\epsilon, \\quad \\epsilon \\sim N(0, \\sigma^2_{\\epsilon})\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/05-mlr.html#multiple-linear-regression",
    "href": "slides/05-mlr.html#multiple-linear-regression",
    "title": "Multiple linear regression (MLR)",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\nRecall: The simple linear regression model\n\\[\nY = \\beta_0 + \\beta_1~ X + \\epsilon\n\\]\n\nThe form of the multiple linear regression model is\n\\[\nY = \\beta_0 + \\beta_1X_1 +  \\dots + \\beta_pX_p + \\epsilon\n\\]\n\n\n\nTherefore,\n\\[\nE(Y|X_1, \\ldots, X_p) = \\beta_0 + \\beta_1X_1 +  \\dots + \\beta_pX_p\n\\]"
  },
  {
    "objectID": "slides/05-mlr.html#fitting-the-least-squares-line",
    "href": "slides/05-mlr.html#fitting-the-least-squares-line",
    "title": "Multiple linear regression (MLR)",
    "section": "Fitting the least squares line",
    "text": "Fitting the least squares line\nSimilar to simple linear regression, we want to find estimates for \\(\\beta_0, \\beta_1, \\ldots, \\beta_p\\) that minimize\n\\[\n\\sum_{i=1}^{n}\\epsilon_i^2 = \\sum_{i=1}^n[y_i - \\hat{y}_i]^2 = \\sum_{i=1}^n[y_i - (\\beta_0 + \\beta_1x_{i1} + \\dots + \\beta_px_{ip})]^2\n\\]\n\n\nThe calculations can be very tedious, especially if \\(p\\) is large"
  },
  {
    "objectID": "slides/05-mlr.html#matrix-form-of-multiple-linear-regression",
    "href": "slides/05-mlr.html#matrix-form-of-multiple-linear-regression",
    "title": "Multiple linear regression (MLR)",
    "section": "Matrix form of multiple linear regression",
    "text": "Matrix form of multiple linear regression\nSuppose we have \\(n\\) observations, a quantitative response variable, and \\(p\\) &gt; 1 predictors \\[\n\\underbrace{\n\\begin{bmatrix}\ny_1 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix} }_\n{\\mathbf{y}} \\hspace{3mm}\n=\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n1 &x_{11} & \\dots & x_{1p}\\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\n1 &  x_{n1} & \\dots &x_{np}\n\\end{bmatrix}\n}_{\\mathbf{X}}\n\\hspace{2mm}\n\\underbrace{\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\vdots \\\\\n\\beta_p\n\\end{bmatrix}\n}_{\\boldsymbol{\\beta}}\n\\hspace{3mm}\n+\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n\\epsilon_1 \\\\\n\\vdots\\\\\n\\epsilon_n\n\\end{bmatrix}\n}_\\boldsymbol{\\epsilon}\n\\]\n\nWhat are the dimensions of \\(\\mathbf{y}\\), \\(\\mathbf{X}\\), \\(\\boldsymbol{\\beta}\\), \\(\\boldsymbol{\\epsilon}\\)?"
  },
  {
    "objectID": "slides/05-mlr.html#matrix-form-of-multiple-linear-regression-1",
    "href": "slides/05-mlr.html#matrix-form-of-multiple-linear-regression-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Matrix form of multiple linear regression",
    "text": "Matrix form of multiple linear regression\nAs with simple linear regression, we have\n\\[\n\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n\\]\n\nGeneralizing the derivations from SLR to \\(p &gt; 2\\), we have\n\\[\n\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^\n\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}\\mathbf{y}\n\\]\nas before."
  },
  {
    "objectID": "slides/05-mlr.html#model-fit-in-r",
    "href": "slides/05-mlr.html#model-fit-in-r",
    "title": "Multiple linear regression (MLR)",
    "section": "Model fit in R",
    "text": "Model fit in R\n\nint_fit &lt;- lm(interest_rate ~ debt_to_income + verified_income  + annual_income_th,\n              data = loan50)\n\ntidy(int_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n10.726\n1.507\n7.116\n0.000\n\n\ndebt_to_income\n0.671\n0.676\n0.993\n0.326\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n\n\nannual_income_th\n-0.021\n0.011\n-1.804\n0.078"
  },
  {
    "objectID": "slides/05-mlr.html#model-equation",
    "href": "slides/05-mlr.html#model-equation",
    "title": "Multiple linear regression (MLR)",
    "section": "Model equation",
    "text": "Model equation\n\\[\n\\begin{align}\\hat{\\text{interest_rate}} =  10.726 &+0.671 \\times \\text{debt_to_income}\\\\\n&+ 2.211 \\times \\text{source_verified}\\\\  \n&+ 6.880 \\times \\text{verified}\\\\\n& -0.021 \\times \\text{annual_income_th}\n\\end{align}\n\\]\n\n\n\n\n\n\nNote\n\n\nWe will talk about why there are only two terms in the model for verified_income soon!"
  },
  {
    "objectID": "slides/05-mlr.html#interpreting-hatbeta_j",
    "href": "slides/05-mlr.html#interpreting-hatbeta_j",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting \\(\\hat{\\beta}_j\\)",
    "text": "Interpreting \\(\\hat{\\beta}_j\\)\n\nThe estimated coefficient \\(\\hat{\\beta}_j\\) is the expected change in the mean of \\(Y\\) when \\(X_j\\) increases by one unit, holding the values of all other predictor variables constant.\n\n\n\nExample: The estimated coefficient for debt_to_income is 0.671. This means for each point in an borrower’s debt to income ratio, the interest rate on the loan is expected to be greater by 0.671%, on average, holding annual income and income verification constant."
  },
  {
    "objectID": "slides/05-mlr.html#interpreting-hatbeta_j-1",
    "href": "slides/05-mlr.html#interpreting-hatbeta_j-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting \\(\\hat{\\beta}_j\\)",
    "text": "Interpreting \\(\\hat{\\beta}_j\\)\n\nThe estimated coefficient for annual_income_th is -0.021. Interpret this coefficient in the context of the data.\n\n\n\n\nWhy do we need to include a statement about holding all other predictors constant?"
  },
  {
    "objectID": "slides/05-mlr.html#interpreting-hatbeta_0",
    "href": "slides/05-mlr.html#interpreting-hatbeta_0",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting \\(\\hat{\\beta}_0\\)",
    "text": "Interpreting \\(\\hat{\\beta}_0\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n10.726\n1.507\n7.116\n0.000\n7.690\n13.762\n\n\ndebt_to_income\n0.671\n0.676\n0.993\n0.326\n-0.690\n2.033\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n-0.606\n5.028\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n3.253\n10.508\n\n\nannual_income_th\n-0.021\n0.011\n-1.804\n0.078\n-0.043\n0.002\n\n\n\n\n\n\n\n\nDescribe the subset of borrowers who are expected to get an interest rate of 10.726% based on our model. Is this interpretation meaningful? Why or why not?"
  },
  {
    "objectID": "slides/05-mlr.html#prediction",
    "href": "slides/05-mlr.html#prediction",
    "title": "Multiple linear regression (MLR)",
    "section": "Prediction",
    "text": "Prediction\n\nWhat is the predicted interest rate for an borrower with an debt-to-income ratio of 0.558, whose income is not verified, and who has an annual income of $59,000?\n\n\n\n10.726 + 0.671 * 0.558 + 2.211 * 0 + 6.880 * 0 - 0.021 * 59\n\n[1] 9.861418\n\n\n\nThe predicted interest rate for an borrower with with an debt-to-income ratio of 0.558, whose income is not verified, and who has an annual income of $59,000 is 9.86%."
  },
  {
    "objectID": "slides/05-mlr.html#prediction-in-r",
    "href": "slides/05-mlr.html#prediction-in-r",
    "title": "Multiple linear regression (MLR)",
    "section": "Prediction in R",
    "text": "Prediction in R\nJust like with simple linear regression, we can use the predict() function in R to calculate the appropriate intervals for our predicted values:\n\nnew_borrower &lt;- tibble(\n  debt_to_income  = 0.558, \n  verified_income = \"Not Verified\", \n  annual_income_th = 59\n)\n\npredict(int_fit, new_borrower)\n\n       1 \n9.890888 \n\n\n\n\n\n\n\n\nNote\n\n\nDifference in predicted value due to rounding the coefficients on the previous slide."
  },
  {
    "objectID": "slides/05-mlr.html#cautions",
    "href": "slides/05-mlr.html#cautions",
    "title": "Multiple linear regression (MLR)",
    "section": "Cautions",
    "text": "Cautions\n\nDo not extrapolate! Because there are multiple predictor variables, there is the potential to extrapolate in many directions\nThe multiple regression model only shows association, not causality\n\nTo show causality, you must have a carefully designed experiment or carefully account for confounding variables in an observational study"
  },
  {
    "objectID": "slides/05-mlr.html#recap",
    "href": "slides/05-mlr.html#recap",
    "title": "Multiple linear regression (MLR)",
    "section": "Recap",
    "text": "Recap\n\nShowed exploratory data analysis for multiple linear regression\nUsed least squares to fit the regression line\nInterpreted the coefficients for quantitative predictors\nPredicted the response for new observations"
  },
  {
    "objectID": "slides/05-mlr-notes.html",
    "href": "slides/05-mlr-notes.html",
    "title": "Multiple linear regression (MLR)",
    "section": "",
    "text": "Introducing multiple linear regression\n\nExploratory data analysis for multiple linear regression\nFitting the least squares line\nInterpreting coefficients for quantitative predictors\nPrediction"
  },
  {
    "objectID": "slides/05-mlr-notes.html#topics",
    "href": "slides/05-mlr-notes.html#topics",
    "title": "Multiple linear regression (MLR)",
    "section": "",
    "text": "Introducing multiple linear regression\n\nExploratory data analysis for multiple linear regression\nFitting the least squares line\nInterpreting coefficients for quantitative predictors\nPrediction"
  },
  {
    "objectID": "slides/05-mlr-notes.html#computing-setup",
    "href": "slides/05-mlr-notes.html#computing-setup",
    "title": "Multiple linear regression (MLR)",
    "section": "Computing setup",
    "text": "Computing setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))"
  },
  {
    "objectID": "slides/05-mlr-notes.html#data-peer-to-peer-lender",
    "href": "slides/05-mlr-notes.html#data-peer-to-peer-lender",
    "title": "Multiple linear regression (MLR)",
    "section": "Data: Peer-to-peer lender",
    "text": "Data: Peer-to-peer lender\nToday’s data is a sample of 50 loans made through a peer-to-peer lending club. The data is in the loan50 data frame in the openintro R package.\n\n\n# A tibble: 50 × 4\n   annual_income debt_to_income verified_income interest_rate\n           &lt;dbl&gt;          &lt;dbl&gt; &lt;fct&gt;                   &lt;dbl&gt;\n 1         59000         0.558  Not Verified            10.9 \n 2         60000         1.31   Not Verified             9.92\n 3         75000         1.06   Verified                26.3 \n 4         75000         0.574  Not Verified             9.92\n 5        254000         0.238  Not Verified             9.43\n 6         67000         1.08   Source Verified          9.92\n 7         28800         0.0997 Source Verified         17.1 \n 8         80000         0.351  Not Verified             6.08\n 9         34000         0.698  Not Verified             7.97\n10         80000         0.167  Source Verified         12.6 \n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/05-mlr-notes.html#variables",
    "href": "slides/05-mlr-notes.html#variables",
    "title": "Multiple linear regression (MLR)",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\n\nannual_income: Annual income\ndebt_to_income: Debt-to-income ratio, i.e. the percentage of a borrower’s total debt divided by their total income\nverified_income: Whether borrower’s income source and amount have been verified (Not Verified, Source Verified, Verified)\n\n\nOutcome: interest_rate: Interest rate for the loan"
  },
  {
    "objectID": "slides/05-mlr-notes.html#outcome-interest_rate",
    "href": "slides/05-mlr-notes.html#outcome-interest_rate",
    "title": "Multiple linear regression (MLR)",
    "section": "Outcome: interest_rate",
    "text": "Outcome: interest_rate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMin\nMedian\nMax\nIQR\n\n\n\n\n5.31\n9.93\n26.3\n5.755"
  },
  {
    "objectID": "slides/05-mlr-notes.html#predictors",
    "href": "slides/05-mlr-notes.html#predictors",
    "title": "Multiple linear regression (MLR)",
    "section": "Predictors",
    "text": "Predictors"
  },
  {
    "objectID": "slides/05-mlr-notes.html#data-manipulation-1-rescale-income",
    "href": "slides/05-mlr-notes.html#data-manipulation-1-rescale-income",
    "title": "Multiple linear regression (MLR)",
    "section": "Data manipulation 1: Rescale income",
    "text": "Data manipulation 1: Rescale income\n\nloan50 &lt;- loan50 |&gt;\n  mutate(annual_income_th = annual_income / 1000)\n\n\n\n\n\n\n\n\n\n\n. . .\n\nWhy did we rescale income?"
  },
  {
    "objectID": "slides/05-mlr-notes.html#outcome-vs.-predictors",
    "href": "slides/05-mlr-notes.html#outcome-vs.-predictors",
    "title": "Multiple linear regression (MLR)",
    "section": "Outcome vs. predictors",
    "text": "Outcome vs. predictors\n\n\n\n\n\n\n\n\n\n. . .\nGoal: Use these predictors in a single model to understand variability in interest rate.\n. . .\n\nWhy do we want to use a single model versus 3 separate simple linear regression models?"
  },
  {
    "objectID": "slides/05-mlr-notes.html#multiple-linear-regression-mlr-1",
    "href": "slides/05-mlr-notes.html#multiple-linear-regression-mlr-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Multiple linear regression (MLR)",
    "text": "Multiple linear regression (MLR)\nBased on the analysis goals, we will use a multiple linear regression model of the following form\n\\[\n\\begin{aligned}\\text{interest_rate} ~ =\n\\beta_0 & + \\beta_1 ~ \\text{debt_to_income} \\\\ & + \\beta_2 ~ \\text{verified_income} \\\\ &+ \\beta_3~ \\text{annual_income_th} \\\\\n& +\\epsilon, \\quad \\epsilon \\sim N(0, \\sigma^2_{\\epsilon})\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/05-mlr-notes.html#multiple-linear-regression",
    "href": "slides/05-mlr-notes.html#multiple-linear-regression",
    "title": "Multiple linear regression (MLR)",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\nRecall: The simple linear regression model\n\\[\nY = \\beta_0 + \\beta_1~ X + \\epsilon\n\\]\n. . .\nThe form of the multiple linear regression model is\n\\[\nY = \\beta_0 + \\beta_1X_1 +  \\dots + \\beta_pX_p + \\epsilon\n\\]\n\n. . .\nTherefore,\n\\[\nE(Y|X_1, \\ldots, X_p) = \\beta_0 + \\beta_1X_1 +  \\dots + \\beta_pX_p\n\\]"
  },
  {
    "objectID": "slides/05-mlr-notes.html#fitting-the-least-squares-line",
    "href": "slides/05-mlr-notes.html#fitting-the-least-squares-line",
    "title": "Multiple linear regression (MLR)",
    "section": "Fitting the least squares line",
    "text": "Fitting the least squares line\nSimilar to simple linear regression, we want to find estimates for \\(\\beta_0, \\beta_1, \\ldots, \\beta_p\\) that minimize\n\\[\n\\sum_{i=1}^{n}\\epsilon_i^2 = \\sum_{i=1}^n[y_i - \\hat{y}_i]^2 = \\sum_{i=1}^n[y_i - (\\beta_0 + \\beta_1x_{i1} + \\dots + \\beta_px_{ip})]^2\n\\]\n\n. . .\nThe calculations can be very tedious, especially if \\(p\\) is large"
  },
  {
    "objectID": "slides/05-mlr-notes.html#matrix-form-of-multiple-linear-regression",
    "href": "slides/05-mlr-notes.html#matrix-form-of-multiple-linear-regression",
    "title": "Multiple linear regression (MLR)",
    "section": "Matrix form of multiple linear regression",
    "text": "Matrix form of multiple linear regression\nSuppose we have \\(n\\) observations, a quantitative response variable, and \\(p\\) &gt; 1 predictors \\[\n\\underbrace{\n\\begin{bmatrix}\ny_1 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix} }_\n{\\mathbf{y}} \\hspace{3mm}\n=\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n1 &x_{11} & \\dots & x_{1p}\\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\n1 &  x_{n1} & \\dots &x_{np}\n\\end{bmatrix}\n}_{\\mathbf{X}}\n\\hspace{2mm}\n\\underbrace{\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\vdots \\\\\n\\beta_p\n\\end{bmatrix}\n}_{\\boldsymbol{\\beta}}\n\\hspace{3mm}\n+\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n\\epsilon_1 \\\\\n\\vdots\\\\\n\\epsilon_n\n\\end{bmatrix}\n}_\\boldsymbol{\\epsilon}\n\\]\n\nWhat are the dimensions of \\(\\mathbf{y}\\), \\(\\mathbf{X}\\), \\(\\boldsymbol{\\beta}\\), \\(\\boldsymbol{\\epsilon}\\)?"
  },
  {
    "objectID": "slides/05-mlr-notes.html#matrix-form-of-multiple-linear-regression-1",
    "href": "slides/05-mlr-notes.html#matrix-form-of-multiple-linear-regression-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Matrix form of multiple linear regression",
    "text": "Matrix form of multiple linear regression\nAs with simple linear regression, we have\n\\[\n\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n\\]\n. . .\nGeneralizing the derivations from SLR to \\(p &gt; 2\\), we have\n\\[\n\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^\n\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}\\mathbf{y}\n\\]\nas before."
  },
  {
    "objectID": "slides/05-mlr-notes.html#model-fit-in-r",
    "href": "slides/05-mlr-notes.html#model-fit-in-r",
    "title": "Multiple linear regression (MLR)",
    "section": "Model fit in R",
    "text": "Model fit in R\n\nint_fit &lt;- lm(interest_rate ~ debt_to_income + verified_income  + annual_income_th,\n              data = loan50)\n\ntidy(int_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n10.726\n1.507\n7.116\n0.000\n\n\ndebt_to_income\n0.671\n0.676\n0.993\n0.326\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n\n\nannual_income_th\n-0.021\n0.011\n-1.804\n0.078"
  },
  {
    "objectID": "slides/05-mlr-notes.html#model-equation",
    "href": "slides/05-mlr-notes.html#model-equation",
    "title": "Multiple linear regression (MLR)",
    "section": "Model equation",
    "text": "Model equation\n\\[\n\\begin{align}\\hat{\\text{interest_rate}} =  10.726 &+0.671 \\times \\text{debt_to_income}\\\\\n&+ 2.211 \\times \\text{source_verified}\\\\  \n&+ 6.880 \\times \\text{verified}\\\\\n& -0.021 \\times \\text{annual_income_th}\n\\end{align}\n\\]\n\n\n\n\n\n\nNote\n\n\n\nWe will talk about why there are only two terms in the model for verified_income soon!"
  },
  {
    "objectID": "slides/05-mlr-notes.html#interpreting-hatbeta_j",
    "href": "slides/05-mlr-notes.html#interpreting-hatbeta_j",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting \\(\\hat{\\beta}_j\\)",
    "text": "Interpreting \\(\\hat{\\beta}_j\\)\n\nThe estimated coefficient \\(\\hat{\\beta}_j\\) is the expected change in the mean of \\(Y\\) when \\(X_j\\) increases by one unit, holding the values of all other predictor variables constant.\n\n. . .\n\nExample: The estimated coefficient for debt_to_income is 0.671. This means for each point in an borrower’s debt to income ratio, the interest rate on the loan is expected to be greater by 0.671%, on average, holding annual income and income verification constant."
  },
  {
    "objectID": "slides/05-mlr-notes.html#interpreting-hatbeta_j-1",
    "href": "slides/05-mlr-notes.html#interpreting-hatbeta_j-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting \\(\\hat{\\beta}_j\\)",
    "text": "Interpreting \\(\\hat{\\beta}_j\\)\n\nThe estimated coefficient for annual_income_th is -0.021. Interpret this coefficient in the context of the data.\n\n\n\n\nWhy do we need to include a statement about holding all other predictors constant?"
  },
  {
    "objectID": "slides/05-mlr-notes.html#interpreting-hatbeta_0",
    "href": "slides/05-mlr-notes.html#interpreting-hatbeta_0",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting \\(\\hat{\\beta}_0\\)",
    "text": "Interpreting \\(\\hat{\\beta}_0\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n10.726\n1.507\n7.116\n0.000\n7.690\n13.762\n\n\ndebt_to_income\n0.671\n0.676\n0.993\n0.326\n-0.690\n2.033\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n-0.606\n5.028\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n3.253\n10.508\n\n\nannual_income_th\n-0.021\n0.011\n-1.804\n0.078\n-0.043\n0.002\n\n\n\n\n\n. . .\n\n\nDescribe the subset of borrowers who are expected to get an interest rate of 10.726% based on our model. Is this interpretation meaningful? Why or why not?"
  },
  {
    "objectID": "slides/05-mlr-notes.html#prediction",
    "href": "slides/05-mlr-notes.html#prediction",
    "title": "Multiple linear regression (MLR)",
    "section": "Prediction",
    "text": "Prediction\n\nWhat is the predicted interest rate for an borrower with an debt-to-income ratio of 0.558, whose income is not verified, and who has an annual income of $59,000?\n\n\n\n10.726 + 0.671 * 0.558 + 2.211 * 0 + 6.880 * 0 - 0.021 * 59\n\n[1] 9.861418\n\n\n. . .\nThe predicted interest rate for an borrower with with an debt-to-income ratio of 0.558, whose income is not verified, and who has an annual income of $59,000 is 9.86%."
  },
  {
    "objectID": "slides/05-mlr-notes.html#prediction-in-r",
    "href": "slides/05-mlr-notes.html#prediction-in-r",
    "title": "Multiple linear regression (MLR)",
    "section": "Prediction in R",
    "text": "Prediction in R\nJust like with simple linear regression, we can use the predict() function in R to calculate the appropriate intervals for our predicted values:\n\nnew_borrower &lt;- tibble(\n  debt_to_income  = 0.558, \n  verified_income = \"Not Verified\", \n  annual_income_th = 59\n)\n\npredict(int_fit, new_borrower)\n\n       1 \n9.890888 \n\n\n\n\n\n\n\n\nNote\n\n\n\nDifference in predicted value due to rounding the coefficients on the previous slide."
  },
  {
    "objectID": "slides/05-mlr-notes.html#cautions",
    "href": "slides/05-mlr-notes.html#cautions",
    "title": "Multiple linear regression (MLR)",
    "section": "Cautions",
    "text": "Cautions\n\nDo not extrapolate! Because there are multiple predictor variables, there is the potential to extrapolate in many directions\nThe multiple regression model only shows association, not causality\n\nTo show causality, you must have a carefully designed experiment or carefully account for confounding variables in an observational study"
  },
  {
    "objectID": "slides/05-mlr-notes.html#recap",
    "href": "slides/05-mlr-notes.html#recap",
    "title": "Multiple linear regression (MLR)",
    "section": "Recap",
    "text": "Recap\n\nShowed exploratory data analysis for multiple linear regression\nUsed least squares to fit the regression line\nInterpreted the coefficients for quantitative predictors\nPredicted the response for new observations"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#announcements",
    "href": "slides/03-slr-model-assessment.html#announcements",
    "title": "SLR: Model Assessment",
    "section": "Announcements",
    "text": "Announcements\n\nNo office hours Mon, Jan 20 - Martin Luther King, Jr. Holiday\nIntroduction to R workshops at Duke library\n\nData wrangling with dplyr - Thu, Jan 16 at 12pm\nData visualization with ggplot2 - Thu, Jan 23 at 12pm"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#topics",
    "href": "slides/03-slr-model-assessment.html#topics",
    "title": "SLR: Model Assessment",
    "section": "Topics",
    "text": "Topics\n\nPredict the response given a value of the predictor\nUse R to conduct exploratory data analysis and fit a model\nEvaluate models using RMSE and \\(R^2\\)\nUse analysis of variance to partition variability in the response variable"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#computing-set-up",
    "href": "slides/03-slr-model-assessment.html#computing-set-up",
    "title": "SLR: Model Assessment",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling (includes broom, yardstick, and other packages)\nlibrary(knitr)       # for pretty tables\nlibrary(patchwork)   # arrange plots\n\n# set default theme for ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#data-movie-scores-on-rotten-tomatoes",
    "href": "slides/03-slr-model-assessment.html#data-movie-scores-on-rotten-tomatoes",
    "title": "SLR: Model Assessment",
    "section": "Data: Movie scores on Rotten Tomatoes",
    "text": "Data: Movie scores on Rotten Tomatoes\n\n\\[\n\\widehat{\\text{audience}} = 32.3142 + 0.5187 \\times \\text{critics}\n\\]"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#making-a-prediction",
    "href": "slides/03-slr-model-assessment.html#making-a-prediction",
    "title": "SLR: Model Assessment",
    "section": "Making a prediction",
    "text": "Making a prediction\nSuppose that a movie has a critics score of 70. According to this model, what is the movie’s predicted audience score?\n\\[\\begin{aligned}\n\\widehat{\\text{audience}} &= 32.3142 + 0.5187 \\times \\text{critics} \\\\\n&= 32.3142 + 0.5187 \\times 70 \\\\\n&= \\mathbf{68.6232}\n\\end{aligned}\\]\n\n\n\n\n\n\n\n\nCaution\n\n\nUsing the model to predict for values outside the range of the original data is extrapolation. Why do we want to avoid extrapolation?"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#fit-the-model",
    "href": "slides/03-slr-model-assessment.html#fit-the-model",
    "title": "SLR: Model Assessment",
    "section": "Fit the model",
    "text": "Fit the model\nUse the lm() function to fit a linear regression model\n\n\nmovie_fit &lt;- lm(audience ~ critics, data = movie_scores)\nmovie_fit\n\n\nCall:\nlm(formula = audience ~ critics, data = movie_scores)\n\nCoefficients:\n(Intercept)      critics  \n    32.3155       0.5187"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#tidy-results",
    "href": "slides/03-slr-model-assessment.html#tidy-results",
    "title": "SLR: Model Assessment",
    "section": "Tidy results",
    "text": "Tidy results\nUse the tidy() function from the broom R package to “tidy” the model output\n\n\nmovie_fit &lt;- lm(audience ~ critics, data = movie_scores)\ntidy(movie_fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   32.3      2.34        13.8 4.03e-28\n2 critics        0.519    0.0345      15.0 2.70e-31"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#format-results",
    "href": "slides/03-slr-model-assessment.html#format-results",
    "title": "SLR: Model Assessment",
    "section": "Format results",
    "text": "Format results\nUse the kable() function from the knitr package to neatly format the results\n\n\n\nmovie_fit &lt;- lm(audience ~ critics, data = movie_scores)\ntidy(movie_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n32.316\n2.343\n13.795\n0\n\n\ncritics\n0.519\n0.035\n15.028\n0"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#prediction-1",
    "href": "slides/03-slr-model-assessment.html#prediction-1",
    "title": "SLR: Model Assessment",
    "section": "Prediction",
    "text": "Prediction\nUse the predict() function to calculate predictions for new observations\n\nSingle observation\n\nnew_movie &lt;- tibble(critics = 70)\npredict(movie_fit, new_movie)\n\n       1 \n68.62297"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#prediction-2",
    "href": "slides/03-slr-model-assessment.html#prediction-2",
    "title": "SLR: Model Assessment",
    "section": "Prediction",
    "text": "Prediction\nUse the predict() function to calculate predictions for new observations\n\nMultiple observations\n\nmore_new_movies &lt;- tibble(critics = c(24,70, 85))\npredict(movie_fit, more_new_movies)\n\n       1        2        3 \n44.76379 68.62297 76.40313"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#data-life-expectancy-in-140-countries",
    "href": "slides/03-slr-model-assessment.html#data-life-expectancy-in-140-countries",
    "title": "SLR: Model Assessment",
    "section": "Data: Life expectancy in 140 countries",
    "text": "Data: Life expectancy in 140 countries\nThe data set comes from Zarulli et al. (2021) who analyze the effects of a country’s healthcare expenditures and other factors on the country’s life expectancy. The data are originally from the Human Development Database and World Health Organization.\nThere are 140 countries (observations) in the data set.\n\nGoal: Use the income inequality in a country to understand variability in the life expectancy.\n\n\nClick here for the original research paper."
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#variables",
    "href": "slides/03-slr-model-assessment.html#variables",
    "title": "SLR: Model Assessment",
    "section": "Variables",
    "text": "Variables\n\n\nlife_exp: The average number of years that a newborn could expect to live, if he or she were to pass through life exposed to the sex- and age-specific death rates prevailing at the time of his or her birth, for a specific year, in a given country, territory, or geographic income_inequality. ( from the World Health Organization)\nincome_inequality: Measure of the deviation of the distribution of income among individuals or households within a country from a perfectly equal distribution. A value of 0 represents absolute equality, a value of 100 absolute inequality (based on Gini coefficient). (from Zarulli et al. (2021))"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#univariate-exploratory-data-analysis",
    "href": "slides/03-slr-model-assessment.html#univariate-exploratory-data-analysis",
    "title": "SLR: Model Assessment",
    "section": "Univariate exploratory data analysis",
    "text": "Univariate exploratory data analysis"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#bivariate-exploratory-data-analysis",
    "href": "slides/03-slr-model-assessment.html#bivariate-exploratory-data-analysis",
    "title": "SLR: Model Assessment",
    "section": "Bivariate exploratory data analysis",
    "text": "Bivariate exploratory data analysis"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#clone-repo-start-new-rstudio-project",
    "href": "slides/03-slr-model-assessment.html#clone-repo-start-new-rstudio-project",
    "title": "SLR: Model Assessment",
    "section": "Clone repo + Start new RStudio project",
    "text": "Clone repo + Start new RStudio project\n\nGo to the course organization. Click on the repo with the prefix ae-01. It contains the starter documents you need to complete the AE.\n\nIf you do not see an ae-01 repo, use this link to create one: https://classroom.github.com/a/6jpkfA8n\n\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File → New Project → Version Control → Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick ae-01.qmd to open the template Quarto file. This is where you will write up your code and narrative for the AE."
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#two-statistics",
    "href": "slides/03-slr-model-assessment.html#two-statistics",
    "title": "SLR: Model Assessment",
    "section": "Two statistics",
    "text": "Two statistics\n\nRoot mean square error, RMSE: A measure of the average error (average difference between observed and predicted values of the outcome)\nR-squared, \\(R^2\\) : Percentage of variability in the outcome explained by the regression model (in the context of SLR, the predictor)\n\n\n\nWhat indicates a good model fit? Higher or lower RMSE? Higher or lower \\(R^2\\)?"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#rmse",
    "href": "slides/03-slr-model-assessment.html#rmse",
    "title": "SLR: Model Assessment",
    "section": "RMSE",
    "text": "RMSE\n\\[\nRMSE = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n}} = \\sqrt{\\frac{\\sum_{i=1}^ne_i^2}{n}}\n\\]\n\n\n\nRanges between 0 (perfect predictor) and infinity (terrible predictor)\nSame units as the response variable\nThe value of RMSE is more useful for comparing across models than evaluating a single model"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#analysis-of-variance-anova",
    "href": "slides/03-slr-model-assessment.html#analysis-of-variance-anova",
    "title": "SLR: Model Assessment",
    "section": "ANOVA",
    "text": "ANOVA\nAnalysis of Variance (ANOVA): Technique to partition variability in \\(Y\\) by the sources of variability"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#total-variability-response",
    "href": "slides/03-slr-model-assessment.html#total-variability-response",
    "title": "SLR: Model Assessment",
    "section": "Total variability (Response)",
    "text": "Total variability (Response)\n\n\n\n\n\n\nMin\nMedian\nMax\nMean\nStd.Dev\n\n\n\n\n51.6\n72.85\n84.1\n71.614\n8.075"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#partition-sources-of-variability-in-life_exp",
    "href": "slides/03-slr-model-assessment.html#partition-sources-of-variability-in-life_exp",
    "title": "SLR: Model Assessment",
    "section": "Partition sources of variability in life_exp",
    "text": "Partition sources of variability in life_exp"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#total-variability-response-1",
    "href": "slides/03-slr-model-assessment.html#total-variability-response-1",
    "title": "SLR: Model Assessment",
    "section": "Total variability (Response)",
    "text": "Total variability (Response)\n\n\\[\\text{Sum of Squares Total (SST)} = \\sum_{i=1}^n(y_i - \\bar{y})^2 = (n-1)s_y^2\\]"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#explained-variability-model",
    "href": "slides/03-slr-model-assessment.html#explained-variability-model",
    "title": "SLR: Model Assessment",
    "section": "Explained variability (Model)",
    "text": "Explained variability (Model)\n\n\\[\\text{Sum of Squares Model (SSM)} = \\sum_{i = 1}^{n}(\\hat{y}_i - \\bar{y})^2\\]"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#unexplained-variability-residuals",
    "href": "slides/03-slr-model-assessment.html#unexplained-variability-residuals",
    "title": "SLR: Model Assessment",
    "section": "Unexplained variability (Residuals)",
    "text": "Unexplained variability (Residuals)\n\n\\[\\text{Sum of Squares Residuals (SSR)} = \\sum_{i = 1}^{n}(y_i - \\hat{y}_i)^2\\]"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#sum-of-squares",
    "href": "slides/03-slr-model-assessment.html#sum-of-squares",
    "title": "SLR: Model Assessment",
    "section": "Sum of Squares",
    "text": "Sum of Squares\n\n\\[\n\\begin{aligned}\n\\color{#407E99}{SST} \\hspace{5mm}&= &\\color{#993399}{SSM} &\\hspace{5mm} +  &\\color{#8BB174}{SSR} \\\\[10pt]\n\\color{#407E99}{\\sum_{i=1}^n(y_i - \\bar{y})^2} \\hspace{5mm}&= &\\color{#993399}{\\sum_{i = 1}^{n}(\\hat{y}_i - \\bar{y})^2} &\\hspace{5mm}+ &\\color{#8BB174}{\\sum_{i = 1}^{n}(y_i - \\hat{y}_i)^2}\n\\end{aligned}\n\\]\n\n\nClick here to see why this equality holds."
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#r2",
    "href": "slides/03-slr-model-assessment.html#r2",
    "title": "SLR: Model Assessment",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\nThe coefficient of determination \\(R^2\\) is the proportion of variation in the response, \\(Y\\), that is explained by the regression model\n\n\\[\\large{R^2 = \\frac{SSM}{SST} = 1 - \\frac{SSR}{SST}}\\]\n\n\nWhat is the range of \\(R^2\\)? Does \\(R^2\\) have units?"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#interpreting-r2",
    "href": "slides/03-slr-model-assessment.html#interpreting-r2",
    "title": "SLR: Model Assessment",
    "section": "Interpreting \\(R^2\\)",
    "text": "Interpreting \\(R^2\\)\n\nQuestionSubmit\n\n\n\nSubmit your response to the following question on Ed Discussion.\n\nThe \\(R^2\\) of the model of life expectancy and income inequality is 70%. Which of the following is the correct interpretation of this value?\n\nA country’s income inequality correctly predicts 70% of its life expectancy.\n70% of the variability in life expectancy can be explained by income inequality.\n70% of the variability in income inequality can be explained by life expectancy.\n70% of the time a country’s life expectancy can be predicted by its income inequality.\n\n\n\n\n\n\n\n\n\n🔗 https://edstem.org/us/courses/70811/discussion/5978094"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#augmented-data-frame",
    "href": "slides/03-slr-model-assessment.html#augmented-data-frame",
    "title": "SLR: Model Assessment",
    "section": "Augmented data frame",
    "text": "Augmented data frame\nUse the augment() function from the broom package to add columns for predicted values, residuals, and other observation-level model statistics\n\n\nlife_exp_aug &lt;- augment(life_exp_fit)\nlife_exp_aug\n\n# A tibble: 140 × 8\n   life_exp income_inequality .fitted .resid    .hat .sigma   .cooksd .std.resid\n      &lt;dbl&gt;             &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1     63.8              28.2    65.8 -1.96  0.0125    4.45 0.00125       -0.444\n 2     78.2              12.2    76.9  1.29  0.0116    4.45 0.000498       0.292\n 3     59.9              32.4    62.8 -2.93  0.0193    4.44 0.00437       -0.667\n 4     76.2              14      75.7  0.542 0.00972   4.45 0.0000739      0.123\n 5     74.6               8.6    79.4 -4.82  0.0168    4.43 0.0102        -1.10 \n 6     83                 8.3    79.6  3.37  0.0173    4.44 0.00515        0.766\n 7     81.3               7.4    80.3  1.04  0.0189    4.45 0.000540       0.237\n 8     72.5              10.1    78.4 -5.88  0.0144    4.42 0.0130        -1.33 \n 9     71.8              27.6    66.2  5.62  0.0118    4.43 0.00972        1.28 \n10     74                 6.5    80.9 -6.89  0.0207    4.41 0.0260        -1.57 \n# ℹ 130 more rows"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#finding-rmse-in-r",
    "href": "slides/03-slr-model-assessment.html#finding-rmse-in-r",
    "title": "SLR: Model Assessment",
    "section": "Finding RMSE in R",
    "text": "Finding RMSE in R\nUse the rmse() function from the yardstick package (part of tidymodels)\n\nrmse(life_exp_aug, truth = life_exp, estimate = .fitted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard        4.40"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#finding-r2-in-r",
    "href": "slides/03-slr-model-assessment.html#finding-r2-in-r",
    "title": "SLR: Model Assessment",
    "section": "Finding \\(R^2\\) in R",
    "text": "Finding \\(R^2\\) in R\nUse the rsq() function from the yardstick package (part of tidymodels)\n\nrsq(life_exp_aug, truth = life_exp, estimate = .fitted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rsq     standard       0.700\n\n\n\n\nAlternatively, use glance() to construct a single row summary of the model fit, including \\(R^2\\):\n\nglance(life_exp_fit)$r.squared\n\n[1] 0.7003831"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#recap",
    "href": "slides/03-slr-model-assessment.html#recap",
    "title": "SLR: Model Assessment",
    "section": "Recap",
    "text": "Recap\n\nUsed R to conduct exploratory data analysis and fit a model\nEvaluated models using RMSE and \\(R^2\\)\nUsed analysis of variance to partition variability in the response variable"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#next-class",
    "href": "slides/03-slr-model-assessment.html#next-class",
    "title": "SLR: Model Assessment",
    "section": "Next class",
    "text": "Next class\n\nMatrix representation of simple linear regression\n\nSee Lec 04: SLR - Matrix representation prepare"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#references",
    "href": "slides/03-slr-model-assessment.html#references",
    "title": "SLR: Model Assessment",
    "section": "References",
    "text": "References\n\n\n\n\nZarulli, Virginia, Elizaveta Sopina, Veronica Toffolutti, and Adam Lenart. 2021. “Health Care System Efficiency and Life Expectancy: A 140-Country Study.” Edited by Srinivas Goli. PLOS ONE 16 (7): e0253450. https://doi.org/10.1371/journal.pone.0253450."
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html",
    "href": "slides/03-slr-model-assessment-notes.html",
    "title": "SLR: Model Assessment",
    "section": "",
    "text": "No office hours Mon, Jan 20 - Martin Luther King, Jr. Holiday\nIntroduction to R workshops at Duke library\n\nData wrangling with dplyr - Thu, Jan 16 at 12pm\nData visualization with ggplot2 - Thu, Jan 23 at 12pm"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#announcements",
    "href": "slides/03-slr-model-assessment-notes.html#announcements",
    "title": "SLR: Model Assessment",
    "section": "",
    "text": "No office hours Mon, Jan 20 - Martin Luther King, Jr. Holiday\nIntroduction to R workshops at Duke library\n\nData wrangling with dplyr - Thu, Jan 16 at 12pm\nData visualization with ggplot2 - Thu, Jan 23 at 12pm"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#topics",
    "href": "slides/03-slr-model-assessment-notes.html#topics",
    "title": "SLR: Model Assessment",
    "section": "Topics",
    "text": "Topics\n\nPredict the response given a value of the predictor\nUse R to conduct exploratory data analysis and fit a model\nEvaluate models using RMSE and \\(R^2\\)\nUse analysis of variance to partition variability in the response variable"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#computing-set-up",
    "href": "slides/03-slr-model-assessment-notes.html#computing-set-up",
    "title": "SLR: Model Assessment",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling (includes broom, yardstick, and other packages)\nlibrary(knitr)       # for pretty tables\nlibrary(patchwork)   # arrange plots\n\n# set default theme for ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#data-movie-scores-on-rotten-tomatoes",
    "href": "slides/03-slr-model-assessment-notes.html#data-movie-scores-on-rotten-tomatoes",
    "title": "SLR: Model Assessment",
    "section": "Data: Movie scores on Rotten Tomatoes",
    "text": "Data: Movie scores on Rotten Tomatoes\n\n\n\n\n\n\n\n\n\n\\[\n\\widehat{\\text{audience}} = 32.3142 + 0.5187 \\times \\text{critics}\n\\]"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#making-a-prediction",
    "href": "slides/03-slr-model-assessment-notes.html#making-a-prediction",
    "title": "SLR: Model Assessment",
    "section": "Making a prediction",
    "text": "Making a prediction\nSuppose that a movie has a critics score of 70. According to this model, what is the movie’s predicted audience score?\n\\[\\begin{aligned}\n\\widehat{\\text{audience}} &= 32.3142 + 0.5187 \\times \\text{critics} \\\\\n&= 32.3142 + 0.5187 \\times 70 \\\\\n&= \\mathbf{68.6232}\n\\end{aligned}\\]\n\n. . .\n\n\n\n\n\n\nCaution\n\n\n\nUsing the model to predict for values outside the range of the original data is extrapolation. Why do we want to avoid extrapolation?"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#fit-the-model",
    "href": "slides/03-slr-model-assessment-notes.html#fit-the-model",
    "title": "SLR: Model Assessment",
    "section": "Fit the model",
    "text": "Fit the model\nUse the lm() function to fit a linear regression model\n\n\nmovie_fit &lt;- lm(audience ~ critics, data = movie_scores)\nmovie_fit\n\n\nCall:\nlm(formula = audience ~ critics, data = movie_scores)\n\nCoefficients:\n(Intercept)      critics  \n    32.3155       0.5187"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#tidy-results",
    "href": "slides/03-slr-model-assessment-notes.html#tidy-results",
    "title": "SLR: Model Assessment",
    "section": "Tidy results",
    "text": "Tidy results\nUse the tidy() function from the broom R package to “tidy” the model output\n\n\nmovie_fit &lt;- lm(audience ~ critics, data = movie_scores)\ntidy(movie_fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   32.3      2.34        13.8 4.03e-28\n2 critics        0.519    0.0345      15.0 2.70e-31"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#format-results",
    "href": "slides/03-slr-model-assessment-notes.html#format-results",
    "title": "SLR: Model Assessment",
    "section": "Format results",
    "text": "Format results\nUse the kable() function from the knitr package to neatly format the results\n\n\n\nmovie_fit &lt;- lm(audience ~ critics, data = movie_scores)\ntidy(movie_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n32.316\n2.343\n13.795\n0\n\n\ncritics\n0.519\n0.035\n15.028\n0"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#prediction-1",
    "href": "slides/03-slr-model-assessment-notes.html#prediction-1",
    "title": "SLR: Model Assessment",
    "section": "Prediction",
    "text": "Prediction\nUse the predict() function to calculate predictions for new observations\n\nSingle observation\n\nnew_movie &lt;- tibble(critics = 70)\npredict(movie_fit, new_movie)\n\n       1 \n68.62297"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#prediction-2",
    "href": "slides/03-slr-model-assessment-notes.html#prediction-2",
    "title": "SLR: Model Assessment",
    "section": "Prediction",
    "text": "Prediction\nUse the predict() function to calculate predictions for new observations\n\nMultiple observations\n\nmore_new_movies &lt;- tibble(critics = c(24,70, 85))\npredict(movie_fit, more_new_movies)\n\n       1        2        3 \n44.76379 68.62297 76.40313"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#data-life-expectancy-in-140-countries",
    "href": "slides/03-slr-model-assessment-notes.html#data-life-expectancy-in-140-countries",
    "title": "SLR: Model Assessment",
    "section": "Data: Life expectancy in 140 countries",
    "text": "Data: Life expectancy in 140 countries\nThe data set comes from Zarulli et al. (2021) who analyze the effects of a country’s healthcare expenditures and other factors on the country’s life expectancy. The data are originally from the Human Development Database and World Health Organization.\nThere are 140 countries (observations) in the data set.\n\nGoal: Use the income inequality in a country to understand variability in the life expectancy.\n\n\nClick here for the original research paper."
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#variables",
    "href": "slides/03-slr-model-assessment-notes.html#variables",
    "title": "SLR: Model Assessment",
    "section": "Variables",
    "text": "Variables\n\n\nlife_exp: The average number of years that a newborn could expect to live, if he or she were to pass through life exposed to the sex- and age-specific death rates prevailing at the time of his or her birth, for a specific year, in a given country, territory, or geographic income_inequality. ( from the World Health Organization)\nincome_inequality: Measure of the deviation of the distribution of income among individuals or households within a country from a perfectly equal distribution. A value of 0 represents absolute equality, a value of 100 absolute inequality (based on Gini coefficient). (from Zarulli et al. (2021))"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#univariate-exploratory-data-analysis",
    "href": "slides/03-slr-model-assessment-notes.html#univariate-exploratory-data-analysis",
    "title": "SLR: Model Assessment",
    "section": "Univariate exploratory data analysis",
    "text": "Univariate exploratory data analysis"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#bivariate-exploratory-data-analysis",
    "href": "slides/03-slr-model-assessment-notes.html#bivariate-exploratory-data-analysis",
    "title": "SLR: Model Assessment",
    "section": "Bivariate exploratory data analysis",
    "text": "Bivariate exploratory data analysis"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#clone-repo-start-new-rstudio-project",
    "href": "slides/03-slr-model-assessment-notes.html#clone-repo-start-new-rstudio-project",
    "title": "SLR: Model Assessment",
    "section": "Clone repo + Start new RStudio project",
    "text": "Clone repo + Start new RStudio project\n\nGo to the course organization. Click on the repo with the prefix ae-01. It contains the starter documents you need to complete the AE.\n\nIf you do not see an ae-01 repo, use this link to create one: https://classroom.github.com/a/6jpkfA8n\n\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File → New Project → Version Control → Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick ae-01.qmd to open the template Quarto file. This is where you will write up your code and narrative for the AE."
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#two-statistics",
    "href": "slides/03-slr-model-assessment-notes.html#two-statistics",
    "title": "SLR: Model Assessment",
    "section": "Two statistics",
    "text": "Two statistics\n\nRoot mean square error, RMSE: A measure of the average error (average difference between observed and predicted values of the outcome)\nR-squared, \\(R^2\\) : Percentage of variability in the outcome explained by the regression model (in the context of SLR, the predictor)\n\n. . .\n\nWhat indicates a good model fit? Higher or lower RMSE? Higher or lower \\(R^2\\)?"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#rmse",
    "href": "slides/03-slr-model-assessment-notes.html#rmse",
    "title": "SLR: Model Assessment",
    "section": "RMSE",
    "text": "RMSE\n\\[\nRMSE = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n}} = \\sqrt{\\frac{\\sum_{i=1}^ne_i^2}{n}}\n\\]\n. . .\n\n\nRanges between 0 (perfect predictor) and infinity (terrible predictor)\nSame units as the response variable\nThe value of RMSE is more useful for comparing across models than evaluating a single model"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#analysis-of-variance-anova",
    "href": "slides/03-slr-model-assessment-notes.html#analysis-of-variance-anova",
    "title": "SLR: Model Assessment",
    "section": "ANOVA",
    "text": "ANOVA\nAnalysis of Variance (ANOVA): Technique to partition variability in \\(Y\\) by the sources of variability"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#total-variability-response",
    "href": "slides/03-slr-model-assessment-notes.html#total-variability-response",
    "title": "SLR: Model Assessment",
    "section": "Total variability (Response)",
    "text": "Total variability (Response)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMin\nMedian\nMax\nMean\nStd.Dev\n\n\n\n\n51.6\n72.85\n84.1\n71.614\n8.075"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#partition-sources-of-variability-in-life_exp",
    "href": "slides/03-slr-model-assessment-notes.html#partition-sources-of-variability-in-life_exp",
    "title": "SLR: Model Assessment",
    "section": "Partition sources of variability in life_exp",
    "text": "Partition sources of variability in life_exp"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#total-variability-response-1",
    "href": "slides/03-slr-model-assessment-notes.html#total-variability-response-1",
    "title": "SLR: Model Assessment",
    "section": "Total variability (Response)",
    "text": "Total variability (Response)\n\n\n\n\n\n\n\n\n\n\\[\\text{Sum of Squares Total (SST)} = \\sum_{i=1}^n(y_i - \\bar{y})^2 = (n-1)s_y^2\\]"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#explained-variability-model",
    "href": "slides/03-slr-model-assessment-notes.html#explained-variability-model",
    "title": "SLR: Model Assessment",
    "section": "Explained variability (Model)",
    "text": "Explained variability (Model)\n\n\n\n\n\n\n\n\n\n\\[\\text{Sum of Squares Model (SSM)} = \\sum_{i = 1}^{n}(\\hat{y}_i - \\bar{y})^2\\]"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#unexplained-variability-residuals",
    "href": "slides/03-slr-model-assessment-notes.html#unexplained-variability-residuals",
    "title": "SLR: Model Assessment",
    "section": "Unexplained variability (Residuals)",
    "text": "Unexplained variability (Residuals)\n\n\n\n\n\n\n\n\n\n\\[\\text{Sum of Squares Residuals (SSR)} = \\sum_{i = 1}^{n}(y_i - \\hat{y}_i)^2\\]"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#sum-of-squares",
    "href": "slides/03-slr-model-assessment-notes.html#sum-of-squares",
    "title": "SLR: Model Assessment",
    "section": "Sum of Squares",
    "text": "Sum of Squares\n\n\\[\n\\begin{aligned}\n\\color{#407E99}{SST} \\hspace{5mm}&= &\\color{#993399}{SSM} &\\hspace{5mm} +  &\\color{#8BB174}{SSR} \\\\[10pt]\n\\color{#407E99}{\\sum_{i=1}^n(y_i - \\bar{y})^2} \\hspace{5mm}&= &\\color{#993399}{\\sum_{i = 1}^{n}(\\hat{y}_i - \\bar{y})^2} &\\hspace{5mm}+ &\\color{#8BB174}{\\sum_{i = 1}^{n}(y_i - \\hat{y}_i)^2}\n\\end{aligned}\n\\]\n\n\nClick here to see why this equality holds."
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#r2",
    "href": "slides/03-slr-model-assessment-notes.html#r2",
    "title": "SLR: Model Assessment",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\nThe coefficient of determination \\(R^2\\) is the proportion of variation in the response, \\(Y\\), that is explained by the regression model\n\n\\[\\large{R^2 = \\frac{SSM}{SST} = 1 - \\frac{SSR}{SST}}\\]\n\n\nWhat is the range of \\(R^2\\)? Does \\(R^2\\) have units?"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#interpreting-r2",
    "href": "slides/03-slr-model-assessment-notes.html#interpreting-r2",
    "title": "SLR: Model Assessment",
    "section": "Interpreting \\(R^2\\)",
    "text": "Interpreting \\(R^2\\)\n\nQuestionSubmit\n\n\n\nSubmit your response to the following question on Ed Discussion.\n\nThe \\(R^2\\) of the model of life expectancy and income inequality is 70%. Which of the following is the correct interpretation of this value?\n\nA country’s income inequality correctly predicts 70% of its life expectancy.\n70% of the variability in life expectancy can be explained by income inequality.\n70% of the variability in income inequality can be explained by life expectancy.\n70% of the time a country’s life expectancy can be predicted by its income inequality.\n\n\n\n\n\n\n\n\n\n🔗 https://edstem.org/us/courses/70811/discussion/5978094"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#augmented-data-frame",
    "href": "slides/03-slr-model-assessment-notes.html#augmented-data-frame",
    "title": "SLR: Model Assessment",
    "section": "Augmented data frame",
    "text": "Augmented data frame\nUse the augment() function from the broom package to add columns for predicted values, residuals, and other observation-level model statistics\n. . .\n\nlife_exp_aug &lt;- augment(life_exp_fit)\nlife_exp_aug\n\n# A tibble: 140 × 8\n   life_exp income_inequality .fitted .resid    .hat .sigma   .cooksd .std.resid\n      &lt;dbl&gt;             &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1     63.8              28.2    65.8 -1.96  0.0125    4.45 0.00125       -0.444\n 2     78.2              12.2    76.9  1.29  0.0116    4.45 0.000498       0.292\n 3     59.9              32.4    62.8 -2.93  0.0193    4.44 0.00437       -0.667\n 4     76.2              14      75.7  0.542 0.00972   4.45 0.0000739      0.123\n 5     74.6               8.6    79.4 -4.82  0.0168    4.43 0.0102        -1.10 \n 6     83                 8.3    79.6  3.37  0.0173    4.44 0.00515        0.766\n 7     81.3               7.4    80.3  1.04  0.0189    4.45 0.000540       0.237\n 8     72.5              10.1    78.4 -5.88  0.0144    4.42 0.0130        -1.33 \n 9     71.8              27.6    66.2  5.62  0.0118    4.43 0.00972        1.28 \n10     74                 6.5    80.9 -6.89  0.0207    4.41 0.0260        -1.57 \n# ℹ 130 more rows"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#finding-rmse-in-r",
    "href": "slides/03-slr-model-assessment-notes.html#finding-rmse-in-r",
    "title": "SLR: Model Assessment",
    "section": "Finding RMSE in R",
    "text": "Finding RMSE in R\nUse the rmse() function from the yardstick package (part of tidymodels)\n\nrmse(life_exp_aug, truth = life_exp, estimate = .fitted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard        4.40"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#finding-r2-in-r",
    "href": "slides/03-slr-model-assessment-notes.html#finding-r2-in-r",
    "title": "SLR: Model Assessment",
    "section": "Finding \\(R^2\\) in R",
    "text": "Finding \\(R^2\\) in R\nUse the rsq() function from the yardstick package (part of tidymodels)\n\nrsq(life_exp_aug, truth = life_exp, estimate = .fitted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rsq     standard       0.700\n\n\n\n. . .\nAlternatively, use glance() to construct a single row summary of the model fit, including \\(R^2\\):\n\nglance(life_exp_fit)$r.squared\n\n[1] 0.7003831"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#recap",
    "href": "slides/03-slr-model-assessment-notes.html#recap",
    "title": "SLR: Model Assessment",
    "section": "Recap",
    "text": "Recap\n\nUsed R to conduct exploratory data analysis and fit a model\nEvaluated models using RMSE and \\(R^2\\)\nUsed analysis of variance to partition variability in the response variable"
  },
  {
    "objectID": "slides/03-slr-model-assessment-notes.html#next-class",
    "href": "slides/03-slr-model-assessment-notes.html#next-class",
    "title": "SLR: Model Assessment",
    "section": "Next class",
    "text": "Next class\n\nMatrix representation of simple linear regression\n\nSee Lec 04: SLR - Matrix representation prepare"
  },
  {
    "objectID": "slides/14-multicollinearity-contd.html#announcements",
    "href": "slides/14-multicollinearity-contd.html#announcements",
    "title": "Multicollinearity cont’d",
    "section": "Announcements",
    "text": "Announcements\n\nExam corrections (optional) due TODAY at 11:59pm\n\nSee assignment on Canvas\n\nTeam Feedback (email from TEAMMATES) due TODAY at 11:59pm (check email)\nNext project milestone: Exploratory data analysis due March 20\n\nWork on it in lab March 7\n\nDataFest: April 4 - 6 - https://dukestatsci.github.io/datafest/"
  },
  {
    "objectID": "slides/14-multicollinearity-contd.html#computing-set-up",
    "href": "slides/14-multicollinearity-contd.html#computing-set-up",
    "title": "Multicollinearity cont’d",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)\nlibrary(GGally)   # for pairwise plot matrix\nlibrary(corrplot) # for correlation matrix\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/14-multicollinearity-contd.html#topics",
    "href": "slides/14-multicollinearity-contd.html#topics",
    "title": "Multicollinearity cont’d",
    "section": "Topics",
    "text": "Topics\n\nMulticollinearity\n\nRecap\nHow to deal with issues of multicollinearity"
  },
  {
    "objectID": "slides/14-multicollinearity-contd.html#data-trail-users",
    "href": "slides/14-multicollinearity-contd.html#data-trail-users",
    "title": "Multicollinearity cont’d",
    "section": "Data: Trail users",
    "text": "Data: Trail users\n\nThe Pioneer Valley Planning Commission (PVPC) collected data at the beginning a trail in Florence, MA for ninety days from April 5, 2005 to November 15, 2005.\nData collectors set up a laser sensor, with breaks in the laser beam recording when a rail-trail user passed the data collection station.\n\n\n\n# A tibble: 5 × 7\n  volume hightemp avgtemp season cloudcover precip day_type\n   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   \n1    501       83    66.5 Summer       7.60  0     Weekday \n2    419       73    61   Summer       6.30  0.290 Weekday \n3    397       74    63   Spring       7.5   0.320 Weekday \n4    385       95    78   Summer       2.60  0     Weekend \n5    200       44    48   Spring      10     0.140 Weekday \n\n\nSource: Pioneer Valley Planning Commission via the mosaicData package."
  },
  {
    "objectID": "slides/14-multicollinearity-contd.html#variables",
    "href": "slides/14-multicollinearity-contd.html#variables",
    "title": "Multicollinearity cont’d",
    "section": "Variables",
    "text": "Variables\nOutcome:\n\nvolume estimated number of trail users that day (number of breaks recorded)\n\nPredictors\n\nhightemp daily high temperature (in degrees Fahrenheit)\navgtemp average of daily low and daily high temperature (in degrees Fahrenheit)\nseason one of “Fall”, “Spring”, or “Summer”\nprecip measure of precipitation (in inches)"
  },
  {
    "objectID": "slides/14-multicollinearity-contd.html#eda-relationship-between-predictors",
    "href": "slides/14-multicollinearity-contd.html#eda-relationship-between-predictors",
    "title": "Multicollinearity cont’d",
    "section": "EDA: Relationship between predictors",
    "text": "EDA: Relationship between predictors"
  },
  {
    "objectID": "slides/14-multicollinearity-contd.html#multicollinearity",
    "href": "slides/14-multicollinearity-contd.html#multicollinearity",
    "title": "Multicollinearity cont’d",
    "section": "Multicollinearity",
    "text": "Multicollinearity\n\nMulticollinearity: near-linear dependence among predictors\nThe variance inflation factor (VIF) measures how much the linear dependencies impact the variance of the predictors\n\n\\[\nVIF_{j} = \\frac{1}{1 - R^2_j}\n\\]\nwhere \\(R^2_j\\) is the proportion of variation in \\(x_j\\) that is explained by a linear combination of all the other predictors\n\nThresholds:\n\nVIF &gt; 10: concerning multicollinearity\nVIF &gt; 5: potentially worth further investigation"
  },
  {
    "objectID": "slides/14-multicollinearity-contd.html#how-multicollinearity-impacts-model",
    "href": "slides/14-multicollinearity-contd.html#how-multicollinearity-impacts-model",
    "title": "Multicollinearity cont’d",
    "section": "How multicollinearity impacts model",
    "text": "How multicollinearity impacts model\n\nLarge variance for the model coefficients that are collinear\n\nDifferent combinations of coefficient estimates produce equally good model fits\n\nUnreliable statistical inference results\n\nMay conclude coefficients are not statistically significant when there is, in fact, a relationship between the predictors and response\n\nInterpretation of coefficient is no longer “holding all other variables constant”, since this would be impossible for correlated predictors"
  },
  {
    "objectID": "slides/14-multicollinearity-contd.html#dealing-with-multicollinearity",
    "href": "slides/14-multicollinearity-contd.html#dealing-with-multicollinearity",
    "title": "Multicollinearity cont’d",
    "section": "Dealing with multicollinearity",
    "text": "Dealing with multicollinearity\n\n\nCollect more data (often not feasible given practical constraints)\nRedefine the correlated predictors to keep the information from predictors but eliminate collinearity\n\ne.g., if \\(x_1, x_2, x_3\\) are correlated, use a new variable \\((x_1 + x_2) / x_3\\) in the model\n\nFor categorical predictors, avoid using levels with very few observations as the baseline\nRemove one of the correlated variables\n\nBe careful about substantially reducing predictive power of the model"
  },
  {
    "objectID": "slides/14-multicollinearity-contd-notes.html",
    "href": "slides/14-multicollinearity-contd-notes.html",
    "title": "Multicollinearity cont’d",
    "section": "",
    "text": "Exam corrections (optional) due TODAY at 11:59pm\n\nSee assignment on Canvas\n\nTeam Feedback (email from TEAMMATES) due TODAY at 11:59pm (check email)\nNext project milestone: Exploratory data analysis due March 20\n\nWork on it in lab March 7\n\nDataFest: April 4 - 6 - https://dukestatsci.github.io/datafest/"
  },
  {
    "objectID": "slides/14-multicollinearity-contd-notes.html#announcements",
    "href": "slides/14-multicollinearity-contd-notes.html#announcements",
    "title": "Multicollinearity cont’d",
    "section": "",
    "text": "Exam corrections (optional) due TODAY at 11:59pm\n\nSee assignment on Canvas\n\nTeam Feedback (email from TEAMMATES) due TODAY at 11:59pm (check email)\nNext project milestone: Exploratory data analysis due March 20\n\nWork on it in lab March 7\n\nDataFest: April 4 - 6 - https://dukestatsci.github.io/datafest/"
  },
  {
    "objectID": "slides/14-multicollinearity-contd-notes.html#computing-set-up",
    "href": "slides/14-multicollinearity-contd-notes.html#computing-set-up",
    "title": "Multicollinearity cont’d",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)\nlibrary(GGally)   # for pairwise plot matrix\nlibrary(corrplot) # for correlation matrix\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/14-multicollinearity-contd-notes.html#topics",
    "href": "slides/14-multicollinearity-contd-notes.html#topics",
    "title": "Multicollinearity cont’d",
    "section": "Topics",
    "text": "Topics\n\nMulticollinearity\n\nRecap\nHow to deal with issues of multicollinearity"
  },
  {
    "objectID": "slides/14-multicollinearity-contd-notes.html#data-trail-users",
    "href": "slides/14-multicollinearity-contd-notes.html#data-trail-users",
    "title": "Multicollinearity cont’d",
    "section": "Data: Trail users",
    "text": "Data: Trail users\n\nThe Pioneer Valley Planning Commission (PVPC) collected data at the beginning a trail in Florence, MA for ninety days from April 5, 2005 to November 15, 2005.\nData collectors set up a laser sensor, with breaks in the laser beam recording when a rail-trail user passed the data collection station.\n\n\n\n# A tibble: 5 × 7\n  volume hightemp avgtemp season cloudcover precip day_type\n   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   \n1    501       83    66.5 Summer       7.60  0     Weekday \n2    419       73    61   Summer       6.30  0.290 Weekday \n3    397       74    63   Spring       7.5   0.320 Weekday \n4    385       95    78   Summer       2.60  0     Weekend \n5    200       44    48   Spring      10     0.140 Weekday \n\n\nSource: Pioneer Valley Planning Commission via the mosaicData package."
  },
  {
    "objectID": "slides/14-multicollinearity-contd-notes.html#variables",
    "href": "slides/14-multicollinearity-contd-notes.html#variables",
    "title": "Multicollinearity cont’d",
    "section": "Variables",
    "text": "Variables\nOutcome:\n\nvolume estimated number of trail users that day (number of breaks recorded)\n\nPredictors\n\nhightemp daily high temperature (in degrees Fahrenheit)\navgtemp average of daily low and daily high temperature (in degrees Fahrenheit)\nseason one of “Fall”, “Spring”, or “Summer”\nprecip measure of precipitation (in inches)"
  },
  {
    "objectID": "slides/14-multicollinearity-contd-notes.html#eda-relationship-between-predictors",
    "href": "slides/14-multicollinearity-contd-notes.html#eda-relationship-between-predictors",
    "title": "Multicollinearity cont’d",
    "section": "EDA: Relationship between predictors",
    "text": "EDA: Relationship between predictors"
  },
  {
    "objectID": "slides/14-multicollinearity-contd-notes.html#multicollinearity",
    "href": "slides/14-multicollinearity-contd-notes.html#multicollinearity",
    "title": "Multicollinearity cont’d",
    "section": "Multicollinearity",
    "text": "Multicollinearity\n\nMulticollinearity: near-linear dependence among predictors\nThe variance inflation factor (VIF) measures how much the linear dependencies impact the variance of the predictors\n\n\\[\nVIF_{j} = \\frac{1}{1 - R^2_j}\n\\]\nwhere \\(R^2_j\\) is the proportion of variation in \\(x_j\\) that is explained by a linear combination of all the other predictors\n\nThresholds:\n\nVIF &gt; 10: concerning multicollinearity\nVIF &gt; 5: potentially worth further investigation"
  },
  {
    "objectID": "slides/14-multicollinearity-contd-notes.html#how-multicollinearity-impacts-model",
    "href": "slides/14-multicollinearity-contd-notes.html#how-multicollinearity-impacts-model",
    "title": "Multicollinearity cont’d",
    "section": "How multicollinearity impacts model",
    "text": "How multicollinearity impacts model\n\nLarge variance for the model coefficients that are collinear\n\nDifferent combinations of coefficient estimates produce equally good model fits\n\nUnreliable statistical inference results\n\nMay conclude coefficients are not statistically significant when there is, in fact, a relationship between the predictors and response\n\nInterpretation of coefficient is no longer “holding all other variables constant”, since this would be impossible for correlated predictors"
  },
  {
    "objectID": "slides/14-multicollinearity-contd-notes.html#dealing-with-multicollinearity",
    "href": "slides/14-multicollinearity-contd-notes.html#dealing-with-multicollinearity",
    "title": "Multicollinearity cont’d",
    "section": "Dealing with multicollinearity",
    "text": "Dealing with multicollinearity\n\n\nCollect more data (often not feasible given practical constraints)\nRedefine the correlated predictors to keep the information from predictors but eliminate collinearity\n\ne.g., if \\(x_1, x_2, x_3\\) are correlated, use a new variable \\((x_1 + x_2) / x_3\\) in the model\n\nFor categorical predictors, avoid using levels with very few observations as the baseline\nRemove one of the correlated variables\n\nBe careful about substantially reducing predictive power of the model"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#announcements",
    "href": "slides/21-logistic-comparison.html#announcements",
    "title": "Logistic Regression: Model comparison",
    "section": "Announcements",
    "text": "Announcements\n\nHW 04 due April 10 - released later today\nTeam Feedback (email from TEAMMATES) due Tuesday, April 8 at 11:59pm (check email)\nNext project milestone: Analysis and draft in April 11 lab\nStatistics experience due April 22"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#questions-from-this-weeks-content",
    "href": "slides/21-logistic-comparison.html#questions-from-this-weeks-content",
    "title": "Logistic Regression: Model comparison",
    "section": "Questions from this week’s content?",
    "text": "Questions from this week’s content?"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#topics",
    "href": "slides/21-logistic-comparison.html#topics",
    "title": "Logistic Regression: Model comparison",
    "section": "Topics",
    "text": "Topics\n\nComparing models using AIC and BIC\nTest of significance for a subset of predictors"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#computational-setup",
    "href": "slides/21-logistic-comparison.html#computational-setup",
    "title": "Logistic Regression: Model comparison",
    "section": "Computational setup",
    "text": "Computational setup\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(pROC)      \nlibrary(knitr)\nlibrary(kableExtra)\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#risk-of-coronary-heart-disease",
    "href": "slides/21-logistic-comparison.html#risk-of-coronary-heart-disease",
    "title": "Logistic Regression: Model comparison",
    "section": "Risk of coronary heart disease",
    "text": "Risk of coronary heart disease\nThis data set is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. We want to examine the relationship between various health characteristics and the risk of having heart disease.\n\nhigh_risk:\n\n1: High risk of having heart disease in next 10 years\n0: Not high risk of having heart disease in next 10 years\n\nage: Age at exam time (in years)\ntotChol: Total cholesterol (in mg/dL)\ncurrentSmoker: 0 = nonsmoker, 1 = smoker\neducation: 1 = Some High School, 2 = High School or GED, 3 = Some College or Vocational School, 4 = College"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#modeling-risk-of-coronary-heart-disease",
    "href": "slides/21-logistic-comparison.html#modeling-risk-of-coronary-heart-disease",
    "title": "Logistic Regression: Model comparison",
    "section": "Modeling risk of coronary heart disease",
    "text": "Modeling risk of coronary heart disease\nUsing age, totChol, and currentSmoker\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-6.673\n0.378\n-17.647\n0.000\n-7.423\n-5.940\n\n\nage\n0.082\n0.006\n14.344\n0.000\n0.071\n0.094\n\n\ntotChol\n0.002\n0.001\n1.940\n0.052\n0.000\n0.004\n\n\ncurrentSmoker1\n0.443\n0.094\n4.733\n0.000\n0.260\n0.627"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#review-roc-curve-model-fit",
    "href": "slides/21-logistic-comparison.html#review-roc-curve-model-fit",
    "title": "Logistic Regression: Model comparison",
    "section": "Review: ROC Curve + Model fit",
    "text": "Review: ROC Curve + Model fit\n\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.697"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#review-classification",
    "href": "slides/21-logistic-comparison.html#review-classification",
    "title": "Logistic Regression: Model comparison",
    "section": "Review: Classification",
    "text": "Review: Classification\nWe will use a threshold of 0.2 to classify observations"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#review-classification-1",
    "href": "slides/21-logistic-comparison.html#review-classification-1",
    "title": "Logistic Regression: Model comparison",
    "section": "Review: Classification",
    "text": "Review: Classification\n\n\n\nCompute the misclassification rate.\nCompute sensitivity and explain what it means in the context of the data.\nCompute specificity and explain what it means in the context of the data."
  },
  {
    "objectID": "slides/21-logistic-comparison.html#which-model-do-we-choose",
    "href": "slides/21-logistic-comparison.html#which-model-do-we-choose",
    "title": "Logistic Regression: Model comparison",
    "section": "Which model do we choose?",
    "text": "Which model do we choose?\n\n\n\nModel 1\n\n\n\n\n\n\nterm\nestimate\n\n\n\n\n(Intercept)\n-6.673\n\n\nage\n0.082\n\n\ntotChol\n0.002\n\n\ncurrentSmoker1\n0.443\n\n\n\n\n\n\n\nModel 2\n\n\n\n\n\n\nterm\nestimate\n\n\n\n\n(Intercept)\n-6.456\n\n\nage\n0.080\n\n\ntotChol\n0.002\n\n\ncurrentSmoker1\n0.445\n\n\neducation2\n-0.270\n\n\neducation3\n-0.232\n\n\neducation4\n-0.035"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#log-likelihood",
    "href": "slides/21-logistic-comparison.html#log-likelihood",
    "title": "Logistic Regression: Model comparison",
    "section": "Log-Likelihood",
    "text": "Log-Likelihood\nRecall the log-likelihood function\n\\[\n\\begin{aligned}\n\\log L&(\\boldsymbol{\\beta}|x_1, \\ldots, x_n, y_1, \\dots, y_n) \\\\\n&= \\sum\\limits_{i=1}^n[y_i \\log(\\pi_i) + (1 - y_i)\\log(1 - \\pi_i)]\n\\end{aligned}\n\\]\nwhere \\(\\pi_i = \\frac{\\exp\\{x_i^\\mathsf{T}\\boldsymbol{\\beta}\\}}{1 + \\exp\\{x_i^\\mathsf{T}\\boldsymbol{\\beta}\\}}\\)"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#aic-bic",
    "href": "slides/21-logistic-comparison.html#aic-bic",
    "title": "Logistic Regression: Model comparison",
    "section": "AIC & BIC",
    "text": "AIC & BIC\nEstimators of prediction error and relative quality of models:\n\nAkaike’s Information Criterion (AIC)1: \\[AIC = -2\\log L + 2 (p+1)\\]\n\n\nSchwarz’s Bayesian Information Criterion (BIC)2: \\[ BIC = -2\\log L + \\log(n)\\times(p+1)\\]\n\nAkaike, Hirotugu. “A new look at the statistical model identification.” IEEE transactions on automatic control 19.6 (1974): 716-723.Schwarz, Gideon. “Estimating the dimension of a model.” The annals of statistics (1978): 461-464."
  },
  {
    "objectID": "slides/21-logistic-comparison.html#aic-bic-1",
    "href": "slides/21-logistic-comparison.html#aic-bic-1",
    "title": "Logistic Regression: Model comparison",
    "section": "AIC & BIC",
    "text": "AIC & BIC\n\\[\n\\begin{aligned}\n& AIC = \\color{blue}{-2\\log L}  \\color{black}{+ 2(p+1)} \\\\\n& BIC = \\color{blue}{-2\\log L}  + \\color{black}{\\log(n)\\times(p+1)}\n\\end{aligned}\n\\]\n\n\nFirst Term: Decreases as p increases"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#aic-bic-2",
    "href": "slides/21-logistic-comparison.html#aic-bic-2",
    "title": "Logistic Regression: Model comparison",
    "section": "AIC & BIC",
    "text": "AIC & BIC\n\\[\n\\begin{aligned} & AIC = -2\\log L  + \\color{blue}{2(p+1)} \\\\\n& BIC = -2\\log L + \\color{blue}{\\log(n)\\times (p+1)}\n\\end{aligned}\n\\]\n\nSecond term: Increases as p increases"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#using-aic-bic",
    "href": "slides/21-logistic-comparison.html#using-aic-bic",
    "title": "Logistic Regression: Model comparison",
    "section": "Using AIC & BIC",
    "text": "Using AIC & BIC\n\\[\n\\begin{aligned} & AIC = -2\\log L  + \\color{red}{2(p+1)} \\\\\n& BIC = -2 \\log L  + \\color{red}{\\log(n)\\times(p+1)}\n\\end{aligned}\n\\]\n\nChoose model with the smaller value of AIC or BIC\nIf \\(n \\geq 8\\), the penalty for BIC is larger than that of AIC, so BIC tends to favor more parsimonious models (i.e. models with fewer terms)"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#aic-from-the-glance-function",
    "href": "slides/21-logistic-comparison.html#aic-from-the-glance-function",
    "title": "Logistic Regression: Model comparison",
    "section": "AIC from the glance() function",
    "text": "AIC from the glance() function\nLet’s look at the AIC for the model that includes age, totChol, and currentSmoker\n\nglance(high_risk_fit)$AIC\n\n[1] 3232.812\n\n\n\n\nCalculating AIC\n\n- 2 * glance(high_risk_fit)$logLik + 2 * (3 + 1)\n\n[1] 3232.812"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#comparing-the-models-using-aic",
    "href": "slides/21-logistic-comparison.html#comparing-the-models-using-aic",
    "title": "Logistic Regression: Model comparison",
    "section": "Comparing the models using AIC",
    "text": "Comparing the models using AIC\nLet’s compare the full and reduced models using AIC.\n\nglance(high_risk_fit_reduced)$AIC\n\n[1] 3232.812\n\nglance(high_risk_fit_full)$AIC\n\n[1] 3231.6\n\n\n\n\nBased on AIC, which model would you choose?"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#comparing-the-models-using-bic",
    "href": "slides/21-logistic-comparison.html#comparing-the-models-using-bic",
    "title": "Logistic Regression: Model comparison",
    "section": "Comparing the models using BIC",
    "text": "Comparing the models using BIC\nLet’s compare the full and reduced models using BIC\n\nglance(high_risk_fit_reduced)$BIC\n\n[1] 3258.074\n\nglance(high_risk_fit_full)$BIC\n\n[1] 3275.807\n\n\n\n\nBased on BIC, which model would you choose?"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#drop-in-deviance-test-1",
    "href": "slides/21-logistic-comparison.html#drop-in-deviance-test-1",
    "title": "Logistic Regression: Model comparison",
    "section": "Drop-in-deviance test",
    "text": "Drop-in-deviance test\nWe will use a drop-in-deviance test (aka Likelihood Ratio Test) to test\n\nthe overall statistical significance of a logistic regression model\nthe statistical significance of a subset of coefficients in the model"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#deviance",
    "href": "slides/21-logistic-comparison.html#deviance",
    "title": "Logistic Regression: Model comparison",
    "section": "Deviance",
    "text": "Deviance\nThe deviance is a measure of the degree to which the predicted values are different from the observed values (compares the current model to a “saturated” model)\nIn logistic regression,\n\\[\nD = -2 \\log L\n\\]\n\n\\(D \\sim \\chi^2_{n - p - 1}\\) ( \\(D\\) follows a Chi-square distribution with \\(n - p - 1\\) degrees of freedom)1\n\nNote: \\(n - p - 1\\) a the degrees of freedom associated with the error in the model (like residuals)\nSee Wilks (1935) for explanation of why -2 is included."
  },
  {
    "objectID": "slides/21-logistic-comparison.html#chi2-distribution",
    "href": "slides/21-logistic-comparison.html#chi2-distribution",
    "title": "Logistic Regression: Model comparison",
    "section": "\\(\\chi^2\\) distribution",
    "text": "\\(\\chi^2\\) distribution"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#test-for-overall-significance",
    "href": "slides/21-logistic-comparison.html#test-for-overall-significance",
    "title": "Logistic Regression: Model comparison",
    "section": "Test for overall significance",
    "text": "Test for overall significance\nWe can test the overall significance for a logistic regression model, i.e., whether there is at least one predictor with a non-zero coefficient\n\\[\n\\begin{aligned}\n&H_0: \\beta_1 = \\dots = \\beta_p = 0 \\\\\n&H_a: \\beta_j \\neq 0 \\text{ for at least one } j\n\\end{aligned}\n\\]\n\nThe drop-in-deviance test for overall significance compares the fit of a model with no predictors to the current model."
  },
  {
    "objectID": "slides/21-logistic-comparison.html#drop-in-deviance-test-statistic",
    "href": "slides/21-logistic-comparison.html#drop-in-deviance-test-statistic",
    "title": "Logistic Regression: Model comparison",
    "section": "Drop-in-deviance test statistic",
    "text": "Drop-in-deviance test statistic\nLet \\(L_0\\) and \\(L_a\\) be the likelihood functions of the model under \\(H_0\\) and \\(H_a\\), respectively. The test statistic is\n\\[\n\\begin{aligned}\nG = D_0 - D_a &= (-2\\log L_0) - (-2\\log L_a)\\\\[5pt]\n& = -2(\\log L_0 - \\log L_a) \\\\[5pt]\n&= -2\\sum_{i=1}^n \\Big[ y_i \\log \\Big(\\frac{\\hat{\\pi}^0}{\\hat{\\pi}^a_i}\\Big) + (1 - y_i)\\log \\Big(\\frac{1-\\hat{\\pi}^0}{1-\\hat{\\pi}^a_i}\\Big)\\Big]\n\\end{aligned}\n\\]\nwhere \\(\\hat{\\pi}^0\\) is the predicted probability under \\(H_0\\) and \\(\\hat{\\pi}_i^a = \\frac{\\exp \\{x_i^\\mathsf{T}\\boldsymbol{\\beta}\\}}{1 + \\exp \\{x_i^\\mathsf{T}\\boldsymbol{\\beta}\\}}\\) is the predicted probability under \\(H_a\\) 1\nSee Wilks (1935) for explanation of why -2 is included."
  },
  {
    "objectID": "slides/21-logistic-comparison.html#drop-in-deviance-test-statistic-1",
    "href": "slides/21-logistic-comparison.html#drop-in-deviance-test-statistic-1",
    "title": "Logistic Regression: Model comparison",
    "section": "Drop-in-deviance test statistic",
    "text": "Drop-in-deviance test statistic\n\\[\nG = -2\\sum_{i=1}^n \\Big[ y_i \\log \\Big(\\frac{\\hat{\\pi}^0}{\\hat{\\pi}^a_i}\\Big) + (1 - y_i)\\log \\Big(\\frac{1-\\hat{\\pi}^0}{1-\\hat{\\pi}^a_i}\\Big)\\Big]\n\\]\n\n\n\nWhen \\(n\\) is large, \\(G \\sim \\chi^2_p\\), ( \\(G\\) follows a Chi-square distribution with \\(p\\) degrees of freedom)\nThe p-value is calculated as \\(P(\\chi^2 &gt; G)\\)\nLarge values of \\(G\\) (small p-values) indicate at least one \\(\\beta_j\\) is non-zero"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#heart-disease-model-drop-in-deviance-test",
    "href": "slides/21-logistic-comparison.html#heart-disease-model-drop-in-deviance-test",
    "title": "Logistic Regression: Model comparison",
    "section": "Heart disease model: drop-in-deviance test",
    "text": "Heart disease model: drop-in-deviance test\n\\[\n\\begin{aligned}\n&H_0: \\beta_{age} = \\beta_{totChol} = \\beta_{currentSmoker} = 0 \\\\\n&H_a: \\beta_j \\neq 0 \\text{ for at least one }j\n\\end{aligned}\\]\n\nFit the null model (we’ve already fit the alternative model)\n\nnull_model &lt;- glm(high_risk ~ 1, data = heart_disease, family = \"binomial\")\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-1.72294\n0.0436342\n-39.486\n0"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#heart-disease-model-drop-in-deviance-test-1",
    "href": "slides/21-logistic-comparison.html#heart-disease-model-drop-in-deviance-test-1",
    "title": "Logistic Regression: Model comparison",
    "section": "Heart disease model: drop-in-deviance test",
    "text": "Heart disease model: drop-in-deviance test\nCalculate the log-likelihood for the null and alternative models\n\n(L_0 &lt;- glance(null_model)$logLik)\n\n[1] -1737.735\n\n(L_a &lt;- glance(high_risk_fit)$logLik)\n\n[1] -1612.406\n\n\n\nCalculate the likelihood ratio test statistic\n\n(G &lt;- -2 * (L_0 - L_a))\n\n[1] 250.6572"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#heart-disease-model-likelihood-ratio-test",
    "href": "slides/21-logistic-comparison.html#heart-disease-model-likelihood-ratio-test",
    "title": "Logistic Regression: Model comparison",
    "section": "Heart disease model: likelihood ratio test",
    "text": "Heart disease model: likelihood ratio test\nCalculate the p-value\n\n(p_value &lt;- pchisq(G, df = 3, lower.tail = FALSE))\n\n[1] 4.717158e-54\n\n\n\nConclusion\nThe p-value is small, so we reject \\(H_0\\). The data provide evidence that at least one predictor in the model has a non-zero coefficient."
  },
  {
    "objectID": "slides/21-logistic-comparison.html#why-use-overall-test",
    "href": "slides/21-logistic-comparison.html#why-use-overall-test",
    "title": "Logistic Regression: Model comparison",
    "section": "Why use overall test?",
    "text": "Why use overall test?\nWhy do we use a test for overall significance instead of just looking at the test for individual coefficients?1\n\nSuppose we have a model such that \\(p = 100\\) and \\(H_0: \\beta_1 = \\dots = \\beta_{100} = 0\\) is true\n\n\n\n\nAbout 5% of the p-values for individual coefficients will be below 0.05 by chance.\nSo we expect to see 5 small p-values if even no linear association actually exists.\nTherefore, it is very likely we will see at least one small p-value by chance.\nThe overall test of significance does not have this problem. There is only a 5% chance we will get a p-value below 0.05, if a relationship truly does not exist.\n\n\n\nExample from Introduction to Statistical Learning"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#testing-a-subset-of-coefficients",
    "href": "slides/21-logistic-comparison.html#testing-a-subset-of-coefficients",
    "title": "Logistic Regression: Model comparison",
    "section": "Testing a subset of coefficients",
    "text": "Testing a subset of coefficients\n\nSuppose there are two models:\n\nReduced Model: includes predictors \\(x_1, \\ldots, x_q\\)\nFull Model: includes predictors \\(x_1, \\ldots, x_q, x_{q+1}, \\ldots, x_p\\)\n\nWe can use a drop-in-deviance test to determine if any of the new predictors are useful\n\n\n\\[\n\\begin{aligned}\n&H_0: \\beta_{q+1} = \\dots = \\beta_p = 0\\\\\n&H_a: \\beta_j \\neq 0 \\text{ for at least one }j\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#drop-in-deviance-test-2",
    "href": "slides/21-logistic-comparison.html#drop-in-deviance-test-2",
    "title": "Logistic Regression: Model comparison",
    "section": "Drop-in-deviance test",
    "text": "Drop-in-deviance test\n\\[\n\\begin{aligned}\n&H_0: \\beta_{q+1} = \\dots = \\beta_p = 0\\\\\n&H_a: \\beta_j \\neq 0 \\text{ for at least one }j\n\\end{aligned}\n\\]\n\nThe test statistic is\n\\[\n\\begin{aligned}\nG = D_{reduced} - D_{full} &= (-2\\log L_{reduced}) - (-2 \\log L_{full}) \\\\\n&= -2(\\log L_{reduced} - \\log L_{full})\n\\end{aligned}\n\\]\n\n\nThe p-value is calculated using a \\(\\chi_{\\Delta df}^2\\) distribution, where \\(\\Delta df\\) is the number of parameters being tested (the difference in number of parameters between the full and reduced model)."
  },
  {
    "objectID": "slides/21-logistic-comparison.html#example-include-education",
    "href": "slides/21-logistic-comparison.html#example-include-education",
    "title": "Logistic Regression: Model comparison",
    "section": "Example: Include education?",
    "text": "Example: Include education?\nShould we include education in the model?\n\nReduced model: age, totChol, currentSmoker\nFull model: age, totChol, currentSmoker , education\n\n\n\\[\n\\begin{aligned}\n&H_0: \\beta_{ed2} = \\beta_{ed3} = \\beta_{ed4} = 0 \\\\\n&H_a: \\beta_j \\neq 0 \\text{ for at least one }j\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#example-include-education-1",
    "href": "slides/21-logistic-comparison.html#example-include-education-1",
    "title": "Logistic Regression: Model comparison",
    "section": "Example: Include education?",
    "text": "Example: Include education?\n\nreduced_model &lt;- glm(high_risk ~ age + totChol + currentSmoker, \n              data = heart_disease, family = \"binomial\")\n\nfull_model &lt;- glm(high_risk ~ age + totChol + currentSmoker + education, \n              data = heart_disease, family = \"binomial\")\n\n\nCalculate deviances\n\n(deviance_reduced &lt;- -2 * glance(reduced_model)$logLik)\n\n[1] 3224.812\n\n(deviance_full &lt;- -2 * glance(full_model)$logLik)\n\n[1] 3217.6\n\n\n\n\nCalculate test statistic\n\n(G &lt;- deviance_reduced - deviance_full)\n\n[1] 7.212113"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#example-include-education-2",
    "href": "slides/21-logistic-comparison.html#example-include-education-2",
    "title": "Logistic Regression: Model comparison",
    "section": "Example: Include education?",
    "text": "Example: Include education?\nCalculate p-value\n\npchisq(G, df = 3, lower.tail = FALSE)\n\n[1] 0.06543567\n\n\n\n\n\nWhat is your conclusion? Would you include education in the model that already has age, totChol, currentSmoker?"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#drop-in-deviance-test-in-r",
    "href": "slides/21-logistic-comparison.html#drop-in-deviance-test-in-r",
    "title": "Logistic Regression: Model comparison",
    "section": "Drop-in-deviance test in R",
    "text": "Drop-in-deviance test in R\nConduct the drop-in-deviance test using the anova() function in R with option test = \"Chisq\"\n\nanova(reduced_model, full_model, test = \"Chisq\") |&gt; \n  tidy() |&gt; \n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\nterm\ndf.residual\nresidual.deviance\ndf\ndeviance\np.value\n\n\n\n\nhigh_risk ~ age + totChol + currentSmoker\n4082\n3224.812\nNA\nNA\nNA\n\n\nhigh_risk ~ age + totChol + currentSmoker + education\n4079\n3217.600\n3\n7.212\n0.065"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#add-interactions-with-currentsmoker",
    "href": "slides/21-logistic-comparison.html#add-interactions-with-currentsmoker",
    "title": "Logistic Regression: Model comparison",
    "section": "Add interactions with currentSmoker?",
    "text": "Add interactions with currentSmoker?\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\ndf.residual\nresidual.deviance\ndf\ndeviance\np.value\n\n\n\n\nhigh_risk ~ age + totChol + currentSmoker\n4082\n3224.812\nNA\nNA\nNA\n\n\nhigh_risk ~ age + totChol + currentSmoker + currentSmoker * age + currentSmoker * totChol\n4080\n3222.377\n2\n2.435\n0.296"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#questions-from-this-weeks-content-1",
    "href": "slides/21-logistic-comparison.html#questions-from-this-weeks-content-1",
    "title": "Logistic Regression: Model comparison",
    "section": "Questions from this week’s content?",
    "text": "Questions from this week’s content?"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#recap",
    "href": "slides/21-logistic-comparison.html#recap",
    "title": "Logistic Regression: Model comparison",
    "section": "Recap",
    "text": "Recap\n\nIntroduced model comparison for logistic regression using\n\nAIC and BIC\nDrop-in-deviance test"
  },
  {
    "objectID": "slides/21-logistic-comparison.html#references",
    "href": "slides/21-logistic-comparison.html#references",
    "title": "Logistic Regression: Model comparison",
    "section": "References",
    "text": "References\n\n\n\n\nWilks, SS. 1935. “The Likelihood Test of Independence in Contingency Tables.” The Annals of Mathematical Statistics 6 (4): 190–96."
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html",
    "href": "slides/21-logistic-comparison-notes.html",
    "title": "Logistic Regression: Model comparison",
    "section": "",
    "text": "HW 04 due April 10 - released later today\nTeam Feedback (email from TEAMMATES) due Tuesday, April 8 at 11:59pm (check email)\nNext project milestone: Analysis and draft in April 11 lab\nStatistics experience due April 22"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#announcements",
    "href": "slides/21-logistic-comparison-notes.html#announcements",
    "title": "Logistic Regression: Model comparison",
    "section": "",
    "text": "HW 04 due April 10 - released later today\nTeam Feedback (email from TEAMMATES) due Tuesday, April 8 at 11:59pm (check email)\nNext project milestone: Analysis and draft in April 11 lab\nStatistics experience due April 22"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#questions-from-this-weeks-content",
    "href": "slides/21-logistic-comparison-notes.html#questions-from-this-weeks-content",
    "title": "Logistic Regression: Model comparison",
    "section": "Questions from this week’s content?",
    "text": "Questions from this week’s content?"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#topics",
    "href": "slides/21-logistic-comparison-notes.html#topics",
    "title": "Logistic Regression: Model comparison",
    "section": "Topics",
    "text": "Topics\n\nComparing models using AIC and BIC\nTest of significance for a subset of predictors"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#computational-setup",
    "href": "slides/21-logistic-comparison-notes.html#computational-setup",
    "title": "Logistic Regression: Model comparison",
    "section": "Computational setup",
    "text": "Computational setup\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(pROC)      \nlibrary(knitr)\nlibrary(kableExtra)\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#risk-of-coronary-heart-disease",
    "href": "slides/21-logistic-comparison-notes.html#risk-of-coronary-heart-disease",
    "title": "Logistic Regression: Model comparison",
    "section": "Risk of coronary heart disease",
    "text": "Risk of coronary heart disease\nThis data set is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. We want to examine the relationship between various health characteristics and the risk of having heart disease.\n\nhigh_risk:\n\n1: High risk of having heart disease in next 10 years\n0: Not high risk of having heart disease in next 10 years\n\nage: Age at exam time (in years)\ntotChol: Total cholesterol (in mg/dL)\ncurrentSmoker: 0 = nonsmoker, 1 = smoker\neducation: 1 = Some High School, 2 = High School or GED, 3 = Some College or Vocational School, 4 = College"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#modeling-risk-of-coronary-heart-disease",
    "href": "slides/21-logistic-comparison-notes.html#modeling-risk-of-coronary-heart-disease",
    "title": "Logistic Regression: Model comparison",
    "section": "Modeling risk of coronary heart disease",
    "text": "Modeling risk of coronary heart disease\nUsing age, totChol, and currentSmoker\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-6.673\n0.378\n-17.647\n0.000\n-7.423\n-5.940\n\n\nage\n0.082\n0.006\n14.344\n0.000\n0.071\n0.094\n\n\ntotChol\n0.002\n0.001\n1.940\n0.052\n0.000\n0.004\n\n\ncurrentSmoker1\n0.443\n0.094\n4.733\n0.000\n0.260\n0.627"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#review-roc-curve-model-fit",
    "href": "slides/21-logistic-comparison-notes.html#review-roc-curve-model-fit",
    "title": "Logistic Regression: Model comparison",
    "section": "Review: ROC Curve + Model fit",
    "text": "Review: ROC Curve + Model fit\n\n\n\n\n\n\n\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.697"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#review-classification",
    "href": "slides/21-logistic-comparison-notes.html#review-classification",
    "title": "Logistic Regression: Model comparison",
    "section": "Review: Classification",
    "text": "Review: Classification\nWe will use a threshold of 0.2 to classify observations"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#review-classification-1",
    "href": "slides/21-logistic-comparison-notes.html#review-classification-1",
    "title": "Logistic Regression: Model comparison",
    "section": "Review: Classification",
    "text": "Review: Classification\n\n\n\n\n\n\n\n\n\n\n\nCompute the misclassification rate.\nCompute sensitivity and explain what it means in the context of the data.\nCompute specificity and explain what it means in the context of the data."
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#which-model-do-we-choose",
    "href": "slides/21-logistic-comparison-notes.html#which-model-do-we-choose",
    "title": "Logistic Regression: Model comparison",
    "section": "Which model do we choose?",
    "text": "Which model do we choose?\n\n\n\nModel 1\n\n\n\n\n\n\nterm\nestimate\n\n\n\n\n(Intercept)\n-6.673\n\n\nage\n0.082\n\n\ntotChol\n0.002\n\n\ncurrentSmoker1\n0.443\n\n\n\n\n\n\n\nModel 2\n\n\n\n\n\n\nterm\nestimate\n\n\n\n\n(Intercept)\n-6.456\n\n\nage\n0.080\n\n\ntotChol\n0.002\n\n\ncurrentSmoker1\n0.445\n\n\neducation2\n-0.270\n\n\neducation3\n-0.232\n\n\neducation4\n-0.035"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#log-likelihood",
    "href": "slides/21-logistic-comparison-notes.html#log-likelihood",
    "title": "Logistic Regression: Model comparison",
    "section": "Log-Likelihood",
    "text": "Log-Likelihood\nRecall the log-likelihood function\n\\[\n\\begin{aligned}\n\\log L&(\\boldsymbol{\\beta}|x_1, \\ldots, x_n, y_1, \\dots, y_n) \\\\\n&= \\sum\\limits_{i=1}^n[y_i \\log(\\pi_i) + (1 - y_i)\\log(1 - \\pi_i)]\n\\end{aligned}\n\\]\nwhere \\(\\pi_i = \\frac{\\exp\\{x_i^\\mathsf{T}\\boldsymbol{\\beta}\\}}{1 + \\exp\\{x_i^\\mathsf{T}\\boldsymbol{\\beta}\\}}\\)"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#aic-bic",
    "href": "slides/21-logistic-comparison-notes.html#aic-bic",
    "title": "Logistic Regression: Model comparison",
    "section": "AIC & BIC",
    "text": "AIC & BIC\nEstimators of prediction error and relative quality of models:\n. . .\nAkaike’s Information Criterion (AIC)1: \\[AIC = -2\\log L + 2 (p+1)\\]\n. . .\nSchwarz’s Bayesian Information Criterion (BIC)2: \\[ BIC = -2\\log L + \\log(n)\\times(p+1)\\]"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#aic-bic-1",
    "href": "slides/21-logistic-comparison-notes.html#aic-bic-1",
    "title": "Logistic Regression: Model comparison",
    "section": "AIC & BIC",
    "text": "AIC & BIC\n\\[\n\\begin{aligned}\n& AIC = \\color{blue}{-2\\log L}  \\color{black}{+ 2(p+1)} \\\\\n& BIC = \\color{blue}{-2\\log L}  + \\color{black}{\\log(n)\\times(p+1)}\n\\end{aligned}\n\\]\n. . .\n\nFirst Term: Decreases as p increases"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#aic-bic-2",
    "href": "slides/21-logistic-comparison-notes.html#aic-bic-2",
    "title": "Logistic Regression: Model comparison",
    "section": "AIC & BIC",
    "text": "AIC & BIC\n\\[\n\\begin{aligned} & AIC = -2\\log L  + \\color{blue}{2(p+1)} \\\\\n& BIC = -2\\log L + \\color{blue}{\\log(n)\\times (p+1)}\n\\end{aligned}\n\\]\n\nSecond term: Increases as p increases"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#using-aic-bic",
    "href": "slides/21-logistic-comparison-notes.html#using-aic-bic",
    "title": "Logistic Regression: Model comparison",
    "section": "Using AIC & BIC",
    "text": "Using AIC & BIC\n\\[\n\\begin{aligned} & AIC = -2\\log L  + \\color{red}{2(p+1)} \\\\\n& BIC = -2 \\log L  + \\color{red}{\\log(n)\\times(p+1)}\n\\end{aligned}\n\\]\n\nChoose model with the smaller value of AIC or BIC\nIf \\(n \\geq 8\\), the penalty for BIC is larger than that of AIC, so BIC tends to favor more parsimonious models (i.e. models with fewer terms)"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#aic-from-the-glance-function",
    "href": "slides/21-logistic-comparison-notes.html#aic-from-the-glance-function",
    "title": "Logistic Regression: Model comparison",
    "section": "AIC from the glance() function",
    "text": "AIC from the glance() function\nLet’s look at the AIC for the model that includes age, totChol, and currentSmoker\n\nglance(high_risk_fit)$AIC\n\n[1] 3232.812\n\n\n\n. . .\nCalculating AIC\n\n- 2 * glance(high_risk_fit)$logLik + 2 * (3 + 1)\n\n[1] 3232.812"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#comparing-the-models-using-aic",
    "href": "slides/21-logistic-comparison-notes.html#comparing-the-models-using-aic",
    "title": "Logistic Regression: Model comparison",
    "section": "Comparing the models using AIC",
    "text": "Comparing the models using AIC\nLet’s compare the full and reduced models using AIC.\n\nglance(high_risk_fit_reduced)$AIC\n\n[1] 3232.812\n\nglance(high_risk_fit_full)$AIC\n\n[1] 3231.6\n\n\n\n\nBased on AIC, which model would you choose?"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#comparing-the-models-using-bic",
    "href": "slides/21-logistic-comparison-notes.html#comparing-the-models-using-bic",
    "title": "Logistic Regression: Model comparison",
    "section": "Comparing the models using BIC",
    "text": "Comparing the models using BIC\nLet’s compare the full and reduced models using BIC\n\nglance(high_risk_fit_reduced)$BIC\n\n[1] 3258.074\n\nglance(high_risk_fit_full)$BIC\n\n[1] 3275.807\n\n\n\n\nBased on BIC, which model would you choose?"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#drop-in-deviance-test-1",
    "href": "slides/21-logistic-comparison-notes.html#drop-in-deviance-test-1",
    "title": "Logistic Regression: Model comparison",
    "section": "Drop-in-deviance test",
    "text": "Drop-in-deviance test\nWe will use a drop-in-deviance test (aka Likelihood Ratio Test) to test\n\nthe overall statistical significance of a logistic regression model\nthe statistical significance of a subset of coefficients in the model"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#deviance",
    "href": "slides/21-logistic-comparison-notes.html#deviance",
    "title": "Logistic Regression: Model comparison",
    "section": "Deviance",
    "text": "Deviance\nThe deviance is a measure of the degree to which the predicted values are different from the observed values (compares the current model to a “saturated” model)\nIn logistic regression,\n\\[\nD = -2 \\log L\n\\]\n\n\\(D \\sim \\chi^2_{n - p - 1}\\) ( \\(D\\) follows a Chi-square distribution with \\(n - p - 1\\) degrees of freedom)3\n\nNote: \\(n - p - 1\\) a the degrees of freedom associated with the error in the model (like residuals)"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#chi2-distribution",
    "href": "slides/21-logistic-comparison-notes.html#chi2-distribution",
    "title": "Logistic Regression: Model comparison",
    "section": "\\(\\chi^2\\) distribution",
    "text": "\\(\\chi^2\\) distribution"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#test-for-overall-significance",
    "href": "slides/21-logistic-comparison-notes.html#test-for-overall-significance",
    "title": "Logistic Regression: Model comparison",
    "section": "Test for overall significance",
    "text": "Test for overall significance\nWe can test the overall significance for a logistic regression model, i.e., whether there is at least one predictor with a non-zero coefficient\n\\[\n\\begin{aligned}\n&H_0: \\beta_1 = \\dots = \\beta_p = 0 \\\\\n&H_a: \\beta_j \\neq 0 \\text{ for at least one } j\n\\end{aligned}\n\\]\n. . .\nThe drop-in-deviance test for overall significance compares the fit of a model with no predictors to the current model."
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#drop-in-deviance-test-statistic",
    "href": "slides/21-logistic-comparison-notes.html#drop-in-deviance-test-statistic",
    "title": "Logistic Regression: Model comparison",
    "section": "Drop-in-deviance test statistic",
    "text": "Drop-in-deviance test statistic\nLet \\(L_0\\) and \\(L_a\\) be the likelihood functions of the model under \\(H_0\\) and \\(H_a\\), respectively. The test statistic is\n\\[\n\\begin{aligned}\nG = D_0 - D_a &= (-2\\log L_0) - (-2\\log L_a)\\\\[5pt]\n& = -2(\\log L_0 - \\log L_a) \\\\[5pt]\n&= -2\\sum_{i=1}^n \\Big[ y_i \\log \\Big(\\frac{\\hat{\\pi}^0}{\\hat{\\pi}^a_i}\\Big) + (1 - y_i)\\log \\Big(\\frac{1-\\hat{\\pi}^0}{1-\\hat{\\pi}^a_i}\\Big)\\Big]\n\\end{aligned}\n\\]\nwhere \\(\\hat{\\pi}^0\\) is the predicted probability under \\(H_0\\) and \\(\\hat{\\pi}_i^a = \\frac{\\exp \\{x_i^\\mathsf{T}\\boldsymbol{\\beta}\\}}{1 + \\exp \\{x_i^\\mathsf{T}\\boldsymbol{\\beta}\\}}\\) is the predicted probability under \\(H_a\\) 4"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#drop-in-deviance-test-statistic-1",
    "href": "slides/21-logistic-comparison-notes.html#drop-in-deviance-test-statistic-1",
    "title": "Logistic Regression: Model comparison",
    "section": "Drop-in-deviance test statistic",
    "text": "Drop-in-deviance test statistic\n\\[\nG = -2\\sum_{i=1}^n \\Big[ y_i \\log \\Big(\\frac{\\hat{\\pi}^0}{\\hat{\\pi}^a_i}\\Big) + (1 - y_i)\\log \\Big(\\frac{1-\\hat{\\pi}^0}{1-\\hat{\\pi}^a_i}\\Big)\\Big]\n\\]\n. . .\n\n\nWhen \\(n\\) is large, \\(G \\sim \\chi^2_p\\), ( \\(G\\) follows a Chi-square distribution with \\(p\\) degrees of freedom)\nThe p-value is calculated as \\(P(\\chi^2 &gt; G)\\)\nLarge values of \\(G\\) (small p-values) indicate at least one \\(\\beta_j\\) is non-zero"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#heart-disease-model-drop-in-deviance-test",
    "href": "slides/21-logistic-comparison-notes.html#heart-disease-model-drop-in-deviance-test",
    "title": "Logistic Regression: Model comparison",
    "section": "Heart disease model: drop-in-deviance test",
    "text": "Heart disease model: drop-in-deviance test\n\\[\n\\begin{aligned}\n&H_0: \\beta_{age} = \\beta_{totChol} = \\beta_{currentSmoker} = 0 \\\\\n&H_a: \\beta_j \\neq 0 \\text{ for at least one }j\n\\end{aligned}\\]\n. . .\nFit the null model (we’ve already fit the alternative model)\n\nnull_model &lt;- glm(high_risk ~ 1, data = heart_disease, family = \"binomial\")\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-1.72294\n0.0436342\n-39.486\n0"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#heart-disease-model-drop-in-deviance-test-1",
    "href": "slides/21-logistic-comparison-notes.html#heart-disease-model-drop-in-deviance-test-1",
    "title": "Logistic Regression: Model comparison",
    "section": "Heart disease model: drop-in-deviance test",
    "text": "Heart disease model: drop-in-deviance test\nCalculate the log-likelihood for the null and alternative models\n\n(L_0 &lt;- glance(null_model)$logLik)\n\n[1] -1737.735\n\n(L_a &lt;- glance(high_risk_fit)$logLik)\n\n[1] -1612.406\n\n\n. . .\nCalculate the likelihood ratio test statistic\n\n(G &lt;- -2 * (L_0 - L_a))\n\n[1] 250.6572\n\n\n. . ."
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#heart-disease-model-likelihood-ratio-test",
    "href": "slides/21-logistic-comparison-notes.html#heart-disease-model-likelihood-ratio-test",
    "title": "Logistic Regression: Model comparison",
    "section": "Heart disease model: likelihood ratio test",
    "text": "Heart disease model: likelihood ratio test\nCalculate the p-value\n\n(p_value &lt;- pchisq(G, df = 3, lower.tail = FALSE))\n\n[1] 4.717158e-54\n\n\n. . .\nConclusion\nThe p-value is small, so we reject \\(H_0\\). The data provide evidence that at least one predictor in the model has a non-zero coefficient."
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#why-use-overall-test",
    "href": "slides/21-logistic-comparison-notes.html#why-use-overall-test",
    "title": "Logistic Regression: Model comparison",
    "section": "Why use overall test?",
    "text": "Why use overall test?\nWhy do we use a test for overall significance instead of just looking at the test for individual coefficients?5\n. . .\nSuppose we have a model such that \\(p = 100\\) and \\(H_0: \\beta_1 = \\dots = \\beta_{100} = 0\\) is true\n. . .\n\n\nAbout 5% of the p-values for individual coefficients will be below 0.05 by chance.\nSo we expect to see 5 small p-values if even no linear association actually exists.\nTherefore, it is very likely we will see at least one small p-value by chance.\nThe overall test of significance does not have this problem. There is only a 5% chance we will get a p-value below 0.05, if a relationship truly does not exist."
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#testing-a-subset-of-coefficients",
    "href": "slides/21-logistic-comparison-notes.html#testing-a-subset-of-coefficients",
    "title": "Logistic Regression: Model comparison",
    "section": "Testing a subset of coefficients",
    "text": "Testing a subset of coefficients\n\nSuppose there are two models:\n\nReduced Model: includes predictors \\(x_1, \\ldots, x_q\\)\nFull Model: includes predictors \\(x_1, \\ldots, x_q, x_{q+1}, \\ldots, x_p\\)\n\nWe can use a drop-in-deviance test to determine if any of the new predictors are useful\n\n. . .\n\\[\n\\begin{aligned}\n&H_0: \\beta_{q+1} = \\dots = \\beta_p = 0\\\\\n&H_a: \\beta_j \\neq 0 \\text{ for at least one }j\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#drop-in-deviance-test-2",
    "href": "slides/21-logistic-comparison-notes.html#drop-in-deviance-test-2",
    "title": "Logistic Regression: Model comparison",
    "section": "Drop-in-deviance test",
    "text": "Drop-in-deviance test\n\\[\n\\begin{aligned}\n&H_0: \\beta_{q+1} = \\dots = \\beta_p = 0\\\\\n&H_a: \\beta_j \\neq 0 \\text{ for at least one }j\n\\end{aligned}\n\\]\n. . .\nThe test statistic is\n\\[\n\\begin{aligned}\nG = D_{reduced} - D_{full} &= (-2\\log L_{reduced}) - (-2 \\log L_{full}) \\\\\n&= -2(\\log L_{reduced} - \\log L_{full})\n\\end{aligned}\n\\]\n. . .\nThe p-value is calculated using a \\(\\chi_{\\Delta df}^2\\) distribution, where \\(\\Delta df\\) is the number of parameters being tested (the difference in number of parameters between the full and reduced model)."
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#example-include-education",
    "href": "slides/21-logistic-comparison-notes.html#example-include-education",
    "title": "Logistic Regression: Model comparison",
    "section": "Example: Include education?",
    "text": "Example: Include education?\nShould we include education in the model?\n\nReduced model: age, totChol, currentSmoker\nFull model: age, totChol, currentSmoker , education\n\n. . .\n\\[\n\\begin{aligned}\n&H_0: \\beta_{ed2} = \\beta_{ed3} = \\beta_{ed4} = 0 \\\\\n&H_a: \\beta_j \\neq 0 \\text{ for at least one }j\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#example-include-education-1",
    "href": "slides/21-logistic-comparison-notes.html#example-include-education-1",
    "title": "Logistic Regression: Model comparison",
    "section": "Example: Include education?",
    "text": "Example: Include education?\n\nreduced_model &lt;- glm(high_risk ~ age + totChol + currentSmoker, \n              data = heart_disease, family = \"binomial\")\n\nfull_model &lt;- glm(high_risk ~ age + totChol + currentSmoker + education, \n              data = heart_disease, family = \"binomial\")\n\n. . .\nCalculate deviances\n\n(deviance_reduced &lt;- -2 * glance(reduced_model)$logLik)\n\n[1] 3224.812\n\n(deviance_full &lt;- -2 * glance(full_model)$logLik)\n\n[1] 3217.6\n\n\n. . .\nCalculate test statistic\n\n(G &lt;- deviance_reduced - deviance_full)\n\n[1] 7.212113"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#example-include-education-2",
    "href": "slides/21-logistic-comparison-notes.html#example-include-education-2",
    "title": "Logistic Regression: Model comparison",
    "section": "Example: Include education?",
    "text": "Example: Include education?\nCalculate p-value\n\npchisq(G, df = 3, lower.tail = FALSE)\n\n[1] 0.06543567\n\n\n\n. . .\n\nWhat is your conclusion? Would you include education in the model that already has age, totChol, currentSmoker?"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#drop-in-deviance-test-in-r",
    "href": "slides/21-logistic-comparison-notes.html#drop-in-deviance-test-in-r",
    "title": "Logistic Regression: Model comparison",
    "section": "Drop-in-deviance test in R",
    "text": "Drop-in-deviance test in R\nConduct the drop-in-deviance test using the anova() function in R with option test = \"Chisq\"\n\nanova(reduced_model, full_model, test = \"Chisq\") |&gt; \n  tidy() |&gt; \n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\nterm\ndf.residual\nresidual.deviance\ndf\ndeviance\np.value\n\n\n\n\nhigh_risk ~ age + totChol + currentSmoker\n4082\n3224.812\nNA\nNA\nNA\n\n\nhigh_risk ~ age + totChol + currentSmoker + education\n4079\n3217.600\n3\n7.212\n0.065"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#add-interactions-with-currentsmoker",
    "href": "slides/21-logistic-comparison-notes.html#add-interactions-with-currentsmoker",
    "title": "Logistic Regression: Model comparison",
    "section": "Add interactions with currentSmoker?",
    "text": "Add interactions with currentSmoker?\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\ndf.residual\nresidual.deviance\ndf\ndeviance\np.value\n\n\n\n\nhigh_risk ~ age + totChol + currentSmoker\n4082\n3224.812\nNA\nNA\nNA\n\n\nhigh_risk ~ age + totChol + currentSmoker + currentSmoker * age + currentSmoker * totChol\n4080\n3222.377\n2\n2.435\n0.296"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#questions-from-this-weeks-content-1",
    "href": "slides/21-logistic-comparison-notes.html#questions-from-this-weeks-content-1",
    "title": "Logistic Regression: Model comparison",
    "section": "Questions from this week’s content?",
    "text": "Questions from this week’s content?"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#recap",
    "href": "slides/21-logistic-comparison-notes.html#recap",
    "title": "Logistic Regression: Model comparison",
    "section": "Recap",
    "text": "Recap\n\nIntroduced model comparison for logistic regression using\n\nAIC and BIC\nDrop-in-deviance test"
  },
  {
    "objectID": "slides/21-logistic-comparison-notes.html#footnotes",
    "href": "slides/21-logistic-comparison-notes.html#footnotes",
    "title": "Logistic Regression: Model comparison",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAkaike, Hirotugu. “A new look at the statistical model identification.” IEEE transactions on automatic control 19.6 (1974): 716-723.↩︎\nSchwarz, Gideon. “Estimating the dimension of a model.” The annals of statistics (1978): 461-464.↩︎\nSee Wilks (1935) for explanation of why -2 is included.↩︎\nSee Wilks (1935) for explanation of why -2 is included.↩︎\nExample from Introduction to Statistical Learning↩︎"
  },
  {
    "objectID": "slides/16-mle.html#announcements",
    "href": "slides/16-mle.html#announcements",
    "title": "Maximum likelihood estimation",
    "section": "Announcements",
    "text": "Announcements\n\nHW 03 due March 20 at 11:59pm\nProject exploratory data analysis due March 20 at 11:59pm\n\nNext milestone: Project presentations in lab March 28\n\nStatistics experience due April 22"
  },
  {
    "objectID": "slides/16-mle.html#topics",
    "href": "slides/16-mle.html#topics",
    "title": "Maximum likelihood estimation",
    "section": "Topics",
    "text": "Topics\n\nLikelihood\nMaximum likelihood estimation (MLE)\nMLE for linear regression"
  },
  {
    "objectID": "slides/16-mle.html#motivation",
    "href": "slides/16-mle.html#motivation",
    "title": "Maximum likelihood estimation",
    "section": "Motivation",
    "text": "Motivation\n\nWe’ve discussed how to find the estimators of \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2_{\\epsilon}\\) for the model\n\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}, \\hspace{10mm} \\boldsymbol{\\epsilon} \\sim N(0, \\sigma^2_\\epsilon\\mathbf{I})\n\\]using least-squares estimation\n\nToday we will introduce another way to find these estimators - maximum likelihood estimation.\nWe will see the least-squares estimator is equal to the maximum likelihood estimator when certain assumptions hold"
  },
  {
    "objectID": "slides/16-mle.html#example-basketball-shots",
    "href": "slides/16-mle.html#example-basketball-shots",
    "title": "Maximum likelihood estimation",
    "section": "Example: Basketball shots",
    "text": "Example: Basketball shots\nSuppose the a basketball player shoots the ball, such that the probability of making the basket (successfully making the shot) is \\(p\\)\n\n\n\nWhat is the probability distribution for this random phenomenon?\nSuppose the probability is \\(p = 0.5\\). What is the probability the player makes a single basket, given this value of \\(p\\)?\nSuppose the probability is \\(p = 0.8\\). What is the probability the player makes a single basket, given this value of \\(p\\)?"
  },
  {
    "objectID": "slides/16-mle.html#shooting-the-ball-three-times",
    "href": "slides/16-mle.html#shooting-the-ball-three-times",
    "title": "Maximum likelihood estimation",
    "section": "Shooting the ball three times",
    "text": "Shooting the ball three times\nSuppose the player shoots the ball three times. They are all independent and the player has the same probability \\(p\\) of making each basket.\nLet \\(B\\) represent a made basket, and \\(M\\) represent a missed basket. The player shoots the ball three times with the outcome \\(BBM\\).\n\n\n\nSuppose the probability is \\(p = 0.5\\). What is the probability of observing the data \\(BBM\\), given this value of \\(p\\)?\nSuppose the probability is \\(p = 0.3\\). What is the probability of observing the data \\(BBM\\), given this value of \\(p\\) ?"
  },
  {
    "objectID": "slides/16-mle.html#shooting-the-ball-three-times-1",
    "href": "slides/16-mle.html#shooting-the-ball-three-times-1",
    "title": "Maximum likelihood estimation",
    "section": "Shooting the ball three times",
    "text": "Shooting the ball three times\nSuppose the player shoots the ball three times. They are all independent and the player has the same probability \\(p\\) of making each basket.\nThe player shoots the ball three times with the outcome \\(BBM\\).\n\n\n\nNew question: What parameter value of \\(p\\) do you think maximizes the probability of observing this data?\nWe will use a likelihood function to answer this question."
  },
  {
    "objectID": "slides/16-mle.html#likelihood",
    "href": "slides/16-mle.html#likelihood",
    "title": "Maximum likelihood estimation",
    "section": "Likelihood",
    "text": "Likelihood\n\n\nA likelihood function is a measure of how likely we are to observe our data under each possible value of the parameter(s)\nNote that this is not the same as the probability function.\nProbability function: Fixed parameter value(s) + input possible outcomes\n\nGiven \\(p=0.8\\) , what is the probability of observing \\(BBM\\) in three basketball shots?\n\nLikelihood function: Fixed data + input possible parameter values\n\nGiven we’ve observed \\(BBM\\), what is the most plausible value of \\(p\\)?"
  },
  {
    "objectID": "slides/16-mle.html#likelihood-three-basketball-shots",
    "href": "slides/16-mle.html#likelihood-three-basketball-shots",
    "title": "Maximum likelihood estimation",
    "section": "Likelihood: Three basketball shots",
    "text": "Likelihood: Three basketball shots\nThe likelihood function for the probability of a basket \\(p\\) given we observed \\(BBM\\) when shooting the ball three independent times \\[\nL(p|BBM) = p \\times p \\times (1 - p)\n\\]\n\n\nThus, if the likelihood for \\(p = 0.8\\) is\n\\[\nL(p = 0.8|BBM) = 0.8 \\times 0.8 \\times (1 - 0.8) = 0.128\n\\]"
  },
  {
    "objectID": "slides/16-mle.html#likelihood-three-basketball-shots-1",
    "href": "slides/16-mle.html#likelihood-three-basketball-shots-1",
    "title": "Maximum likelihood estimation",
    "section": "Likelihood: Three basketball shots",
    "text": "Likelihood: Three basketball shots\n\n\n\nWhat is the general formula for the likelihood function for \\(p\\) given the observed data \\(BBM\\)?\nHow does assuming independence simplify things?\nHow does having identically distributed data simplify things?"
  },
  {
    "objectID": "slides/16-mle.html#likelihood-three-basketball-shots-2",
    "href": "slides/16-mle.html#likelihood-three-basketball-shots-2",
    "title": "Maximum likelihood estimation",
    "section": "Likelihood: Three basketball shots",
    "text": "Likelihood: Three basketball shots\nThe likelihood function for \\(p\\) given the data \\(BBM\\) is\n\\[\nL(p|BBM) = p \\times p \\times (1 - p) = p^2 \\times (1 - p)\n\\]\n\n\n\nWe want of the value of \\(p\\) that maximizes this likelihood function, i.e., the value of \\(p\\) that is most likely given the observed data.\nThe process of finding this value is maximum likelihood estimation.\nThere are three primary ways to find the maximum likelihood estimator\n\nApproximate using a graph\nUsing calculus\nNumerical approximation"
  },
  {
    "objectID": "slides/16-mle.html#finding-the-mle-using-graphs",
    "href": "slides/16-mle.html#finding-the-mle-using-graphs",
    "title": "Maximum likelihood estimation",
    "section": "Finding the MLE using graphs",
    "text": "Finding the MLE using graphs\n\n\nWhat do you think is the approximate value of the MLE of \\(p\\) given the data?"
  },
  {
    "objectID": "slides/16-mle.html#finding-the-mle-using-calculus",
    "href": "slides/16-mle.html#finding-the-mle-using-calculus",
    "title": "Maximum likelihood estimation",
    "section": "Finding the MLE using calculus",
    "text": "Finding the MLE using calculus\n\nFind the MLE using the first derivative of the likelihood function.\n\n\n\nThis can be tricky because of the product rule, so we can maximize the log(Likelihood) instead. The same value maximizes the likelihood and log(Likelihood).\n\n\nUse calculus to find the MLE of \\(p\\) given the data \\(BBM\\)."
  },
  {
    "objectID": "slides/16-mle.html#shooting-the-ball-n-times",
    "href": "slides/16-mle.html#shooting-the-ball-n-times",
    "title": "Maximum likelihood estimation",
    "section": "Shooting the ball \\(n\\) times",
    "text": "Shooting the ball \\(n\\) times\nSuppose the player shoots the ball \\(n\\) times. They are all independent and the player has the same probability \\(p\\) of making each one.\nSuppose the player makes \\(k\\) baskets out of the \\(n\\) shots. This is the observed data.\n\n\n\nWhat is the formula for the probability distribution to describe this random phenomenon?\nWhat is the formula for the likelihood function for \\(p\\) given the observed data?\nFor what value of \\(p\\) do we maximize the likelihood given the observed data? Use calculus to find the response."
  },
  {
    "objectID": "slides/16-mle.html#why-maximum-likelihood-estimation",
    "href": "slides/16-mle.html#why-maximum-likelihood-estimation",
    "title": "Maximum likelihood estimation",
    "section": "Why maximum likelihood estimation?",
    "text": "Why maximum likelihood estimation?\n\n“Maximum likelihood estimation is, by far, the most popular technique for deriving estimators.” (Casella and Berger 2024, 315)\nMLEs have nice statistical properties (more on this next class)\n\nConsistent\nEfficient\nAsymptotically normal\n\n\n\n\n\n\n\n\n\nNote\n\n\nIf the normality assumption holds, the least squares estimator is the maximum likelihood estimator for \\(\\beta\\). Therefore, it has all the properties of the MLE."
  },
  {
    "objectID": "slides/16-mle.html#linear-regression",
    "href": "slides/16-mle.html#linear-regression",
    "title": "Maximum likelihood estimation",
    "section": "Linear regression",
    "text": "Linear regression\nRecall the linear model\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}, \\hspace{10mm} \\boldsymbol{\\epsilon} \\sim N(\\mathbf{0}, \\sigma^2_{\\epsilon}\\mathbf{I})\n\\]\n\n\n\nWe have discussed least-squares estimation to find \\(\\hat{\\boldsymbol{\\beta}}\\) and \\(\\hat{\\sigma}_\\epsilon^2\\)\nWe have used the fact that \\(\\hat{\\boldsymbol{\\beta}} \\sim N(\\boldsymbol{\\beta}, \\sigma^2_{\\epsilon}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1})\\) when doing hypothesis testing and confidence intervals.\nNow we will discuss how we know \\(\\hat{\\boldsymbol{\\beta}}\\) is normally distributed, as we introduce MLE for linear regression"
  },
  {
    "objectID": "slides/16-mle.html#simple-linear-regression-model",
    "href": "slides/16-mle.html#simple-linear-regression-model",
    "title": "Maximum likelihood estimation",
    "section": "Simple linear regression model",
    "text": "Simple linear regression model\nSuppose we have the simple linear regression (SLR) model\n\\[\ny_i = \\beta_0 + \\beta_1x_i + \\epsilon_i, \\hspace{10mm} \\epsilon_i \\sim N(0, \\sigma^2_{\\epsilon})\n\\]\nsuch that \\(\\epsilon_i\\) are independently and identically distributed.\n\n\nWe can write this model in the form below and use this to find the MLE\n\\[\ny_i | x_i \\sim N(\\beta_0 + \\beta_1 x_i, \\sigma^2_{\\epsilon})\n\\]"
  },
  {
    "objectID": "slides/16-mle.html#side-note-normal-distribution",
    "href": "slides/16-mle.html#side-note-normal-distribution",
    "title": "Maximum likelihood estimation",
    "section": "Side note: Normal distribution",
    "text": "Side note: Normal distribution\nLet \\(Z\\) be a random variable, such that \\(Z \\sim N(\\mu, \\sigma^2)\\). Then the probability function is\n\\[\nP(Z = z | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\Big\\{-{\\frac{1}{2\\sigma^2}(z - \\mu)^2}\\Big\\}\n\\]"
  },
  {
    "objectID": "slides/16-mle.html#slr-likelihood-for-beta_0-beta_1-sigma2_epsilon",
    "href": "slides/16-mle.html#slr-likelihood-for-beta_0-beta_1-sigma2_epsilon",
    "title": "Maximum likelihood estimation",
    "section": "SLR: Likelihood for \\(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon}\\)",
    "text": "SLR: Likelihood for \\(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon}\\)\nThe likelihood function for \\(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon}\\) is\n\\[\n\\begin{aligned}\nL(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon} &| x_1, \\ldots, x_n, y_1, \\ldots, y_n) \\\\ &= p(y_1|x_1, \\beta_0, \\beta_1, \\sigma^2_{\\epsilon}) \\dots  p(y_n|x_n, \\beta_0, \\beta_1, \\sigma^2_{\\epsilon}) \\\\[5pt]\n& = \\class{fragment}{\\prod_{i=1}^n p(y_i | x_i, \\beta_0, \\beta_1, \\sigma^2_{\\epsilon})} \\\\[5pt]\n&= \\class{fragment}{\\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma_\n\\epsilon^2}}\\exp\\Big\\{{-\\frac{1}{2\\sigma_\\epsilon^2}(y_i - [\\beta_0 + \\beta_1x_i])^2}\\Big\\}} \\\\[10pt]\n& = \\class{fragment}{(2\\pi\\sigma^2_{\\epsilon})^{-\\frac{n}{2}}\\exp\\Big\\{-\\frac{1}{2\\sigma^2_{\\epsilon}}\\sum_{i=1}^n(y_i - \\beta_0 - \\beta_1x_i)^2\\Big\\}}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/16-mle.html#log-likelihood-for-beta_0-beta_1-sigma2_epsilon",
    "href": "slides/16-mle.html#log-likelihood-for-beta_0-beta_1-sigma2_epsilon",
    "title": "Maximum likelihood estimation",
    "section": "Log-Likelihood for \\(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon}\\)",
    "text": "Log-Likelihood for \\(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon}\\)\nThe log-likelihood function for \\(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon}\\) is\n\\[\n\\begin{aligned}\n\\log &L(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon} | x_1, \\ldots, x_n, y_1, \\ldots, y_n) \\\\[8pt]\n& = \\class{fragment}{\\log\\Big((2\\pi\\sigma^2_{\\epsilon})^{-\\frac{n}{2}}\\exp\\Big\\{-\\frac{1}{2\\sigma^2_{\\epsilon}}\\sum_{i=1}^n(y_i - \\beta_0 - \\beta_1x_i)^2\\Big\\}\\Big)} \\\\[8pt]\n& = \\class{fragment}{-\\frac{n}{2}\\log(2\\pi\\sigma^2_{\\epsilon}) -\\frac{1}{2\\sigma^2_{\\epsilon}}\\sum_{i=1}^n(y_i - \\beta_0 - \\beta_1x_i)^2}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/16-mle.html#mle-for-beta_0",
    "href": "slides/16-mle.html#mle-for-beta_0",
    "title": "Maximum likelihood estimation",
    "section": "MLE for \\(\\beta_0\\)",
    "text": "MLE for \\(\\beta_0\\)\n1️⃣ Take derivative of \\(\\log L\\) with respect to \\(\\beta_0\\) and set it equal to 0\n\\[\n\\frac{\\partial \\log L}{\\partial \\beta_0} = -\\frac{2}{2\\sigma^2_\\epsilon}\\sum_{i=1}^n (y_i - \\beta_0 - \\beta_1x_i)(-1) = 0\n\\]"
  },
  {
    "objectID": "slides/16-mle.html#mle-for-beta_0-1",
    "href": "slides/16-mle.html#mle-for-beta_0-1",
    "title": "Maximum likelihood estimation",
    "section": "MLE for \\(\\beta_0\\)",
    "text": "MLE for \\(\\beta_0\\)\n2️⃣ Find the \\(\\tilde{\\beta}_0\\) that satisfies the equality on the previous slide\n\nAfter a few steps…\n\\[\n\\begin{aligned}\n&\\Rightarrow \\class{fragment}{\\sum_{i=1}^ny_i - n\\tilde{\\beta}_0 - \\tilde{\\beta}_1\\sum_{i=1}^n x_i = 0} \\\\[8pt]\n&\\Rightarrow \\class{fragment}{\\sum_{i=1}^ny_i  - \\tilde{\\beta}_1\\sum_{i=1}^n x_i = n\\tilde{\\beta}_0} \\\\[8pt]\n&\\Rightarrow \\class{fragment}{ \\frac{1}{n}\\sum_{i=1}^ny_i  - \\frac{1}{n}\\tilde{\\beta}_1\\sum_{i=1}^n x_i = \\tilde{\\beta}_0}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/16-mle.html#mle-for-beta_0-2",
    "href": "slides/16-mle.html#mle-for-beta_0-2",
    "title": "Maximum likelihood estimation",
    "section": "MLE for \\(\\beta_0\\)",
    "text": "MLE for \\(\\beta_0\\)\n3️⃣ We can use the second derivative to show we’ve found the maximum\n\\[\n\\frac{\\partial^2 \\log L}{\\partial \\beta_0^2} = -\\frac{n}{2\\tilde{\\sigma}^2_\\epsilon}  &lt; 0\n\\]\n\n\nTherefore, we have found the maximum. Thus, MLE for \\(\\beta_0\\) is\n\\[\n\\tilde{\\beta}_0 = \\bar{y} - \\tilde{\\beta}_1\\bar{x}\n\\]\n\n\nNote that \\(\\tilde{\\beta}_0\\) is equal to \\(\\hat{\\beta}_0\\), the least-squares estimate"
  },
  {
    "objectID": "slides/16-mle.html#mle-for-beta_1-and-sigma2_epsilon",
    "href": "slides/16-mle.html#mle-for-beta_1-and-sigma2_epsilon",
    "title": "Maximum likelihood estimation",
    "section": "MLE for \\(\\beta_1\\) and \\(\\sigma^2_{\\epsilon}\\)",
    "text": "MLE for \\(\\beta_1\\) and \\(\\sigma^2_{\\epsilon}\\)\nWe can use a similar process to find the MLEs for \\(\\beta_1\\) and \\(\\sigma^2_{\\epsilon}\\)\n\\[\n\\tilde{\\beta}_1 = \\frac{\\sum_{i=1}^n (y_i - \\bar{y})(x_i - \\bar{x})}{\\sum_{i=1}^n(x_i - \\bar{x})^2}\n\\] \n\n\\[\n\\tilde{\\sigma}^2_{\\epsilon} = \\frac{\\sum_{i=1}^n(y_i - \\tilde{\\beta}_0 - \\tilde{\\beta}_1x_i)^2}{n} = \\frac{\\sum_{i=1}^ne_i^2}{n}\n\\]\n\n\nNote: \\(\\tilde{\\beta}_1 = \\hat{\\beta}_1\\) and \\(\\tilde{\\sigma}^2_{\\epsilon} \\approx \\hat{\\sigma}^2_{\\epsilon}\\)"
  },
  {
    "objectID": "slides/16-mle.html#mle-for-linear-regression-in-matrix-form",
    "href": "slides/16-mle.html#mle-for-linear-regression-in-matrix-form",
    "title": "Maximum likelihood estimation",
    "section": "MLE for linear regression in matrix form",
    "text": "MLE for linear regression in matrix form\n\\[\nL(\\boldsymbol{\\beta}, \\sigma^2_{\\epsilon} | \\mathbf{X}, \\mathbf{y}) = \\frac{1}{(2\\pi)^{n/2}\\sigma^n_{\\epsilon}}\\exp\\Big\\{-\\frac{1}{2\\sigma^2_{\\epsilon}}(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^\\mathsf{T}(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\Big\\}\n\\] \n\n\\[\n\\begin{aligned}\n\\log L(\\boldsymbol{\\beta}, \\sigma^2_\\epsilon &| \\mathbf{X}, \\mathbf{y}) \\\\\n& = -\\frac{n}{2}\\log(2\\pi) - n \\log(\\sigma_{\\epsilon}) - \\frac{1}{2\\sigma^2_{\\epsilon}}(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^\\mathsf{T}(\\mathbf{y} - \\mathbf{X}\\mathbf{\\beta})\n\\end{aligned}\n\\]\n\n\n\n\nFor a fixed value of \\(\\sigma_\\epsilon\\) , we know that \\(\\log L\\) is maximized when what is true about \\((\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^\\mathsf{T}(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\) ?\nWhat does this tell us about the relationship between the MLE and least-squares estimator for \\(\\boldsymbol{\\beta}\\)?"
  },
  {
    "objectID": "slides/16-mle.html#putting-it-all-together",
    "href": "slides/16-mle.html#putting-it-all-together",
    "title": "Maximum likelihood estimation",
    "section": "Putting it all together",
    "text": "Putting it all together\n\n\nThe MLE \\(\\tilde{\\boldsymbol{\\beta}}\\) is equivalent to the least-squares estimator \\(\\hat{\\boldsymbol{\\beta}}\\) , when the errors follow independent and identical normal distributions\nMLEs have nice properties, so this means the least-squares estimator \\(\\hat{\\mathbf{\\boldsymbol{\\beta}}}\\) inherits all the nice properties of MLEs\nThe MLE \\(\\tilde{\\sigma}^2_{\\epsilon}\\) is approximately equal to the least-squares estimator \\(\\hat{\\sigma}^2_\\epsilon\\). When \\(n &gt;&gt; p\\), the difference is trivial"
  },
  {
    "objectID": "slides/16-mle.html#references",
    "href": "slides/16-mle.html#references",
    "title": "Maximum likelihood estimation",
    "section": "References",
    "text": "References\n\n\n\n\nCasella, George, and Roger Berger. 2024. Statistical Inference. CRC Press."
  },
  {
    "objectID": "slides/16-mle-notes.html",
    "href": "slides/16-mle-notes.html",
    "title": "Maximum likelihood estimation",
    "section": "",
    "text": "HW 03 due March 20 at 11:59pm\nProject exploratory data analysis due March 20 at 11:59pm\n\nNext milestone: Project presentations in lab March 28\n\nStatistics experience due April 22"
  },
  {
    "objectID": "slides/16-mle-notes.html#announcements",
    "href": "slides/16-mle-notes.html#announcements",
    "title": "Maximum likelihood estimation",
    "section": "",
    "text": "HW 03 due March 20 at 11:59pm\nProject exploratory data analysis due March 20 at 11:59pm\n\nNext milestone: Project presentations in lab March 28\n\nStatistics experience due April 22"
  },
  {
    "objectID": "slides/16-mle-notes.html#topics",
    "href": "slides/16-mle-notes.html#topics",
    "title": "Maximum likelihood estimation",
    "section": "Topics",
    "text": "Topics\n\nLikelihood\nMaximum likelihood estimation (MLE)\nMLE for linear regression"
  },
  {
    "objectID": "slides/16-mle-notes.html#motivation",
    "href": "slides/16-mle-notes.html#motivation",
    "title": "Maximum likelihood estimation",
    "section": "Motivation",
    "text": "Motivation\n\nWe’ve discussed how to find the estimators of \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2_{\\epsilon}\\) for the model\n\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}, \\hspace{10mm} \\boldsymbol{\\epsilon} \\sim N(0, \\sigma^2_\\epsilon\\mathbf{I})\n\\]using least-squares estimation\n\nToday we will introduce another way to find these estimators - maximum likelihood estimation.\nWe will see the least-squares estimator is equal to the maximum likelihood estimator when certain assumptions hold"
  },
  {
    "objectID": "slides/16-mle-notes.html#example-basketball-shots",
    "href": "slides/16-mle-notes.html#example-basketball-shots",
    "title": "Maximum likelihood estimation",
    "section": "Example: Basketball shots",
    "text": "Example: Basketball shots\nSuppose the a basketball player shoots the ball, such that the probability of making the basket (successfully making the shot) is \\(p\\)\n. . .\n\n\nWhat is the probability distribution for this random phenomenon?\nSuppose the probability is \\(p = 0.5\\). What is the probability the player makes a single basket, given this value of \\(p\\)?\nSuppose the probability is \\(p = 0.8\\). What is the probability the player makes a single basket, given this value of \\(p\\)?"
  },
  {
    "objectID": "slides/16-mle-notes.html#shooting-the-ball-three-times",
    "href": "slides/16-mle-notes.html#shooting-the-ball-three-times",
    "title": "Maximum likelihood estimation",
    "section": "Shooting the ball three times",
    "text": "Shooting the ball three times\nSuppose the player shoots the ball three times. They are all independent and the player has the same probability \\(p\\) of making each basket.\nLet \\(B\\) represent a made basket, and \\(M\\) represent a missed basket. The player shoots the ball three times with the outcome \\(BBM\\).\n. . .\n\n\nSuppose the probability is \\(p = 0.5\\). What is the probability of observing the data \\(BBM\\), given this value of \\(p\\)?\nSuppose the probability is \\(p = 0.3\\). What is the probability of observing the data \\(BBM\\), given this value of \\(p\\) ?"
  },
  {
    "objectID": "slides/16-mle-notes.html#shooting-the-ball-three-times-1",
    "href": "slides/16-mle-notes.html#shooting-the-ball-three-times-1",
    "title": "Maximum likelihood estimation",
    "section": "Shooting the ball three times",
    "text": "Shooting the ball three times\nSuppose the player shoots the ball three times. They are all independent and the player has the same probability \\(p\\) of making each basket.\nThe player shoots the ball three times with the outcome \\(BBM\\).\n. . .\n\n\nNew question: What parameter value of \\(p\\) do you think maximizes the probability of observing this data?\nWe will use a likelihood function to answer this question."
  },
  {
    "objectID": "slides/16-mle-notes.html#likelihood",
    "href": "slides/16-mle-notes.html#likelihood",
    "title": "Maximum likelihood estimation",
    "section": "Likelihood",
    "text": "Likelihood\n\n\nA likelihood function is a measure of how likely we are to observe our data under each possible value of the parameter(s)\nNote that this is not the same as the probability function.\nProbability function: Fixed parameter value(s) + input possible outcomes\n\nGiven \\(p=0.8\\) , what is the probability of observing \\(BBM\\) in three basketball shots?\n\nLikelihood function: Fixed data + input possible parameter values\n\nGiven we’ve observed \\(BBM\\), what is the most plausible value of \\(p\\)?"
  },
  {
    "objectID": "slides/16-mle-notes.html#likelihood-three-basketball-shots",
    "href": "slides/16-mle-notes.html#likelihood-three-basketball-shots",
    "title": "Maximum likelihood estimation",
    "section": "Likelihood: Three basketball shots",
    "text": "Likelihood: Three basketball shots\nThe likelihood function for the probability of a basket \\(p\\) given we observed \\(BBM\\) when shooting the ball three independent times \\[\nL(p|BBM) = p \\times p \\times (1 - p)\n\\]\n\n. . .\nThus, if the likelihood for \\(p = 0.8\\) is\n\\[\nL(p = 0.8|BBM) = 0.8 \\times 0.8 \\times (1 - 0.8) = 0.128\n\\]"
  },
  {
    "objectID": "slides/16-mle-notes.html#likelihood-three-basketball-shots-1",
    "href": "slides/16-mle-notes.html#likelihood-three-basketball-shots-1",
    "title": "Maximum likelihood estimation",
    "section": "Likelihood: Three basketball shots",
    "text": "Likelihood: Three basketball shots\n\n\n\nWhat is the general formula for the likelihood function for \\(p\\) given the observed data \\(BBM\\)?\nHow does assuming independence simplify things?\nHow does having identically distributed data simplify things?"
  },
  {
    "objectID": "slides/16-mle-notes.html#likelihood-three-basketball-shots-2",
    "href": "slides/16-mle-notes.html#likelihood-three-basketball-shots-2",
    "title": "Maximum likelihood estimation",
    "section": "Likelihood: Three basketball shots",
    "text": "Likelihood: Three basketball shots\nThe likelihood function for \\(p\\) given the data \\(BBM\\) is\n\\[\nL(p|BBM) = p \\times p \\times (1 - p) = p^2 \\times (1 - p)\n\\]\n. . .\n\n\nWe want of the value of \\(p\\) that maximizes this likelihood function, i.e., the value of \\(p\\) that is most likely given the observed data.\nThe process of finding this value is maximum likelihood estimation.\nThere are three primary ways to find the maximum likelihood estimator\n\nApproximate using a graph\nUsing calculus\nNumerical approximation"
  },
  {
    "objectID": "slides/16-mle-notes.html#finding-the-mle-using-graphs",
    "href": "slides/16-mle-notes.html#finding-the-mle-using-graphs",
    "title": "Maximum likelihood estimation",
    "section": "Finding the MLE using graphs",
    "text": "Finding the MLE using graphs\n\n\n\n\n\n\n\n\n\n\nWhat do you think is the approximate value of the MLE of \\(p\\) given the data?"
  },
  {
    "objectID": "slides/16-mle-notes.html#finding-the-mle-using-calculus",
    "href": "slides/16-mle-notes.html#finding-the-mle-using-calculus",
    "title": "Maximum likelihood estimation",
    "section": "Finding the MLE using calculus",
    "text": "Finding the MLE using calculus\n\nFind the MLE using the first derivative of the likelihood function.\n\n\n\nThis can be tricky because of the product rule, so we can maximize the log(Likelihood) instead. The same value maximizes the likelihood and log(Likelihood).\n\n\nUse calculus to find the MLE of \\(p\\) given the data \\(BBM\\)."
  },
  {
    "objectID": "slides/16-mle-notes.html#shooting-the-ball-n-times",
    "href": "slides/16-mle-notes.html#shooting-the-ball-n-times",
    "title": "Maximum likelihood estimation",
    "section": "Shooting the ball \\(n\\) times",
    "text": "Shooting the ball \\(n\\) times\nSuppose the player shoots the ball \\(n\\) times. They are all independent and the player has the same probability \\(p\\) of making each one.\nSuppose the player makes \\(k\\) baskets out of the \\(n\\) shots. This is the observed data.\n. . .\n\n\nWhat is the formula for the probability distribution to describe this random phenomenon?\nWhat is the formula for the likelihood function for \\(p\\) given the observed data?\nFor what value of \\(p\\) do we maximize the likelihood given the observed data? Use calculus to find the response."
  },
  {
    "objectID": "slides/16-mle-notes.html#why-maximum-likelihood-estimation",
    "href": "slides/16-mle-notes.html#why-maximum-likelihood-estimation",
    "title": "Maximum likelihood estimation",
    "section": "Why maximum likelihood estimation?",
    "text": "Why maximum likelihood estimation?\n\n“Maximum likelihood estimation is, by far, the most popular technique for deriving estimators.” (Casella and Berger 2024, 315)\nMLEs have nice statistical properties (more on this next class)\n\nConsistent\nEfficient\nAsymptotically normal\n\n\n. . .\n\n\n\n\n\n\nNote\n\n\n\nIf the normality assumption holds, the least squares estimator is the maximum likelihood estimator for \\(\\beta\\). Therefore, it has all the properties of the MLE."
  },
  {
    "objectID": "slides/16-mle-notes.html#linear-regression",
    "href": "slides/16-mle-notes.html#linear-regression",
    "title": "Maximum likelihood estimation",
    "section": "Linear regression",
    "text": "Linear regression\nRecall the linear model\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}, \\hspace{10mm} \\boldsymbol{\\epsilon} \\sim N(\\mathbf{0}, \\sigma^2_{\\epsilon}\\mathbf{I})\n\\]\n. . .\n\n\nWe have discussed least-squares estimation to find \\(\\hat{\\boldsymbol{\\beta}}\\) and \\(\\hat{\\sigma}_\\epsilon^2\\)\nWe have used the fact that \\(\\hat{\\boldsymbol{\\beta}} \\sim N(\\boldsymbol{\\beta}, \\sigma^2_{\\epsilon}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1})\\) when doing hypothesis testing and confidence intervals.\nNow we will discuss how we know \\(\\hat{\\boldsymbol{\\beta}}\\) is normally distributed, as we introduce MLE for linear regression"
  },
  {
    "objectID": "slides/16-mle-notes.html#simple-linear-regression-model",
    "href": "slides/16-mle-notes.html#simple-linear-regression-model",
    "title": "Maximum likelihood estimation",
    "section": "Simple linear regression model",
    "text": "Simple linear regression model\nSuppose we have the simple linear regression (SLR) model\n\\[\ny_i = \\beta_0 + \\beta_1x_i + \\epsilon_i, \\hspace{10mm} \\epsilon_i \\sim N(0, \\sigma^2_{\\epsilon})\n\\]\nsuch that \\(\\epsilon_i\\) are independently and identically distributed.\n\n. . .\nWe can write this model in the form below and use this to find the MLE\n\\[\ny_i | x_i \\sim N(\\beta_0 + \\beta_1 x_i, \\sigma^2_{\\epsilon})\n\\]"
  },
  {
    "objectID": "slides/16-mle-notes.html#side-note-normal-distribution",
    "href": "slides/16-mle-notes.html#side-note-normal-distribution",
    "title": "Maximum likelihood estimation",
    "section": "Side note: Normal distribution",
    "text": "Side note: Normal distribution\nLet \\(Z\\) be a random variable, such that \\(Z \\sim N(\\mu, \\sigma^2)\\). Then the probability function is\n\\[\nP(Z = z | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\Big\\{-{\\frac{1}{2\\sigma^2}(z - \\mu)^2}\\Big\\}\n\\]"
  },
  {
    "objectID": "slides/16-mle-notes.html#slr-likelihood-for-beta_0-beta_1-sigma2_epsilon",
    "href": "slides/16-mle-notes.html#slr-likelihood-for-beta_0-beta_1-sigma2_epsilon",
    "title": "Maximum likelihood estimation",
    "section": "SLR: Likelihood for \\(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon}\\)",
    "text": "SLR: Likelihood for \\(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon}\\)\nThe likelihood function for \\(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon}\\) is\n\\[\n\\begin{aligned}\nL(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon} &| x_1, \\ldots, x_n, y_1, \\ldots, y_n) \\\\ &= p(y_1|x_1, \\beta_0, \\beta_1, \\sigma^2_{\\epsilon}) \\dots  p(y_n|x_n, \\beta_0, \\beta_1, \\sigma^2_{\\epsilon}) \\\\[5pt]\n& = \\class{fragment}{\\prod_{i=1}^n p(y_i | x_i, \\beta_0, \\beta_1, \\sigma^2_{\\epsilon})} \\\\[5pt]\n&= \\class{fragment}{\\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma_\n\\epsilon^2}}\\exp\\Big\\{{-\\frac{1}{2\\sigma_\\epsilon^2}(y_i - [\\beta_0 + \\beta_1x_i])^2}\\Big\\}} \\\\[10pt]\n& = \\class{fragment}{(2\\pi\\sigma^2_{\\epsilon})^{-\\frac{n}{2}}\\exp\\Big\\{-\\frac{1}{2\\sigma^2_{\\epsilon}}\\sum_{i=1}^n(y_i - \\beta_0 - \\beta_1x_i)^2\\Big\\}}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/16-mle-notes.html#log-likelihood-for-beta_0-beta_1-sigma2_epsilon",
    "href": "slides/16-mle-notes.html#log-likelihood-for-beta_0-beta_1-sigma2_epsilon",
    "title": "Maximum likelihood estimation",
    "section": "Log-Likelihood for \\(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon}\\)",
    "text": "Log-Likelihood for \\(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon}\\)\nThe log-likelihood function for \\(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon}\\) is\n\\[\n\\begin{aligned}\n\\log &L(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon} | x_1, \\ldots, x_n, y_1, \\ldots, y_n) \\\\[8pt]\n& = \\class{fragment}{\\log\\Big((2\\pi\\sigma^2_{\\epsilon})^{-\\frac{n}{2}}\\exp\\Big\\{-\\frac{1}{2\\sigma^2_{\\epsilon}}\\sum_{i=1}^n(y_i - \\beta_0 - \\beta_1x_i)^2\\Big\\}\\Big)} \\\\[8pt]\n& = \\class{fragment}{-\\frac{n}{2}\\log(2\\pi\\sigma^2_{\\epsilon}) -\\frac{1}{2\\sigma^2_{\\epsilon}}\\sum_{i=1}^n(y_i - \\beta_0 - \\beta_1x_i)^2}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/16-mle-notes.html#mle-for-beta_0",
    "href": "slides/16-mle-notes.html#mle-for-beta_0",
    "title": "Maximum likelihood estimation",
    "section": "MLE for \\(\\beta_0\\)",
    "text": "MLE for \\(\\beta_0\\)\n1️⃣ Take derivative of \\(\\log L\\) with respect to \\(\\beta_0\\) and set it equal to 0\n\\[\n\\frac{\\partial \\log L}{\\partial \\beta_0} = -\\frac{2}{2\\sigma^2_\\epsilon}\\sum_{i=1}^n (y_i - \\beta_0 - \\beta_1x_i)(-1) = 0\n\\]"
  },
  {
    "objectID": "slides/16-mle-notes.html#mle-for-beta_0-1",
    "href": "slides/16-mle-notes.html#mle-for-beta_0-1",
    "title": "Maximum likelihood estimation",
    "section": "MLE for \\(\\beta_0\\)",
    "text": "MLE for \\(\\beta_0\\)\n2️⃣ Find the \\(\\tilde{\\beta}_0\\) that satisfies the equality on the previous slide\n. . .\nAfter a few steps…\n\\[\n\\begin{aligned}\n&\\Rightarrow \\class{fragment}{\\sum_{i=1}^ny_i - n\\tilde{\\beta}_0 - \\tilde{\\beta}_1\\sum_{i=1}^n x_i = 0} \\\\[8pt]\n&\\Rightarrow \\class{fragment}{\\sum_{i=1}^ny_i  - \\tilde{\\beta}_1\\sum_{i=1}^n x_i = n\\tilde{\\beta}_0} \\\\[8pt]\n&\\Rightarrow \\class{fragment}{ \\frac{1}{n}\\sum_{i=1}^ny_i  - \\frac{1}{n}\\tilde{\\beta}_1\\sum_{i=1}^n x_i = \\tilde{\\beta}_0}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/16-mle-notes.html#mle-for-beta_0-2",
    "href": "slides/16-mle-notes.html#mle-for-beta_0-2",
    "title": "Maximum likelihood estimation",
    "section": "MLE for \\(\\beta_0\\)",
    "text": "MLE for \\(\\beta_0\\)\n3️⃣ We can use the second derivative to show we’ve found the maximum\n\\[\n\\frac{\\partial^2 \\log L}{\\partial \\beta_0^2} = -\\frac{n}{2\\tilde{\\sigma}^2_\\epsilon}  &lt; 0\n\\]\n\n. . .\nTherefore, we have found the maximum. Thus, MLE for \\(\\beta_0\\) is\n\\[\n\\tilde{\\beta}_0 = \\bar{y} - \\tilde{\\beta}_1\\bar{x}\n\\]\n. . .\nNote that \\(\\tilde{\\beta}_0\\) is equal to \\(\\hat{\\beta}_0\\), the least-squares estimate"
  },
  {
    "objectID": "slides/16-mle-notes.html#mle-for-beta_1-and-sigma2_epsilon",
    "href": "slides/16-mle-notes.html#mle-for-beta_1-and-sigma2_epsilon",
    "title": "Maximum likelihood estimation",
    "section": "MLE for \\(\\beta_1\\) and \\(\\sigma^2_{\\epsilon}\\)",
    "text": "MLE for \\(\\beta_1\\) and \\(\\sigma^2_{\\epsilon}\\)\nWe can use a similar process to find the MLEs for \\(\\beta_1\\) and \\(\\sigma^2_{\\epsilon}\\)\n\\[\n\\tilde{\\beta}_1 = \\frac{\\sum_{i=1}^n (y_i - \\bar{y})(x_i - \\bar{x})}{\\sum_{i=1}^n(x_i - \\bar{x})^2}\n\\] \n. . .\n\\[\n\\tilde{\\sigma}^2_{\\epsilon} = \\frac{\\sum_{i=1}^n(y_i - \\tilde{\\beta}_0 - \\tilde{\\beta}_1x_i)^2}{n} = \\frac{\\sum_{i=1}^ne_i^2}{n}\n\\]\n. . .\nNote: \\(\\tilde{\\beta}_1 = \\hat{\\beta}_1\\) and \\(\\tilde{\\sigma}^2_{\\epsilon} \\approx \\hat{\\sigma}^2_{\\epsilon}\\)"
  },
  {
    "objectID": "slides/16-mle-notes.html#mle-for-linear-regression-in-matrix-form",
    "href": "slides/16-mle-notes.html#mle-for-linear-regression-in-matrix-form",
    "title": "Maximum likelihood estimation",
    "section": "MLE for linear regression in matrix form",
    "text": "MLE for linear regression in matrix form\n\\[\nL(\\boldsymbol{\\beta}, \\sigma^2_{\\epsilon} | \\mathbf{X}, \\mathbf{y}) = \\frac{1}{(2\\pi)^{n/2}\\sigma^n_{\\epsilon}}\\exp\\Big\\{-\\frac{1}{2\\sigma^2_{\\epsilon}}(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^\\mathsf{T}(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\Big\\}\n\\] \n. . .\n\\[\n\\begin{aligned}\n\\log L(\\boldsymbol{\\beta}, \\sigma^2_\\epsilon &| \\mathbf{X}, \\mathbf{y}) \\\\\n& = -\\frac{n}{2}\\log(2\\pi) - n \\log(\\sigma_{\\epsilon}) - \\frac{1}{2\\sigma^2_{\\epsilon}}(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^\\mathsf{T}(\\mathbf{y} - \\mathbf{X}\\mathbf{\\beta})\n\\end{aligned}\n\\]\n. . .\n\n\nFor a fixed value of \\(\\sigma_\\epsilon\\) , we know that \\(\\log L\\) is maximized when what is true about \\((\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^\\mathsf{T}(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\) ?\nWhat does this tell us about the relationship between the MLE and least-squares estimator for \\(\\boldsymbol{\\beta}\\)?"
  },
  {
    "objectID": "slides/16-mle-notes.html#putting-it-all-together",
    "href": "slides/16-mle-notes.html#putting-it-all-together",
    "title": "Maximum likelihood estimation",
    "section": "Putting it all together",
    "text": "Putting it all together\n\n\nThe MLE \\(\\tilde{\\boldsymbol{\\beta}}\\) is equivalent to the least-squares estimator \\(\\hat{\\boldsymbol{\\beta}}\\) , when the errors follow independent and identical normal distributions\nMLEs have nice properties, so this means the least-squares estimator \\(\\hat{\\mathbf{\\boldsymbol{\\beta}}}\\) inherits all the nice properties of MLEs\nThe MLE \\(\\tilde{\\sigma}^2_{\\epsilon}\\) is approximately equal to the least-squares estimator \\(\\hat{\\sigma}^2_\\epsilon\\). When \\(n &gt;&gt; p\\), the difference is trivial"
  },
  {
    "objectID": "slides/lab-project-topics.html#goals",
    "href": "slides/lab-project-topics.html#goals",
    "title": "Project: Research Topics",
    "section": "Goals",
    "text": "Goals\n\nTeam icebreaker\nHypothesis testing practice\nFinal project - research topics"
  },
  {
    "objectID": "slides/lab-project-topics.html#icebreaker",
    "href": "slides/lab-project-topics.html#icebreaker",
    "title": "Project: Research Topics",
    "section": "Icebreaker",
    "text": "Icebreaker\n\nGet into your lab teams.\nChoose a reporter\n\nNeed help choosing? Person with birthday closest to today’s date.\n\nIdentify 8 things everyone in the group has in common (~ 5 minutes)\n\nNot being a Duke student\nNot clothes (e.g., we’re all wearing socks)\nNot body parts (e.g., we all have a nose)\n\nReporter will share list with the class."
  },
  {
    "objectID": "slides/lab-project-topics.html#hypothesis-testing",
    "href": "slides/lab-project-topics.html#hypothesis-testing",
    "title": "Project: Research Topics",
    "section": "Hypothesis testing",
    "text": "Hypothesis testing\nBelow is the model using student enrollment (in thousands) and institution type to predict an institution’s football expenditures (in millions). Click here for more details about the data.\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0\n\n\n\n\n\n\n\n\n\nExplain what each value in the row for typePublic means.\nDo the data provide evidence that institution type is a useful predictor in this model?"
  },
  {
    "objectID": "slides/lab-project-topics.html#final-team-project",
    "href": "slides/lab-project-topics.html#final-team-project",
    "title": "Project: Research Topics",
    "section": "Final team project",
    "text": "Final team project\n\nGoal: Use the methods from STA 221 to analyze data and answer a research question developed by your team\nPrimary deliverables:\n\nan in-person presentation about the exploratory data analysis and initial modeling\na written, reproducible final report detailing your analysis\na summary of your project highlights to share with the class\na GitHub repository containing all work from the project\n\nThere are periodic project milestones throughout the semester to help you work towards the primary deliverables"
  },
  {
    "objectID": "slides/lab-project-topics.html#todays-focus-research-topics",
    "href": "slides/lab-project-topics.html#todays-focus-research-topics",
    "title": "Project: Research Topics",
    "section": "Today’s focus: Research topics",
    "text": "Today’s focus: Research topics\n\nGoals: Identify three potential research topics your team is interested in investigating and draft research questions.\nYou do not need to have a data set at this point\nYou can discuss the topics you put in the student survey to help generate ideas\nSubmission: All work for the project will be submitted in your team’s GitHub repo. You will receive feedback via an Issue on GitHub to model a workflow often used in practice.\n\n🔗 https://sta221-sp25.netlify.app/project"
  },
  {
    "objectID": "slides/14-variable-transformations.html#computing-set-up",
    "href": "slides/14-variable-transformations.html#computing-set-up",
    "title": "Variable transformations",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/14-variable-transformations.html#topics",
    "href": "slides/14-variable-transformations.html#topics",
    "title": "Variable transformations",
    "section": "Topics",
    "text": "Topics\n\nLog-transformation on the response"
  },
  {
    "objectID": "slides/14-variable-transformations.html#data-life-expectancy-in-140-countries",
    "href": "slides/14-variable-transformations.html#data-life-expectancy-in-140-countries",
    "title": "Variable transformations",
    "section": "Data: Life expectancy in 140 countries",
    "text": "Data: Life expectancy in 140 countries\nThe data set comes from Zarulli et al. (2021) who analyze the effects of a country’s healthcare expenditures and other factors on the country’s life expectancy. The data are originally from the Human Development Database and World Health Organization.\nThere are 140 countries (observations) in the data set.\n\n\nClick here for the original research paper."
  },
  {
    "objectID": "slides/14-variable-transformations.html#variables",
    "href": "slides/14-variable-transformations.html#variables",
    "title": "Variable transformations",
    "section": "Variables",
    "text": "Variables\n\nlife_exp: The average number of years that a newborn could expect to live, if he or she were to pass through life exposed to the sex- and age-specific death rates prevailing at the time of his or her birth, for a specific year, in a given country, territory, or geographic income_inequality. ( from the World Health Organization)\nincome_inequality: Measure of the deviation of the distribution of income among individuals or households within a country from a perfectly equal distribution. A value of 0 represents absolute equality, a value of 100 absolute inequality (based on Gini coefficient). (from Zarulli et al. (2021))"
  },
  {
    "objectID": "slides/14-variable-transformations.html#variables-1",
    "href": "slides/14-variable-transformations.html#variables-1",
    "title": "Variable transformations",
    "section": "Variables",
    "text": "Variables\n\neducation: Indicator of whether a country’s education index is above (High) or below (Low) the median index for the 140 countries in the data set.\n\nEducation index: Average of mean years of schooling (of adults) and expected years of school (of children), both expressed as an index obtained by scaling wit the corresponding maxima.\n\nhealth_expend: Per capita current spending on on healthcare good sand services, expressed in respective currency - international Purchasing Power Parity (PPP) dollar (from the World Health Organization)"
  },
  {
    "objectID": "slides/14-variable-transformations.html#exploratory-data-analysis",
    "href": "slides/14-variable-transformations.html#exploratory-data-analysis",
    "title": "Variable transformations",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis"
  },
  {
    "objectID": "slides/14-variable-transformations.html#exploratory-data-analysis-1",
    "href": "slides/14-variable-transformations.html#exploratory-data-analysis-1",
    "title": "Variable transformations",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\nThe goal is to use income inequality and education to understand variability in health expenditure"
  },
  {
    "objectID": "slides/14-variable-transformations.html#original-model",
    "href": "slides/14-variable-transformations.html#original-model",
    "title": "Variable transformations",
    "section": "Original model",
    "text": "Original model\n\nhealth_fit &lt;- lm(health_expenditure ~ income_inequality + education, \n                     data = health_data)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n2070.599\n534.653\n3.873\n0.000\n\n\nincome_inequality\n-64.346\n18.626\n-3.455\n0.001\n\n\neducationHigh\n1039.298\n359.736\n2.889\n0.004"
  },
  {
    "objectID": "slides/14-variable-transformations.html#original-model-residuals-vs.-fitted",
    "href": "slides/14-variable-transformations.html#original-model-residuals-vs.-fitted",
    "title": "Variable transformations",
    "section": "Original model: Residuals vs. fitted",
    "text": "Original model: Residuals vs. fitted\n\n\nWhat model assumption(s) appear to be violated?"
  },
  {
    "objectID": "slides/14-variable-transformations.html#consider-different-transformations",
    "href": "slides/14-variable-transformations.html#consider-different-transformations",
    "title": "Variable transformations",
    "section": "Consider different transformations…",
    "text": "Consider different transformations…"
  },
  {
    "objectID": "slides/14-variable-transformations.html#identifying-a-need-to-transform-y",
    "href": "slides/14-variable-transformations.html#identifying-a-need-to-transform-y",
    "title": "Variable transformations",
    "section": "Identifying a need to transform Y",
    "text": "Identifying a need to transform Y\n\n\nTypically, a “fan-shaped” residual plot indicates the need for a transformation of the response variable Y\n\nThere are multiple ways to transform a variable, e.g., \\(Y^{1/2}\\), \\(1/Y\\), \\(\\log(Y)\\) . These are called variance stabilizing transformations\n\\(\\log(Y)\\) the most straightforward to interpret, so we use that transformation when possible\n\n\n\n\nWhen building a model:\n\nChoose a transformation and build the model on the transformed data\nReassess the residual plots\nIf the residuals plots did not sufficiently improve, try a new transformation!"
  },
  {
    "objectID": "slides/14-variable-transformations.html#log-transformation-on-y",
    "href": "slides/14-variable-transformations.html#log-transformation-on-y",
    "title": "Variable transformations",
    "section": "Log transformation on \\(Y\\)",
    "text": "Log transformation on \\(Y\\)\n\nIf we apply a log transformation to the response variable, we want to estimate the parameters for the statistical model\n\n\\[\n\\log(\\mathbf{Y}) = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}, \\quad \\boldsymbol{\\epsilon} \\sim N(\\mathbf{0}, \\sigma^2_{\\epsilon}\\mathbf{I})\n\\]\n\nThe regression equation is\n\n\\[\\widehat{\\log(\\mathbf{Y})} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}\\]"
  },
  {
    "objectID": "slides/14-variable-transformations.html#log-transformation-on-y-1",
    "href": "slides/14-variable-transformations.html#log-transformation-on-y-1",
    "title": "Variable transformations",
    "section": "Log transformation on \\(Y\\)",
    "text": "Log transformation on \\(Y\\)\nWe fit the model in terms of \\(\\log(\\mathbf{Y})\\) but want to interpret the model in terms of the original variable \\(Y\\) , so we need to write the regression equation in terms of \\(Y\\)\n\\[\n\\begin{aligned}\n&\\widehat{\\log(\\mathbf{Y})} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\\\[8pt]\n\\Rightarrow \\quad &\\hat{\\mathbf{Y}} = e^{\\mathbf{X}\\hat{\\boldsymbol{\\beta}}}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/14-variable-transformations.html#model-interpretation",
    "href": "slides/14-variable-transformations.html#model-interpretation",
    "title": "Variable transformations",
    "section": "Model interpretation",
    "text": "Model interpretation\n\\[\\begin{align}\\hat{y_i} &=  e^{\\mathbf{x}_i\\hat{\\boldsymbol{\\beta}}} \\\\ & = e^{(\\hat{\\beta}_0 + \\hat{\\beta}_1 x_{i1} + \\dots + \\hat{\\beta}_px_{ip})} \\\\\n&= e^{\\hat{\\beta}_0}e^{\\hat{\\beta}_1x_{i1}}\\dots e^{\\hat{\\beta}_px_{ip}}\\end{align}\\]\n\n\nIntercept: When \\(x_{i1} = \\dots = x_{ip} =0\\), \\(y_i\\) is expected to be \\(e^{\\hat{\\beta}_0}\\)\nCoefficient of \\(X_j\\): For every one unit increase in \\(x_{ij}\\), \\(y_{i}\\) is expected to multiply by a factor of \\(e^{\\hat{\\beta}_j}\\), holding all else constant."
  },
  {
    "objectID": "slides/14-variable-transformations.html#model-with-logy",
    "href": "slides/14-variable-transformations.html#model-with-logy",
    "title": "Variable transformations",
    "section": "Model with log(Y)",
    "text": "Model with log(Y)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n7.096\n0.324\n21.895\n0\n\n\nincome_inequality\n-0.065\n0.011\n-5.714\n0\n\n\neducationHigh\n1.117\n0.218\n5.121\n0\n\n\n\n\n\n\n\nInterpret each of the following in terms of health expenditure\n\nIntercept\nincome_inequality\neducation"
  },
  {
    "objectID": "slides/14-variable-transformations.html#model-with-logy-residuals",
    "href": "slides/14-variable-transformations.html#model-with-logy-residuals",
    "title": "Variable transformations",
    "section": "Model with log(Y): Residuals",
    "text": "Model with log(Y): Residuals"
  },
  {
    "objectID": "slides/14-variable-transformations.html#compare-residual-plots",
    "href": "slides/14-variable-transformations.html#compare-residual-plots",
    "title": "Variable transformations",
    "section": "Compare residual plots",
    "text": "Compare residual plots"
  },
  {
    "objectID": "slides/14-variable-transformations.html#learn-more",
    "href": "slides/14-variable-transformations.html#learn-more",
    "title": "Variable transformations",
    "section": "Learn more",
    "text": "Learn more\nSee Log Transformations in Linear Regression for more details about interpreting regression models with log-transformed variables."
  },
  {
    "objectID": "slides/14-variable-transformations.html#recap",
    "href": "slides/14-variable-transformations.html#recap",
    "title": "Variable transformations",
    "section": "Recap",
    "text": "Recap\n\nLog-transformation on the response"
  },
  {
    "objectID": "slides/14-variable-transformations.html#references",
    "href": "slides/14-variable-transformations.html#references",
    "title": "Variable transformations",
    "section": "References",
    "text": "References\n\n\n\n\nZarulli, Virginia, Elizaveta Sopina, Veronica Toffolutti, and Adam Lenart. 2021. “Health Care System Efficiency and Life Expectancy: A 140-Country Study.” Edited by Srinivas Goli. PLOS ONE 16 (7): e0253450. https://doi.org/10.1371/journal.pone.0253450."
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html",
    "href": "slides/14-variable-transformations-notes.html",
    "title": "Variable transformations",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#computing-set-up",
    "href": "slides/14-variable-transformations-notes.html#computing-set-up",
    "title": "Variable transformations",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#topics",
    "href": "slides/14-variable-transformations-notes.html#topics",
    "title": "Variable transformations",
    "section": "Topics",
    "text": "Topics\n\nLog-transformation on the response"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#data-life-expectancy-in-140-countries",
    "href": "slides/14-variable-transformations-notes.html#data-life-expectancy-in-140-countries",
    "title": "Variable transformations",
    "section": "Data: Life expectancy in 140 countries",
    "text": "Data: Life expectancy in 140 countries\nThe data set comes from Zarulli et al. (2021) who analyze the effects of a country’s healthcare expenditures and other factors on the country’s life expectancy. The data are originally from the Human Development Database and World Health Organization.\nThere are 140 countries (observations) in the data set.\n\n\nClick here for the original research paper."
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#variables",
    "href": "slides/14-variable-transformations-notes.html#variables",
    "title": "Variable transformations",
    "section": "Variables",
    "text": "Variables\n\nlife_exp: The average number of years that a newborn could expect to live, if he or she were to pass through life exposed to the sex- and age-specific death rates prevailing at the time of his or her birth, for a specific year, in a given country, territory, or geographic income_inequality. ( from the World Health Organization)\nincome_inequality: Measure of the deviation of the distribution of income among individuals or households within a country from a perfectly equal distribution. A value of 0 represents absolute equality, a value of 100 absolute inequality (based on Gini coefficient). (from Zarulli et al. (2021))"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#variables-1",
    "href": "slides/14-variable-transformations-notes.html#variables-1",
    "title": "Variable transformations",
    "section": "Variables",
    "text": "Variables\n\neducation: Indicator of whether a country’s education index is above (High) or below (Low) the median index for the 140 countries in the data set.\n\nEducation index: Average of mean years of schooling (of adults) and expected years of school (of children), both expressed as an index obtained by scaling wit the corresponding maxima.\n\nhealth_expend: Per capita current spending on on healthcare good sand services, expressed in respective currency - international Purchasing Power Parity (PPP) dollar (from the World Health Organization)"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#exploratory-data-analysis",
    "href": "slides/14-variable-transformations-notes.html#exploratory-data-analysis",
    "title": "Variable transformations",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#exploratory-data-analysis-1",
    "href": "slides/14-variable-transformations-notes.html#exploratory-data-analysis-1",
    "title": "Variable transformations",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\nThe goal is to use income inequality and education to understand variability in health expenditure"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#original-model",
    "href": "slides/14-variable-transformations-notes.html#original-model",
    "title": "Variable transformations",
    "section": "Original model",
    "text": "Original model\n\nhealth_fit &lt;- lm(health_expenditure ~ income_inequality + education, \n                     data = health_data)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n2070.599\n534.653\n3.873\n0.000\n\n\nincome_inequality\n-64.346\n18.626\n-3.455\n0.001\n\n\neducationHigh\n1039.298\n359.736\n2.889\n0.004"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#original-model-residuals-vs.-fitted",
    "href": "slides/14-variable-transformations-notes.html#original-model-residuals-vs.-fitted",
    "title": "Variable transformations",
    "section": "Original model: Residuals vs. fitted",
    "text": "Original model: Residuals vs. fitted\n\n\n\n\n\n\n\n\n\n\nWhat model assumption(s) appear to be violated?"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#consider-different-transformations",
    "href": "slides/14-variable-transformations-notes.html#consider-different-transformations",
    "title": "Variable transformations",
    "section": "Consider different transformations…",
    "text": "Consider different transformations…"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#identifying-a-need-to-transform-y",
    "href": "slides/14-variable-transformations-notes.html#identifying-a-need-to-transform-y",
    "title": "Variable transformations",
    "section": "Identifying a need to transform Y",
    "text": "Identifying a need to transform Y\n\n\nTypically, a “fan-shaped” residual plot indicates the need for a transformation of the response variable Y\n\nThere are multiple ways to transform a variable, e.g., \\(Y^{1/2}\\), \\(1/Y\\), \\(\\log(Y)\\) . These are called variance stabilizing transformations\n\\(\\log(Y)\\) the most straightforward to interpret, so we use that transformation when possible\n\n\n\n\nWhen building a model:\n\nChoose a transformation and build the model on the transformed data\nReassess the residual plots\nIf the residuals plots did not sufficiently improve, try a new transformation!"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#log-transformation-on-y",
    "href": "slides/14-variable-transformations-notes.html#log-transformation-on-y",
    "title": "Variable transformations",
    "section": "Log transformation on \\(Y\\)",
    "text": "Log transformation on \\(Y\\)\n\nIf we apply a log transformation to the response variable, we want to estimate the parameters for the statistical model\n\n\\[\n\\log(\\mathbf{Y}) = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}, \\quad \\boldsymbol{\\epsilon} \\sim N(\\mathbf{0}, \\sigma^2_{\\epsilon}\\mathbf{I})\n\\]\n\nThe regression equation is\n\n\\[\\widehat{\\log(\\mathbf{Y})} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}\\]"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#log-transformation-on-y-1",
    "href": "slides/14-variable-transformations-notes.html#log-transformation-on-y-1",
    "title": "Variable transformations",
    "section": "Log transformation on \\(Y\\)",
    "text": "Log transformation on \\(Y\\)\nWe fit the model in terms of \\(\\log(\\mathbf{Y})\\) but want to interpret the model in terms of the original variable \\(Y\\) , so we need to write the regression equation in terms of \\(Y\\)\n\\[\n\\begin{aligned}\n&\\widehat{\\log(\\mathbf{Y})} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\\\[8pt]\n\\Rightarrow \\quad &\\hat{\\mathbf{Y}} = e^{\\mathbf{X}\\hat{\\boldsymbol{\\beta}}}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#model-interpretation",
    "href": "slides/14-variable-transformations-notes.html#model-interpretation",
    "title": "Variable transformations",
    "section": "Model interpretation",
    "text": "Model interpretation\n\\[\\begin{align}\\hat{y_i} &=  e^{\\mathbf{x}_i\\hat{\\boldsymbol{\\beta}}} \\\\ & = e^{(\\hat{\\beta}_0 + \\hat{\\beta}_1 x_{i1} + \\dots + \\hat{\\beta}_px_{ip})} \\\\\n&= e^{\\hat{\\beta}_0}e^{\\hat{\\beta}_1x_{i1}}\\dots e^{\\hat{\\beta}_px_{ip}}\\end{align}\\]\n. . .\n\nIntercept: When \\(x_{i1} = \\dots = x_{ip} =0\\), \\(y_i\\) is expected to be \\(e^{\\hat{\\beta}_0}\\)\nCoefficient of \\(X_j\\): For every one unit increase in \\(x_{ij}\\), \\(y_{i}\\) is expected to multiply by a factor of \\(e^{\\hat{\\beta}_j}\\), holding all else constant."
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#model-with-logy",
    "href": "slides/14-variable-transformations-notes.html#model-with-logy",
    "title": "Variable transformations",
    "section": "Model with log(Y)",
    "text": "Model with log(Y)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n7.096\n0.324\n21.895\n0\n\n\nincome_inequality\n-0.065\n0.011\n-5.714\n0\n\n\neducationHigh\n1.117\n0.218\n5.121\n0\n\n\n\n\n\n\n\nInterpret each of the following in terms of health expenditure\n\nIntercept\nincome_inequality\neducation"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#model-with-logy-residuals",
    "href": "slides/14-variable-transformations-notes.html#model-with-logy-residuals",
    "title": "Variable transformations",
    "section": "Model with log(Y): Residuals",
    "text": "Model with log(Y): Residuals"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#compare-residual-plots",
    "href": "slides/14-variable-transformations-notes.html#compare-residual-plots",
    "title": "Variable transformations",
    "section": "Compare residual plots",
    "text": "Compare residual plots"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#learn-more",
    "href": "slides/14-variable-transformations-notes.html#learn-more",
    "title": "Variable transformations",
    "section": "Learn more",
    "text": "Learn more\nSee Log Transformations in Linear Regression for more details about interpreting regression models with log-transformed variables."
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#recap",
    "href": "slides/14-variable-transformations-notes.html#recap",
    "title": "Variable transformations",
    "section": "Recap",
    "text": "Recap\n\nLog-transformation on the response"
  },
  {
    "objectID": "slides/10-inference-pt3.html#announcements",
    "href": "slides/10-inference-pt3.html#announcements",
    "title": "Inference for regression",
    "section": "Announcements",
    "text": "Announcements\n\nResearch topics due TODAY at 11:59pm on GitHub\nHW 02 due Thursday at 11:59pm\nStatistics experience due Tuesday, April 22"
  },
  {
    "objectID": "slides/10-inference-pt3.html#exam-01",
    "href": "slides/10-inference-pt3.html#exam-01",
    "title": "Inference for regression",
    "section": "Exam 01",
    "text": "Exam 01\n\n50 points total\n\nin-class: 35-40 points\ntake-home: 10 - 15 points\n\nIn-class (35 -40 pts): 75 minutes during February 18 lecture\n\nWill be randomly assigned to exam room\n\nTake-home (10 -15 pts): released after class on Tuesday\nIf you miss any part of the exam for an excused absence (with academic dean’s note or other official documentation), your Exam 02 score will be counted twice"
  },
  {
    "objectID": "slides/10-inference-pt3.html#resources",
    "href": "slides/10-inference-pt3.html#resources",
    "title": "Inference for regression",
    "section": "Resources",
    "text": "Resources\n\nExam 01 practice\nLecture recordings\nPrepare readings (see course schedule)\nLecture notes (use search bar to find specific topics)\nAEs\nAssignments"
  },
  {
    "objectID": "slides/10-inference-pt3.html#topics",
    "href": "slides/10-inference-pt3.html#topics",
    "title": "Inference for regression",
    "section": "Topics",
    "text": "Topics\n\nConduct inference on a single coefficient"
  },
  {
    "objectID": "slides/10-inference-pt3.html#computing-setup",
    "href": "slides/10-inference-pt3.html#computing-setup",
    "title": "Inference for regression",
    "section": "Computing setup",
    "text": "Computing setup\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(kableExtra)  \nlibrary(patchwork)   \n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/10-inference-pt3.html#data-ncaa-football-expenditures",
    "href": "slides/10-inference-pt3.html#data-ncaa-football-expenditures",
    "title": "Inference for regression",
    "section": "Data: NCAA Football expenditures",
    "text": "Data: NCAA Football expenditures\nToday’s data come from Equity in Athletics Data Analysis and includes information about sports expenditures and revenues for colleges and universities in the United States. This data set was featured in a March 2022 Tidy Tuesday.\nWe will focus on the 2019 - 2020 season expenditures on football for institutions in the NCAA - Division 1 FBS. The variables are :\n\ntotal_exp_m: Total expenditures on football in the 2019 - 2020 academic year (in millions USD)\nenrollment_th: Total student enrollment in the 2019 - 2020 academic year (in thousands)\ntype: institution type (Public or Private)\n\n\nfootball &lt;- read_csv(\"data/ncaa-football-exp.csv\")"
  },
  {
    "objectID": "slides/10-inference-pt3.html#regression-model",
    "href": "slides/10-inference-pt3.html#regression-model",
    "title": "Inference for regression",
    "section": "Regression model",
    "text": "Regression model\n\nexp_fit &lt;- lm(total_exp_m ~ enrollment_th + type, data = football)\ntidy(exp_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0"
  },
  {
    "objectID": "slides/10-inference-pt3.html#inference-for-beta_j",
    "href": "slides/10-inference-pt3.html#inference-for-beta_j",
    "title": "Inference for regression",
    "section": "Inference for \\(\\beta_j\\)",
    "text": "Inference for \\(\\beta_j\\)\nWe often want to conduct inference on individual model coefficients\n\nHypothesis test: Is there a linear relationship between the response and \\(x_j\\)?\nConfidence interval: What is a plausible range of values \\(\\beta_j\\) can take?"
  },
  {
    "objectID": "slides/10-inference-pt3.html#sampling-distribution-of-hatbeta",
    "href": "slides/10-inference-pt3.html#sampling-distribution-of-hatbeta",
    "title": "Inference for regression",
    "section": "Sampling distribution of \\(\\hat{\\beta}\\)",
    "text": "Sampling distribution of \\(\\hat{\\beta}\\)\n\nA sampling distribution is the probability distribution of a statistic for a large number of random samples of size \\(n\\) from a population\nThe sampling distribution of \\(\\hat{\\boldsymbol{\\beta}}\\) is the probability distribution of the estimated coefficients if we repeatedly took samples of size \\(n\\) and fit the regression model\n\n\\[\n\\hat{\\boldsymbol{\\beta}} \\sim N(\\boldsymbol{\\beta}, \\sigma^2_\\epsilon(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1})\n\\]\nThe estimated coefficients \\(\\hat{\\boldsymbol{\\beta}}\\) are normally distributed with\n\\[\nE(\\hat{\\boldsymbol{\\beta}}) = \\boldsymbol{\\beta} \\hspace{10mm} Var(\\hat{\\boldsymbol{\\beta}}) = \\sigma^2_{\\epsilon}(\\boldsymbol{X}^\\mathsf{T}\\boldsymbol{X})^{-1}\n\\]"
  },
  {
    "objectID": "slides/10-inference-pt3.html#sampling-distribution-of-hatbeta_j",
    "href": "slides/10-inference-pt3.html#sampling-distribution-of-hatbeta_j",
    "title": "Inference for regression",
    "section": "Sampling distribution of \\(\\hat{\\beta}_j\\)",
    "text": "Sampling distribution of \\(\\hat{\\beta}_j\\)\n\\[\n\\hat{\\boldsymbol{\\beta}} \\sim N(\\boldsymbol{\\beta}, \\sigma^2_\\epsilon(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1})\n\\]\nLet \\(\\mathbf{C} = (\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\). Then, for each coefficient \\(\\hat{\\beta}_j\\),\n\n\n\\(E(\\hat{\\beta}_j) = \\boldsymbol{\\beta}_j\\), the \\(j^{th}\\) element of \\(\\boldsymbol{\\beta}\\)\n\\(Var(\\hat{\\beta}_j) = \\sigma^2_{\\epsilon}C_{jj}\\)\n\\(Cov(\\hat{\\beta}_i, \\hat{\\beta}_j) = \\sigma^2_{\\epsilon}C_{ij}\\)"
  },
  {
    "objectID": "slides/10-inference-pt3.html#steps-for-a-hypothesis-test",
    "href": "slides/10-inference-pt3.html#steps-for-a-hypothesis-test",
    "title": "Inference for regression",
    "section": "Steps for a hypothesis test",
    "text": "Steps for a hypothesis test\n\nState the null and alternative hypotheses.\nCalculate a test statistic.\nCalculate the p-value.\nState the conclusion.\n\n\n\nLet’s walk through the steps to test \\(\\beta_j\\), the coefficient for typePublic ."
  },
  {
    "objectID": "slides/10-inference-pt3.html#hypothesis-test-for-beta_j-hypotheses",
    "href": "slides/10-inference-pt3.html#hypothesis-test-for-beta_j-hypotheses",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Hypotheses",
    "text": "Hypothesis test for \\(\\beta_j\\): Hypotheses\n\nNull: There is no linear relationship between institution type and football expenditure, after adjusting for enrollment \\(H_0: \\beta_j = 0\\)\nAlternative: There is a linear relationship between institution type and football expenditure, after adjusting for enrollment \\(H_a: \\beta_j \\neq 0\\)"
  },
  {
    "objectID": "slides/10-inference-pt3.html#hypothesis-test-for-beta_j-test-statistic",
    "href": "slides/10-inference-pt3.html#hypothesis-test-for-beta_j-test-statistic",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Test statistic",
    "text": "Hypothesis test for \\(\\beta_j\\): Test statistic\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0\n\n\n\n\n\nTest statistic: Number of standard errors the estimate is away from the null\n\\[\n\\text{Test Statistic} = \\frac{\\text{Estimate - Null}}{\\text{Standard error}} = \\frac{-13.226 - 0}{3.153} = -4.195 \\\\\n\\]\n\nThis means the estimated slope of -13.226 is 4.195 standard errors below the hypothesized mean of 0."
  },
  {
    "objectID": "slides/10-inference-pt3.html#hypothesis-test-for-beta_j-p-value",
    "href": "slides/10-inference-pt3.html#hypothesis-test-for-beta_j-p-value",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): p-value",
    "text": "Hypothesis test for \\(\\beta_j\\): p-value\n\nThe test statistic follows a \\(t\\) distribution with 124 degrees of freedom.\n\n\\[\np-value = P(|T| &gt; |-4.195|)\n\\]\n\n\n2 * pt(4.195, df = nrow(football) - 2 - 1, lower.tail = FALSE)\n\n[1] 0.00005153923\n\n\n\n\n\nGiven \\(\\beta_j = 0\\) ( \\(H_0\\) is true), the probability of observing a slope of -13.226 or more extreme is \\(\\approx 0\\) ."
  },
  {
    "objectID": "slides/10-inference-pt3.html#hypothesis-test-for-beta_j-conclusion",
    "href": "slides/10-inference-pt3.html#hypothesis-test-for-beta_j-conclusion",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Conclusion",
    "text": "Hypothesis test for \\(\\beta_j\\): Conclusion\n\nThe p-value is \\(\\approx 0\\), so we reject \\(H_0\\).\nThe data provide sufficient evidence that \\(\\beta_j \\neq 0\\), meaning evidence there is a linear relationship between institution type and football expenditure, after adjusting for enrollment."
  },
  {
    "objectID": "slides/10-inference-pt3.html#confidence-interval-for-beta_j-1",
    "href": "slides/10-inference-pt3.html#confidence-interval-for-beta_j-1",
    "title": "Inference for regression",
    "section": "Confidence interval for \\(\\beta_j\\)",
    "text": "Confidence interval for \\(\\beta_j\\)\n\n\nA plausible range of values for a population parameter is called a confidence interval\nUsing only a single point estimate is like fishing in a murky lake with a spear, and using a confidence interval is like fishing with a net\n\nWe can throw a spear where we saw a fish but we will probably miss, if we toss a net in that area, we have a good chance of catching the fish\nSimilarly, if we report a point estimate, we probably will not hit the exact population parameter, but if we report a range of plausible values we have a good shot at capturing the parameter"
  },
  {
    "objectID": "slides/10-inference-pt3.html#what-confidence-means",
    "href": "slides/10-inference-pt3.html#what-confidence-means",
    "title": "Inference for regression",
    "section": "What “confidence” means",
    "text": "What “confidence” means\n\n\nWe will construct \\(C\\%\\) confidence intervals.\n\nThe confidence level impacts the width of the interval\n\n“Confident” means if we were to take repeated samples of the same size as our data, fit regression lines using the same predictors, and calculate \\(C\\%\\) Cs for the coefficient of \\(x_j\\), then \\(C\\%\\) of those intervals will contain the true value of the coefficient \\(\\beta_j\\)\nBalance precision and accuracy when selecting a confidence level"
  },
  {
    "objectID": "slides/10-inference-pt3.html#confidence-interval-for-beta_j-2",
    "href": "slides/10-inference-pt3.html#confidence-interval-for-beta_j-2",
    "title": "Inference for regression",
    "section": "Confidence interval for \\(\\beta_j\\)",
    "text": "Confidence interval for \\(\\beta_j\\)\n\\[\n\\text{Estimate} \\pm \\text{ (critical value) } \\times \\text{SE}\n\\]\n\n\n\\[\n\\hat{\\beta}_1 \\pm t^* \\times SE({\\hat{\\beta}_j})\n\\]\nwhere \\(t^*\\) is calculated from a \\(t\\) distribution with \\(n-p-1\\) degrees of freedom"
  },
  {
    "objectID": "slides/10-inference-pt3.html#confidence-interval-critical-value",
    "href": "slides/10-inference-pt3.html#confidence-interval-critical-value",
    "title": "Inference for regression",
    "section": "Confidence interval: Critical value",
    "text": "Confidence interval: Critical value\n\n\n# confidence level: 95%\nqt(0.975, df = nrow(football) - 2 - 1)\n\n[1] 1.97928\n\n\n\n\n\n\n# confidence level: 90%\nqt(0.95, df = nrow(football) - 2 - 1)\n\n[1] 1.657235\n\n\n\n\n\n\n# confidence level: 99%\nqt(0.995, df = nrow(football) - 2 - 1)\n\n[1] 2.61606"
  },
  {
    "objectID": "slides/10-inference-pt3.html#ci-for-beta_j-calculation",
    "href": "slides/10-inference-pt3.html#ci-for-beta_j-calculation",
    "title": "Inference for regression",
    "section": "95% CI for \\(\\beta_j\\): Calculation",
    "text": "95% CI for \\(\\beta_j\\): Calculation\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0"
  },
  {
    "objectID": "slides/10-inference-pt3.html#ci-for-beta_j-in-r",
    "href": "slides/10-inference-pt3.html#ci-for-beta_j-in-r",
    "title": "Inference for regression",
    "section": "95% CI for \\(\\beta_j\\) in R",
    "text": "95% CI for \\(\\beta_j\\) in R\n\ntidy(exp_fit, conf.int = TRUE, conf.level = 0.95) |&gt; \n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n13.426\n25.239\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n0.562\n0.999\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0\n-19.466\n-6.986\n\n\n\n\n\n\nInterpretation: We are 95% confident that for each additional 1,000 students enrolled, the institution’s expenditures on football will be greater by $562,000 to $999,000, on average, holding institution type constant."
  },
  {
    "objectID": "slides/10-inference-pt3.html#recap",
    "href": "slides/10-inference-pt3.html#recap",
    "title": "Inference for regression",
    "section": "Recap",
    "text": "Recap\n\nConducted hypothesis tests for a single coefficient \\(\\beta_j\\)\nComputed and interpreted confidence intervals for a single coefficient \\(\\beta_j\\)"
  },
  {
    "objectID": "slides/10-inference-pt3.html#next-class",
    "href": "slides/10-inference-pt3.html#next-class",
    "title": "Inference for regression",
    "section": "Next class",
    "text": "Next class\n\nExam 01 review"
  },
  {
    "objectID": "slides/10-inference-pt3-notes.html",
    "href": "slides/10-inference-pt3-notes.html",
    "title": "Inference for regression",
    "section": "",
    "text": "Research topics due TODAY at 11:59pm on GitHub\nHW 02 due Thursday at 11:59pm\nStatistics experience due Tuesday, April 22"
  },
  {
    "objectID": "slides/10-inference-pt3-notes.html#announcements",
    "href": "slides/10-inference-pt3-notes.html#announcements",
    "title": "Inference for regression",
    "section": "",
    "text": "Research topics due TODAY at 11:59pm on GitHub\nHW 02 due Thursday at 11:59pm\nStatistics experience due Tuesday, April 22"
  },
  {
    "objectID": "slides/10-inference-pt3-notes.html#exam-01",
    "href": "slides/10-inference-pt3-notes.html#exam-01",
    "title": "Inference for regression",
    "section": "Exam 01",
    "text": "Exam 01\n\n50 points total\n\nin-class: 35-40 points\ntake-home: 10 - 15 points\n\nIn-class (35 -40 pts): 75 minutes during February 18 lecture\n\nWill be randomly assigned to exam room\n\nTake-home (10 -15 pts): released after class on Tuesday\nIf you miss any part of the exam for an excused absence (with academic dean’s note or other official documentation), your Exam 02 score will be counted twice"
  },
  {
    "objectID": "slides/10-inference-pt3-notes.html#resources",
    "href": "slides/10-inference-pt3-notes.html#resources",
    "title": "Inference for regression",
    "section": "Resources",
    "text": "Resources\n\nExam 01 practice\nLecture recordings\nPrepare readings (see course schedule)\nLecture notes (use search bar to find specific topics)\nAEs\nAssignments"
  },
  {
    "objectID": "slides/10-inference-pt3-notes.html#topics",
    "href": "slides/10-inference-pt3-notes.html#topics",
    "title": "Inference for regression",
    "section": "Topics",
    "text": "Topics\n\nConduct inference on a single coefficient"
  },
  {
    "objectID": "slides/10-inference-pt3-notes.html#computing-setup",
    "href": "slides/10-inference-pt3-notes.html#computing-setup",
    "title": "Inference for regression",
    "section": "Computing setup",
    "text": "Computing setup\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(kableExtra)  \nlibrary(patchwork)   \n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/10-inference-pt3-notes.html#data-ncaa-football-expenditures",
    "href": "slides/10-inference-pt3-notes.html#data-ncaa-football-expenditures",
    "title": "Inference for regression",
    "section": "Data: NCAA Football expenditures",
    "text": "Data: NCAA Football expenditures\nToday’s data come from Equity in Athletics Data Analysis and includes information about sports expenditures and revenues for colleges and universities in the United States. This data set was featured in a March 2022 Tidy Tuesday.\nWe will focus on the 2019 - 2020 season expenditures on football for institutions in the NCAA - Division 1 FBS. The variables are :\n\ntotal_exp_m: Total expenditures on football in the 2019 - 2020 academic year (in millions USD)\nenrollment_th: Total student enrollment in the 2019 - 2020 academic year (in thousands)\ntype: institution type (Public or Private)\n\n\nfootball &lt;- read_csv(\"data/ncaa-football-exp.csv\")"
  },
  {
    "objectID": "slides/10-inference-pt3-notes.html#regression-model",
    "href": "slides/10-inference-pt3-notes.html#regression-model",
    "title": "Inference for regression",
    "section": "Regression model",
    "text": "Regression model\n\nexp_fit &lt;- lm(total_exp_m ~ enrollment_th + type, data = football)\ntidy(exp_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0"
  },
  {
    "objectID": "slides/10-inference-pt3-notes.html#inference-for-beta_j",
    "href": "slides/10-inference-pt3-notes.html#inference-for-beta_j",
    "title": "Inference for regression",
    "section": "Inference for \\(\\beta_j\\)",
    "text": "Inference for \\(\\beta_j\\)\nWe often want to conduct inference on individual model coefficients\n\nHypothesis test: Is there a linear relationship between the response and \\(x_j\\)?\nConfidence interval: What is a plausible range of values \\(\\beta_j\\) can take?"
  },
  {
    "objectID": "slides/10-inference-pt3-notes.html#sampling-distribution-of-hatbeta",
    "href": "slides/10-inference-pt3-notes.html#sampling-distribution-of-hatbeta",
    "title": "Inference for regression",
    "section": "Sampling distribution of \\(\\hat{\\beta}\\)",
    "text": "Sampling distribution of \\(\\hat{\\beta}\\)\n\nA sampling distribution is the probability distribution of a statistic for a large number of random samples of size \\(n\\) from a population\nThe sampling distribution of \\(\\hat{\\boldsymbol{\\beta}}\\) is the probability distribution of the estimated coefficients if we repeatedly took samples of size \\(n\\) and fit the regression model\n\n\\[\n\\hat{\\boldsymbol{\\beta}} \\sim N(\\boldsymbol{\\beta}, \\sigma^2_\\epsilon(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1})\n\\]\nThe estimated coefficients \\(\\hat{\\boldsymbol{\\beta}}\\) are normally distributed with\n\\[\nE(\\hat{\\boldsymbol{\\beta}}) = \\boldsymbol{\\beta} \\hspace{10mm} Var(\\hat{\\boldsymbol{\\beta}}) = \\sigma^2_{\\epsilon}(\\boldsymbol{X}^\\mathsf{T}\\boldsymbol{X})^{-1}\n\\]"
  },
  {
    "objectID": "slides/10-inference-pt3-notes.html#sampling-distribution-of-hatbeta_j",
    "href": "slides/10-inference-pt3-notes.html#sampling-distribution-of-hatbeta_j",
    "title": "Inference for regression",
    "section": "Sampling distribution of \\(\\hat{\\beta}_j\\)",
    "text": "Sampling distribution of \\(\\hat{\\beta}_j\\)\n\\[\n\\hat{\\boldsymbol{\\beta}} \\sim N(\\boldsymbol{\\beta}, \\sigma^2_\\epsilon(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1})\n\\]\nLet \\(\\mathbf{C} = (\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\). Then, for each coefficient \\(\\hat{\\beta}_j\\),\n\n\n\\(E(\\hat{\\beta}_j) = \\boldsymbol{\\beta}_j\\), the \\(j^{th}\\) element of \\(\\boldsymbol{\\beta}\\)\n\\(Var(\\hat{\\beta}_j) = \\sigma^2_{\\epsilon}C_{jj}\\)\n\\(Cov(\\hat{\\beta}_i, \\hat{\\beta}_j) = \\sigma^2_{\\epsilon}C_{ij}\\)"
  },
  {
    "objectID": "slides/10-inference-pt3-notes.html#steps-for-a-hypothesis-test",
    "href": "slides/10-inference-pt3-notes.html#steps-for-a-hypothesis-test",
    "title": "Inference for regression",
    "section": "Steps for a hypothesis test",
    "text": "Steps for a hypothesis test\n\nState the null and alternative hypotheses.\nCalculate a test statistic.\nCalculate the p-value.\nState the conclusion.\n\n\n\nLet’s walk through the steps to test \\(\\beta_j\\), the coefficient for typePublic ."
  },
  {
    "objectID": "slides/10-inference-pt3-notes.html#hypothesis-test-for-beta_j-hypotheses",
    "href": "slides/10-inference-pt3-notes.html#hypothesis-test-for-beta_j-hypotheses",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Hypotheses",
    "text": "Hypothesis test for \\(\\beta_j\\): Hypotheses\n\nNull: There is no linear relationship between institution type and football expenditure, after adjusting for enrollment \\(H_0: \\beta_j = 0\\)\nAlternative: There is a linear relationship between institution type and football expenditure, after adjusting for enrollment \\(H_a: \\beta_j \\neq 0\\)"
  },
  {
    "objectID": "slides/10-inference-pt3-notes.html#hypothesis-test-for-beta_j-test-statistic",
    "href": "slides/10-inference-pt3-notes.html#hypothesis-test-for-beta_j-test-statistic",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Test statistic",
    "text": "Hypothesis test for \\(\\beta_j\\): Test statistic\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0\n\n\n\n\n\nTest statistic: Number of standard errors the estimate is away from the null\n\\[\n\\text{Test Statistic} = \\frac{\\text{Estimate - Null}}{\\text{Standard error}} = \\frac{-13.226 - 0}{3.153} = -4.195 \\\\\n\\]\n. . .\nThis means the estimated slope of -13.226 is 4.195 standard errors below the hypothesized mean of 0."
  },
  {
    "objectID": "slides/10-inference-pt3-notes.html#hypothesis-test-for-beta_j-p-value",
    "href": "slides/10-inference-pt3-notes.html#hypothesis-test-for-beta_j-p-value",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): p-value",
    "text": "Hypothesis test for \\(\\beta_j\\): p-value\n\nThe test statistic follows a \\(t\\) distribution with 124 degrees of freedom.\n\n\\[\np-value = P(|T| &gt; |-4.195|)\n\\]\n. . .\n\n2 * pt(4.195, df = nrow(football) - 2 - 1, lower.tail = FALSE)\n\n[1] 0.00005153923\n\n\n\n. . .\nGiven \\(\\beta_j = 0\\) ( \\(H_0\\) is true), the probability of observing a slope of -13.226 or more extreme is \\(\\approx 0\\) ."
  },
  {
    "objectID": "slides/10-inference-pt3-notes.html#hypothesis-test-for-beta_j-conclusion",
    "href": "slides/10-inference-pt3-notes.html#hypothesis-test-for-beta_j-conclusion",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Conclusion",
    "text": "Hypothesis test for \\(\\beta_j\\): Conclusion\n\nThe p-value is \\(\\approx 0\\), so we reject \\(H_0\\).\nThe data provide sufficient evidence that \\(\\beta_j \\neq 0\\), meaning evidence there is a linear relationship between institution type and football expenditure, after adjusting for enrollment."
  },
  {
    "objectID": "slides/10-inference-pt3-notes.html#confidence-interval-for-beta_j-1",
    "href": "slides/10-inference-pt3-notes.html#confidence-interval-for-beta_j-1",
    "title": "Inference for regression",
    "section": "Confidence interval for \\(\\beta_j\\)",
    "text": "Confidence interval for \\(\\beta_j\\)\n\n\nA plausible range of values for a population parameter is called a confidence interval\nUsing only a single point estimate is like fishing in a murky lake with a spear, and using a confidence interval is like fishing with a net\n\nWe can throw a spear where we saw a fish but we will probably miss, if we toss a net in that area, we have a good chance of catching the fish\nSimilarly, if we report a point estimate, we probably will not hit the exact population parameter, but if we report a range of plausible values we have a good shot at capturing the parameter"
  },
  {
    "objectID": "slides/10-inference-pt3-notes.html#what-confidence-means",
    "href": "slides/10-inference-pt3-notes.html#what-confidence-means",
    "title": "Inference for regression",
    "section": "What “confidence” means",
    "text": "What “confidence” means\n\n\nWe will construct \\(C\\%\\) confidence intervals.\n\nThe confidence level impacts the width of the interval\n\n“Confident” means if we were to take repeated samples of the same size as our data, fit regression lines using the same predictors, and calculate \\(C\\%\\) Cs for the coefficient of \\(x_j\\), then \\(C\\%\\) of those intervals will contain the true value of the coefficient \\(\\beta_j\\)\nBalance precision and accuracy when selecting a confidence level"
  },
  {
    "objectID": "slides/10-inference-pt3-notes.html#confidence-interval-for-beta_j-2",
    "href": "slides/10-inference-pt3-notes.html#confidence-interval-for-beta_j-2",
    "title": "Inference for regression",
    "section": "Confidence interval for \\(\\beta_j\\)",
    "text": "Confidence interval for \\(\\beta_j\\)\n\\[\n\\text{Estimate} \\pm \\text{ (critical value) } \\times \\text{SE}\n\\]\n\n. . .\n\\[\n\\hat{\\beta}_1 \\pm t^* \\times SE({\\hat{\\beta}_j})\n\\]\nwhere \\(t^*\\) is calculated from a \\(t\\) distribution with \\(n-p-1\\) degrees of freedom"
  },
  {
    "objectID": "slides/10-inference-pt3-notes.html#confidence-interval-critical-value",
    "href": "slides/10-inference-pt3-notes.html#confidence-interval-critical-value",
    "title": "Inference for regression",
    "section": "Confidence interval: Critical value",
    "text": "Confidence interval: Critical value\n\n\n# confidence level: 95%\nqt(0.975, df = nrow(football) - 2 - 1)\n\n[1] 1.97928\n\n\n\n\n\n\n# confidence level: 90%\nqt(0.95, df = nrow(football) - 2 - 1)\n\n[1] 1.657235\n\n\n\n\n\n\n# confidence level: 99%\nqt(0.995, df = nrow(football) - 2 - 1)\n\n[1] 2.61606"
  },
  {
    "objectID": "slides/10-inference-pt3-notes.html#ci-for-beta_j-calculation",
    "href": "slides/10-inference-pt3-notes.html#ci-for-beta_j-calculation",
    "title": "Inference for regression",
    "section": "95% CI for \\(\\beta_j\\): Calculation",
    "text": "95% CI for \\(\\beta_j\\): Calculation\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0"
  },
  {
    "objectID": "slides/10-inference-pt3-notes.html#ci-for-beta_j-in-r",
    "href": "slides/10-inference-pt3-notes.html#ci-for-beta_j-in-r",
    "title": "Inference for regression",
    "section": "95% CI for \\(\\beta_j\\) in R",
    "text": "95% CI for \\(\\beta_j\\) in R\n\ntidy(exp_fit, conf.int = TRUE, conf.level = 0.95) |&gt; \n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n13.426\n25.239\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n0.562\n0.999\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0\n-19.466\n-6.986\n\n\n\n\n\n\nInterpretation: We are 95% confident that for each additional 1,000 students enrolled, the institution’s expenditures on football will be greater by $562,000 to $999,000, on average, holding institution type constant."
  },
  {
    "objectID": "slides/10-inference-pt3-notes.html#recap",
    "href": "slides/10-inference-pt3-notes.html#recap",
    "title": "Inference for regression",
    "section": "Recap",
    "text": "Recap\n\nConducted hypothesis tests for a single coefficient \\(\\beta_j\\)\nComputed and interpreted confidence intervals for a single coefficient \\(\\beta_j\\)"
  },
  {
    "objectID": "slides/10-inference-pt3-notes.html#next-class",
    "href": "slides/10-inference-pt3-notes.html#next-class",
    "title": "Inference for regression",
    "section": "Next class",
    "text": "Next class\n\nExam 01 review"
  },
  {
    "objectID": "slides/08-inference.html#announcements",
    "href": "slides/08-inference.html#announcements",
    "title": "Inference for regression",
    "section": "Announcements",
    "text": "Announcements\n\nLab 03 due TODAY at 11:59pm\nClick here to learn more about the Academic Resource Center\nStatistics experience due Tuesday, April 22"
  },
  {
    "objectID": "slides/08-inference.html#poll-office-hours-availability",
    "href": "slides/08-inference.html#poll-office-hours-availability",
    "title": "Inference for regression",
    "section": "Poll: Office hours availability",
    "text": "Poll: Office hours availability\n\n \n🔗 https://forms.office.com/r/DL8rBQ988y"
  },
  {
    "objectID": "slides/08-inference.html#topics",
    "href": "slides/08-inference.html#topics",
    "title": "Inference for regression",
    "section": "Topics",
    "text": "Topics\n\nUnderstand statistical inference in the context of regression\nDescribe the assumptions for regression\nUnderstand connection between distribution of residuals and inferential procedures\nConduct inference on a single coefficient"
  },
  {
    "objectID": "slides/08-inference.html#computing-setup",
    "href": "slides/08-inference.html#computing-setup",
    "title": "Inference for regression",
    "section": "Computing setup",
    "text": "Computing setup\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(kableExtra)  \nlibrary(patchwork)   \n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/08-inference.html#data-ncaa-football-expenditures",
    "href": "slides/08-inference.html#data-ncaa-football-expenditures",
    "title": "Inference for regression",
    "section": "Data: NCAA Football expenditures",
    "text": "Data: NCAA Football expenditures\nToday’s data come from Equity in Athletics Data Analysis and includes information about sports expenditures and revenues for colleges and universities in the United States. This data set was featured in a March 2022 Tidy Tuesday.\nWe will focus on the 2019 - 2020 season expenditures on football for institutions in the NCAA - Division 1 FBS. The variables are :\n\ntotal_exp_m: Total expenditures on football in the 2019 - 2020 academic year (in millions USD)\nenrollment_th: Total student enrollment in the 2019 - 2020 academic year (in thousands)\ntype: institution type (Public or Private)\n\n\nfootball &lt;- read_csv(\"data/ncaa-football-exp.csv\")"
  },
  {
    "objectID": "slides/08-inference.html#univariate-eda",
    "href": "slides/08-inference.html#univariate-eda",
    "title": "Inference for regression",
    "section": "Univariate EDA",
    "text": "Univariate EDA"
  },
  {
    "objectID": "slides/08-inference.html#bivariate-eda",
    "href": "slides/08-inference.html#bivariate-eda",
    "title": "Inference for regression",
    "section": "Bivariate EDA",
    "text": "Bivariate EDA"
  },
  {
    "objectID": "slides/08-inference.html#regression-model",
    "href": "slides/08-inference.html#regression-model",
    "title": "Inference for regression",
    "section": "Regression model",
    "text": "Regression model\n\nexp_fit &lt;- lm(total_exp_m ~ enrollment_th + type, data = football)\ntidy(exp_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0\n\n\n\n\n\n\nFor every additional 1,000 students, we expect an institution’s total expenditures on football to increase by $780,000, on average, holding institution type constant."
  },
  {
    "objectID": "slides/08-inference.html#from-sample-to-population",
    "href": "slides/08-inference.html#from-sample-to-population",
    "title": "Inference for regression",
    "section": "From sample to population",
    "text": "From sample to population\n\nFor every additional 1,000 students, we expect an institution’s total expenditures on football to increase by $780,000, on average, holding institution type constant.\n\n\n\n\nThis estimate is valid for the single sample of 127 higher education institutions in the 2019 - 2020 academic year.\nBut what if we’re not interested quantifying the relationship between student enrollment, institution type, and football expenditures for this single sample?\nWhat if we want to say something about the relationship between these variables for all colleges and universities with football programs and across different years?"
  },
  {
    "objectID": "slides/08-inference.html#statistical-inference",
    "href": "slides/08-inference.html#statistical-inference",
    "title": "Inference for regression",
    "section": "Statistical inference",
    "text": "Statistical inference\n\n\n\n\nStatistical inference provides methods and tools so we can use the single observed sample to make valid statements (inferences) about the population it comes from\nFor our inferences to be valid, the sample should be representative (ideally random) of the population we’re interested in\n\n\n\n\n\n\nImage source: Eugene Morgan © Penn State"
  },
  {
    "objectID": "slides/08-inference.html#inference-for-linear-regression",
    "href": "slides/08-inference.html#inference-for-linear-regression",
    "title": "Inference for regression",
    "section": "Inference for linear regression",
    "text": "Inference for linear regression\n\nInference based on ANOVA\n\nHypothesis test for the statistical significance of the overall regression model\nHypothesis test for a subset of coefficients\n\nInference for a single coefficient \\(\\beta_j\\) (today’s focus)\n\nHypothesis test for a coefficient \\(\\beta_j\\)\nConfidence interval for a coefficient \\(\\beta_j\\)"
  },
  {
    "objectID": "slides/08-inference.html#linear-regression-model",
    "href": "slides/08-inference.html#linear-regression-model",
    "title": "Inference for regression",
    "section": "Linear regression model",
    "text": "Linear regression model\n\\[\n\\begin{aligned}\n\\mathbf{y} &= \\text{Model} + \\text{Error} \\\\[5pt]\n&= f(\\mathbf{X}) + \\boldsymbol{\\epsilon} \\\\[5pt]\n&= E(\\mathbf{y}|\\mathbf{X}) + \\mathbf{\\epsilon} \\\\[5pt]\n&= \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon}\n\\end{aligned}\n\\]\n\n\n\nWe have discussed multiple ways to find the least squares estimates of \\(\\boldsymbol{\\beta} = \\begin{bmatrix}\\beta_0 \\\\\\beta_1\\end{bmatrix}\\)\n\nNone of these approaches depend on the distribution of \\(\\boldsymbol{\\epsilon}\\)\n\nNow we will use statistical inference to draw conclusions about \\(\\boldsymbol{\\beta}\\) that depend on particular assumptions about the distribution of \\(\\boldsymbol{\\epsilon}\\)"
  },
  {
    "objectID": "slides/08-inference.html#linear-regression-model-1",
    "href": "slides/08-inference.html#linear-regression-model-1",
    "title": "Inference for regression",
    "section": "Linear regression model",
    "text": "Linear regression model\n\\[\\begin{aligned}\n\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}, \\hspace{8mm} \\boldsymbol{\\epsilon} \\sim N(\\mathbf{0}, \\sigma^2_{\\epsilon}\\mathbf{I})\n\\end{aligned}\n\\]\nsuch that the errors are independent and normally distributed.\n\n\nIndependent: Knowing the error term for one observation doesn’t tell us about the error term for another observation\nNormally distributed: The distribution follows a particular mathematical model that is unimodal and symmetric"
  },
  {
    "objectID": "slides/08-inference.html#describing-random-phenomena",
    "href": "slides/08-inference.html#describing-random-phenomena",
    "title": "Inference for regression",
    "section": "Describing random phenomena",
    "text": "Describing random phenomena\n\n\nThere is some uncertainty in the error terms (and thus the response variable), so we use mathematical models to describe that uncertainty.\nSome terminology:\n\nSample space: Set of all possible outcomes\nRandom variable: Function (mapping) from the sample space onto real numbers\nEvent: Subset of the sample space, i.e., a set of possible outcomes (possible values the random variable can take)\nProbability density function: Mathematical function that produces probability of occurrences for events in the sample space for a continuous random variable"
  },
  {
    "objectID": "slides/08-inference.html#distribution-of-error-terms",
    "href": "slides/08-inference.html#distribution-of-error-terms",
    "title": "Inference for regression",
    "section": "Distribution of error terms",
    "text": "Distribution of error terms\nThe error terms follow a (multivariate) normal distribution with mean \\(\\mathbf{0}\\) and variance \\(\\sigma^2\\mathbf{I}\\)\n\\[f(\\boldsymbol{\\epsilon}) = \\frac{1}{(2\\pi)^{n/2}|\\sigma^2_{\\epsilon}\\mathbf{I}|^{1/2}}\\exp\\Big\\{-\\frac{1}{2}(\\boldsymbol{\\epsilon} - \\mathbf{0})^\\mathsf{T}(\\sigma^2_{\\epsilon}\\mathbf{I})^{-1}(\\boldsymbol{\\epsilon}- \\mathbf{0})\\Big\\}\\]"
  },
  {
    "objectID": "slides/08-inference.html#visualizing-distribution-of-mathbfymathbfx",
    "href": "slides/08-inference.html#visualizing-distribution-of-mathbfymathbfx",
    "title": "Inference for regression",
    "section": "Visualizing distribution of \\(\\mathbf{y}|\\mathbf{X}\\)",
    "text": "Visualizing distribution of \\(\\mathbf{y}|\\mathbf{X}\\)\n\\[\n\\mathbf{y}|\\mathbf{X} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma_\\epsilon^2\\mathbf{I})\n\\]\n\nImage source: Introduction to the Practice of Statistics (5th ed)"
  },
  {
    "objectID": "slides/08-inference.html#expected-value",
    "href": "slides/08-inference.html#expected-value",
    "title": "Inference for regression",
    "section": "Expected value",
    "text": "Expected value\nLet \\(\\mathbf{z} = \\begin{bmatrix}z_1 \\\\ \\vdots \\\\z_p\\end{bmatrix}\\) be a \\(p \\times 1\\) vector of random variables.\n\n\nThen \\(E(\\mathbf{z}) = E\\begin{bmatrix}z_1 \\\\ \\vdots \\\\ z_p\\end{bmatrix} = \\begin{bmatrix}E(z_1) \\\\ \\vdots \\\\ E(z_p)\\end{bmatrix}\\)"
  },
  {
    "objectID": "slides/08-inference.html#expected-value-1",
    "href": "slides/08-inference.html#expected-value-1",
    "title": "Inference for regression",
    "section": "Expected value",
    "text": "Expected value\nLet \\(\\mathbf{A}\\) be an \\(n \\times p\\) matrix of constants, \\(\\mathbf{C}\\) a \\(n \\times 1\\) vector of constants, and \\(\\mathbf{z}\\) a \\(p \\times 1\\) vector of random variables. Then\n\\[\nE(\\mathbf{Az}) = \\mathbf{A}E(\\mathbf{z})\n\\]\n\n\n\\[\nE(\\mathbf{Az} + \\mathbf{C}) = E(\\mathbf{Az}) + E(\\mathbf{C}) = \\mathbf{A}E(\\mathbf{z}) + \\mathbf{C}\n\\]"
  },
  {
    "objectID": "slides/08-inference.html#expected-value-of-the-response",
    "href": "slides/08-inference.html#expected-value-of-the-response",
    "title": "Inference for regression",
    "section": "Expected value of the response",
    "text": "Expected value of the response\n\nShow \\[\nE(\\mathbf{y}|\\mathbf{X}) = \\mathbf{X}\\boldsymbol{\\beta}\n\\]"
  },
  {
    "objectID": "slides/08-inference.html#variance",
    "href": "slides/08-inference.html#variance",
    "title": "Inference for regression",
    "section": "Variance",
    "text": "Variance\n\nLet \\(\\mathbf{z} = \\begin{bmatrix}z_1 \\\\ \\vdots \\\\z_p\\end{bmatrix}\\) be a \\(p \\times 1\\) vector of random variables.\n\n\nThen \\(Var(\\mathbf{z}) = \\begin{bmatrix}Var(z_1) & Cov(z_1, z_2) & \\dots & Cov(z_1, z_p)\\\\ Cov(z_2, z_1) & Var(z_2) & \\dots & Cov(z_2, z_p) \\\\ \\vdots & \\vdots & \\dots & \\cdot \\\\ Cov(z_p, z_1) & Cov(z_p, z_2) & \\dots & Var(z_p)\\end{bmatrix}\\)"
  },
  {
    "objectID": "slides/08-inference.html#variance-1",
    "href": "slides/08-inference.html#variance-1",
    "title": "Inference for regression",
    "section": "Variance",
    "text": "Variance\nLet \\(\\mathbf{A}\\) be an \\(n \\times p\\) matrix of constants and \\(\\mathbf{z}\\) a \\(p \\times 1\\) vector of random variables. Then\n\\[\nVar(\\mathbf{z}) = E[(\\mathbf{z} - E(\\mathbf{z}))(\\mathbf{z} - E(\\mathbf{z}))^\\mathsf{T}]\n\\]\n\n\n\\[\n\\begin{aligned}\nVar(\\mathbf{Az}) &= E[(\\mathbf{Az} - E(\\mathbf{Az}))(\\mathbf{Az} - E(\\mathbf{Az}))^\\mathsf{T}] \\\\[8pt]\n& = \\mathbf{A}Var(\\mathbf{z})\\mathbf{A}^\\mathsf{T}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/08-inference.html#variance-of-the-response",
    "href": "slides/08-inference.html#variance-of-the-response",
    "title": "Inference for regression",
    "section": "Variance of the response",
    "text": "Variance of the response\n\nShow\n\\[\nVar(\\mathbf{y}|\\mathbf{X}) = \\sigma^2_\\epsilon\\mathbf{I}\n\\]"
  },
  {
    "objectID": "slides/08-inference.html#linear-transformation-of-normal-random-variable",
    "href": "slides/08-inference.html#linear-transformation-of-normal-random-variable",
    "title": "Inference for regression",
    "section": "Linear transformation of normal random variable",
    "text": "Linear transformation of normal random variable\nSuppose \\(\\mathbf{z}\\) is a (multivariate) normal random variable such that \\(\\mathbf{z} \\sim N(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\\)\n\nA linear transformation of \\(\\mathbf{z}\\) is also multivariate normal, such that\n\\[\n\\mathbf{A}\\mathbf{z} + \\mathbf{B} \\sim N(\\mathbf{A}\\boldsymbol{\\mu} + \\mathbf{B}, \\mathbf{A}\\boldsymbol{\\Sigma}\\mathbf{A}^\\mathsf{T})\n\\]\n\nExplain why \\(\\mathbf{y}|\\mathbf{X}\\) is normally distributed."
  },
  {
    "objectID": "slides/08-inference.html#recap",
    "href": "slides/08-inference.html#recap",
    "title": "Inference for regression",
    "section": "Recap",
    "text": "Recap\n\nIntroduced statistical inference in the context of regression\nDescribed the assumptions for regression\nConnected the distribution of residuals and inferential procedures"
  },
  {
    "objectID": "slides/08-inference.html#next-class",
    "href": "slides/08-inference.html#next-class",
    "title": "Inference for regression",
    "section": "Next class",
    "text": "Next class\n\nConfidence intervals for \\(\\hat{\\beta}_j\\)\nHypothesis testing based on ANOVA\nSee Prepare for Lecture 09"
  },
  {
    "objectID": "slides/08-inference-notes.html",
    "href": "slides/08-inference-notes.html",
    "title": "Inference for regression",
    "section": "",
    "text": "Lab 03 due TODAY at 11:59pm\nClick here to learn more about the Academic Resource Center\nStatistics experience due Tuesday, April 22"
  },
  {
    "objectID": "slides/08-inference-notes.html#announcements",
    "href": "slides/08-inference-notes.html#announcements",
    "title": "Inference for regression",
    "section": "",
    "text": "Lab 03 due TODAY at 11:59pm\nClick here to learn more about the Academic Resource Center\nStatistics experience due Tuesday, April 22"
  },
  {
    "objectID": "slides/08-inference-notes.html#poll-office-hours-availability",
    "href": "slides/08-inference-notes.html#poll-office-hours-availability",
    "title": "Inference for regression",
    "section": "Poll: Office hours availability",
    "text": "Poll: Office hours availability\n\n \n🔗 https://forms.office.com/r/DL8rBQ988y"
  },
  {
    "objectID": "slides/08-inference-notes.html#topics",
    "href": "slides/08-inference-notes.html#topics",
    "title": "Inference for regression",
    "section": "Topics",
    "text": "Topics\n\nUnderstand statistical inference in the context of regression\nDescribe the assumptions for regression\nUnderstand connection between distribution of residuals and inferential procedures\nConduct inference on a single coefficient"
  },
  {
    "objectID": "slides/08-inference-notes.html#computing-setup",
    "href": "slides/08-inference-notes.html#computing-setup",
    "title": "Inference for regression",
    "section": "Computing setup",
    "text": "Computing setup\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(kableExtra)  \nlibrary(patchwork)   \n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/08-inference-notes.html#data-ncaa-football-expenditures",
    "href": "slides/08-inference-notes.html#data-ncaa-football-expenditures",
    "title": "Inference for regression",
    "section": "Data: NCAA Football expenditures",
    "text": "Data: NCAA Football expenditures\nToday’s data come from Equity in Athletics Data Analysis and includes information about sports expenditures and revenues for colleges and universities in the United States. This data set was featured in a March 2022 Tidy Tuesday.\nWe will focus on the 2019 - 2020 season expenditures on football for institutions in the NCAA - Division 1 FBS. The variables are :\n\ntotal_exp_m: Total expenditures on football in the 2019 - 2020 academic year (in millions USD)\nenrollment_th: Total student enrollment in the 2019 - 2020 academic year (in thousands)\ntype: institution type (Public or Private)\n\n\nfootball &lt;- read_csv(\"data/ncaa-football-exp.csv\")"
  },
  {
    "objectID": "slides/08-inference-notes.html#univariate-eda",
    "href": "slides/08-inference-notes.html#univariate-eda",
    "title": "Inference for regression",
    "section": "Univariate EDA",
    "text": "Univariate EDA"
  },
  {
    "objectID": "slides/08-inference-notes.html#bivariate-eda",
    "href": "slides/08-inference-notes.html#bivariate-eda",
    "title": "Inference for regression",
    "section": "Bivariate EDA",
    "text": "Bivariate EDA"
  },
  {
    "objectID": "slides/08-inference-notes.html#regression-model",
    "href": "slides/08-inference-notes.html#regression-model",
    "title": "Inference for regression",
    "section": "Regression model",
    "text": "Regression model\n\nexp_fit &lt;- lm(total_exp_m ~ enrollment_th + type, data = football)\ntidy(exp_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0\n\n\n\n\n\n\nFor every additional 1,000 students, we expect an institution’s total expenditures on football to increase by $780,000, on average, holding institution type constant."
  },
  {
    "objectID": "slides/08-inference-notes.html#from-sample-to-population",
    "href": "slides/08-inference-notes.html#from-sample-to-population",
    "title": "Inference for regression",
    "section": "From sample to population",
    "text": "From sample to population\n\nFor every additional 1,000 students, we expect an institution’s total expenditures on football to increase by $780,000, on average, holding institution type constant.\n\n. . .\n\n\nThis estimate is valid for the single sample of 127 higher education institutions in the 2019 - 2020 academic year.\nBut what if we’re not interested quantifying the relationship between student enrollment, institution type, and football expenditures for this single sample?\nWhat if we want to say something about the relationship between these variables for all colleges and universities with football programs and across different years?"
  },
  {
    "objectID": "slides/08-inference-notes.html#statistical-inference",
    "href": "slides/08-inference-notes.html#statistical-inference",
    "title": "Inference for regression",
    "section": "Statistical inference",
    "text": "Statistical inference\n\n\n\n\nStatistical inference provides methods and tools so we can use the single observed sample to make valid statements (inferences) about the population it comes from\nFor our inferences to be valid, the sample should be representative (ideally random) of the population we’re interested in\n\n\n\n\n\n\nImage source: Eugene Morgan © Penn State"
  },
  {
    "objectID": "slides/08-inference-notes.html#inference-for-linear-regression",
    "href": "slides/08-inference-notes.html#inference-for-linear-regression",
    "title": "Inference for regression",
    "section": "Inference for linear regression",
    "text": "Inference for linear regression\n\nInference based on ANOVA\n\nHypothesis test for the statistical significance of the overall regression model\nHypothesis test for a subset of coefficients\n\nInference for a single coefficient \\(\\beta_j\\) (today’s focus)\n\nHypothesis test for a coefficient \\(\\beta_j\\)\nConfidence interval for a coefficient \\(\\beta_j\\)"
  },
  {
    "objectID": "slides/08-inference-notes.html#linear-regression-model",
    "href": "slides/08-inference-notes.html#linear-regression-model",
    "title": "Inference for regression",
    "section": "Linear regression model",
    "text": "Linear regression model\n\\[\n\\begin{aligned}\n\\mathbf{y} &= \\text{Model} + \\text{Error} \\\\[5pt]\n&= f(\\mathbf{X}) + \\boldsymbol{\\epsilon} \\\\[5pt]\n&= E(\\mathbf{y}|\\mathbf{X}) + \\mathbf{\\epsilon} \\\\[5pt]\n&= \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon}\n\\end{aligned}\n\\]\n. . .\n\n\nWe have discussed multiple ways to find the least squares estimates of \\(\\boldsymbol{\\beta} = \\begin{bmatrix}\\beta_0 \\\\\\beta_1\\end{bmatrix}\\)\n\nNone of these approaches depend on the distribution of \\(\\boldsymbol{\\epsilon}\\)\n\nNow we will use statistical inference to draw conclusions about \\(\\boldsymbol{\\beta}\\) that depend on particular assumptions about the distribution of \\(\\boldsymbol{\\epsilon}\\)"
  },
  {
    "objectID": "slides/08-inference-notes.html#linear-regression-model-1",
    "href": "slides/08-inference-notes.html#linear-regression-model-1",
    "title": "Inference for regression",
    "section": "Linear regression model",
    "text": "Linear regression model\n\\[\\begin{aligned}\n\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}, \\hspace{8mm} \\boldsymbol{\\epsilon} \\sim N(\\mathbf{0}, \\sigma^2_{\\epsilon}\\mathbf{I})\n\\end{aligned}\n\\]\nsuch that the errors are independent and normally distributed.\n. . .\n\nIndependent: Knowing the error term for one observation doesn’t tell us about the error term for another observation\nNormally distributed: The distribution follows a particular mathematical model that is unimodal and symmetric"
  },
  {
    "objectID": "slides/08-inference-notes.html#describing-random-phenomena",
    "href": "slides/08-inference-notes.html#describing-random-phenomena",
    "title": "Inference for regression",
    "section": "Describing random phenomena",
    "text": "Describing random phenomena\n\n\nThere is some uncertainty in the error terms (and thus the response variable), so we use mathematical models to describe that uncertainty.\nSome terminology:\n\nSample space: Set of all possible outcomes\nRandom variable: Function (mapping) from the sample space onto real numbers\nEvent: Subset of the sample space, i.e., a set of possible outcomes (possible values the random variable can take)\nProbability density function: Mathematical function that produces probability of occurrences for events in the sample space for a continuous random variable"
  },
  {
    "objectID": "slides/08-inference-notes.html#distribution-of-error-terms",
    "href": "slides/08-inference-notes.html#distribution-of-error-terms",
    "title": "Inference for regression",
    "section": "Distribution of error terms",
    "text": "Distribution of error terms\nThe error terms follow a (multivariate) normal distribution with mean \\(\\mathbf{0}\\) and variance \\(\\sigma^2\\mathbf{I}\\)\n\\[f(\\boldsymbol{\\epsilon}) = \\frac{1}{(2\\pi)^{n/2}|\\sigma^2_{\\epsilon}\\mathbf{I}|^{1/2}}\\exp\\Big\\{-\\frac{1}{2}(\\boldsymbol{\\epsilon} - \\mathbf{0})^\\mathsf{T}(\\sigma^2_{\\epsilon}\\mathbf{I})^{-1}(\\boldsymbol{\\epsilon}- \\mathbf{0})\\Big\\}\\]"
  },
  {
    "objectID": "slides/08-inference-notes.html#visualizing-distribution-of-mathbfymathbfx",
    "href": "slides/08-inference-notes.html#visualizing-distribution-of-mathbfymathbfx",
    "title": "Inference for regression",
    "section": "Visualizing distribution of \\(\\mathbf{y}|\\mathbf{X}\\)",
    "text": "Visualizing distribution of \\(\\mathbf{y}|\\mathbf{X}\\)\n\\[\n\\mathbf{y}|\\mathbf{X} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma_\\epsilon^2\\mathbf{I})\n\\]\n\n\n\nImage source: Introduction to the Practice of Statistics (5th ed)"
  },
  {
    "objectID": "slides/08-inference-notes.html#expected-value",
    "href": "slides/08-inference-notes.html#expected-value",
    "title": "Inference for regression",
    "section": "Expected value",
    "text": "Expected value\nLet \\(\\mathbf{z} = \\begin{bmatrix}z_1 \\\\ \\vdots \\\\z_p\\end{bmatrix}\\) be a \\(p \\times 1\\) vector of random variables.\n\n. . .\nThen \\(E(\\mathbf{z}) = E\\begin{bmatrix}z_1 \\\\ \\vdots \\\\ z_p\\end{bmatrix} = \\begin{bmatrix}E(z_1) \\\\ \\vdots \\\\ E(z_p)\\end{bmatrix}\\)"
  },
  {
    "objectID": "slides/08-inference-notes.html#expected-value-1",
    "href": "slides/08-inference-notes.html#expected-value-1",
    "title": "Inference for regression",
    "section": "Expected value",
    "text": "Expected value\nLet \\(\\mathbf{A}\\) be an \\(n \\times p\\) matrix of constants, \\(\\mathbf{C}\\) a \\(n \\times 1\\) vector of constants, and \\(\\mathbf{z}\\) a \\(p \\times 1\\) vector of random variables. Then\n\\[\nE(\\mathbf{Az}) = \\mathbf{A}E(\\mathbf{z})\n\\]\n\n. . .\n\\[\nE(\\mathbf{Az} + \\mathbf{C}) = E(\\mathbf{Az}) + E(\\mathbf{C}) = \\mathbf{A}E(\\mathbf{z}) + \\mathbf{C}\n\\]"
  },
  {
    "objectID": "slides/08-inference-notes.html#expected-value-of-the-response",
    "href": "slides/08-inference-notes.html#expected-value-of-the-response",
    "title": "Inference for regression",
    "section": "Expected value of the response",
    "text": "Expected value of the response\n\nShow \\[\nE(\\mathbf{y}|\\mathbf{X}) = \\mathbf{X}\\boldsymbol{\\beta}\n\\]"
  },
  {
    "objectID": "slides/08-inference-notes.html#variance",
    "href": "slides/08-inference-notes.html#variance",
    "title": "Inference for regression",
    "section": "Variance",
    "text": "Variance\n\nLet \\(\\mathbf{z} = \\begin{bmatrix}z_1 \\\\ \\vdots \\\\z_p\\end{bmatrix}\\) be a \\(p \\times 1\\) vector of random variables.\n\n. . .\nThen \\(Var(\\mathbf{z}) = \\begin{bmatrix}Var(z_1) & Cov(z_1, z_2) & \\dots & Cov(z_1, z_p)\\\\ Cov(z_2, z_1) & Var(z_2) & \\dots & Cov(z_2, z_p) \\\\ \\vdots & \\vdots & \\dots & \\cdot \\\\ Cov(z_p, z_1) & Cov(z_p, z_2) & \\dots & Var(z_p)\\end{bmatrix}\\)"
  },
  {
    "objectID": "slides/08-inference-notes.html#variance-1",
    "href": "slides/08-inference-notes.html#variance-1",
    "title": "Inference for regression",
    "section": "Variance",
    "text": "Variance\nLet \\(\\mathbf{A}\\) be an \\(n \\times p\\) matrix of constants and \\(\\mathbf{z}\\) a \\(p \\times 1\\) vector of random variables. Then\n\\[\nVar(\\mathbf{z}) = E[(\\mathbf{z} - E(\\mathbf{z}))(\\mathbf{z} - E(\\mathbf{z}))^\\mathsf{T}]\n\\]\n\n. . .\n\\[\n\\begin{aligned}\nVar(\\mathbf{Az}) &= E[(\\mathbf{Az} - E(\\mathbf{Az}))(\\mathbf{Az} - E(\\mathbf{Az}))^\\mathsf{T}] \\\\[8pt]\n& = \\mathbf{A}Var(\\mathbf{z})\\mathbf{A}^\\mathsf{T}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/08-inference-notes.html#variance-of-the-response",
    "href": "slides/08-inference-notes.html#variance-of-the-response",
    "title": "Inference for regression",
    "section": "Variance of the response",
    "text": "Variance of the response\n\nShow\n\\[\nVar(\\mathbf{y}|\\mathbf{X}) = \\sigma^2_\\epsilon\\mathbf{I}\n\\]"
  },
  {
    "objectID": "slides/08-inference-notes.html#linear-transformation-of-normal-random-variable",
    "href": "slides/08-inference-notes.html#linear-transformation-of-normal-random-variable",
    "title": "Inference for regression",
    "section": "Linear transformation of normal random variable",
    "text": "Linear transformation of normal random variable\nSuppose \\(\\mathbf{z}\\) is a (multivariate) normal random variable such that \\(\\mathbf{z} \\sim N(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\\)\n\nA linear transformation of \\(\\mathbf{z}\\) is also multivariate normal, such that\n\\[\n\\mathbf{A}\\mathbf{z} + \\mathbf{B} \\sim N(\\mathbf{A}\\boldsymbol{\\mu} + \\mathbf{B}, \\mathbf{A}\\boldsymbol{\\Sigma}\\mathbf{A}^\\mathsf{T})\n\\]\n\nExplain why \\(\\mathbf{y}|\\mathbf{X}\\) is normally distributed."
  },
  {
    "objectID": "slides/08-inference-notes.html#recap",
    "href": "slides/08-inference-notes.html#recap",
    "title": "Inference for regression",
    "section": "Recap",
    "text": "Recap\n\nIntroduced statistical inference in the context of regression\nDescribed the assumptions for regression\nConnected the distribution of residuals and inferential procedures"
  },
  {
    "objectID": "slides/08-inference-notes.html#next-class",
    "href": "slides/08-inference-notes.html#next-class",
    "title": "Inference for regression",
    "section": "Next class",
    "text": "Next class\n\nConfidence intervals for \\(\\hat{\\beta}_j\\)\nHypothesis testing based on ANOVA\nSee Prepare for Lecture 09"
  },
  {
    "objectID": "slides/lab-06.html#goals",
    "href": "slides/lab-06.html#goals",
    "title": "Lab 06",
    "section": "Goals",
    "text": "Goals\n\nProject milestones\nLab 06: Logistic regression"
  },
  {
    "objectID": "slides/lab-06.html#upcoming-project-milestones",
    "href": "slides/lab-06.html#upcoming-project-milestones",
    "title": "Lab 06",
    "section": "Upcoming project milestones",
    "text": "Upcoming project milestones\n\nNext week’s lab: Project work day\nDecember 2 (Monday after Thanksgiving break): Project draft due at 10am + peer review in lab\nDecember 6: Deadline for Round 1 submission (optional)\nDecember 12: Final report + organized GitHub repo due\n\nSee project instructions for more detail."
  },
  {
    "objectID": "slides/lab-06.html#lab-06-logistic-regression",
    "href": "slides/lab-06.html#lab-06-logistic-regression",
    "title": "Lab 06",
    "section": "Lab 06: Logistic regression",
    "text": "Lab 06: Logistic regression\nThis lab focuses on\n\nfitting and interpreting logistic regression models\nusing the logistic regression model for classification\nevaluating model fit using testing data\n\n🔗 https://sta221-fa24.netlify.app/labs/lab-06"
  },
  {
    "objectID": "slides/lab-06.html#reminder-tips-for-working-on-a-team",
    "href": "slides/lab-06.html#reminder-tips-for-working-on-a-team",
    "title": "Lab 06",
    "section": "Reminder: Tips for working on a team",
    "text": "Reminder: Tips for working on a team\n\nDo not pressure each other to finish early; use the time wisely to really learn the material and produce a quality report.\nThe labs are structured to help you learn the steps of a data analysis. Do not split up the lab among the team members; work on it together in its entirety.\nEveryone has something to contribute! Use the lab groups as an opportunity to share ideas and learn from each other."
  },
  {
    "objectID": "slides/lab-04.html#reminders",
    "href": "slides/lab-04.html#reminders",
    "title": "Lab 04",
    "section": "Reminders",
    "text": "Reminders\n\nExam 01 will be during lecture on Tuesday, February 18\n\nGo directly to your assigned room (let us know if you don’t know your room assignment)\n\nExam 01 take home will be released Tuesday and is due Thursday, February 20 at 9pm\nNext week:\n\nNo lecture on Thursday (use time for take-home exam)\nNo office hours Tuesday - Thursday\nEd Discussion will be read-only Tuesday - Thursday"
  },
  {
    "objectID": "slides/lab-04.html#todays-lab-exam-01-review",
    "href": "slides/lab-04.html#todays-lab-exam-01-review",
    "title": "Lab 04",
    "section": "Today’s lab: Exam 01 review",
    "text": "Today’s lab: Exam 01 review\nThis lab focuses on reviewing for Exam 01. It includes exercises from AE 03 and the Exam review that we didn’t go over in lecture.\n\nComplete the exercise assigned to your team. If you finish early you can work on other exercises.\nAssign one person to post the group’s response on the Google slide (link on board)\nAssign one person to present the group’s response to the class.\n\n🔗 https://sta221-sp25.netlify.app/labs/lab-04"
  },
  {
    "objectID": "slides/variance-inflation-factors.html",
    "href": "slides/variance-inflation-factors.html",
    "title": "Variance Inflation Factors",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \n\nrail_trail &lt;- read_csv(\"data/rail_trail.csv\")\nHere we explain the connection between the Variance Inflation Factor (VIF) and \\(\\mathbf{C} = (\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\). This explanation is motivated by Chapter 3 of Montgomery, Peck, and Vining (2021)."
  },
  {
    "objectID": "slides/variance-inflation-factors.html#unit-length-scaling",
    "href": "slides/variance-inflation-factors.html#unit-length-scaling",
    "title": "Variance Inflation Factors",
    "section": "Unit length scaling",
    "text": "Unit length scaling\nWe have talked about standardizing predictors, such that\n\\[x_{ij_{std}} = \\frac{x_{ij} - \\bar{x_j}}{s_{x_{j}}}\\] such that \\(\\bar{x}_j\\) is the mean and \\(s_{x_{j}}\\) is the standard deviation of the predictor \\(x_j\\).\nThe standardized predictors have a mean of 0 and variance of 1.\nAnother common type of scaling is unit length scaling. We will denote these scaled predictors as \\(w_j\\). We apply this scaling on both the predictor and response variable in the following way.\n\\[w_{ij} = \\frac{x_{ij} - \\bar{x_j}}{\\sqrt{s_{jj}}}\\] where \\(s_{jj} = \\sum_{i = 1}^{n}(x_{ij} - \\bar{x}_j)^2\\)\nThe scaled response variable, denoted \\(y^0\\) is\n\\[y_i^0 = \\frac{y_i - \\bar{y}}{\\sqrt{SST}}\\]\nwhere \\(SST\\) is the sum of squares total, \\(\\sum_{i=1}^n(y_i - \\bar{y})^2\\)\nWe will use the scaled predictor and response variable to show the relationship between \\(\\mathbf{C} = (\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\) and the formula for VIF. More specifically, that\n\\[\nC_{jj} = VIF_{j} = \\frac{1}{1 - R^2_j}\n\\]\nWhen we use the scaled predictors and response."
  },
  {
    "objectID": "slides/variance-inflation-factors.html#variance-inflation-factor",
    "href": "slides/variance-inflation-factors.html#variance-inflation-factor",
    "title": "Variance Inflation Factors",
    "section": "Variance inflation factor",
    "text": "Variance inflation factor\nWe will use the rail_trail data from the notes to illustrate this connection. We will focus on the predictors hightemp, avgtemp, and precip.\nWe begin by creating unit length scaled versions of the variables.\n\nhightemp_norm &lt;- sum((rail_trail$hightemp - mean(rail_trail$hightemp))^2)\navgtemp_norm &lt;- sum((rail_trail$avgtemp - mean(rail_trail$avgtemp))^2)\nprecip_norm &lt;- sum((rail_trail$precip - mean(rail_trail$precip))^2)\nvolume_norm &lt;- sum((rail_trail$volume - mean(rail_trail$volume))^2)\n\nrail_trail &lt;- rail_trail |&gt;\n  mutate(hightemp_scaled = (hightemp - mean(hightemp)) / hightemp_norm^.5,\n         avgtemp_scaled = (avgtemp - mean(avgtemp)) / avgtemp_norm^.5, \n         precip_scaled = (precip - mean(precip)) / precip_norm^.5,\n         volume_scaled = (volume - mean(volume)) / volume_norm^.5\n         )\n\nThe matrix \\(\\mathbf{W}^\\mathsf{T}\\mathbf{W}\\) is equivalent to the correlation matrix for these predictors.\n\n# use -1 to remove the intercept for the correlation matrix\nW &lt;- model.matrix(volume_scaled ~ hightemp_scaled + avgtemp_scaled + precip_scaled - 1, data = rail_trail)\n\nt(W)%*%W\n\n                hightemp_scaled avgtemp_scaled precip_scaled\nhightemp_scaled       1.0000000      0.9196439     0.1343172\navgtemp_scaled        0.9196439      1.0000000     0.2725832\nprecip_scaled         0.1343172      0.2725832     1.0000000\n\n\nWhen we fit a model using the unit length scaling for the response and predictor variables, we would expect \\(Var(\\hat{\\beta}_j) / \\hat{\\sigma}^2_{\\epsilon} \\approx 1\\). As we see below, however, these values are greater than 1.\n\ntrail_model_scaled &lt;- lm(volume_scaled ~ hightemp_scaled + avgtemp_scaled + precip_scaled , data = rail_trail)\n\nbeta_se &lt;- tidy(trail_model_scaled)$std.error\nsigma &lt;- glance(trail_model_scaled)$sigma\n\nbeta_se^2 / sigma^2\n\n[1] 0.01111111 7.16188175 7.59715405 1.19343051\n\n\n(You can ignore the first element, which represents the intercept).\nThese values show how much the standard errors of the coefficients are inflated given the correlation between the predictors (the off diagonal elements of \\(\\mathbf{W}^\\mathsf{T}\\mathbf{W}\\)). The amount by which the standard errors are inflated are called the variance inflation factors (VIF).\nUnder this model using the unit-length-scaled predictors and response, we see these variance inflation factors are equal to the diagonal elements of \\(\\mathbf{C} = (\\mathbf{W}^\\mathsf{T}\\mathbf{W})^{1}\\).\n\nC &lt;- solve(t(W) %*% W)\ndiag(C)\n\nhightemp_scaled  avgtemp_scaled   precip_scaled \n       7.161882        7.597154        1.193431 \n\n\nThus,\n\\[C_{jj} = VIF_{j} = \\frac{1}{1 - R^2_j}\\]"
  },
  {
    "objectID": "slides/lab-01.html#todays-lab",
    "href": "slides/lab-01.html#todays-lab",
    "title": "Lab 01",
    "section": "Today’s lab",
    "text": "Today’s lab\nTopics\n\nData wrangling and visualizations in R\nReview linear algebra concepts and introduce some matrix calculus concepts\n\nNotes\n\nPut all responses for computing questions in your lab-01 Quarto document. You may write any mathematical work by hand and attach it to the rendered PDF before uploading to Gradescope.\nThis lab will be graded for completion. You will receive feedback so you know what to expect in future assignments. See Grading for more detail"
  },
  {
    "objectID": "slides/lab-01.html#tips-for-working-on-lab",
    "href": "slides/lab-01.html#tips-for-working-on-lab",
    "title": "Lab 01",
    "section": "Tips for working on lab",
    "text": "Tips for working on lab\n\nLabs will always be due Tuesdays at 11:59pm, but you are encouraged to complete as much as you can during the lab session.\nOne work strategy is to get through portions that you think will be most challenging during lab when a TA can help you on the spot.\nFor today’s lab, start with the material you most need to review - computing or linear algebra concepts.\n\nWe will begin using the linear algebra concepts in class on January 21."
  },
  {
    "objectID": "slides/lab-01.html#workflow-and-formatting",
    "href": "slides/lab-01.html#workflow-and-formatting",
    "title": "Lab 01",
    "section": "Workflow and formatting",
    "text": "Workflow and formatting\nPart of the lab grade is for “workflow and formatting” assessing the reproducible workflow and document format. This includes\n\nHaving at least 3 informative commit messages (practicing version control)\n\nThere are markers in Lab 01 to help you incorporate version control in your workflow\n\nThe PDF is neatly organized document with clear exercise headings and readable code and narrative\nThe name (first and last) and date are updated at the top of the document."
  },
  {
    "objectID": "slides/lab-01.html#when-youre-done-with-lab",
    "href": "slides/lab-01.html#when-youre-done-with-lab",
    "title": "Lab 01",
    "section": "When you’re done with lab",
    "text": "When you’re done with lab\n\nMake sure all your final changes have been pushed to your GitHub repo\nSubmit your final PDF to Gradescope\n\nCombine the rendered Quarto document and handwritten math work into a single PDF document if needed.\nAccess Gradescope through the course Canvas site\nMark the pages associated with each exercise."
  },
  {
    "objectID": "slides/lab-01.html#getting-started",
    "href": "slides/lab-01.html#getting-started",
    "title": "Lab 01",
    "section": "Getting started",
    "text": "Getting started\nAsk your TA if\n\nYou do not have a lab-01 repo in the GitHub course organization: github.com/sta221-sp25\nYou need help cloning the repo and starting a new RStudio project\n\n🔗 sta221-sp25.netlify.app/labs/lab–01.html"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#announcements",
    "href": "slides/20-logistic-prediction.html#announcements",
    "title": "Logistic Regression: Prediction",
    "section": "Announcements",
    "text": "Announcements\n\nNext project milestone: Analysis and draft in April 11 lab\nTeam Feedback (email from TEAMMATES) due Tuesday, April 8 at 11:59pm (check email)\nStatistics experience due April 22"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#computational-set-up",
    "href": "slides/20-logistic-prediction.html#computational-set-up",
    "title": "Logistic Regression: Prediction",
    "section": "Computational set up",
    "text": "Computational set up\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(pROC)       # make ROC curves\nlibrary(knitr)\nlibrary(kableExtra)\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#topics",
    "href": "slides/20-logistic-prediction.html#topics",
    "title": "Logistic Regression: Prediction",
    "section": "Topics",
    "text": "Topics\n\nCalculating predicted probabilities from the logistic regression model\nUsing predicted probabilities to classify observations\nMake decisions and assess model performance using\n\nConfusion matrix\nROC curve"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#data-risk-of-coronary-heart-disease",
    "href": "slides/20-logistic-prediction.html#data-risk-of-coronary-heart-disease",
    "title": "Logistic Regression: Prediction",
    "section": "Data: Risk of coronary heart disease",
    "text": "Data: Risk of coronary heart disease\nThis data set is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. We want to examine the relationship between various health characteristics and the risk of having heart disease.\n\nhigh_risk: 1 = High risk of having heart disease in next 10 years, 0 = Not high risk of having heart disease in next 10 years\nage: Age at exam time (in years)\ntotChol: Total cholesterol (in mg/dL)\ncurrentSmoker: 0 = nonsmoker; 1 = smoker"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#modeling-risk-of-coronary-heart-disease",
    "href": "slides/20-logistic-prediction.html#modeling-risk-of-coronary-heart-disease",
    "title": "Logistic Regression: Prediction",
    "section": "Modeling risk of coronary heart disease",
    "text": "Modeling risk of coronary heart disease\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-6.638\n0.372\n-17.860\n0.000\n-7.374\n-5.917\n\n\nage\n0.082\n0.006\n14.430\n0.000\n0.071\n0.093\n\n\ntotChol\n0.002\n0.001\n2.001\n0.045\n0.000\n0.004\n\n\ncurrentSmoker1\n0.457\n0.092\n4.951\n0.000\n0.277\n0.639\n\n\n\n\n\n\n\nInterpret totChol in terms of the odds of being high risk for heart disease.\nInterpret currentSmoker1 in terms of the odds of being high risk for heart disease."
  },
  {
    "objectID": "slides/20-logistic-prediction.html#prediction-and-classification",
    "href": "slides/20-logistic-prediction.html#prediction-and-classification",
    "title": "Logistic Regression: Prediction",
    "section": "Prediction and classification",
    "text": "Prediction and classification\n\n\nWe are often interested in using the model to classify observations, i.e., predict whether a given observation will have a 1 or 0 response\nFor each observation\n\nUse the logistic regression model to calculate the predicted log-odds the response for the \\(i^{th}\\) observation is 1\nUse the log-odds to calculate the predicted probability the \\(i^{th}\\) observation is 1\nThen, use the predicted probability to classify the observation as having a 1 or 0 response using some predefined threshold"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#augmented-data-frame",
    "href": "slides/20-logistic-prediction.html#augmented-data-frame",
    "title": "Logistic Regression: Prediction",
    "section": "Augmented data frame",
    "text": "Augmented data frame\n\naugment(heart_disease_fit)\n\n# A tibble: 4,190 × 10\n   high_risk   age totChol currentSmoker .fitted .resid     .hat .sigma  .cooksd\n   &lt;fct&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;           &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n 1 0            39     195 0              -3.06  -0.302 0.000594  0.890  6.94e-6\n 2 0            46     250 0              -2.38  -0.420 0.000543  0.890  1.25e-5\n 3 0            48     245 1              -1.77  -0.560 0.000527  0.890  2.24e-5\n 4 1            61     225 1              -0.751  1.51  0.00164   0.889  8.70e-4\n 5 0            46     285 1              -1.86  -0.539 0.000830  0.890  3.25e-5\n 6 0            43     228 0              -2.67  -0.366 0.000546  0.890  9.43e-6\n 7 1            63     205 0              -1.08   1.66  0.00154   0.889  1.15e-3\n 8 0            45     313 1              -1.88  -0.532 0.00127   0.890  4.86e-5\n 9 0            52     260 0              -1.87  -0.535 0.000542  0.890  2.08e-5\n10 0            43     225 1              -2.22  -0.454 0.000532  0.890  1.44e-5\n# ℹ 4,180 more rows\n# ℹ 1 more variable: .std.resid &lt;dbl&gt;"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#predicted-log-odds",
    "href": "slides/20-logistic-prediction.html#predicted-log-odds",
    "title": "Logistic Regression: Prediction",
    "section": "Predicted log-odds",
    "text": "Predicted log-odds\n\nheart_disease_aug &lt;- augment(heart_disease_fit)\n\n\n\n# A tibble: 5 × 1\n  .fitted\n    &lt;dbl&gt;\n1  -3.06 \n2  -2.38 \n3  -1.77 \n4  -0.751\n5  -1.86 \n\n\n\nObservation 1\n\\[\n\\text{predicted log-odds} = \\log\\Big(\\frac{\\hat{\\pi}}{1- \\hat{\\pi}}\\Big) = -3.06\n\\]"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#predicted-odds",
    "href": "slides/20-logistic-prediction.html#predicted-odds",
    "title": "Logistic Regression: Prediction",
    "section": "Predicted odds",
    "text": "Predicted odds\n\n\n# A tibble: 5 × 1\n  .fitted\n    &lt;dbl&gt;\n1  -3.06 \n2  -2.38 \n3  -1.77 \n4  -0.751\n5  -1.86 \n\n\n\nObservation 1\n\\[\n\\text{predicted odds} =  \\frac{\\hat{\\pi}}{1- \\hat{\\pi}} = \\exp\\{-3.06\\} = 0.0469\n\\]"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#predicted-probability",
    "href": "slides/20-logistic-prediction.html#predicted-probability",
    "title": "Logistic Regression: Prediction",
    "section": "Predicted probability",
    "text": "Predicted probability\n\n\n# A tibble: 5 × 1\n  .fitted\n    &lt;dbl&gt;\n1  -3.06 \n2  -2.38 \n3  -1.77 \n4  -0.751\n5  -1.86 \n\n\n\nObservation 1\n\\[\n\\text{predicted prob.} = \\hat{\\pi} = \\frac{\\hat{\\text{odds}}}{1+\\hat{\\text{odds}}} = \\frac{\\exp\\{-3.06\\}}{1 + \\exp\\{-3.06\\}}= 0.045\n\\]\n\n\n\nWould you classify this individual as high risk \\((\\hat{y} = 1)\\) or not high risk \\((\\hat{y} = 0)\\)?"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#another-individual",
    "href": "slides/20-logistic-prediction.html#another-individual",
    "title": "Logistic Regression: Prediction",
    "section": "Another individual",
    "text": "Another individual\n\n\n# A tibble: 5 × 1\n  .fitted\n    &lt;dbl&gt;\n1  -3.06 \n2  -2.38 \n3  -1.77 \n4  -0.751\n5  -1.86 \n\n\n\nObservation 4\n\\[\n\\text{predicted prob.} = \\hat{\\pi} = \\frac{\\hat{\\text{odds}}}{1+\\hat{\\text{odds}}} = \\frac{\\exp\\{-0.751\\}}{1 + \\exp\\{-0.751\\}}= 0.321\n\\]\n\n\n\nWould you classify this individual as high risk \\((\\hat{y} = 1)\\) or not high risk \\((\\hat{y} = 0)\\)?"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#predicted-probabilities-in-r",
    "href": "slides/20-logistic-prediction.html#predicted-probabilities-in-r",
    "title": "Logistic Regression: Prediction",
    "section": "Predicted probabilities in R",
    "text": "Predicted probabilities in R\nWe can calculate predicted probabilities using the predict.glm() function. Use type = \"response\" to get probabilities.1\n\n\n\npredict.glm(heart_disease_fit, type = \"response\")\n\n\n\nPredicted probabilities for Observations 1 -5\n\n\n         1          2          3          4          5 \n0.04459439 0.08445209 0.14523257 0.32065849 0.13515474 \n\n\n\nThe default is type = \"link\", which produces the predicted log-odds."
  },
  {
    "objectID": "slides/20-logistic-prediction.html#predictions-in-r",
    "href": "slides/20-logistic-prediction.html#predictions-in-r",
    "title": "Logistic Regression: Prediction",
    "section": "Predictions in R",
    "text": "Predictions in R\n\npred_prob &lt;- predict.glm(heart_disease_fit, type = \"response\")\n\nheart_disease_aug &lt;- heart_disease_aug |&gt; \n  bind_cols(pred_prob = pred_prob)\n\n\n\n\n# A tibble: 5 × 3\n  high_risk .fitted pred_prob\n  &lt;fct&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n1 0          -3.06     0.0446\n2 0          -2.38     0.0845\n3 0          -1.77     0.145 \n4 1          -0.751    0.321 \n5 0          -1.86     0.135"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#classifying-observations",
    "href": "slides/20-logistic-prediction.html#classifying-observations",
    "title": "Logistic Regression: Prediction",
    "section": "Classifying observations",
    "text": "Classifying observations\n\nYou would like to determine a threshold for classifying individuals as high risk or not high risk.\nWhat considerations would you make in determining the threshold?"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#classify-using-0.5-as-threshold",
    "href": "slides/20-logistic-prediction.html#classify-using-0.5-as-threshold",
    "title": "Logistic Regression: Prediction",
    "section": "Classify using 0.5 as threshold",
    "text": "Classify using 0.5 as threshold\nWe can use a threshold of 0.5 to classify observations.\n\nIf \\(\\hat{\\pi} &gt; 0.5\\), classify as 1\nIf \\(\\hat{\\pi} \\leq 0.5\\), classify as 0\n\n\n\n\n# A tibble: 5 × 4\n  high_risk .fitted pred_prob pred_class\n  &lt;fct&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;     \n1 0          -3.06     0.0446 0         \n2 0          -2.38     0.0845 0         \n3 0          -1.77     0.145  0         \n4 1          -0.751    0.321  0         \n5 0          -1.86     0.135  0"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#confusion-matrix",
    "href": "slides/20-logistic-prediction.html#confusion-matrix",
    "title": "Logistic Regression: Prediction",
    "section": "Confusion matrix",
    "text": "Confusion matrix\nA confusion matrix is a \\(2 \\times 2\\) table that compares the predicted and actual classes. We can produce this matrix using the conf_mat() function in the yardstick package (part of tidymodels).\n\n\n\nheart_disease_aug |&gt;\n  conf_mat(high_risk, pred_class) \n\n          Truth\nPrediction    0    1\n         0 3553  635\n         1    2    0"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#visualize-confusion-matrix",
    "href": "slides/20-logistic-prediction.html#visualize-confusion-matrix",
    "title": "Logistic Regression: Prediction",
    "section": "Visualize confusion matrix",
    "text": "Visualize confusion matrix\n\nheart_conf_mat &lt;- heart_disease_aug |&gt;\n  conf_mat(high_risk, pred_class)\n\nautoplot(heart_conf_mat, type = \"heatmap\")"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#using-the-confusion-matrix",
    "href": "slides/20-logistic-prediction.html#using-the-confusion-matrix",
    "title": "Logistic Regression: Prediction",
    "section": "Using the confusion matrix",
    "text": "Using the confusion matrix\n\n\n\n          Truth\nPrediction    0    1\n         0 3553  635\n         1    2    0\n\n\n\n\n\nThe accuracy of this model with a classification threshold of 0.5 is\n\\[\n\\text{accuracy} = \\frac{3553 + 0}{3553 + 635 + 2 + 0} = 0.848\n\\]"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#using-the-confusion-matrix-1",
    "href": "slides/20-logistic-prediction.html#using-the-confusion-matrix-1",
    "title": "Logistic Regression: Prediction",
    "section": "Using the confusion matrix",
    "text": "Using the confusion matrix\n\n\n\n          Truth\nPrediction    0    1\n         0 3553  635\n         1    2    0\n\n\n\n\n\nThe misclassification rate of this model with a threshold of 0.5 is\n\\[\n\\text{misclassification} = \\frac{635 + 2}{3553 + 635 + 2 + 0} = 0.152\n\\]"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#using-the-confusion-matrix-2",
    "href": "slides/20-logistic-prediction.html#using-the-confusion-matrix-2",
    "title": "Logistic Regression: Prediction",
    "section": "Using the confusion matrix",
    "text": "Using the confusion matrix\n\n\n\n          Truth\nPrediction    0    1\n         0 3553  635\n         1    2    0\n\n\n\n\nAccuracy is 0.848 and the misclassification rate is 0.152.\n\n\n\nWhat is the limitation of solely relying on accuracy and misclassification to assess the model performance?\nWhat is the limitation of using a single confusion matrix to assess the model performance?"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#truefalse-positivenegative",
    "href": "slides/20-logistic-prediction.html#truefalse-positivenegative",
    "title": "Logistic Regression: Prediction",
    "section": "True/false positive/negative",
    "text": "True/false positive/negative\n\n\n\n\n\n\n\n\n\nNot high risk \\((y_i = 0)\\)\nHigh risk \\((y_i = 1)\\)\n\n\n\n\nClassified not high risk \\((\\hat{\\pi}_i \\leq \\text{threshold})\\)\nTrue negative (TN)\nFalse negative (FN)\n\n\nClassified high risk \\((\\hat{\\pi}_i &gt; \\text{threshold})\\)\nFalse positive (FP)\nTrue positive (TP)\n\n\n\n\n\n\\(\\text{accuracy} = \\frac{TN + TP}{TN + TP + FN + FP}\\)\n\\(\\text{misclassification} = \\frac{FN + FP}{TN+ TP + FN + FP}\\)"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#false-negative-rate",
    "href": "slides/20-logistic-prediction.html#false-negative-rate",
    "title": "Logistic Regression: Prediction",
    "section": "False negative rate",
    "text": "False negative rate\n\n\n\n\n\n\n\n\n\nNot high risk \\((y_i = 0)\\)\nHigh risk \\((y_i = 1)\\)\n\n\n\n\nClassified not high risk \\((\\hat{\\pi}_i \\leq \\text{threshold})\\)\nTrue negative (TN)\nFalse negative (FN)\n\n\nClassified high risk \\((\\hat{\\pi}_i &gt; \\text{threshold})\\)\nFalse positive (FP)\nTrue positive (TP)\n\n\n\n\n\nFalse negative rate: Proportion of actual positives that were classified as negatives\n\nP(classified not high risk | high risk) = \\(\\frac{FN}{TP + FN}\\)"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#false-positive-rate",
    "href": "slides/20-logistic-prediction.html#false-positive-rate",
    "title": "Logistic Regression: Prediction",
    "section": "False positive rate",
    "text": "False positive rate\n\n\n\n\n\n\n\n\n\nNot high risk \\((y_i = 0)\\)\nHigh risk \\((y_i = 1)\\)\n\n\n\n\nClassified not high risk \\((\\hat{\\pi}_i \\leq \\text{threshold})\\)\nTrue negative (TN)\nFalse negative (FN)\n\n\nClassified high risk \\((\\hat{\\pi}_i &gt; \\text{threshold})\\)\nFalse positive (FP)\nTrue positive (TP)\n\n\n\n\n\nFalse positive rate: Proportion of actual negatives that were classified as positives\n\nP(classified high risk | not high risk) = \\(\\frac{FP}{TN + FP}\\)"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#sensitivity",
    "href": "slides/20-logistic-prediction.html#sensitivity",
    "title": "Logistic Regression: Prediction",
    "section": "Sensitivity",
    "text": "Sensitivity\n\n\n\n\n\n\n\n\n\nNot high risk \\((y_i = 0)\\)\nHigh risk \\((y_i = 1)\\)\n\n\n\n\nClassified not high risk \\((\\hat{\\pi}_i \\leq \\text{threshold})\\)\nTrue negative (TN)\nFalse negative (FN)\n\n\nClassified high risk \\((\\hat{\\pi}_i &gt; \\text{threshold})\\)\nFalse positive (FP)\nTrue positive (TP)\n\n\n\n\n\nSensitivity: Proportion of actual positives that were correctly classified as positive\n\nAlso known as true positive rate (TPR) and recall\nP(classified high risk | high risk) = 1 − False negative rate"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#specificity",
    "href": "slides/20-logistic-prediction.html#specificity",
    "title": "Logistic Regression: Prediction",
    "section": "Specificity",
    "text": "Specificity\n\n\n\n\n\n\n\n\n\nNot high risk \\((y_i = 0)\\)\nHigh risk \\((y_i = 1)\\)\n\n\n\n\nClassified not high risk \\((\\hat{\\pi}_i \\leq \\text{threshold})\\)\nTrue negative (TN)\nFalse negative (FN)\n\n\nClassified high risk \\((\\hat{\\pi}_i &gt; \\text{threshold})\\)\nFalse positive (FP)\nTrue positive (TP)\n\n\n\n\n\nSpecificity: Proportion of actual negatives that were correctly classified as negative\n\nP(classified not high risk | not high risk) = 1 − False positive rate"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#practice",
    "href": "slides/20-logistic-prediction.html#practice",
    "title": "Logistic Regression: Prediction",
    "section": "Practice",
    "text": "Practice\n\n\n\n          Truth\nPrediction    0    1\n         0 3553  635\n         1    2    0\n\n\n\n\nCalculate the\n\nFalse negative rate\nFalse positive rate\nSensitivity\nSpecificity"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#using-metrics-to-select-model-and-threshold",
    "href": "slides/20-logistic-prediction.html#using-metrics-to-select-model-and-threshold",
    "title": "Logistic Regression: Prediction",
    "section": "Using metrics to select model and threshold",
    "text": "Using metrics to select model and threshold\n\n\n\n\n\n\n\nMetric\nGuidance for use\n\n\n\n\nAccuracy\nFor balanced data, use only in combination with other metrics.\nAvoid using for imbalanced data.\n\n\nSensitivity (true positive rate)\nUse when false negatives are more “expensive” than false positives.\n\n\nFalse positive rate\nUse when false positives are more “expensive” than false negatives.\n\n\nPrecision = \\(\\frac{TP}{TP + FP}\\)\nUse when it’s important for positive predictions to be accurate.\n\n\n\n\nThis table is a modification of work created and shared by Google in the Google Machine Learning Crash Course."
  },
  {
    "objectID": "slides/20-logistic-prediction.html#choosing-a-classification-threshold",
    "href": "slides/20-logistic-prediction.html#choosing-a-classification-threshold",
    "title": "Logistic Regression: Prediction",
    "section": "Choosing a classification threshold",
    "text": "Choosing a classification threshold\n\nA doctor plans to use your model to determine which patients are high risk for heart disease. The doctor will recommend a treatment plan for high risk patients.\n\nWould you want sensitivity to be high or low? What about specificity?\nWhat are the trade-offs associated with each decision?"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#roc-curve",
    "href": "slides/20-logistic-prediction.html#roc-curve",
    "title": "Logistic Regression: Prediction",
    "section": "ROC curve",
    "text": "ROC curve\nSo far the model assessment has depended on the model and selected threshold. The receiver operating characteristic (ROC) curve allows us to assess the model performance across a range of thresholds.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx-axis: 1 - Specificity (False positive rate)\ny-axis: Sensitivity (True positive rate)\n\nWhich corner of the plot indicates the best model performance?"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#roc-curve-1",
    "href": "slides/20-logistic-prediction.html#roc-curve-1",
    "title": "Logistic Regression: Prediction",
    "section": "ROC curve",
    "text": "ROC curve"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#roc-curve-in-r",
    "href": "slides/20-logistic-prediction.html#roc-curve-in-r",
    "title": "Logistic Regression: Prediction",
    "section": "ROC curve in R",
    "text": "ROC curve in R\n\n# calculate sensitivity and specificity at each threshold\nroc_curve_data &lt;- heart_disease_aug |&gt;\n  roc_curve(high_risk, pred_prob, \n            event_level = \"second\") \n\n# plot roc curve\nautoplot(roc_curve_data)"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#roc-curve-in-r-1",
    "href": "slides/20-logistic-prediction.html#roc-curve-in-r-1",
    "title": "Logistic Regression: Prediction",
    "section": "ROC curve in R",
    "text": "ROC curve in R\n\n\nSample from underlying data\n\n\n# A tibble: 10 × 3\n   .threshold specificity sensitivity\n        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1     0.0545       0.103       0.980\n 2     0.0660       0.181       0.959\n 3     0.0832       0.305       0.909\n 4     0.136        0.583       0.715\n 5     0.193        0.754       0.501\n 6     0.221        0.805       0.411\n 7     0.221        0.805       0.411\n 8     0.262        0.881       0.287\n 9     0.270        0.901       0.254\n10     0.279        0.915       0.227"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#area-under-the-curve",
    "href": "slides/20-logistic-prediction.html#area-under-the-curve",
    "title": "Logistic Regression: Prediction",
    "section": "Area under the curve",
    "text": "Area under the curve\nThe area under the curve (AUC) can be used to assess how well the logistic model fits the data\n\nAUC=0.5: model is a very bad fit (no better than a coin flip)\nAUC close to 1: model is a good fit\n\n\n\nheart_disease_aug |&gt;\n  roc_auc(high_risk, pred_prob,\n    event_level = \"second\"\n  )\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.695"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#recap",
    "href": "slides/20-logistic-prediction.html#recap",
    "title": "Logistic Regression: Prediction",
    "section": "Recap",
    "text": "Recap\n\nCalculated predicted probabilities from the logistic regression model\nUsed predicted probabilities to classify observations\nMade decisions and assessed model performance using\n\nConfusion matrix\nROC curve"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#further-reading",
    "href": "slides/20-logistic-prediction.html#further-reading",
    "title": "Logistic Regression: Prediction",
    "section": "Further reading",
    "text": "Further reading\nClassification module in Google Machine Learning Crash Course"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html",
    "href": "slides/20-logistic-prediction-notes.html",
    "title": "Logistic Regression: Prediction",
    "section": "",
    "text": "Next project milestone: Analysis and draft in April 11 lab\nTeam Feedback (email from TEAMMATES) due Tuesday, April 8 at 11:59pm (check email)\nStatistics experience due April 22"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#announcements",
    "href": "slides/20-logistic-prediction-notes.html#announcements",
    "title": "Logistic Regression: Prediction",
    "section": "",
    "text": "Next project milestone: Analysis and draft in April 11 lab\nTeam Feedback (email from TEAMMATES) due Tuesday, April 8 at 11:59pm (check email)\nStatistics experience due April 22"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#computational-set-up",
    "href": "slides/20-logistic-prediction-notes.html#computational-set-up",
    "title": "Logistic Regression: Prediction",
    "section": "Computational set up",
    "text": "Computational set up\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(pROC)       # make ROC curves\nlibrary(knitr)\nlibrary(kableExtra)\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#topics",
    "href": "slides/20-logistic-prediction-notes.html#topics",
    "title": "Logistic Regression: Prediction",
    "section": "Topics",
    "text": "Topics\n\nCalculating predicted probabilities from the logistic regression model\nUsing predicted probabilities to classify observations\nMake decisions and assess model performance using\n\nConfusion matrix\nROC curve"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#data-risk-of-coronary-heart-disease",
    "href": "slides/20-logistic-prediction-notes.html#data-risk-of-coronary-heart-disease",
    "title": "Logistic Regression: Prediction",
    "section": "Data: Risk of coronary heart disease",
    "text": "Data: Risk of coronary heart disease\nThis data set is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. We want to examine the relationship between various health characteristics and the risk of having heart disease.\n\nhigh_risk: 1 = High risk of having heart disease in next 10 years, 0 = Not high risk of having heart disease in next 10 years\nage: Age at exam time (in years)\ntotChol: Total cholesterol (in mg/dL)\ncurrentSmoker: 0 = nonsmoker; 1 = smoker"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#modeling-risk-of-coronary-heart-disease",
    "href": "slides/20-logistic-prediction-notes.html#modeling-risk-of-coronary-heart-disease",
    "title": "Logistic Regression: Prediction",
    "section": "Modeling risk of coronary heart disease",
    "text": "Modeling risk of coronary heart disease\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-6.638\n0.372\n-17.860\n0.000\n-7.374\n-5.917\n\n\nage\n0.082\n0.006\n14.430\n0.000\n0.071\n0.093\n\n\ntotChol\n0.002\n0.001\n2.001\n0.045\n0.000\n0.004\n\n\ncurrentSmoker1\n0.457\n0.092\n4.951\n0.000\n0.277\n0.639\n\n\n\n\n\n\n\nInterpret totChol in terms of the odds of being high risk for heart disease.\nInterpret currentSmoker1 in terms of the odds of being high risk for heart disease."
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#prediction-and-classification",
    "href": "slides/20-logistic-prediction-notes.html#prediction-and-classification",
    "title": "Logistic Regression: Prediction",
    "section": "Prediction and classification",
    "text": "Prediction and classification\n\n\nWe are often interested in using the model to classify observations, i.e., predict whether a given observation will have a 1 or 0 response\nFor each observation\n\nUse the logistic regression model to calculate the predicted log-odds the response for the \\(i^{th}\\) observation is 1\nUse the log-odds to calculate the predicted probability the \\(i^{th}\\) observation is 1\nThen, use the predicted probability to classify the observation as having a 1 or 0 response using some predefined threshold"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#augmented-data-frame",
    "href": "slides/20-logistic-prediction-notes.html#augmented-data-frame",
    "title": "Logistic Regression: Prediction",
    "section": "Augmented data frame",
    "text": "Augmented data frame\n\naugment(heart_disease_fit)\n\n# A tibble: 4,190 × 10\n   high_risk   age totChol currentSmoker .fitted .resid     .hat .sigma  .cooksd\n   &lt;fct&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;           &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n 1 0            39     195 0              -3.06  -0.302 0.000594  0.890  6.94e-6\n 2 0            46     250 0              -2.38  -0.420 0.000543  0.890  1.25e-5\n 3 0            48     245 1              -1.77  -0.560 0.000527  0.890  2.24e-5\n 4 1            61     225 1              -0.751  1.51  0.00164   0.889  8.70e-4\n 5 0            46     285 1              -1.86  -0.539 0.000830  0.890  3.25e-5\n 6 0            43     228 0              -2.67  -0.366 0.000546  0.890  9.43e-6\n 7 1            63     205 0              -1.08   1.66  0.00154   0.889  1.15e-3\n 8 0            45     313 1              -1.88  -0.532 0.00127   0.890  4.86e-5\n 9 0            52     260 0              -1.87  -0.535 0.000542  0.890  2.08e-5\n10 0            43     225 1              -2.22  -0.454 0.000532  0.890  1.44e-5\n# ℹ 4,180 more rows\n# ℹ 1 more variable: .std.resid &lt;dbl&gt;"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#predicted-log-odds",
    "href": "slides/20-logistic-prediction-notes.html#predicted-log-odds",
    "title": "Logistic Regression: Prediction",
    "section": "Predicted log-odds",
    "text": "Predicted log-odds\n\nheart_disease_aug &lt;- augment(heart_disease_fit)\n\n\n\n# A tibble: 5 × 1\n  .fitted\n    &lt;dbl&gt;\n1  -3.06 \n2  -2.38 \n3  -1.77 \n4  -0.751\n5  -1.86 \n\n\n. . .\nObservation 1\n\\[\n\\text{predicted log-odds} = \\log\\Big(\\frac{\\hat{\\pi}}{1- \\hat{\\pi}}\\Big) = -3.06\n\\]"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#predicted-odds",
    "href": "slides/20-logistic-prediction-notes.html#predicted-odds",
    "title": "Logistic Regression: Prediction",
    "section": "Predicted odds",
    "text": "Predicted odds\n\n\n# A tibble: 5 × 1\n  .fitted\n    &lt;dbl&gt;\n1  -3.06 \n2  -2.38 \n3  -1.77 \n4  -0.751\n5  -1.86 \n\n\n. . .\nObservation 1\n\\[\n\\text{predicted odds} =  \\frac{\\hat{\\pi}}{1- \\hat{\\pi}} = \\exp\\{-3.06\\} = 0.0469\n\\]"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#predicted-probability",
    "href": "slides/20-logistic-prediction-notes.html#predicted-probability",
    "title": "Logistic Regression: Prediction",
    "section": "Predicted probability",
    "text": "Predicted probability\n\n\n# A tibble: 5 × 1\n  .fitted\n    &lt;dbl&gt;\n1  -3.06 \n2  -2.38 \n3  -1.77 \n4  -0.751\n5  -1.86 \n\n\n. . .\nObservation 1\n\\[\n\\text{predicted prob.} = \\hat{\\pi} = \\frac{\\hat{\\text{odds}}}{1+\\hat{\\text{odds}}} = \\frac{\\exp\\{-3.06\\}}{1 + \\exp\\{-3.06\\}}= 0.045\n\\]\n. . .\n\nWould you classify this individual as high risk \\((\\hat{y} = 1)\\) or not high risk \\((\\hat{y} = 0)\\)?"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#another-individual",
    "href": "slides/20-logistic-prediction-notes.html#another-individual",
    "title": "Logistic Regression: Prediction",
    "section": "Another individual",
    "text": "Another individual\n\n\n# A tibble: 5 × 1\n  .fitted\n    &lt;dbl&gt;\n1  -3.06 \n2  -2.38 \n3  -1.77 \n4  -0.751\n5  -1.86 \n\n\n. . .\nObservation 4\n\\[\n\\text{predicted prob.} = \\hat{\\pi} = \\frac{\\hat{\\text{odds}}}{1+\\hat{\\text{odds}}} = \\frac{\\exp\\{-0.751\\}}{1 + \\exp\\{-0.751\\}}= 0.321\n\\]\n. . .\n\nWould you classify this individual as high risk \\((\\hat{y} = 1)\\) or not high risk \\((\\hat{y} = 0)\\)?"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#predicted-probabilities-in-r",
    "href": "slides/20-logistic-prediction-notes.html#predicted-probabilities-in-r",
    "title": "Logistic Regression: Prediction",
    "section": "Predicted probabilities in R",
    "text": "Predicted probabilities in R\nWe can calculate predicted probabilities using the predict.glm() function. Use type = \"response\" to get probabilities.1\n\n. . .\n\npredict.glm(heart_disease_fit, type = \"response\")\n\n. . .\nPredicted probabilities for Observations 1 -5\n\n\n         1          2          3          4          5 \n0.04459439 0.08445209 0.14523257 0.32065849 0.13515474"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#predictions-in-r",
    "href": "slides/20-logistic-prediction-notes.html#predictions-in-r",
    "title": "Logistic Regression: Prediction",
    "section": "Predictions in R",
    "text": "Predictions in R\n\npred_prob &lt;- predict.glm(heart_disease_fit, type = \"response\")\n\nheart_disease_aug &lt;- heart_disease_aug |&gt; \n  bind_cols(pred_prob = pred_prob)\n\n. . .\n\n\n# A tibble: 5 × 3\n  high_risk .fitted pred_prob\n  &lt;fct&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n1 0          -3.06     0.0446\n2 0          -2.38     0.0845\n3 0          -1.77     0.145 \n4 1          -0.751    0.321 \n5 0          -1.86     0.135"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#classifying-observations",
    "href": "slides/20-logistic-prediction-notes.html#classifying-observations",
    "title": "Logistic Regression: Prediction",
    "section": "Classifying observations",
    "text": "Classifying observations\n\nYou would like to determine a threshold for classifying individuals as high risk or not high risk.\nWhat considerations would you make in determining the threshold?"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#classify-using-0.5-as-threshold",
    "href": "slides/20-logistic-prediction-notes.html#classify-using-0.5-as-threshold",
    "title": "Logistic Regression: Prediction",
    "section": "Classify using 0.5 as threshold",
    "text": "Classify using 0.5 as threshold\nWe can use a threshold of 0.5 to classify observations.\n\nIf \\(\\hat{\\pi} &gt; 0.5\\), classify as 1\nIf \\(\\hat{\\pi} \\leq 0.5\\), classify as 0\n\n. . .\n. . .\n\n\n# A tibble: 5 × 4\n  high_risk .fitted pred_prob pred_class\n  &lt;fct&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;     \n1 0          -3.06     0.0446 0         \n2 0          -2.38     0.0845 0         \n3 0          -1.77     0.145  0         \n4 1          -0.751    0.321  0         \n5 0          -1.86     0.135  0"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#confusion-matrix",
    "href": "slides/20-logistic-prediction-notes.html#confusion-matrix",
    "title": "Logistic Regression: Prediction",
    "section": "Confusion matrix",
    "text": "Confusion matrix\nA confusion matrix is a \\(2 \\times 2\\) table that compares the predicted and actual classes. We can produce this matrix using the conf_mat() function in the yardstick package (part of tidymodels).\n\n. . .\n\nheart_disease_aug |&gt;\n  conf_mat(high_risk, pred_class) \n\n          Truth\nPrediction    0    1\n         0 3553  635\n         1    2    0"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#visualize-confusion-matrix",
    "href": "slides/20-logistic-prediction-notes.html#visualize-confusion-matrix",
    "title": "Logistic Regression: Prediction",
    "section": "Visualize confusion matrix",
    "text": "Visualize confusion matrix\n\nheart_conf_mat &lt;- heart_disease_aug |&gt;\n  conf_mat(high_risk, pred_class)\n\nautoplot(heart_conf_mat, type = \"heatmap\")"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#using-the-confusion-matrix",
    "href": "slides/20-logistic-prediction-notes.html#using-the-confusion-matrix",
    "title": "Logistic Regression: Prediction",
    "section": "Using the confusion matrix",
    "text": "Using the confusion matrix\n\n\n\n          Truth\nPrediction    0    1\n         0 3553  635\n         1    2    0\n\n\n\n\n. . .\nThe accuracy of this model with a classification threshold of 0.5 is\n\\[\n\\text{accuracy} = \\frac{3553 + 0}{3553 + 635 + 2 + 0} = 0.848\n\\]"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#using-the-confusion-matrix-1",
    "href": "slides/20-logistic-prediction-notes.html#using-the-confusion-matrix-1",
    "title": "Logistic Regression: Prediction",
    "section": "Using the confusion matrix",
    "text": "Using the confusion matrix\n\n\n\n          Truth\nPrediction    0    1\n         0 3553  635\n         1    2    0\n\n\n\n\n. . .\nThe misclassification rate of this model with a threshold of 0.5 is\n\\[\n\\text{misclassification} = \\frac{635 + 2}{3553 + 635 + 2 + 0} = 0.152\n\\]"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#using-the-confusion-matrix-2",
    "href": "slides/20-logistic-prediction-notes.html#using-the-confusion-matrix-2",
    "title": "Logistic Regression: Prediction",
    "section": "Using the confusion matrix",
    "text": "Using the confusion matrix\n\n\n\n          Truth\nPrediction    0    1\n         0 3553  635\n         1    2    0\n\n\n\n\nAccuracy is 0.848 and the misclassification rate is 0.152.\n. . .\n\n\nWhat is the limitation of solely relying on accuracy and misclassification to assess the model performance?\nWhat is the limitation of using a single confusion matrix to assess the model performance?"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#truefalse-positivenegative",
    "href": "slides/20-logistic-prediction-notes.html#truefalse-positivenegative",
    "title": "Logistic Regression: Prediction",
    "section": "True/false positive/negative",
    "text": "True/false positive/negative\n\n\n\n\n\n\n\n\n\nNot high risk \\((y_i = 0)\\)\nHigh risk \\((y_i = 1)\\)\n\n\n\n\nClassified not high risk \\((\\hat{\\pi}_i \\leq \\text{threshold})\\)\nTrue negative (TN)\nFalse negative (FN)\n\n\nClassified high risk \\((\\hat{\\pi}_i &gt; \\text{threshold})\\)\nFalse positive (FP)\nTrue positive (TP)\n\n\n\n\n\n\\(\\text{accuracy} = \\frac{TN + TP}{TN + TP + FN + FP}\\)\n\\(\\text{misclassification} = \\frac{FN + FP}{TN+ TP + FN + FP}\\)"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#false-negative-rate",
    "href": "slides/20-logistic-prediction-notes.html#false-negative-rate",
    "title": "Logistic Regression: Prediction",
    "section": "False negative rate",
    "text": "False negative rate\n\n\n\n\n\n\n\n\n\nNot high risk \\((y_i = 0)\\)\nHigh risk \\((y_i = 1)\\)\n\n\n\n\nClassified not high risk \\((\\hat{\\pi}_i \\leq \\text{threshold})\\)\nTrue negative (TN)\nFalse negative (FN)\n\n\nClassified high risk \\((\\hat{\\pi}_i &gt; \\text{threshold})\\)\nFalse positive (FP)\nTrue positive (TP)\n\n\n\n\n. . .\nFalse negative rate: Proportion of actual positives that were classified as negatives\n\nP(classified not high risk | high risk) = \\(\\frac{FN}{TP + FN}\\)"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#false-positive-rate",
    "href": "slides/20-logistic-prediction-notes.html#false-positive-rate",
    "title": "Logistic Regression: Prediction",
    "section": "False positive rate",
    "text": "False positive rate\n\n\n\n\n\n\n\n\n\nNot high risk \\((y_i = 0)\\)\nHigh risk \\((y_i = 1)\\)\n\n\n\n\nClassified not high risk \\((\\hat{\\pi}_i \\leq \\text{threshold})\\)\nTrue negative (TN)\nFalse negative (FN)\n\n\nClassified high risk \\((\\hat{\\pi}_i &gt; \\text{threshold})\\)\nFalse positive (FP)\nTrue positive (TP)\n\n\n\n\n. . .\nFalse positive rate: Proportion of actual negatives that were classified as positives\n\nP(classified high risk | not high risk) = \\(\\frac{FP}{TN + FP}\\)"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#sensitivity",
    "href": "slides/20-logistic-prediction-notes.html#sensitivity",
    "title": "Logistic Regression: Prediction",
    "section": "Sensitivity",
    "text": "Sensitivity\n\n\n\n\n\n\n\n\n\nNot high risk \\((y_i = 0)\\)\nHigh risk \\((y_i = 1)\\)\n\n\n\n\nClassified not high risk \\((\\hat{\\pi}_i \\leq \\text{threshold})\\)\nTrue negative (TN)\nFalse negative (FN)\n\n\nClassified high risk \\((\\hat{\\pi}_i &gt; \\text{threshold})\\)\nFalse positive (FP)\nTrue positive (TP)\n\n\n\n\n. . .\nSensitivity: Proportion of actual positives that were correctly classified as positive\n\nAlso known as true positive rate (TPR) and recall\nP(classified high risk | high risk) = 1 − False negative rate"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#specificity",
    "href": "slides/20-logistic-prediction-notes.html#specificity",
    "title": "Logistic Regression: Prediction",
    "section": "Specificity",
    "text": "Specificity\n\n\n\n\n\n\n\n\n\nNot high risk \\((y_i = 0)\\)\nHigh risk \\((y_i = 1)\\)\n\n\n\n\nClassified not high risk \\((\\hat{\\pi}_i \\leq \\text{threshold})\\)\nTrue negative (TN)\nFalse negative (FN)\n\n\nClassified high risk \\((\\hat{\\pi}_i &gt; \\text{threshold})\\)\nFalse positive (FP)\nTrue positive (TP)\n\n\n\n\n. . .\nSpecificity: Proportion of actual negatives that were correctly classified as negative\n\nP(classified not high risk | not high risk) = 1 − False positive rate"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#practice",
    "href": "slides/20-logistic-prediction-notes.html#practice",
    "title": "Logistic Regression: Prediction",
    "section": "Practice",
    "text": "Practice\n\n\n\n          Truth\nPrediction    0    1\n         0 3553  635\n         1    2    0\n\n\n\n\nCalculate the\n\nFalse negative rate\nFalse positive rate\nSensitivity\nSpecificity"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#using-metrics-to-select-model-and-threshold",
    "href": "slides/20-logistic-prediction-notes.html#using-metrics-to-select-model-and-threshold",
    "title": "Logistic Regression: Prediction",
    "section": "Using metrics to select model and threshold",
    "text": "Using metrics to select model and threshold\n\n\n\n\n\n\n\nMetric\nGuidance for use\n\n\n\n\nAccuracy\nFor balanced data, use only in combination with other metrics.\nAvoid using for imbalanced data.\n\n\nSensitivity (true positive rate)\nUse when false negatives are more “expensive” than false positives.\n\n\nFalse positive rate\nUse when false positives are more “expensive” than false negatives.\n\n\nPrecision = \\(\\frac{TP}{TP + FP}\\)\nUse when it’s important for positive predictions to be accurate.\n\n\n\n\nThis table is a modification of work created and shared by Google in the Google Machine Learning Crash Course."
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#choosing-a-classification-threshold",
    "href": "slides/20-logistic-prediction-notes.html#choosing-a-classification-threshold",
    "title": "Logistic Regression: Prediction",
    "section": "Choosing a classification threshold",
    "text": "Choosing a classification threshold\n\nA doctor plans to use your model to determine which patients are high risk for heart disease. The doctor will recommend a treatment plan for high risk patients.\n\nWould you want sensitivity to be high or low? What about specificity?\nWhat are the trade-offs associated with each decision?"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#roc-curve",
    "href": "slides/20-logistic-prediction-notes.html#roc-curve",
    "title": "Logistic Regression: Prediction",
    "section": "ROC curve",
    "text": "ROC curve\nSo far the model assessment has depended on the model and selected threshold. The receiver operating characteristic (ROC) curve allows us to assess the model performance across a range of thresholds.\n. . .\n\n\n\n\n\n\n\n\n\n\n\n\n\nx-axis: 1 - Specificity (False positive rate)\ny-axis: Sensitivity (True positive rate)\n\nWhich corner of the plot indicates the best model performance?"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#roc-curve-1",
    "href": "slides/20-logistic-prediction-notes.html#roc-curve-1",
    "title": "Logistic Regression: Prediction",
    "section": "ROC curve",
    "text": "ROC curve"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#roc-curve-in-r",
    "href": "slides/20-logistic-prediction-notes.html#roc-curve-in-r",
    "title": "Logistic Regression: Prediction",
    "section": "ROC curve in R",
    "text": "ROC curve in R\n\n# calculate sensitivity and specificity at each threshold\nroc_curve_data &lt;- heart_disease_aug |&gt;\n  roc_curve(high_risk, pred_prob, \n            event_level = \"second\") \n\n# plot roc curve\nautoplot(roc_curve_data)"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#roc-curve-in-r-1",
    "href": "slides/20-logistic-prediction-notes.html#roc-curve-in-r-1",
    "title": "Logistic Regression: Prediction",
    "section": "ROC curve in R",
    "text": "ROC curve in R\n\n\nSample from underlying data\n\n\n# A tibble: 10 × 3\n   .threshold specificity sensitivity\n        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1     0.0545       0.103       0.980\n 2     0.0660       0.181       0.959\n 3     0.0832       0.305       0.909\n 4     0.136        0.583       0.715\n 5     0.193        0.754       0.501\n 6     0.221        0.805       0.411\n 7     0.221        0.805       0.411\n 8     0.262        0.881       0.287\n 9     0.270        0.901       0.254\n10     0.279        0.915       0.227"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#area-under-the-curve",
    "href": "slides/20-logistic-prediction-notes.html#area-under-the-curve",
    "title": "Logistic Regression: Prediction",
    "section": "Area under the curve",
    "text": "Area under the curve\nThe area under the curve (AUC) can be used to assess how well the logistic model fits the data\n\nAUC=0.5: model is a very bad fit (no better than a coin flip)\nAUC close to 1: model is a good fit\n\n. . .\n\nheart_disease_aug |&gt;\n  roc_auc(high_risk, pred_prob,\n    event_level = \"second\"\n  )\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.695"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#recap",
    "href": "slides/20-logistic-prediction-notes.html#recap",
    "title": "Logistic Regression: Prediction",
    "section": "Recap",
    "text": "Recap\n\nCalculated predicted probabilities from the logistic regression model\nUsed predicted probabilities to classify observations\nMade decisions and assessed model performance using\n\nConfusion matrix\nROC curve"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#further-reading",
    "href": "slides/20-logistic-prediction-notes.html#further-reading",
    "title": "Logistic Regression: Prediction",
    "section": "Further reading",
    "text": "Further reading\nClassification module in Google Machine Learning Crash Course"
  },
  {
    "objectID": "slides/20-logistic-prediction-notes.html#footnotes",
    "href": "slides/20-logistic-prediction-notes.html#footnotes",
    "title": "Logistic Regression: Prediction",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe default is type = \"link\", which produces the predicted log-odds.↩︎"
  },
  {
    "objectID": "slides/lab-03.html#goals",
    "href": "slides/lab-03.html#goals",
    "title": "Lab 03",
    "section": "Goals",
    "text": "Goals\n\nMeet your team!\nTeam agreement\nLab 03: Multiple linear regression"
  },
  {
    "objectID": "slides/lab-03.html#icebreaker",
    "href": "slides/lab-03.html#icebreaker",
    "title": "Lab 03",
    "section": "Icebreaker",
    "text": "Icebreaker\n\n\nWhat is your favorite place to eat at Brodhead Center (West Union)?"
  },
  {
    "objectID": "slides/lab-03.html#meet-your-team",
    "href": "slides/lab-03.html#meet-your-team",
    "title": "Lab 03",
    "section": "Meet your team!",
    "text": "Meet your team!\n\nClickhere to find your team.\nSit with your team."
  },
  {
    "objectID": "slides/lab-03.html#team-name-agreement",
    "href": "slides/lab-03.html#team-name-agreement",
    "title": "Lab 03",
    "section": "Team name + agreement",
    "text": "Team name + agreement\n\nCome up with a team name. You can’t have the same name as another team in the class, so be creative!\n\nYour TA will get your team name by the end of lab.\n\nFill out the team agreement. The goals of the agreement are to…\n\nGain a common understanding of the team’s goals and expectations for collaboration\nMake a plan for team communication\nMake a plan for working outside of lab"
  },
  {
    "objectID": "slides/lab-03.html#team-workflow",
    "href": "slides/lab-03.html#team-workflow",
    "title": "Lab 03",
    "section": "Team workflow",
    "text": "Team workflow\n\nOnly one team member should type at a time. There are markers in today’s lab to help you determine whose turn it is to type.\n\nEvery team member should still be engaged in discussion for all questions, even if it’s not your turn type.\n\nDon’t forget to pull to get your teammates’ updates before making changes to the .qmd file.\n\n\n\n\n\n\nImportant\n\n\nOnly one submission per team on Gradescope. Read the submission instructions carefully!"
  },
  {
    "objectID": "slides/lab-03.html#team-workflow-in-action",
    "href": "slides/lab-03.html#team-workflow-in-action",
    "title": "Lab 03",
    "section": "Team workflow, in action",
    "text": "Team workflow, in action\n\nComplete the “Workflow: Using Git and GitHub as a team” section of the lab in your teams.\nRaise your hand if you have any questions about the workflow.\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/lab-03.html#tips-for-working-on-a-team",
    "href": "slides/lab-03.html#tips-for-working-on-a-team",
    "title": "Lab 03",
    "section": "Tips for working on a team",
    "text": "Tips for working on a team\n\nDo not pressure each other to finish early; use the time wisely to really learn the material and produce a quality report.\nThe labs are structured to help you learn the steps of a data analysis. Do not split up the lab among the team members; work on it together in its entirety.\nEveryone has something to contribute! Use the lab groups as an opportunity to share ideas and learn from each other."
  },
  {
    "objectID": "slides/lab-03.html#lab-03-multiple-linear-regression",
    "href": "slides/lab-03.html#lab-03-multiple-linear-regression",
    "title": "Lab 03",
    "section": "Lab 03: Multiple linear regression",
    "text": "Lab 03: Multiple linear regression\nToday’s lab focuses on using multiple linear regression to predict childcare costs for preschool-aged children in North Carolina.\n🔗 sta221-sp25.netlify.app/labs/lab-03.html"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 221 - Regression Analysis: Theory and Applications",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the semester. Note that this schedule will be updated as the semester progresses, with all changes documented here.\n\n\n\n\n\n\n\n\n\nweek\ndow\ndate\ntopic\nprepare\nslides\nnotes\nae\nhw\nlab\nproject\ndue\n\n\n\n\n1\nTh\nJan 9\nWelcome to STA 221!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF\nJan 10\nLab 00: Welcome + Getting started\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2\nTu\nJan 14\nSimple linear regression (SLR)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nJan 16\nSLR: Model assessment\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF\nJan 17\nLab 01: Computing + linear algebra review\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3\nTu\nJan 21\nSLR: Matrix representation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 01 due\n\n\n\nTh\nJan 23\nGeometric interpretation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultiple linear regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF\nJan 24\nLab 02: Linear regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4\nTu\nJan 28\nMLR: Types of predictors\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 02 due\n\n\n\nTh\nJan 30\nMLR: Types of predictors cont'd + Model comparison\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 01 due, Statstics experience assigned\n\n\n\nF\nJan 31\nLab 03: Multiple linear regression + Meet your team!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5\nTu\nFeb 4\nInference for regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 03 due\n\n\n\nTh\nFeb 6\nInference for regression cont'd\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF\nFeb 7\nLab: Project research topics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6\nTu\nFeb 11\nInference for regression cont'd\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject topics due\n\n\n\nTh\nFeb 13\nExam 01 review\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 02 due\n\n\n\nF\nFeb 14\nLab 04: Exam 01 review\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7\nTu\nFeb 18\nExam 01\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nFeb 20\nNo Lecture: Take-home exam\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF\nFeb 21\nLab: Project proposal\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8\nTu\nFeb 25\nMLR: Model conditions + diagnostics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject propsal due\n\n\n\nTh\nFeb 27\nMLR: Multicollinearity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF\nFeb 28\nLab 05: Expanding multiple linear regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9\nTu\nMar 4\nMLR: Multicollinearity cont'd\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 05 due, Exam 01 corrections due, Team feedback due\n\n\n\n\n\n\nVariable transformations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nMar 6\nMLR: variable transformation cont'd\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF\nMar 7\nLab: Project exploratory data analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10\nTu\nMar 11\nNo lecture: Spring break\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nMar 13\nNo lecture: Spring break\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF\nMar 14\nNo lab: Spring break\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11\nTu\nMar 18\nMaximum likelihood estimation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nMar 20\nProperties of estimators\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 03 due, Project EDA due\n\n\n\nF\nMar 21\nLab 06: Maximum likelihood estimation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12\nTu\nMar 25\nProbabilities + Odds + Odds ratios\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 06 due\n\n\n\nTh\nMar 27\nLogistic regression (LR)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF\nMar 28\nLab: Project presentations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n13\nTu\nApr 1\nLR: Prediction\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nApr 3\nLR: Model comparison\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF\nApr 4\nLab 07: Logistic regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n14\nTu\nApr 8\nLogistic regression Inference + Assumptions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 07 due, Team Feedback due\n\n\n\nTh\nApr 10\nLogistic regression overview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 04 due\n\n\n\nF\nApr 11\nLab: Project peer review\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n15\nTu\nApr 15\nExam 02 review\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nApr 17\nExam 02\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF\nApr 18\nProject work day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n16\nTu\nApr 22\nWrap up + Looking ahead\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStatistics experience due\n\n\nExam period\nMo\nApr 28\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWritten report due\n\n\n\nWe\nApr 30\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject highlights, Repo organzation due\n\n\n\nTh\nMay 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject survey due",
    "crumbs": [
      "Schedule"
    ]
  },
  {
    "objectID": "computing-r-resources.html",
    "href": "computing-r-resources.html",
    "title": "Resources for learning R",
    "section": "",
    "text": "Below are freely available resources to learn or review the following in R: data wrangling, data visualization, Quarto basics.",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#in-depth-introduction",
    "href": "computing-r-resources.html#in-depth-introduction",
    "title": "Resources for learning R",
    "section": "In-depth introduction",
    "text": "In-depth introduction\nCoursera: Data Visualization and Transformation with R by Mine Çetinkaya-Rundel and Elijah Meyer\n\nIncludes videos, readings, practice exercise, quizzes, and other resources\nYou can select content within the modules you want to complete.\nFocus on Modules 2 and 3. Review the content in Module 1 as needed.s\nClick here for instructions to register for Coursera for free as a Duke student",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#in-depth-review",
    "href": "computing-r-resources.html#in-depth-review",
    "title": "Resources for learning R",
    "section": "In-depth review",
    "text": "In-depth review\nData Science with R videos by Mine Çetinkaya-Rundel and Elijah Meyer\n\nVideos from the data science Coursera course\nFocus on videos on visualizing and summarizing data\nYou need to join the Coursera course to access the files from the code along videos.\n\nLearn R: An interactive introduction to data analysis with R\n\nHands-on tutorial that can be completed within the site (no RStudio required)\nFocus on Chapters 4 - 6",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#shorter-review",
    "href": "computing-r-resources.html#shorter-review",
    "title": "Resources for learning R",
    "section": "Shorter review",
    "text": "Shorter review\nR for Data Science (2nd ed) by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund\n\nFocus on Chapters 1 - 3, 10",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#additional-resources",
    "href": "computing-r-resources.html#additional-resources",
    "title": "Resources for learning R",
    "section": "Additional resources",
    "text": "Additional resources\n\nTidy Modeling with R by Max Kuhn & Julia Silge\nPosit Cheatsheets\nR workshops by Duke Center for Data and Visualization Sciences",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "ae/ae-02-mlr.html",
    "href": "ae/ae-02-mlr.html",
    "title": "AE 02: Multiple linear regression",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-02 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE."
  },
  {
    "objectID": "ae/ae-02-mlr.html#exercise-1",
    "href": "ae/ae-02-mlr.html#exercise-1",
    "title": "AE 02: Multiple linear regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nWe’ll start by fitting a model in which we include all levels of verified_income.\n\nFit a model using debt_to_income, annual_income_th, and the indicator variables created below to predict interest_rate.\nWhat do you notice about the model output? Why did this happen?\n\n\nloan50 &lt;- loan50 |&gt;\n  mutate(\n    not_verified = factor(if_else(verified_income == \"Not Verified\", 1, 0)),\n    source_verified = factor(if_else(verified_income == \"Source Verified\", 1, 0)),\n    verified = factor(if_else(verified_income == \"Verified\", 1, 0))\n  )\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-02-mlr.html#exercise-2",
    "href": "ae/ae-02-mlr.html#exercise-2",
    "title": "AE 02: Multiple linear regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nNow let’s take a look at the design matrix for the model with predictors debt_to_income, annual_income_th, and verified_income.\nHow does R choose the baseline level by default?\n\n## add code here"
  },
  {
    "objectID": "ae/ae-02-mlr.html#exercise-3",
    "href": "ae/ae-02-mlr.html#exercise-3",
    "title": "AE 02: Multiple linear regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nWhat is the intercept for individuals with\n\nNot verified income?\nSource verified income?\nVerified income?"
  },
  {
    "objectID": "ae/ae-02-mlr.html#exercise-4",
    "href": "ae/ae-02-mlr.html#exercise-4",
    "title": "AE 02: Multiple linear regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nFit the model with the predictors debt_to_income, annual_income_th, verified_income , and the interaction between annual_income_th and verified_income.\nNeatly display the model results using 3 digits.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-02-mlr.html#exercise-5",
    "href": "ae/ae-02-mlr.html#exercise-5",
    "title": "AE 02: Multiple linear regression",
    "section": "Exercise 5",
    "text": "Exercise 5\n\nWrite the estimated regression equation for the people with Not Verified income.\nWrite the estimated regression equation for people with Verified income."
  },
  {
    "objectID": "ae/ae-02-mlr.html#exercise-6",
    "href": "ae/ae-02-mlr.html#exercise-6",
    "title": "AE 02: Multiple linear regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nIn general, how do\n\nindicators for categorical predictors impact the model equation?\ninteraction terms impact the model equation?"
  },
  {
    "objectID": "ae/ae-09-exam-02-review.html",
    "href": "ae/ae-09-exam-02-review.html",
    "title": "AE 09: Exam 02 review",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-09 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE.\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(tidymodels)\nlibrary(pROC)\nlibrary(Stat2Data)"
  },
  {
    "objectID": "ae/ae-09-exam-02-review.html#exercise-1",
    "href": "ae/ae-09-exam-02-review.html#exercise-1",
    "title": "AE 09: Exam 02 review",
    "section": "Exercise 1",
    "text": "Exercise 1\nSuppose you fit a simple linear regression model.\n\nDraw a scatterplot that contains an observation with large leverage but low Cook’s distance.\nDraw a scatterplot that contains an observation with large leverage and high Cook’s distance.\nDraw a scatterplot that contains an observation with a large studentized residual."
  },
  {
    "objectID": "ae/ae-09-exam-02-review.html#exercise-2",
    "href": "ae/ae-09-exam-02-review.html#exercise-2",
    "title": "AE 09: Exam 02 review",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nDescribe what it means for \\(\\tilde{\\boldsymbol{\\beta}}\\) to be the maximum likelihood estimator.\nWhat are properties of MLEs?\n\n\n\n\n\n\n\nNote\n\n\n\nUse this data analysis scenario for Exercises 3 - 6.\n\n\nThe data for this analysis is about credit card customers. It can be found in the file credit.csv. The following variables are in the data set:\n\nincome: Income in $1,000’s\nlimit: Credit limit\nrating: Credit rating\ncards: Number of credit cards\nage: Age in years\neducation: Number of years of education\nown: Whether an individual owns their home ( No or Yes )\nstudent: Whether the individual was a student ( No or Yes )\nmarried: Whether the individual was married (No and Yes)\nregion: Region the individual is from ( South, East, and West)\nbalance: Average credit card balance in $.\n\n\ncredit &lt;- read_csv(\"data/credit.csv\") |&gt;\n  mutate(maxed = factor(if_else(balance == 0, 1, 0)))\n\nThe objective of this analysis is to predict whether a person has maxed out their credit card, i.e., had $0 average card balance.\nWe’ll start with a model predicting the odds of maxed = 1 using income, rating, and region.\n\ncredit_fit &lt;- glm(maxed ~ income + rating + region, data = credit, \n                  family = \"binomial\")\n\ntidy(credit_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n9.898\n1.449\n6.829\n0.000\n\n\nincome\n0.113\n0.021\n5.273\n0.000\n\n\nrating\n-0.057\n0.008\n-7.397\n0.000\n\n\nregionSouth\n-0.595\n0.604\n-0.985\n0.324\n\n\nregionWest\n-0.082\n0.649\n-0.126\n0.900"
  },
  {
    "objectID": "ae/ae-09-exam-02-review.html#exercise-3",
    "href": "ae/ae-09-exam-02-review.html#exercise-3",
    "title": "AE 09: Exam 02 review",
    "section": "Exercise 3",
    "text": "Exercise 3\nThe logistic regression model takes the following form:\n\\[\n\\log(\\frac{\\pi_i}{1 - \\pi_i}) = \\beta_0 + \\beta_1 ~ income + \\beta_2 ~ rating + \\beta_3 ~ regionSouth + \\beta_4 ~ regionWest\n\\]\n\nUse the equation above to show the expected change in the odds of maxing out a credit card when the credit rating increases by 10 points. Assume income and region are constant. Write your answer in terms of \\(\\beta_0, \\beta_1, \\beta_2, \\beta_3, \\beta_4\\)\nSuppose there are two individuals. Individual 1 has an income of $64,000, a credit rating of 590, and is from the South region. Individual 2 has an income of $135,000, a credit rating of 695, and is from the East region. Use the equation above to show how the odds of maxing out a credit card differ between Individual 1 and Individual 2. Write your answer in terms of \\(\\beta_0, \\beta_1, \\beta_2\\), etc.\nUse R to compute the odds for each individual. How do the odds compare? Is this consistent with your response to part (b)?"
  },
  {
    "objectID": "ae/ae-09-exam-02-review.html#exercise-4",
    "href": "ae/ae-09-exam-02-review.html#exercise-4",
    "title": "AE 09: Exam 02 review",
    "section": "Exercise 4",
    "text": "Exercise 4\nWe consider adding the interaction between region and income to the current model. We’ll use a drop-in-deviance test to determine whether or not to add the interaction term.\n\nState the null and alternative hypotheses in words and using mathematical notation.\nDescribe what the test statistic \\(G\\) means in the context of the data.\nShow why the degrees of freedom for the test statistic are equal to 2.\nConduct the drop-in-deviance test and state your conclusion in the context of the data."
  },
  {
    "objectID": "ae/ae-09-exam-02-review.html#exercise-5",
    "href": "ae/ae-09-exam-02-review.html#exercise-5",
    "title": "AE 09: Exam 02 review",
    "section": "Exercise 5",
    "text": "Exercise 5\nUse the model credit_fit that includes the main effects for income, rating, and region.\n\nCompute the predicted probabilities, then use those to predict whether individuals maxed out their credit card using a threshold of \\(\\hat{\\pi}   = 0.5\\).\nWhat is the accuracy? What does it mean in the context of the data?\nWhat is the sensitivity? What does it mean in the context of the data ?\nWhat is the false positive rate? How it is computed given the specificity? What does it mean in the context of the data?"
  },
  {
    "objectID": "ae/ae-09-exam-02-review.html#exercise-6",
    "href": "ae/ae-09-exam-02-review.html#exercise-6",
    "title": "AE 09: Exam 02 review",
    "section": "Exercise 6",
    "text": "Exercise 6\nUse the model credit_fit that includes the main effects for income, rating, and region.\n\nConstruct the ROC curve and compute the area under the curve (AUC).\nBased on the AUC, do you think this model sufficiently identifies those who will max out their credit card vs. those who will not? Explain.\nSuppose a credit card company uses your model to inform the credit limit to give to new customers. Do you think they would prioritize sensitivity, specificity, or regard both equally? Briefly explain.\nBased on your response to part(c), select a threshold for classifying observations into those likely to max out the credit card and those who are not. What is your threshold in terms of probability? What is the sensitivity? What is the specificity?\n\n\n\n\n\n\n\nSubmission\n\n\n\nTo submit the AE:\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your AE repo on GitHub. You’re done! 🎉"
  },
  {
    "objectID": "ae/ae-05-prob-odds.html",
    "href": "ae/ae-05-prob-odds.html",
    "title": "AE 05: Probabilities, Odds, Odds ratios",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-05 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE.\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(tidymodels)"
  },
  {
    "objectID": "ae/ae-05-prob-odds.html#exercise-1",
    "href": "ae/ae-05-prob-odds.html#exercise-1",
    "title": "AE 05: Probabilities, Odds, Odds ratios",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nWhat is the probability a randomly selected respondent has heard a lot about AI?\nWhat are the odds a randomly selected respondent has heard a lot about AI?"
  },
  {
    "objectID": "ae/ae-05-prob-odds.html#exercise-2",
    "href": "ae/ae-05-prob-odds.html#exercise-2",
    "title": "AE 05: Probabilities, Odds, Odds ratios",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nWhat is the probability a randomly selected respondent who is concerned about increased use of AI in daily life has heard a lot about AI?\nWhat are the odds a randomly selected respondent who is concerned about increased use of AI in daily life has heard a lot about AI?"
  },
  {
    "objectID": "ae/ae-05-prob-odds.html#exercise-3",
    "href": "ae/ae-05-prob-odds.html#exercise-3",
    "title": "AE 05: Probabilities, Odds, Odds ratios",
    "section": "Exercise 3",
    "text": "Exercise 3\nMake a plot to visualize the relationship between how much a respondent has heard about AI and being concerned with increased use of AI in daily life. Use the plot to describe the relationship between the two variables."
  },
  {
    "objectID": "ae/ae-05-prob-odds.html#exercise-4",
    "href": "ae/ae-05-prob-odds.html#exercise-4",
    "title": "AE 05: Probabilities, Odds, Odds ratios",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nHow do the odds of being concerned about increased use of AI in daily life for a randomly selected respondent who has heard nothing about AI compare to the odds for a randomly selected respondent who has heard a lot about AI?\nHow do the odds of being concerned about increased use of AI in daily life for a randomly selected respondent who has heard a little about AI compare to the odds for a randomly selected respondent who has heard a lot about AI?"
  },
  {
    "objectID": "ae/ae-05-prob-odds.html#exercise-5",
    "href": "ae/ae-05-prob-odds.html#exercise-5",
    "title": "AE 05: Probabilities, Odds, Odds ratios",
    "section": "Exercise 5",
    "text": "Exercise 5\nWe can use a logistic regression model to understand the relationship between how much someone has heard about AI and whether they are concerned about increased use of AI in daily life. (We will discuss this in detail next class, but will get a preview for now.)\nLet \\(p\\) be the probability a randomly selected respondent is concerned about increased use of AI in daily life. The statistical model is\n\\[\n\\begin{aligned}\n\\log\\Big(\\frac{p_i}{1-p_i}\\Big) = \\beta_0 &+ \\beta_1\\boldsymbol{1}(ai\\_heard_i = \\text{A little}) \\\\ &+ \\beta_2\\mathbf{1}(ai\\_heard_i = \\text{Nothing}) \\\\  &+ \\beta_3\\mathbf{1}(ai\\_heard_i = \\text{Refused})\n\\end{aligned}\n\\]\nThe code and output to fit this model is shown below:\n\nai_concern_fit &lt;- glm(ai_concern ~ ai_heard, data = pew_data,\n                      family = \"binomial\")\ntidy(ai_concern_fit) |&gt; \n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.065\n0.031\n-2.082\n0.037\n\n\nai_heardA little\n0.383\n0.040\n9.504\n0.000\n\n\nai_heardNothing at all\n-0.276\n0.079\n-3.505\n0.000\n\n\nai_heardRefused\n-0.697\n0.459\n-1.520\n0.129\n\n\n\n\n\n\nInterpret the intercept in the context of the data in terms of the log-odds of being concerned about increased use of AI in daily life.\nInterpret the coefficient of ai_heardA little in the context of the data in terms of the log-odds of being concerned about increased use of AI in daily life.\nInterpret the coefficient of ai_heardNothing at all in the context of the data in terms of the odds of being concerned about the increased use of AI in daily life. How does this compare to your response to Exercise 4?\n\n\n\n\n\n\n\nSubmission\n\n\n\nTo submit the AE:\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your AE repo on GitHub. You’re done! 🎉"
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html",
    "href": "ae/ae-04-exam-01-review.html",
    "title": "AE 04: Exam 01 Review",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-04 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE."
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#packages",
    "href": "ae/ae-04-exam-01-review.html#packages",
    "title": "AE 04: Exam 01 Review",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(patchwork)"
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#restaurant-tips",
    "href": "ae/ae-04-exam-01-review.html#restaurant-tips",
    "title": "AE 04: Exam 01 Review",
    "section": "Restaurant tips",
    "text": "Restaurant tips\nWhat factors are associated with the amount customers tip at a restaurant? To answer this question, we will use data collected in 2011 by a student at St. Olaf who worked at a local restaurant.1\nThe variables we’ll focus on for this analysis are\n\nTip: amount of the tip\nParty: number of people in the party\nAge: Age of the payer\n\nView the data set to see the remaining variables.\n\ntips &lt;- read_csv(\"data/tip-data.csv\")"
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#exploratory-data-analysis",
    "href": "ae/ae-04-exam-01-review.html#exploratory-data-analysis",
    "title": "AE 04: Exam 01 Review",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\np1 &lt;- ggplot(data = tips, aes(x = Tip)) + \n  geom_histogram(color = \"white\", binwidth = 2) +\n  labs(x = \"Tips ($)\",\n       title = \"Tips at local restaurant\")\n\np2 &lt;- ggplot(data = tips, aes(x = Party)) + \n  geom_histogram(color = \"white\") +\n  labs(x = \"Party\",\n       title = \"Number of diners in party\") +\n  xlim(c(0, 7))\n\np3 &lt;- ggplot(data = tips, aes(x = Age)) + \n  geom_bar(color = \"white\") +\n  labs(x = \"\",\n       title = \"Age of Payer\") \n\np1 / (p2 + p3)\n\n\n\n\n\n\n\n\n\np4 &lt;- ggplot(data = tips, aes(x = Party, y = Tip)) + \n  geom_jitter() + \n  labs(x = \"Number of diners in party\", \n       y = \"Tips ($)\",\n       title = \"Tips vs. Party\")\n\np5 &lt;- ggplot(data = tips, aes(x = Age, y = Tip)) + \n  geom_boxplot() + \n  labs(x = \"Age of payer\", \n       y = \"Tips ($)\",\n       title = \"Tips vs. Age\")\n\np4 + p5\n\n\n\n\n\n\n\n\nWe will use the number of diners in the party and age of the payer to understand variability in the tips."
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#exercise-1",
    "href": "ae/ae-04-exam-01-review.html#exercise-1",
    "title": "AE 04: Exam 01 Review",
    "section": "Exercise 1",
    "text": "Exercise 1\nWe will start with the main effects model.\n\nHow many indicator variables for Age can we create from the data?\nHow many indicator variables for Age will be in the regression model?\nAre the responses to parts a and b equal? If not, explain why not.\nWhich of the following is true for this model? Select all that apply.\n\nThe intercepts are the same for every level of Age.\nThe intercepts differ by Age.\nThe effect of Party is the same for every level of Age.\nThe effect of Party differs by Age."
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#exercise-2",
    "href": "ae/ae-04-exam-01-review.html#exercise-2",
    "title": "AE 04: Exam 01 Review",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nWhat is the dimension of the design matrix \\(\\mathbf{X}\\) for the main effects model?\nCalculate the coefficient estimates \\(\\hat{\\boldsymbol{\\beta}}\\) directly from the data.\nWrite the equation of the estimated regression model.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#exercise-3",
    "href": "ae/ae-04-exam-01-review.html#exercise-3",
    "title": "AE 04: Exam 01 Review",
    "section": "Exercise 3",
    "text": "Exercise 3\nCompute the following directly from the data:\n\nThe regression standard error \\(\\hat{\\sigma}_{\\epsilon}\\) . Interpret this value in the context of the data.\n\\(R^2\\). Interpret this value in the context of the data.\n\\(RMSE\\). Interpret this value in the context of the data.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#exercise-4",
    "href": "ae/ae-04-exam-01-review.html#exercise-4",
    "title": "AE 04: Exam 01 Review",
    "section": "Exercise 4",
    "text": "Exercise 4\nYou decide to add an interaction effect between Age and Party to the model and fit a model of the following form:\n\\[\n\\hat{Tip}_i = \\beta_0 + \\beta_1Party_i + \\beta_2SenCit_i + \\beta_3Yadult_i + \\beta_4Party_i \\times SenCit_i + \\beta_5 Party_i \\times Yadult_i\n\\]\n\nWhich of the following is true for this model? Select all that apply.\n\nThe intercepts are the same for every level of Age.\nThe intercepts differ by Age.\nThe effect of Party is the same for every level of Age.\nThe effect of Party differs by Age.\n\nBy how much does the intercept for tables with young adult payers differ from tables with middle age payers?\nWrite the equation of the model for tables in which the payer is a senior citizen.\nSuppose you wish to test the hypotheses: \\(H_0: \\beta_5 = 0 \\text{ vs. }H_a: \\beta_5 \\neq 0\\) . State what is being tested in terms of the effect of Party."
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#exercise-5",
    "href": "ae/ae-04-exam-01-review.html#exercise-5",
    "title": "AE 04: Exam 01 Review",
    "section": "Exercise 5",
    "text": "Exercise 5\nThe output for the model with the interaction term and 90% confidence intervals for the coefficients is shown below.\n\ntip_int_fit &lt;- lm(Tip ~ Party + Age + Party * Age, data = tips)\ntidy(tip_int_fit, conf.int = TRUE, conf.level = 0.9) |&gt;\n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.604\n0.504\n1.199\n0.232\n-0.229\n1.438\n\n\nParty\n1.924\n0.169\n11.359\n0.000\n1.644\n2.204\n\n\nAgeSenCit\n1.033\n0.784\n1.317\n0.190\n-0.265\n2.330\n\n\nAgeYadult\n-1.203\n0.928\n-1.297\n0.197\n-2.739\n0.332\n\n\nParty:AgeSenCit\n-0.259\n0.262\n-0.986\n0.325\n-0.692\n0.175\n\n\nParty:AgeYadult\n0.199\n0.504\n0.395\n0.693\n-0.635\n1.034\n\n\n\n\n\n\nWhat does 0.784, the standard error of AgeSenCit mean in the context of the data?\nWhat does 1.317, the test statistic for AgeSenCit mean in the context of the data?\nWhat does the p-value 0.190 mean in the context of the data?\nThe 90% confidence interval corresponds to what \\(\\alpha\\)-level?\nWhat is your conclusion about the effect of AgeSenCit?"
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#exercise-6",
    "href": "ae/ae-04-exam-01-review.html#exercise-6",
    "title": "AE 04: Exam 01 Review",
    "section": "Exercise 6",
    "text": "Exercise 6\nThe following are general questions about regression. They are not specific to the tips data set.\n\nWhat does it mean for an estimator to be the “least-squares” estimator?\nConsider the following derivation of \\(Var(\\hat{\\boldsymbol{\\beta}})\\) , the variance of the least-squares estimator:\n\\[\n\\begin{aligned}\nVar(\\hat{\\boldsymbol{\\beta}}) & = E[(\\hat{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta})(\\hat{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta})^T] \\\\\n& = E[((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\boldsymbol{\\epsilon})((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\boldsymbol{\\epsilon})^T] \\\\\n& = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^TE(\\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}^T)\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1} \\\\\n& = \\sigma^2(\\mathbf{X}^T\\mathbf{X})^{-1}\n\\end{aligned}\n\\]\n\nExplain how to go from Line 1 to Line 2.\n\nWhat assumptions are used to go from Line 3 to Line 4?\n\n\n\n\n\n\n\nSubmission\n\n\n\nTo submit the AE:\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your AE repo on GitHub. You’re done! 🎉"
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#footnotes",
    "href": "ae/ae-04-exam-01-review.html#footnotes",
    "title": "AE 04: Exam 01 Review",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDahlquist, Samantha, and Jin Dong. 2011. “The Effects of Credit Cards on Tipping.” Project for Statistics 212-Statistics for the Sciences, St. Olaf College.↩︎"
  },
  {
    "objectID": "ae/ae-08-logistic-review.html",
    "href": "ae/ae-08-logistic-review.html",
    "title": "AE 08: Logistic regression review",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-08 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE.\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(tidymodels)\nlibrary(pROC)\nlibrary(Stat2Data)"
  },
  {
    "objectID": "ae/ae-08-logistic-review.html#exercise-1",
    "href": "ae/ae-08-logistic-review.html#exercise-1",
    "title": "AE 08: Logistic regression review",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nWhy do we use logistic regression (instead of linear regression) for this analysis?\nThe four assumptions for linear regression are Linearity, Constant Variance, Normality, and Independence. For each assumption, state whether it is satisfied in logistic regression. If yes, state what the assumption means in the context of logistic regression. Otherwise, briefly explain why it is not satisfied."
  },
  {
    "objectID": "ae/ae-08-logistic-review.html#exercise-2",
    "href": "ae/ae-08-logistic-review.html#exercise-2",
    "title": "AE 08: Logistic regression review",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nWrite the interpretation of income in terms of the odds of maxing out a credit card.\nShow mathematically why we include “holding all else constant” in the interpretation for income.\nDescribe the expected change in the odds of maxing out a credit card when income increases from the median value $33,100 to $57,500 (the \\(75^{th}\\)) percentile. Assume rating and region are constant."
  },
  {
    "objectID": "ae/ae-08-logistic-review.html#exercise-3",
    "href": "ae/ae-08-logistic-review.html#exercise-3",
    "title": "AE 08: Logistic regression review",
    "section": "Exercise 3",
    "text": "Exercise 3\nThe logistic regression model takes the following form:\n\\[\n\\log(\\frac{\\pi_i}{1 - \\pi_i}) = \\beta_0 + \\beta_1 ~ income + \\beta_2 ~ rating + \\beta_3 ~ regionSouth + \\beta_4 ~ regionWest\n\\]\n\nUse the equation above to show the expected change in the odds of maxing out a credit card when the credit rating increases by 10 points. Assume income and region are constant. Write your answer in terms of \\(\\beta_0, \\beta_1, \\beta_2, \\beta_3, \\beta_4\\)\n\n\n\nSuppose there are two individuals. Individual 1 has an income of $64,000, a credit rating of 590, and is from the South region. Individual 2 has an income of $135,000, a credit rating of 695, and is from the East region. Use the equation above to show how the odds of maxing out a credit card differ between Individual 1 and Individual 2. Write your answer in terms of \\(\\beta_0, \\beta_1, \\beta_2\\), etc.\nUse R to compute the odds for each individual. How do the odds compare? Is this consistent with your response to part (b)?"
  },
  {
    "objectID": "ae/ae-08-logistic-review.html#exercise-4",
    "href": "ae/ae-08-logistic-review.html#exercise-4",
    "title": "AE 08: Logistic regression review",
    "section": "Exercise 4",
    "text": "Exercise 4\nWe consider adding the interaction between region and income to the current model. We’ll use a drop-in-deviance test to determine whether or not to add the interaction term.\n\nState the null and alternative hypotheses in words and using mathematical notation.\nDescribe what the test statistic \\(G\\) means in the context of the data.\nShow why the degrees of freedom for the test statistic is equal to 2.\nConduct the drop-in-deviance test and state your conclusion in the context of the data."
  },
  {
    "objectID": "ae/ae-08-logistic-review.html#exercise-5",
    "href": "ae/ae-08-logistic-review.html#exercise-5",
    "title": "AE 08: Logistic regression review",
    "section": "Exercise 5",
    "text": "Exercise 5\nUse the model credit_fit that includes the main effects for income, rating, and region.\n\nCompute the predicted probabilities, then use those to predict whether individuals maxed out their credit card using a threshold of \\(\\hat{\\pi}   = 0.5\\).\nWhat is the accuracy? What does it mean in the context of the data?\nWhat is the sensitivity? What does it mean in the context of the data ?\nWhat is the false positive rate? How it is computed given the specificity? What does it mean in the context of the data?"
  },
  {
    "objectID": "ae/ae-08-logistic-review.html#exercise-6",
    "href": "ae/ae-08-logistic-review.html#exercise-6",
    "title": "AE 08: Logistic regression review",
    "section": "Exercise 6",
    "text": "Exercise 6\nUse the model credit_fit that includes the main effects for income, rating, and region.\n\nConstruct the ROC curve and compute the area under the curve (AUC).\nBased on the AUC, do you think this model sufficiently identifies those who will max out their credit card vs. those who will not? Explain.\nSuppose a credit card company uses your model to inform the credit limit to give to new customers. Do you think they would prioritize sensitivity, specificity, or regard both equally? Briefly explain.\nBased on your response to part(c), select a threshold for classifying observations into those likely to max out the credit card and those who are not. What is your threshold in terms of probability? What is the sensitivity? What is the specificity?\n\n\n\n\n\n\n\nSubmission\n\n\n\nTo submit the AE:\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your AE repo on GitHub. You’re done! 🎉"
  },
  {
    "objectID": "prepare/prepare-lec02.html",
    "href": "prepare/prepare-lec02.html",
    "title": "Prepare for Lecture 02: Simple linear regression",
    "section": "",
    "text": "📖 Read Simple linear regression, Section 4.1 - 4.6\n📖 Read R for Data Science, Introduction: What you will learn\n📖 Read GitHub for supporting, reusing, contributing, and failing safely\nFor computing introduction / review\n🎥 Watch Meet the Toolkit: R + RStudio\n🎥 Watch Meet the Toolkit: Quarto"
  },
  {
    "objectID": "prepare/prepare-lec04.html",
    "href": "prepare/prepare-lec04.html",
    "title": "Prepare for Lecture 04: SLR - Matrix representation",
    "section": "",
    "text": "Review linear algebra concepts (as needed)\n\nMatrices and vectors: [slides][video]\nMatrix-Vector products: [slides][video]\nMatrix multiplication: [slides][video]\n\n\n\n\n\n\n\nNote\n\n\n\nAll linear algebra review materials from Math 218: Matrices and Vectors (Summer 2024) taught by Dr. Brian Fitzpatrick at Duke University"
  },
  {
    "objectID": "prepare/prepare-lec08.html",
    "href": "prepare/prepare-lec08.html",
    "title": "Prepare for Lecture 08: Inference for regression",
    "section": "",
    "text": "📖 Read Inference for Simple Linear Regression:\n\nSections 5.1 - 5.3\nSection 5.6\nSection 5.8\nSection 5.9"
  },
  {
    "objectID": "exam-01-practice.html",
    "href": "exam-01-practice.html",
    "title": "Exam 01 practice",
    "section": "",
    "text": "Important\n\n\n\nThis page contains practice problems to help prepare for Exam 01. This set of practice problems is not comprehensive. You should review these study tips as you prepare for the exam.\n\nThere is no answer key for these problems. You may ask questions in office hours and on Ed Discussion.",
    "crumbs": [
      "Exam 01 Practice"
    ]
  },
  {
    "objectID": "exam-01-practice.html#exercise-1",
    "href": "exam-01-practice.html#exercise-1",
    "title": "Exam 01 practice",
    "section": "Exercise 1",
    "text": "Exercise 1\nWe will use data from nrow(penguins) penguins at Palmer Station in Antartica to fit linear regression model model using species (Adelie, Chinstrap, or Gentoo), flipper length (in millimeters), and bill depth (in millimeters) to predict its body mass (in grams). Click here to read more about the variables.\nThe linear regression model has the form\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n\\]Write the dimensions of \\(\\mathbf{y}, \\mathbf{X},\\boldsymbol{\\beta}, \\boldsymbol{\\epsilon}\\) specifically for this analysis.",
    "crumbs": [
      "Exam 01 Practice"
    ]
  },
  {
    "objectID": "exam-01-practice.html#exercise-2",
    "href": "exam-01-practice.html#exercise-2",
    "title": "Exam 01 practice",
    "section": "Exercise 2",
    "text": "Exercise 2\nThe output for the model described in Exercise 1, along with 95% confidence intervals for the model coefficients, is shown below:\n\npenguins_fit &lt;- lm(body_mass_g ~ species + flipper_length_mm + \n                     bill_depth_mm + body_mass_g, \n                   data = penguins)\n\nWarning in model.matrix.default(mt, mf, contrasts): the response appeared on\nthe right-hand side and was dropped\n\n\nWarning in model.matrix.default(mt, mf, contrasts): problem with term 4 in\nmodel.matrix: no columns are assigned\n\ntidy(penguins_fit,conf.int = TRUE) |&gt;\n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-4526.887\n516.931\n-8.757\n0.000\n-5543.705\n-3510.068\n\n\nspeciesChinstrap\n-131.968\n51.400\n-2.567\n0.011\n-233.073\n-30.863\n\n\nspeciesGentoo\n1288.968\n132.774\n9.708\n0.000\n1027.798\n1550.138\n\n\nflipper_length_mm\n25.700\n3.098\n8.295\n0.000\n19.606\n31.794\n\n\nbill_depth_mm\n182.364\n18.358\n9.934\n0.000\n146.252\n218.475\n\n\n\n\n\n\nInterpret the coefficient of flipper_length_mm in the context of the data.\nWhat is the baseline category for speices?\nInterpret the coefficient of speciesChinstrap in the context of the data.",
    "crumbs": [
      "Exam 01 Practice"
    ]
  },
  {
    "objectID": "exam-01-practice.html#exercise-3",
    "href": "exam-01-practice.html#exercise-3",
    "title": "Exam 01 practice",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nDoes the intercept have a meaningful interpretation?\nIf not, what are some strategies we can use to fit a model such that the intercept is meaningful?",
    "crumbs": [
      "Exam 01 Practice"
    ]
  },
  {
    "objectID": "exam-01-practice.html#exercise-4",
    "href": "exam-01-practice.html#exercise-4",
    "title": "Exam 01 practice",
    "section": "Exercise 4",
    "text": "Exercise 4\nThere are three species in the data set (Adelie, Chinstrap, Gentoo), but only two terms for species in the model. Use the design matrix to show why we cannot put indicators for all three species and the intercept in the model.",
    "crumbs": [
      "Exam 01 Practice"
    ]
  },
  {
    "objectID": "exam-01-practice.html#exercise-5",
    "href": "exam-01-practice.html#exercise-5",
    "title": "Exam 01 practice",
    "section": "Exercise 5",
    "text": "Exercise 5\nWe conduct the following hypothesis test for the coefficient of flipper_length_mm.\n\nNull: There is no linear relationship between flipper length and body mass, after accounting for species and bill depth\nAlternative: There is a linear relationship between flipper length and body mass, after accounting for species and bill depth\n\n\nWrite these hypotheses in mathematical notation.\nThe standard error is 3.098. Explain how this value is computed and what this value means in the context of the data.\nThe test statistic is 8.295. Explain how this value is computed and what this value means in the context of the data.\nWhat distribution is used to compute the p-value?\nWhat is the conclusion from the test in the context of the data?",
    "crumbs": [
      "Exam 01 Practice"
    ]
  },
  {
    "objectID": "exam-01-practice.html#exercise-6",
    "href": "exam-01-practice.html#exercise-6",
    "title": "Exam 01 practice",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nInterpret the 95% confidence interval for flipper_length_mm in the context of the data.\nIs the interval consistent with the test from the previous exercise? Briefly explain.",
    "crumbs": [
      "Exam 01 Practice"
    ]
  },
  {
    "objectID": "exam-01-practice.html#exercise-7",
    "href": "exam-01-practice.html#exercise-7",
    "title": "Exam 01 practice",
    "section": "Exercise 7",
    "text": "Exercise 7\nSketch a scatterplot of the relationship between bill depth and body mass such that the effect of bill depth differs by species.",
    "crumbs": [
      "Exam 01 Practice"
    ]
  },
  {
    "objectID": "exam-01-practice.html#exercise-8",
    "href": "exam-01-practice.html#exercise-8",
    "title": "Exam 01 practice",
    "section": "Exercise 8",
    "text": "Exercise 8\nWhen we conduct inference for regression, we assume the following distribution for \\(\\mathbf{y}|\\mathbf{X}\\)\n\\[\n\\mathbf{y}|\\mathbf{X} \\sim(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma^2_\\epsilon\\mathbf{I})\n\\]\n\nShow that \\(E(\\mathbf{y}|\\mathbf{X}) = \\mathbf{X}\\boldsymbol{\\beta}\\)\nShow that \\(Var(\\mathbf{y}|\\mathbf{X})= \\sigma^2_{\\epsilon}\\mathbf{I}\\)\n\nSee February 4 lecture “Inference for Regression” to check your work.",
    "crumbs": [
      "Exam 01 Practice"
    ]
  },
  {
    "objectID": "exam-01-practice.html#exercise-9",
    "href": "exam-01-practice.html#exercise-9",
    "title": "Exam 01 practice",
    "section": "Exercise 9",
    "text": "Exercise 9\nWe conduct inference on the coefficients \\(\\boldsymbol{\\beta}\\) assuming that the variability of \\(\\mathbf{y}|\\mathbf{X}\\) is constant for value (or combination) of predictors. Briefly explain why is assumption is important.",
    "crumbs": [
      "Exam 01 Practice"
    ]
  },
  {
    "objectID": "exam-01-practice.html#exercise-10",
    "href": "exam-01-practice.html#exercise-10",
    "title": "Exam 01 practice",
    "section": "Exercise 10",
    "text": "Exercise 10\nGiven the model \\(\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\\), derive the least-squares estimator \\(\\hat{\\boldsymbol{\\beta}}\\) using matrix calculus.\nSee January 21 lecture “SLR: Matrix representation” to check your work.",
    "crumbs": [
      "Exam 01 Practice"
    ]
  },
  {
    "objectID": "exam-01-practice.html#exercise-11",
    "href": "exam-01-practice.html#exercise-11",
    "title": "Exam 01 practice",
    "section": "Exercise 11",
    "text": "Exercise 11\nGiven the model \\(\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\\), derive the least-squares estimator \\(\\hat{\\boldsymbol{\\beta}}\\) using the geometric interpretation of the model.\nSee January 23 lecture “Geometric interpretation of least-squares regression” to check your work.",
    "crumbs": [
      "Exam 01 Practice"
    ]
  },
  {
    "objectID": "exam-01-practice.html#exercise-12",
    "href": "exam-01-practice.html#exercise-12",
    "title": "Exam 01 practice",
    "section": "Exercise 12",
    "text": "Exercise 12\nExplain why we say “holding all else constant” when interpreting the coefficients in a multiple linear regression model.",
    "crumbs": [
      "Exam 01 Practice"
    ]
  },
  {
    "objectID": "exam-01-practice.html#exercise-13",
    "href": "exam-01-practice.html#exercise-13",
    "title": "Exam 01 practice",
    "section": "Exercise 13",
    "text": "Exercise 13\nSuppose we have two models:\n\nModel 1 includes predictors \\(X_1\\) and \\(X_2\\)\nModel 2 includes predictors \\(X_1, X_2, X_3\\) and \\(X_4\\)\n\nExplain why we should use \\(Adj. R^2\\) and not \\(R^2\\) to compare these models.",
    "crumbs": [
      "Exam 01 Practice"
    ]
  },
  {
    "objectID": "exam-01-practice.html#exercise-14",
    "href": "exam-01-practice.html#exercise-14",
    "title": "Exam 01 practice",
    "section": "Exercise 14",
    "text": "Exercise 14\nRework Exercises 1 - 5 in HW 01 for more practice with theory and math.",
    "crumbs": [
      "Exam 01 Practice"
    ]
  },
  {
    "objectID": "exam-01-practice.html#exercise-15",
    "href": "exam-01-practice.html#exercise-15",
    "title": "Exam 01 practice",
    "section": "Exercise 15",
    "text": "Exercise 15\nRework Exercises 1 - 5 in HW 02 for more practice with theory and math.",
    "crumbs": [
      "Exam 01 Practice"
    ]
  },
  {
    "objectID": "exam-01-practice.html#relevant-lectures-assignments-and-aes",
    "href": "exam-01-practice.html#relevant-lectures-assignments-and-aes",
    "title": "Exam 01 practice",
    "section": "Relevant lectures, assignments and AEs",
    "text": "Relevant lectures, assignments and AEs\nAsk yourself “why” questions as you the slides, review your answers, process, and derivations on these assignments. It may also be helpful to explain your process to others.\n\nLectures: January 9 - February 13 (February 13 lecture is an exam review)\nHW 01 - 02\nLab 01 - 04 (Lab 04 is an exam review)\nAE 01 - 04 (AE 04 is an exam review)",
    "crumbs": [
      "Exam 01 Practice"
    ]
  },
  {
    "objectID": "hw/hw-02.html",
    "href": "hw/hw-02.html",
    "title": "HW 02: Multiple linear regression",
    "section": "",
    "text": "Due date\n\n\n\nThis assignment is due on Thursday, February 13 at 11:59pm.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#instructions",
    "href": "hw/hw-02.html#instructions",
    "title": "HW 02: Multiple linear regression",
    "section": "Instructions",
    "text": "Instructions\nThe conceptual exercises are focused on explaining concepts and showing results mathematically. Show your work for each question.\n\nYou may write the answers and associated work for conceptual exercises by hand or type them in your Quarto document.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-1",
    "href": "hw/hw-02.html#exercise-1",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nIn lecture, we defined the hat matrix \\(\\mathbf{H}\\) as a projection matrix that projects \\(\\mathbf{y}\\) onto \\(\\text{Col}(\\mathbf{X})\\) and discussed the properties of a projection matrix. You have previously shown that \\(\\mathbf{H}\\) is symmetric and \\(\\mathbf{H}\\) is idempotent. Now we will focus on two other properties.\n\nShow that for any vector \\(\\mathbf{v}\\) in \\(\\text{Col}(\\mathbf{X})\\), \\(\\mathbf{Hv} = \\mathbf{v}\\).\nShow that for any vector \\(\\mathbf{v}\\) orthogonal to \\(\\text{Col}(\\mathbf{X})\\), \\(\\mathbf{Hv} = \\mathbf{0}\\).",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-2",
    "href": "hw/hw-02.html#exercise-2",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nShow that the following is true for the residuals from a linear regression model: \\(\\mathbf{e} = (\\mathbf{I} - \\mathbf{H})\\boldsymbol{\\epsilon}\\)\nFind the \\(E(\\mathbf{e})\\) , the expected value of the residuals.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-3",
    "href": "hw/hw-02.html#exercise-3",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nLet \\(\\hat{\\boldsymbol{\\beta}}\\) be the least-squares estimator for a linear regression model. Show that\\(Var(\\hat{\\boldsymbol{\\beta}}) = \\sigma^2_{\\epsilon}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\) .",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-4",
    "href": "hw/hw-02.html#exercise-4",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nSuppose we fit the model \\(\\mathbf{y} = \\mathbf{X}_1\\boldsymbol{\\beta}_1 + \\boldsymbol{\\epsilon}\\) when the true model is actually given by \\(\\mathbf{y} = \\mathbf{X}_1\\boldsymbol{\\beta}_1 + \\mathbf{X}_2\\boldsymbol{\\beta}_2 + \\boldsymbol{\\epsilon}\\). Assume \\(E(\\boldsymbol{\\epsilon}) = \\mathbf{0}\\) for both models.\n\nFind \\(E(\\hat{\\boldsymbol{\\beta}}_1)\\), the expected value of the least-squares estimate \\(\\hat{\\boldsymbol{\\beta}}_1\\).\nUnder what condition does \\(E(\\hat{\\boldsymbol{\\beta}}_1) = \\boldsymbol{\\beta}_1\\) ? What is the relationship between \\(\\mathbf{X}_1\\) and \\(\\mathbf{X}_2\\) under this condition?",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-5",
    "href": "hw/hw-02.html#exercise-5",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nWe conduct least-squares regression analysis with certain assumptions underlying the regression model. Consider the linear regression model:\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}, \\quad \\boldsymbol{\\epsilon} \\sim N(\\mathbf{0}, \\sigma^2_{\\epsilon}\\mathbf{I})\n\\tag{1}\\]\nThis model relies on four assumptions:\n\nLinearity: There is a linear relationship between the response and predictor variables.\nConstant Variance: The variability about the least squares line is constant for every value of the predictor.\nNormality: The distribution of the residuals is approximately normal.\nIndependence: The residuals are independent from one another.\n\nFor each condition, state the components of Equation 1 that are used to represent it.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#instructions-1",
    "href": "hw/hw-02.html#instructions-1",
    "title": "HW 02: Multiple linear regression",
    "section": "Instructions",
    "text": "Instructions\nThe applied exercises are focused on applying the concepts to analyze data.\nAll work for the applied exercises must be typed in your Quarto document following a reproducible workflow.\nWrite all narrative using complete sentences and include informative axis labels / titles on visualizations.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#data-lego-sets",
    "href": "hw/hw-02.html#data-lego-sets",
    "title": "HW 02: Multiple linear regression",
    "section": "Data: LEGO® sets",
    "text": "Data: LEGO® sets\nThe data set includes information about LEGO® sets from themes produced January 1, 2018 and September 11, 2020. The data were originally scraped from Brickset.com, an online LEGO set guide and were obtained for this assignment from Peterson and Ziegler (2021).\nYou will work with data on 391 randomly selected LEGO® sets produced during this time period. The primary variables are interest in this analysis are\n\nPieces: Number of pieces in the set from brickset.com.\nMinifigures: Number of minifigures (LEGO® people) in the set scraped from brickset.com.\nAmazon_Price: Price of the set on Amazon.com (in U.S. dollars)\nSize: General size of the interlocking bricks (Large = LEGO Duplo® sets - which include large brick pieces safe for children ages 1 to 5, Small = LEGO® sets which- include the traditional smaller brick pieces created for age groups 5 and - older, e.g., City, Friends)\n\nThe data are contained in lego-sample.csv.\n\nlegos &lt;- read_csv(\"data/lego-sample.csv\")\n\n\n\n\n\n\n\nAnalysis goal\n\n\n\nWe want to fit a multiple linear regression model to predict the price of LEGO® sets on Amazon.com based on Pieces, Size, and Minifigures.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-6",
    "href": "hw/hw-02.html#exercise-6",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nInstead of using the number of minifigures in the model, you decide to create an indicator variable for whether or not there are any minifigures in the set.\nCreate an indicator variable that takes the value “No” if there are zero minifigures in the LEGO® set, and “Yes” if there is at least one minifigure.\nFit the regression model using the number of pieces, size of the blocks, and the indicator for minifigures to predict the price on Amazon. Neatly display the results, including the 95% confidence interval for the coefficients, using three digits.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-7",
    "href": "hw/hw-02.html#exercise-7",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 7",
    "text": "Exercise 7\nWe want to understand the relationship between Pieces and Amazon_Price in the model from the previous exercise.\nYou are convinced from the model output that there is evidence of a linear relationship between the two variables. Now you want to be more specific and test whether the slope is actually different from 0.1 ($10 increase in the price for every 100 additional pieces).\n\nWrite the null and alternative hypotheses for this test in using words and mathematical notation.\nCalculate the test statistic for this test. Show the code used to calculate the test statistic; you may use any relevant output from the model in the previous exercise.\nWhat is the distribution of the test statistic under the null hypothesis for this problem?\nCalculate the p-value and state your conclusion in the context of the data using a threshold of \\(\\alpha = 0.05\\).",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-8",
    "href": "hw/hw-02.html#exercise-8",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 8",
    "text": "Exercise 8\n\nInterpret the 95% confidence interval for the effect of pieces in the context of the data.\nIs the confidence interval consistent with your conclusion from the hypothesis test in the previous exercise? Briefly explain.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-9",
    "href": "hw/hw-02.html#exercise-9",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 9",
    "text": "Exercise 9\n\nYou hypothesize that the relationship between the price and number of pieces may differ based on whether or not there are minifigures in the set.\nMake a plot to visualize this potential effect. Does the relationship between price and number of pieces seem to differ based on the inclusion of minifigures? Briefly explain.\nFit a model using the number of pieces, size of the blocks, and presence of minifigures to predict the price on Amazon.com. Fit the model such that the intercept has a meaningful interpretation and that the effect of pieces may differ based on the presence of minifigures.\nInterpret the intercept in the context of the data.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-10",
    "href": "hw/hw-02.html#exercise-10",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 10",
    "text": "Exercise 10\nWhich model is a better fit for the data - The model in Exercise 6 or the model in Exercise 9? Briefly explain your choice using \\(R^2\\) and/or \\(Adj. R^2\\).",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#submission",
    "href": "hw/hw-02.html#submission",
    "title": "HW 02: Multiple linear regression",
    "section": "Submission",
    "text": "Submission\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nRemember – you must turn in a PDF file to the Gradescope page before the submission deadline for full credit.\nIf you write your responses to conceptual exercises by hand, you will need to combine your written work to the completed PDF for the applied exercises before submitting on Gradescope.\nInstructions to combine PDFs:\n\nPreview (Mac): support.apple.com/guide/preview/combine-pdfs-prvw43696/mac\nAdobe (Mac or PC): helpx.adobe.com/acrobat/using/merging-files-single-pdf.html\n\nGet free access to Adobe Acrobat as a Duke student: oit.duke.edu/help/articles/kb0030141/\n\n\n\n\nTo submit your assignment:\n\nAccess Gradescope through the menu on the STA 221 Canvas site.\nClick on the assignment, and you’ll be prompted to submit it.\nMark the pages associated with each exercise. All of the pages of your lab should be associated with at least one question (i.e., should be “checked”).\nSelect the first page of your .PDF submission to be associated with the “Workflow & formatting” section.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#footnotes",
    "href": "hw/hw-02.html#footnotes",
    "title": "HW 02: Multiple linear regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nExercise 4 is adapted from Montgomery, Peck, and Vining (2021) .↩︎",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-01.html",
    "href": "hw/hw-01.html",
    "title": "HW 01: Simple linear regression",
    "section": "",
    "text": "Due date\n\n\n\nThis assignment is due on Thursday, January 30 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#instructions",
    "href": "hw/hw-01.html#instructions",
    "title": "HW 01: Simple linear regression",
    "section": "Instructions",
    "text": "Instructions\nThe conceptual exercises are focused on explaining concepts and showing results mathematically. Show your work for each question.\n\nYou may write the answers and associated work for conceptual exercises by hand or type them in your Quarto document.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-1",
    "href": "hw/hw-01.html#exercise-1",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 1",
    "text": "Exercise 1\na. Show that the hat matrix \\(\\mathbf{H}\\) is symmetric \\((\\mathbf{H}^\\mathsf{T} = \\mathbf{H})\\) and idempotent \\((\\mathbf{H}^2 = \\mathbf{H})\\).\nb. Show that \\((\\mathbf{I} - \\mathbf{H})\\) is symmetric and idempotent.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-2",
    "href": "hw/hw-01.html#exercise-2",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nLet \\(\\mathbf{x}\\) be a \\(k \\times 1\\) vector and \\(\\mathbf{A}\\) be a symmetric \\(k \\times k\\) matrix, such that \\(\\mathbf{A}\\) is not a function of \\(\\mathbf{x}\\).\nShow that the gradient of \\(\\boldsymbol{x}^\\mathsf{T}\\mathbf{A}\\mathbf{x}\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x} \\hspace{1mm} \\mathbf{x}^\\mathsf{T}\\mathbf{A}\\mathbf{x} = 2\\mathbf{A}\\mathbf{x}\n\\]\n(Property 2 from class)",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-3",
    "href": "hw/hw-01.html#exercise-3",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nIn class we used the sum of squared errors, \\(\\boldsymbol{\\epsilon}^\\mathsf{T}\\boldsymbol{\\epsilon}\\) , to estimate the regression coefficients, \\(\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}\\mathbf{Y}\\) . To show this is the least squares estimate, we now need to show that we have, in fact, found the estimate of \\(\\boldsymbol{\\beta}\\) that minimizes the sum of\nIf the Hessian matrix \\(\\nabla_{\\boldsymbol{\\beta}}^2 \\boldsymbol{\\epsilon}^\\mathsf{T}\\boldsymbol{\\epsilon}\\) is positive definite, then we know we have found the \\(\\hat{\\boldsymbol{\\beta}}\\) that minimizes the sum of squared errors, i.e., the least squares estimator.\nShow that \\(\\nabla_{\\boldsymbol{\\beta}}^2 \\boldsymbol{\\epsilon}^\\mathsf{T}\\boldsymbol{\\epsilon} \\propto \\mathbf{X}^\\mathsf{T}\\mathbf{X}\\) is positive definite.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-4",
    "href": "hw/hw-01.html#exercise-4",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nProve that the maximum value of \\(R^2\\) must be less than 1 if the data set contains observations such that there are different observed values of the response for the same value of the predictor (e.g., the data set contains observations \\((x_i, y_i)\\) and \\((x_j, y_j)\\) such that \\(x_i = x_j\\) and \\(y_i \\neq y_j\\) ).",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-5",
    "href": "hw/hw-01.html#exercise-5",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nShow that the sum of squared residuals (SSR) can be written as the following:\n\\[\n\\mathbf{y}^\\mathsf{T}\\mathbf{y} - \\hat{\\boldsymbol{\\beta}}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{y}\n\\]",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#instructions-1",
    "href": "hw/hw-01.html#instructions-1",
    "title": "HW 01: Simple linear regression",
    "section": "Instructions",
    "text": "Instructions\nThe applied exercises are focused on applying the concepts to analyze data.\nAll work for the applied exercises must be typed in your Quarto document following a reproducible workflow.\nWrite all narrative using complete sentences and include informative axis labels / titles on visualizations.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#data",
    "href": "hw/hw-01.html#data",
    "title": "HW 01: Simple linear regression",
    "section": "Data",
    "text": "Data\nThe datasets wi-icecover.csv and wi-air-temperature.csv contain information about ice cover and air temperature, respectively, at Lake Monona and Lake Mendota (both in Madison, Wisconsin) for days in 1886 through 2019. The data were obtained from the ntl_icecover and ntl_airtemp data frames in the lterdatasampler R package. They were originally collected by the US Long Term Ecological Research program (LTER) Network.\n\nicecover &lt;- read_csv(\"data/wi-icecover.csv\")\nairtemp &lt;- read_csv(\"data/wi-air-temperature.csv\")\n\nThe analysis will focus on the following variables:\n\nyear: year of observation\nlakeid: lake name\nice_duration: number of days between the freeze and ice breakup dates of each lake\nair_temp_avg: yearly average air temperature in Madison, WI (degrees Celsius)",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#analysis-goal",
    "href": "hw/hw-01.html#analysis-goal",
    "title": "HW 01: Simple linear regression",
    "section": "Analysis goal",
    "text": "Analysis goal\nThe goal of this analysis is to use linear regression explain variability in ice duration for lakes in Madison, WI based on air temperature. Because ice cover is impacted by various environmental factors, researchers are interested in examining the association between these two factors to better understand the changing climate.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-6",
    "href": "hw/hw-01.html#exercise-6",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nLet’s start by looking at the response variable ice_duration.\n\nVisualize the distribution of ice duration versus year with separate lines for each lake.\nThere are separate yearly measurements for each lake in the icecover data frame. In this analysis, we will combine the data from both lakes and use the average ice duration each year.\nComment on the analysis choice to use the average per year rather than the individual lake measurements. Some things to consider in your comments: Does the average accurately reflects the ice duration for these lakes in a given year year? Will there be information lost? How might that impact (or not) the analysis conclusions? Etc.\n\n\n\n\n\n\n\nTip\n\n\n\nSee the ggplot2 reference for example code and plots.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-7",
    "href": "hw/hw-01.html#exercise-7",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 7",
    "text": "Exercise 7\nNext, let’s combine the ice duration and air temperature data into a single analysis data frame.\n\nFill in the code below to create a new data frame, icecover_avg, of the average ice duration by year.\nThen join icecover_avg and airtemp to create a new data frame. The new data frame should have 134 observations.\n\nicecover_avg &lt;- icecover |&gt;\n  group_by(_____) |&gt;\n  summarise(_____) |&gt;\n  ungroup()\n\n\n\n\n\n\n\n\nImportant\n\n\n\nYou will use the new data frame with average ice duration and average air temperature for the remainder of the assignment.\n\n\n\nVisualize the relationship between the air temperature and average ice duration. Do you think a linear model is a reasonable choice to model the relationship between the two variables? Briefly explain.\n\n\nNow is a good time to render your document again if you haven’t done so recently and commit (with a meaningful commit message) and push all updates.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-8",
    "href": "hw/hw-01.html#exercise-8",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 8",
    "text": "Exercise 8\nWe will fit a model using the average air temperature to explain variability in ice duration. The model takes the form\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n\\]\n\nState the dimensions of \\(\\mathbf{y}\\), \\(\\mathbf{X}\\), \\(\\boldsymbol{\\beta}\\), \\(\\boldsymbol{\\epsilon}\\) for this analysis. Your answer should have exact values given this data set.\nEstimate the regression coefficients \\(\\hat{\\boldsymbol{\\beta}}\\) in R using the matrix representation. Show the code used to get the answer.\nCheck your results from part (b) by using the lm function to fit the model. Neatly display your results using 3 digits.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-9",
    "href": "hw/hw-01.html#exercise-9",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 9",
    "text": "Exercise 9\n\nCalculate \\(R^2\\) for the model in the previous exercise and interpret it in the context of the data.\nCalculate \\(RMSE\\) for the model from the previous exercise and interpret it in the context of the data.\nComment on the model fit based on \\(R^2\\) and \\(RMSE\\).",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-10",
    "href": "hw/hw-01.html#exercise-10",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 10",
    "text": "Exercise 10\na. Interpret the slope in the context of the data.\nb. The average air temperature in 2019, the most recent year in the data set, was 7.925 degrees Celsius. What was the predicted ice duration for 2019? What is the residual?",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#footnotes",
    "href": "hw/hw-01.html#footnotes",
    "title": "HW 01: Simple linear regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nExercise 4 is adapted from Montgomery, Peck, and Vining (2021) .↩︎",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "overview.html",
    "href": "overview.html",
    "title": "STA 221 - Regression Analysis: Theory and Applications",
    "section": "",
    "text": "In STA 221, students will learn how linear and logistic regression models are used to explore multivariable relationships, apply these methods to answer relevant and engaging questions using a data-driven approach, and learn the mathematical underpinnings of the models. Students will develop computing skills to implement a reproducible data analysis workflow and gain experience communicating statistical results. Throughout the semester, students will work on a team project where they will develop a research question, answer it using methods learned in the course, and share results through a written report and presentation.\nTopics include applications of linear and logistic regression, analysis of variance, model diagnostics, and model selection. Regression parameter estimation via maximum likelihood least squares will also be discussed. Students will gain experience using the computing tools R and GitHub to analyze real-world data from a variety of fields.\n\n\nEither any STA 100-level course or STA 230, 231, or 240L and MATH 216, 218, or 221. The recommended co-requisite is STA 230, 231, or 240L. Interested students with different backgrounds should seek instructor consent.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "overview.html#pre-requisites",
    "href": "overview.html#pre-requisites",
    "title": "STA 221 - Regression Analysis: Theory and Applications",
    "section": "",
    "text": "Either any STA 100-level course or STA 230, 231, or 240L and MATH 216, 218, or 221. The recommended co-requisite is STA 230, 231, or 240L. Interested students with different backgrounds should seek instructor consent.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "overview.html#teaching-assistants",
    "href": "overview.html#teaching-assistants",
    "title": "STA 221 - Regression Analysis: Theory and Applications",
    "section": "Teaching assistants",
    "text": "Teaching assistants\n\n\n\n\n\n\n\nName\nRole\n\n\nKat Husar\nHead TA\nLab 01L leader\n\n\nKelly Huang\nClassroom TA\n\n\nJanice Kim\nClassroom TA\n\n\nCathy Lee\nLab 02L leader\n\n\nAlan Wang\nLab 01L helper\n\n\n\nOffice hours times and locations on Canvas.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "labs/lab-07.html",
    "href": "labs/lab-07.html",
    "title": "Lab 07: Logistic Regression",
    "section": "",
    "text": "Due date\n\n\n\nThis lab is due on Tuesday, April 8 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your team’s GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 07"
    ]
  },
  {
    "objectID": "labs/lab-07.html#exercise-1",
    "href": "labs/lab-07.html#exercise-1",
    "title": "Lab 07: Logistic Regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nWe’ll begin by exploring the data. Create a scatterplot of Area versus Eccentricity with the color and shape of the points by Class.",
    "crumbs": [
      "Labs",
      "Lab 07"
    ]
  },
  {
    "objectID": "labs/lab-07.html#exercise-2",
    "href": "labs/lab-07.html#exercise-2",
    "title": "Lab 07: Logistic Regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nBased on the plot from the previous exercise, do you think the two types of rice can be distinguished based on Area and Eccentricity. Briefly explain.",
    "crumbs": [
      "Labs",
      "Lab 07"
    ]
  },
  {
    "objectID": "labs/lab-07.html#exercise-3",
    "href": "labs/lab-07.html#exercise-3",
    "title": "Lab 07: Logistic Regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nWith this type of classification problem, it is common to test the performance of a logistic regression model by splitting the data into a training and a test set. This means that we will choose a random subset of the data to estimate the regression coefficient (training), and we will then test the predictions on the remaining observations (test).\n\nRandomly select 75% of the rows of the data to create the training set rice_train . Use set.seed(221).\nPut the remaining 25% of the observations in the testing set called rice_test.",
    "crumbs": [
      "Labs",
      "Lab 07"
    ]
  },
  {
    "objectID": "labs/lab-07.html#exercise-4",
    "href": "labs/lab-07.html#exercise-4",
    "title": "Lab 07: Logistic Regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nIn a logistic regression model, the log-odds of the response being “1” (or a “success”) is given by \\[\\log\\Big(\\frac{\\pi_i}{1-\\pi_i}\\Big) = \\mathbf{x}_i^\\mathsf{T} \\boldsymbol{\\beta}\\]\nIn this analysis a “success” is the Class “Osmancik”.\n\nWhat does each \\(\\pi_i\\) represent in the context of this analysis?\nHow is the probability of the response variable being “1” calculated from the log-odds? Show the mathematical steps to go from the log-odds to the probability in your response.",
    "crumbs": [
      "Labs",
      "Lab 07"
    ]
  },
  {
    "objectID": "labs/lab-07.html#exercise-5",
    "href": "labs/lab-07.html#exercise-5",
    "title": "Lab 07: Logistic Regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nUse rice_train to fit the logistic regression model for the response variable Class on the predictors Area and Eccentricity .\n\nNeatly display the output using 3 digits.\nDoes the intercept have any reasonable interpretation? If so, interpret the intercept. Otherwise explain why not.",
    "crumbs": [
      "Labs",
      "Lab 07"
    ]
  },
  {
    "objectID": "labs/lab-07.html#exercise-6",
    "href": "labs/lab-07.html#exercise-6",
    "title": "Lab 07: Logistic Regression",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nInterpret the coefficients on Area and Eccentricity in the context of the data in terms of the odds and comment on whether they are useful predictors of Class in the model.",
    "crumbs": [
      "Labs",
      "Lab 07"
    ]
  },
  {
    "objectID": "labs/lab-07.html#exercise-7",
    "href": "labs/lab-07.html#exercise-7",
    "title": "Lab 07: Logistic Regression",
    "section": "Exercise 7",
    "text": "Exercise 7\n\nHow would you expect the log-odds of the rice grain being of the Osmancik variety to change if the measures eccentricity changes from 0.85 to 0.9?\nHow would you expect the odds of the rice grain being of the Osmancik variety to change if the measures eccentricity changes from 0.85 to 0.9?",
    "crumbs": [
      "Labs",
      "Lab 07"
    ]
  },
  {
    "objectID": "labs/lab-07.html#exercise-8",
    "href": "labs/lab-07.html#exercise-8",
    "title": "Lab 07: Logistic Regression",
    "section": "Exercise 8",
    "text": "Exercise 8\nNow let’s test our model on the test set. Use the predict() function to obtain the predicted probabilities of the rice being Osmancik for the observations in rice_test.",
    "crumbs": [
      "Labs",
      "Lab 07"
    ]
  },
  {
    "objectID": "labs/lab-07.html#exercise-9",
    "href": "labs/lab-07.html#exercise-9",
    "title": "Lab 07: Logistic Regression",
    "section": "Exercise 9",
    "text": "Exercise 9\nWith these estimated probabilities, we can now try to classify the rice in the test set. Choose a threshold for assigning a class to each observation based on the estimated probability. Briefly explain your reasoning for selecting the threshold, including any analysis used to make your decision.",
    "crumbs": [
      "Labs",
      "Lab 07"
    ]
  },
  {
    "objectID": "labs/lab-07.html#exercise-10",
    "href": "labs/lab-07.html#exercise-10",
    "title": "Lab 07: Logistic Regression",
    "section": "Exercise 10",
    "text": "Exercise 10\nCompare the estimated class assignments you constructed with the actual classes. Comment on the result and thus the model performance.",
    "crumbs": [
      "Labs",
      "Lab 07"
    ]
  },
  {
    "objectID": "labs/lab-04.html",
    "href": "labs/lab-04.html",
    "title": "Lab 04: Exam 01 Review",
    "section": "",
    "text": "Important\n\n\n\nThis lab will be based on attendance and participation in lab on February 14.\nPush your work to GitHub. You do not need to submit anything on Gradescope.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exploratory-data-analysis",
    "href": "labs/lab-04.html#exploratory-data-analysis",
    "title": "Lab 04: Exam 01 Review",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\np1 &lt;- ggplot(data = tips, aes(x = Tip)) + \n  geom_histogram(color = \"white\", binwidth = 2) +\n  labs(x = \"Tips ($)\",\n       title = \"Tips at local restaurant\")\n\np2 &lt;- ggplot(data = tips, aes(x = Party)) + \n  geom_histogram(color = \"white\") +\n  labs(x = \"Party\",\n       title = \"Number of diners in party\") +\n  xlim(c(0, 7))\n\np3 &lt;- ggplot(data = tips, aes(x = Age)) + \n  geom_bar(color = \"white\") +\n  labs(x = \"\",\n       title = \"Age of Payer\") \n\np1 / (p2 + p3)\n\n\n\n\n\n\n\n\n\np4 &lt;- ggplot(data = tips, aes(x = Party, y = Tip)) + \n  geom_jitter() + \n  labs(x = \"Number of diners in party\", \n       y = \"Tips ($)\",\n       title = \"Tips vs. Party\")\n\np5 &lt;- ggplot(data = tips, aes(x = Age, y = Tip)) + \n  geom_boxplot() + \n  labs(x = \"Age of payer\", \n       y = \"Tips ($)\",\n       title = \"Tips vs. Age\")\n\np4 + p5\n\n\n\n\n\n\n\n\nWe will use the number of diners in the party and age of the payer to understand variability in the tips.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-1",
    "href": "labs/lab-04.html#exercise-1",
    "title": "Lab 04: Exam 01 Review",
    "section": "Exercise 1",
    "text": "Exercise 1\nWe will start with the main effects model that includes Age and Party.\n\nHow many indicator variables for Age can we create from the data?\nHow many indicator variables for Age will be in the regression model?\nAre the responses to parts a and b equal? If not, explain why not.\nWhich of the following is true for this model? Select all that apply.\n\nThe intercepts are the same for every level of Age.\nThe intercepts differ by Age.\nThe effect of Party is the same for every level of Age.\nThe effect of Party differs by Age.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-2",
    "href": "labs/lab-04.html#exercise-2",
    "title": "Lab 04: Exam 01 Review",
    "section": "Exercise 2",
    "text": "Exercise 2\nConsider the main effects model that includes Age and Party.\n\nWhat is the dimension of the design matrix \\(\\mathbf{X}\\) for the main effects model?\nCalculate the coefficient estimates \\(\\hat{\\boldsymbol{\\beta}}\\) directly from the data.\nWrite the equation of the estimated regression model.\n\n\n# add code here",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-3",
    "href": "labs/lab-04.html#exercise-3",
    "title": "Lab 04: Exam 01 Review",
    "section": "Exercise 3",
    "text": "Exercise 3\nConsider the main effects model that includes Age and Party. Get \\(\\mathbf{y}\\) and \\(\\mathbf{X}\\) from the data.\n\nUse \\(\\mathbf{y}\\) and \\(\\mathbf{X}\\) to compute \\(\\hat{\\sigma}_{\\epsilon}\\) .\nInterpret \\(\\hat{\\sigma}_\\epsilon\\) in the context of the data.\nCompute \\(Var(\\hat{\\boldsymbol{\\beta}})\\).\nYou wish to test whether there is a linear relationship between tips and the number of diners in the party, after adjusting for the age of the payer. Compute the test statistic.\n\n\n# add code here",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-4",
    "href": "labs/lab-04.html#exercise-4",
    "title": "Lab 04: Exam 01 Review",
    "section": "Exercise 4",
    "text": "Exercise 4\nConsider the main effects model that includes Age and Party. Get \\(\\mathbf{y}\\) and \\(\\mathbf{X}\\) from the data.\n\nUse \\(\\mathbf{y}\\) and \\(\\mathbf{X}\\) to compute \\(R^2\\). Interpret this value in the context of the data.\nUse \\(\\mathbf{y}\\) and \\(\\mathbf{X}\\) to compute \\(RMSE\\). Interpret this value in the context of the data.\n\n\n# add code here",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-5",
    "href": "labs/lab-04.html#exercise-5",
    "title": "Lab 04: Exam 01 Review",
    "section": "Exercise 5",
    "text": "Exercise 5\nYou decide to add an interaction effect between Age and Party to the model and fit a model of the following form:\n\\[\nTip_i = \\beta_0 + \\beta_1Party_i + \\beta_2SenCit_i + \\beta_3Yadult_i + \\beta_4Party_i \\times SenCit_i + \\beta_5 Party_i \\times Yadult_i + \\epsilon_i\n\\]\n\nWhich of the following is true for this model? Select all that apply.\n\nThe intercepts are the same for every level of Age.\nThe intercepts differ by Age.\nThe effect of Party is the same for every level of Age.\nThe effect of Party differs by Age.\n\nBy how much does the intercept for tables with young adult payers differ from tables with middle age payers? Write the answer in terms of the \\(\\beta\\)’s.\nWrite the equation of the model for tables in which the payer is a senior citizen.\nSuppose you wish to test the hypotheses: \\(H_0: \\beta_5 = 0 \\text{ vs. }H_a: \\beta_5 \\neq 0\\) . State what is being tested in terms of the effect of Party.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-6",
    "href": "labs/lab-04.html#exercise-6",
    "title": "Lab 04: Exam 01 Review",
    "section": "Exercise 6",
    "text": "Exercise 6\nUse the lm() function to fit the model that includes Age and Party and the interaction between the two variables. Display the 90% confidence interval for the coefficients.\n\nThe standard error for AgeSenCit is 0.784. State what this value means in the context of the data.\nWrite code to show how the 90% confidence interval for AgeSenCit was computed.\nBased on the confidence interval, is there evidence that tables with senior citizen payers tip differently on average than tables with middle age payers?",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-7",
    "href": "labs/lab-04.html#exercise-7",
    "title": "Lab 04: Exam 01 Review",
    "section": "Exercise 7",
    "text": "Exercise 7\nThe following are general questions about regression. They are not specific to the tips data set.\n\nWhat does it mean for an estimator to be the “least-squares” estimator?\nConsider the derivation of the least-squares estimator:\n\\[\n\\begin{aligned}\n\\nabla_{\\beta}\\boldsymbol{\\epsilon}^\\mathsf{T}\\boldsymbol{\\epsilon} &= \\nabla_{\\boldsymbol{\\beta}}[(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^\\mathsf{T}(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})] \\\\[5pt]\n&=\\nabla_{\\boldsymbol{\\beta}}[\\mathbf{y}^\\mathsf{T}\\mathbf{y} - \\mathbf{y}^\\mathsf{T}\\mathbf{X}\\boldsymbol{\\beta} - \\boldsymbol{\\beta}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{y} + \\boldsymbol{\\beta}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{X}\\boldsymbol{\\beta}] \\\\[5pt]\n&=\\nabla_{\\boldsymbol{\\beta}}[\\mathbf{y}^\\mathsf{T}\\mathbf{y} - 2\\boldsymbol{\\beta}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{y} + \\boldsymbol{\\beta}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{X}\\boldsymbol{\\beta}]\\\\[5pt]\n& = -2\\mathbf{X}^\\mathsf{T}\\mathbf{y} + 2\\mathbf{X}^\\mathsf{T}\\mathbf{X}\\boldsymbol{\\beta} \\\\[5pt]\n&\\Rightarrow \\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}\\mathbf{y}\n\\end{aligned}\n\\]\n\nExplain how \\(-\\mathbf{y}^\\mathsf{T}\\mathbf{X}\\boldsymbol{\\beta} - \\boldsymbol{\\beta}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{y}\\) is simplified to \\(-2\\boldsymbol{\\beta}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{y}\\) when going from lines 2 to 3.\n\nExplain what rules were used to compute the gradient in line 4.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-8",
    "href": "labs/lab-04.html#exercise-8",
    "title": "Lab 04: Exam 01 Review",
    "section": "Exercise 8",
    "text": "Exercise 8\nBelow we show how SSR = \\(\\mathbf{y}^\\mathsf{T}\\mathbf{y} - \\hat{\\boldsymbol{\\beta}}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{y}\\)\n\\[\n\\begin{aligned}\nSSR = \\mathbf{e}^\\mathsf{T}\\mathbf{e} &= (\\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}})^\\mathsf{T}(\\mathbf{y} - \\mathbf{X}\\hat{\\mathbf{\\beta}}) \\\\[5pt]\n& = \\mathbf{y}^\\mathsf{T}\\mathbf{y} - \\mathbf{y}^\\mathsf{T}\\mathbf{X}\\hat{\\boldsymbol{\\beta}} - \\hat{\\boldsymbol{\\beta}}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{y} + \\hat{\\boldsymbol{\\beta}}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\\\[5pt]\n&= \\mathbf{y}^\\mathsf{T}\\mathbf{y} - 2\\hat{\\boldsymbol{\\beta}}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{y}+\\hat{\\boldsymbol{\\beta}}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{X}\\hat{\\boldsymbol{\\beta}}\\\\[5pt]\n& = \\mathbf{y}^\\mathsf{T}\\mathbf{y} - \\hat{\\boldsymbol{\\beta}}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{y}\n\\end{aligned}\n\\]\na. Explain how \\(-\\mathbf{y}^\\mathsf{T}\\mathbf{X}\\boldsymbol{\\beta} - \\boldsymbol{\\beta}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{y}\\) is simplified to \\(-2\\boldsymbol{\\beta}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{y}\\) when going from lines 2 to\nb. Explain how we know \\(\\hat{\\boldsymbol{\\beta}}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{y} = \\hat{\\boldsymbol{\\beta}}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{X}\\hat{\\boldsymbol{\\beta}}\\) when going from lines 3 to 4.\n\n\n\n\n\n\nSubmission\n\n\n\nTo submit the AE:\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work on GitHub. You’re done! 🎉\nThere is no Gradescope submission for this lab.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#footnotes",
    "href": "labs/lab-04.html#footnotes",
    "title": "Lab 04: Exam 01 Review",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDahlquist, Samantha, and Jin Dong. 2011. “The Effects of Credit Cards on Tipping.” Project for Statistics 212-Statistics for the Sciences, St. Olaf College.↩︎",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-01.html",
    "href": "labs/lab-01.html",
    "title": "Lab 01: Computing + linear algebra review",
    "section": "",
    "text": "Due date\n\n\n\nThis lab is due on Tuesday, January 21 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#learning-goals",
    "href": "labs/lab-01.html#learning-goals",
    "title": "Lab 01: Computing + linear algebra review",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of the lab, you will…\n\nRecall some basic matrix operations and linear algebra rules\nBe familiar with the workflow using RStudio and GitHub\nGain practice writing a reproducible report using Quarto\nPractice version control using GitHub\nBe able to produce visualizations and summary statistics to describe distributions",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#clone-the-repo-start-new-rstudio-project",
    "href": "labs/lab-01.html#clone-the-repo-start-new-rstudio-project",
    "title": "Lab 01: Computing + linear algebra review",
    "section": "Clone the repo & start new RStudio project",
    "text": "Clone the repo & start new RStudio project\n\nGo to the course organization at github.com/sta221-sp25 organization on GitHub.\nClick on the repo with the prefix lab-01. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\n\nSee the Lab 00 instructions if you have not set up the SSH key or configured git.\n\nIn RStudio, go to File \\(\\rightarrow\\) New Project \\(\\rightarrow\\) Version Control \\(\\rightarrow\\) Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-01.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#r-and-r-studio",
    "href": "labs/lab-01.html#r-and-r-studio",
    "title": "Lab 01: Computing + linear algebra review",
    "section": "R and R Studio",
    "text": "R and R Studio\nBelow are the components of the RStudio IDE.\n\n\n\n\n\nBelow are the components of an Quarto (.qmd) file.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#yaml",
    "href": "labs/lab-01.html#yaml",
    "title": "Lab 01: Computing + linear algebra review",
    "section": "YAML",
    "text": "YAML\nThe top portion of your Quarto file (between the three dashed lines) is called YAML. It stands for “YAML Ain’t Markup Language”. It is a human friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\n\n\n\n\n\n\nImportant\n\n\n\nOpen the Quarto (.qmd) file in your project, change the author name to your name, and render the document. Examine the rendered document.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#committing-changes",
    "href": "labs/lab-01.html#committing-changes",
    "title": "Lab 01: Computing + linear algebra review",
    "section": "Committing changes",
    "text": "Committing changes\nNow, go to the Git pane in your RStudio instance. This will be in the top right hand corner in a separate tab.\nIf you have made changes to your Quarto (.qmd) file, you should see it listed here. Click on it to select it in this list and then click on Diff. This shows you the difference between the last committed state of the document and its current state including changes. You should see deletions in red and additions in green.\nIf you’re happy with these changes, we’ll prepare the changes to be pushed to your remote repository. First, stage your changes by checking the appropriate box on the files you want to prepare. Next, write a meaningful commit message (for instance, “updated author name”) in the Commit message box. Finally, click Commit. Note that every commit needs to have a commit message associated with it.\nYou don’t have to commit after every change, as this would get quite tedious. You should commit states that are meaningful to you for inspection, comparison, or restoration.\nIn the first few assignments we will tell you exactly when to commit and in some cases, what commit message to use. As the semester progresses we will let you make these decisions.\nNow let’s make sure all the changes went to GitHub. Go to your GitHub repo and refresh the page. You should see your commit message next to the updated files. If you see this, all your changes are on GitHub and you’re good to go!",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#push-changes",
    "href": "labs/lab-01.html#push-changes",
    "title": "Lab 01: Computing + linear algebra review",
    "section": "Push changes",
    "text": "Push changes\nNow that you have made an update and committed this change, it’s time to push these changes to your repo on GitHub.\nIn order to push your changes to GitHub, you must have staged your commit to be pushed. click on Push.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#instructions",
    "href": "labs/lab-01.html#instructions",
    "title": "Lab 01: Computing + linear algebra review",
    "section": "Instructions",
    "text": "Instructions\nWrite all code and narrative in your Quarto file. Write all narrative in complete sentences. Throughout the assignment, you should periodically render your Quarto document to produce the updated PDF, commit the changes in the Git pane, and push the updated files to GitHub.\n\n\n\n\n\n\nTip\n\n\n\nMake sure we can read all of your code in your PDF document. This means you will need to break up long lines of code. One way to help avoid long lines of code is is start a new line after every pipe (|&gt;) and plus sign (+).",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-1",
    "href": "labs/lab-01.html#exercise-1",
    "title": "Lab 01: Computing + linear algebra review",
    "section": "Exercise 1",
    "text": "Exercise 1\nViewing a summary of the data is a useful starting point for data analysis, especially if the data set has a large number of observations (rows) or variables (columns). Run the code below to use the glimpse function to see a summary of the ikea data set.\nHow many observations are in the ikea data set? How many variables?\n\nglimpse(ikea)\n\n\n\n\n\n\n\nNote\n\n\n\nIn your `lab-01.qmd` document you’ll see that we already added the code required for the exercise as well as a sentence where you can fill in the blanks to report the answer. Use this format for the remaining exercises.\nAlso note that the code chunk has a label: glimpse-data. Labeling your code chunks is not required, but it is good practice and highly encouraged.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-2",
    "href": "labs/lab-01.html#exercise-2",
    "title": "Lab 01: Computing + linear algebra review",
    "section": "Exercise 2",
    "text": "Exercise 2\nWe begin each regression analysis with exploratory data analysis (EDA) to help us “get to know” the data and examine the variable distributions and relationships between variables. We do this by visualizing the data and calculating summary statistics to describe the variables in our data set. In this lab, we will focus on data visualizations.\nWhen we make visualizations, we want them to be clear and suitable to present to a professional audience. This means that, at a minimum, each visualization should have an informative title and informative axis labels.\nFill in the code below to visualize the distribution of price_usd, the price in US dollars.\n\nggplot(data = ikea, aes(x = _____)) +\n  geom_histogram() +\n    labs(x = \"_____\",\n       y = \"_____\", \n       title = \"_____\")",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-3",
    "href": "labs/lab-01.html#exercise-3",
    "title": "Lab 01: Computing + linear algebra review",
    "section": "Exercise 3",
    "text": "Exercise 3\nUse the visualization to describe the distribution of price. In your narrative, include descriptions of the shape, approximate center, approximate spread, and any presence of outliers. Briefly explain why the median is more representative of the center of this distribution than the mean.\nNote: You may compute summary statistics to more precisely describe the center and spread.\n\nThis is a good place to render, commit, and push changes to your lab-01 repo on GitHub. Write an informative commit message (e.g. “Completed exercises 1 - 3”), and push every file to GitHub by clicking the check box next to each file in the Git pane. After you push the changes, the Git pane in RStudio should be empty.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-4",
    "href": "labs/lab-01.html#exercise-4",
    "title": "Lab 01: Computing + linear algebra review",
    "section": "Exercise 4",
    "text": "Exercise 4\nIn this course, we’ll be most interested in the relationship between two or more variables, so let’s begin by looking at the distribution of price by category. We’ll focus on two categories, Sofas & armchairs and Bookcases & shelving units, since these may be types of furniture most useful to furnish an office.\nFill in the code below to create a new data frame called ikea_sub that only includes the furniture categories of interest. We’re assigning this subsetted data frame to an object with a new name, so we don’t overwrite the original data.\n\nikea_sub &lt;- ikea |&gt;\n  filter(_____ %in% c( \"_____\",\n                       \"_____\"))\n\nNow, run the code below to remove observations that have that have a missing value for at least one of width or price_usd.\n\nikea_sub &lt;- ikea_sub |&gt;\n  drop_na(width, price_usd)\n\nHow many observations are in the ikea_sub data frame? How many variables?\n\n\n\n\n\n\nImportant\n\n\n\nUse the ikea_sub data frame for the remainder of lab.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-5",
    "href": "labs/lab-01.html#exercise-5",
    "title": "Lab 01: Computing + linear algebra review",
    "section": "Exercise 5",
    "text": "Exercise 5\nCreate a visualization of the relationship between the width and price of your items at Ikea in the two categories of interest. Include informative axis labels and an informative title. Use the visualization to describe the relationship between the two variables.\nThen, recreate your visualization, but now adding color based on furniture category. Comment on your observations from this visualization.\nNote: Show both visualizations in the response.\n\nThis is a good place to render, commit, and push changes to your lab-01 repo on GitHub. Write an informative commit message (e.g. “Completed exercises 4 - 5”), and push every file to GitHub by clicking the check box next to each file in the Git pane. After you push the changes, the Git pane in RStudio should be empty.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#instructions-1",
    "href": "labs/lab-01.html#instructions-1",
    "title": "Lab 01: Computing + linear algebra review",
    "section": "Instructions",
    "text": "Instructions\n\nThe conceptual exercises are focused on explaining concepts and showing results mathematically. Show your work for each question.\n\nPut any relevant R code in the Quarto document. You may write the answers and show any associated work for conceptual exercises by hand or type them in your Quarto document using LaTex.\nLet\n\\[\nA = \\begin{bmatrix}\n1 & 2\\\\\n3 & 4\\\\\n5 & 6\\end{bmatrix},\n\\qquad\nB = \\begin{bmatrix}\n1 & 1 & 1 & 1\\\\\n0 & 1 & 2 & 3\n\\end{bmatrix},\n\\qquad\nC = \\begin{bmatrix}\n1 & 4\\\\\n2 & 5\\\\\n3 & 6\\end{bmatrix}\n\\qquad\n\\]\n\\[\n\\mathbf{X} = \\begin{bmatrix}\nx_{11} & x_{12}& \\dots & x_{1p}\\\\\nx_{21} & x_{22}& \\dots & x_{2p}\\\\\n\\vdots & \\vdots& \\ddots & \\vdots\\\\\nx_{n1} & x_{n2}& \\dots & x_{np}\\\\\\end{bmatrix}\n\\]",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-6",
    "href": "labs/lab-01.html#exercise-6",
    "title": "Lab 01: Computing + linear algebra review",
    "section": "Exercise 6",
    "text": "Exercise 6\nWrite the dimensions of the following matrices:\n\n\\(A\\)\n\\(B\\)\n\\(A^\\top\\)\n\\(\\mathbf{X}\\)\n\\(\\mathbf{X}^\\top\\)",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-7",
    "href": "labs/lab-01.html#exercise-7",
    "title": "Lab 01: Computing + linear algebra review",
    "section": "Exercise 7",
    "text": "Exercise 7\ni. Which of the following is a proper matrix multiplication operation? Explain why.\n\n\\(A\\times C\\)\n\\(A\\times B\\)\n\\(A^\\top \\times B\\)\n\\(B \\times A\\)\n\\(B^\\top \\times C\\)\n\\(B\\times B\\)\n\nii. Perform the multiplication you chose in part (i).",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#matrix-operations-in-r",
    "href": "labs/lab-01.html#matrix-operations-in-r",
    "title": "Lab 01: Computing + linear algebra review",
    "section": "Matrix operations in R",
    "text": "Matrix operations in R\nR has built in matrix tools such as addition, multiplication, transpose, etc. We will now practice using these tools to review some matrix properties.\nWe first begin by creating matrices using matrix() function. We provide elements of our matrices as the data argument and specify how many rows our matrices have. byrow = TRUE allows us to fill the matrix by row.\n\nA &lt;- matrix(data = c(1, 2,\n                     3, 4,\n                     5, 6),\n            nrow = 3, \n            byrow = TRUE) \n\nB &lt;- matrix(data = c(1, 1, 1, 1, \n                     0, 1, 2, 3), \n            nrow = 2,\n            byrow = TRUE)\n\nC &lt;-  matrix(data = c(1, 4,\n                      2, 5,\n                      3, 6),\n            nrow = 3, \n            byrow = TRUE) \n\nYou can learn more about matrix() function by typing ?matrix in console.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-8",
    "href": "labs/lab-01.html#exercise-8",
    "title": "Lab 01: Computing + linear algebra review",
    "section": "Exercise 8",
    "text": "Exercise 8\ni. To perform addition or subtraction, we can simply use a + or - operators.\n\n# Add A and C\nA + C\n\n     [,1] [,2]\n[1,]    2    6\n[2,]    5    9\n[3,]    8   12\n\n\nUsing R, find \\(C + A\\). Is addition commutative (i.e. does \\(A + C = C + A\\))? Show the work to support your response.\nii. In R, we have to use a special matrix multiplication operator, %*% .\n\n# multiply A and B\nA %*% B\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    3    5    7\n[2,]    3    7   11   15\n[3,]    5   11   17   23\n\n\nDoes the output match your answer to Exercise 7 (ii)? What happens if you try to multiply \\(B\\times A\\) in R?\n\n\n\n\n\n\nWarning\n\n\n\nMatrix multiplication is not commutative! Matrix multiplication satisfies left and right distributivity: \\((\\mathbf{A} + \\mathbf{B}) \\mathbf{C} = \\mathbf{A}\\mathbf{C} + \\mathbf{B}\\mathbf{C}\\), and \\(\\mathbf{A}( \\mathbf{B}+ \\mathbf{C}) = \\mathbf{A}\\mathbf{B} + \\mathbf{A}\\mathbf{C}\\), but the order here matters. \\((\\mathbf{A} + \\mathbf{B}) \\mathbf{C} \\neq \\mathbf{C}\\mathbf{A} +\\mathbf{C} \\mathbf{B}\\), and \\(\\mathbf{A}( \\mathbf{B}+ \\mathbf{C}) \\neq \\mathbf{B}\\mathbf{A} + \\mathbf{C}\\mathbf{A}\\). Pay attention to the order and dimensions of matrices.\n\n\niii. In this class, we will work a lot with matrix transposes. You can transpose a matrix in R by applying t() function.\n\n# transpose A\nt(A)\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\n\nFind \\(B^\\top \\times A^\\top\\) using R. How is your answer compare to the result of \\(A\\times B\\) you found in previous part?\n\nThis is a good place to render, commit, and push changes to your lab-01 repo on GitHub. Write an informative commit message (e.g., “Completed exercises 6 - 8”), and push every file to GitHub by clicking the check box next to each file in the Git pane. After you push the changes, the Git pane in RStudio should be empty.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-9",
    "href": "labs/lab-01.html#exercise-9",
    "title": "Lab 01: Computing + linear algebra review",
    "section": "Exercise 9",
    "text": "Exercise 9\nLet \\(\\mathbf a = \\begin{bmatrix}a_1 \\\\ \\vdots \\\\ a_n\\end{bmatrix}\\) and \\(\\mathbf b = \\begin{bmatrix}b_1 \\\\ \\vdots \\\\ b_n\\end{bmatrix}\\). Recall, \\[\\mathbf{a}^\\top \\mathbf{a} = \\sum_{i=1}^n a_i^2.\\]\nWrite \\((\\mathbf{a} - \\mathbf{b})^\\top (\\mathbf{a} - \\mathbf{b})\\) using summation notation.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#more-linear-algebra",
    "href": "labs/lab-01.html#more-linear-algebra",
    "title": "Lab 01: Computing + linear algebra review",
    "section": "More Linear Algebra",
    "text": "More Linear Algebra\nRecall the definition of linear dependence:\nA sequence of vectors \\(\\mathbf{x_1}, \\mathbf{x_2}, \\dots, \\mathbf{x_p}\\) is said to be linearly dependent if there exists a series of scalars \\(a_1, a_2, \\dots, a_p\\), not all zero, such that\n\\[\na_1 \\mathbf{x_1} + a_2 \\mathbf{x_2} + \\dots + a_p \\mathbf{x_p} = \\mathbf{0}\n\\] Further, matrix \\(\\mathbf{X}\\) has full column rank if all of its columns are linearly independent.\nFor example, the following matrix is not full rank,\n\\[\n\\mathbf{X} = \\begin{bmatrix}\n1 & 2 & 3\\\\\n1 & 1 & 2\n\\end{bmatrix}\n\\] since, letting letting \\(\\mathbf{x_1} = \\begin{bmatrix}1\\\\1 \\end{bmatrix}\\), \\(\\mathbf{x_2} = \\begin{bmatrix}2\\\\1 \\end{bmatrix}\\), \\(\\mathbf{x_3} = \\begin{bmatrix}3\\\\2 \\end{bmatrix}\\), and letting \\(a_1 = 1\\), \\(a_2 = 1\\), and \\(a_3 = -1\\), we have:\n\\[\na_1 \\mathbf{x_1} + a_2\\mathbf{x_2} + a_3\\mathbf{x_3} =  \\begin{bmatrix}1\\\\1 \\end{bmatrix} + \\begin{bmatrix}2\\\\1 \\end{bmatrix} - \\begin{bmatrix}3\\\\2 \\end{bmatrix} = \\mathbf{0}.\n\\]",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-10",
    "href": "labs/lab-01.html#exercise-10",
    "title": "Lab 01: Computing + linear algebra review",
    "section": "Exercise 10",
    "text": "Exercise 10\nFor each of the following matrices, state whether it is full rank. If not full rank, show why (find corresponding coefficients \\(a\\)’s).\n\n\\[\\begin{bmatrix}\n1 & 0 & 0\\\\\n1 & 1 & 0\\\\\n1 & 1 & 0\\\\\n1 & 0 & 1\n\\end{bmatrix}\\]\n\\[\\begin{bmatrix}\n0 & 0 & 1\\\\\n1 & 0 & 0\\\\\n1 & 0 & 0\\\\\n0 & 1 & 0\n\\end{bmatrix}\\]\n\\[\\begin{bmatrix}\n1 & 0 & 0 & 1\\\\\n1 & 1 & 0 & 0\\\\\n1 & 1 & 0 & 0\\\\\n1 & 0 & 1 & 0\n\\end{bmatrix}\\]",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-02.html",
    "href": "labs/lab-02.html",
    "title": "Lab 02: Linear regression",
    "section": "",
    "text": "Due date\n\n\n\nThis lab is due on Tuesday, January 28 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#learning-goals",
    "href": "labs/lab-02.html#learning-goals",
    "title": "Lab 02: Linear regression",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of the lab, you will…\n\nContinue developing a reproducible workflow using RStudio and GitHub\nProduce visualizations and summary statistics to describe distributions\nFit, interpret, and evaluate linear regression models\nUse the matrix representation of the linear regression model to estimate coefficients\nExplore properties of the linear regression model",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-1",
    "href": "labs/lab-02.html#exercise-1",
    "title": "Lab 02: Linear regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nWe begin with univariate exploratory data analysis.\n\nVisualize the distribution of the response variable total_cup_points and calculate summary statistics.\nComment on the features of the distribution of this variable by describing the shape, center, spread, and presence of potential outliers.\nBased on this distribution, do you think the data set is representative of all coffee available to consumers? Briefly explain.\n\n\n\n\n\n\n\nTip\n\n\n\nMake sure your data visualizations have clear and informative titles and axis labels.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-2",
    "href": "labs/lab-02.html#exercise-2",
    "title": "Lab 02: Linear regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nNow let’s consider the relationship between how good a coffee smells and its overall quality.\n\nVisualize the relationship between aroma and total_cup_points.\nDoes there appear to be a relationship between a coffee’s aroma and its overall quality? If so, what is the shape and direction of the relationship?",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-3",
    "href": "labs/lab-02.html#exercise-3",
    "title": "Lab 02: Linear regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nWe have seen the mathematical formulation for simple linear regression in class. In particular, given a response variable \\(Y\\) and predictor variable \\(X\\), the simple linear regression model is \\[Y = \\beta_0 + \\beta_1 X + \\epsilon\\]\nfor some unknown regression coefficients for intercept and slope\\((\\beta_0, \\beta_1)\\) and error terms \\(\\epsilon\\) that are centered at 0 and have variance \\(\\sigma^2_{\\epsilon}\\) . This means that the expected value of each observation lies on the regression line\n\\[ E(Y|X) = \\beta_0 + \\beta_1 X\\]\nAnswer the following questions about simple linear regression. Your response should be in general terms about regression, not be specific to the coffee data.\n\nWhat does \\(E(Y|X) = \\beta_0 + \\beta_1X\\) mean in terms of a given value of \\(X\\)?\nWhat are the interpretations of the coefficients \\(\\beta_0\\) and \\(\\beta_1\\) in terms of the expected value of \\(Y\\)?\n\n\nThis is a good place to render, commit, and push changes to your lab-01 repo on GitHub. Write an informative commit message (e.g., “Completed exercises 1 - 3”), and push every file to GitHub by clicking the check box next to each file in the Git pane. After you push the changes, the Git pane in RStudio should be empty.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-4",
    "href": "labs/lab-02.html#exercise-4",
    "title": "Lab 02: Linear regression",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nFit the model of the relationship between aroma and total_cup_points. Neatly display the output using 3 digits.\nInterpret the slope in the context of the data.\nWhat is the expected total_cup_points for coffees that receive the worst aroma score of 0? Is this a reliable estimate of the total_cup_points for these coffees? Briefly explain why or why not.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-5",
    "href": "labs/lab-02.html#exercise-5",
    "title": "Lab 02: Linear regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nNow let’s add flavor to the model, so we will use both flavor and aroma to understand variability in the overall quality of coffees. Use this model for the remainder of the lab.\nIn class we have seen how vectors and matrices can be used to represent the linear regression model:\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon}\n\\]\n\nState the dimensions of \\(\\mathbf{y}, \\mathbf{X}, \\boldsymbol{\\beta}, \\boldsymbol{\\epsilon}\\) for this model. Your answer should have exact values given the coffee data set.\nCompute the estimated regression coefficients using the matrix form of the model. Show the code used to get the answer.\n\n\n\n\n\n\n\nTip\n\n\n\nYou can use the model.matrix() function to get the design matrix. The code takes the general form:\n\nmodel.matrix(y ~ x, data = my_data)\n\nSee Lab 01 for other matrix operations in R.\n\n\n\nCheck your results from part (b) by using the lm function to fit the model. Neatly display your results using 3 digits.\nWrite the estimated regression equation.\n\n\nThis is a good place to render, commit, and push changes to your lab-01 repo on GitHub. Write an informative commit message (e.g., “Completed exercises 4 - 5”), and push every file to GitHub by clicking the check box next to each file in the Git pane. After you push the changes, the Git pane in RStudio should be empty.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-6",
    "href": "labs/lab-02.html#exercise-6",
    "title": "Lab 02: Linear regression",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nThe coefficient for aroma for the model fit in Exercise 5 is different than the coefficient from the model fit in Exercise 4. Briefly explain why these coefficients are different.\nWould you willingly drink a coffee represented by the intercept of the model in Exercise 5? Briefly explain why or why not.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-7",
    "href": "labs/lab-02.html#exercise-7",
    "title": "Lab 02: Linear regression",
    "section": "Exercise 7",
    "text": "Exercise 7\n\nCompute \\(\\mathbf{H}\\), the hat matrix corresponding to the model from Exercise 5. Then use \\(\\mathbf{H}\\) to compute the residuals for this model. Do not print out \\(\\mathbf{H}\\) or the residuals.\nCompute the mean and standard deviation of the residuals.\nRecall root mean square error RMSE\n\\[\nRMSE = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n}}\n\\]\nSimilar to other statistics we’ve seen thus far, we can write the RMSE in matrix form. Compute RMSE for the model from Exercise 5 using matrix form. Show the code used to get the answer.\nHow do the standard deviation of the residuals and RMSE compare?\n\n\nYou’re done and ready to submit your work! render, commit, and push all remaining changes. You can use the commit message “Done with Lab 02!”, and make sure you have pushed all the files to GitHub (your Git pane in RStudio should be empty) and that all documents are updated in your repo on GitHub. The PDF document you submit to Gradescope should be identical to the one in your GitHub repo.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-03.html",
    "href": "labs/lab-03.html",
    "title": "Lab 03: Multiple Linear Regression",
    "section": "",
    "text": "Due date\n\n\n\nThis lab is due on Tuesday, February 4 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your team’s GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-1",
    "href": "labs/lab-03.html#exercise-1",
    "title": "Lab 03: Multiple Linear Regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nLet’s start with some exploratory data analysis. Visualize the distribution of the response variable mc_preschool and calculate summary statistics. Describe the distribution of this variable, including the shape, center, spread, and presence of potential outliers.\n\n\n\n\n\n\nImportant\n\n\n\nYou will use the childcare_train for all analysis in Exercises 1 - 7.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-2",
    "href": "labs/lab-03.html#exercise-2",
    "title": "Lab 03: Multiple Linear Regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nAs you can see from the data dictionary in the README of the data folder, there are many interesting potential variables that could be included in the model to predict median childcare cost for preschool-age children. Therefore, we will do some feature selection and feature design to choose potential predictors and construct new ones.\nAs a team, select four variables you want to use as predictors for the model. For each variable, state the variable name, definition, and a brief explanation about why your team hypothesizes this will be a relevant predictor of median childcare costs. The explanation may (but is not required to) include some short exploratory analysis.\n\nTeam Member 1: Knit, commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.\n\n\nAll other team members: Pull to get the updated documents from GitHub. Click on the .qmd file, and you should see the responses to exercises 1- 2.\nTeam Member 2: It’s your turn! Type the team’s response to exercises 3 - 4.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-3",
    "href": "labs/lab-03.html#exercise-3",
    "title": "Lab 03: Multiple Linear Regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nOnce we’ve identified potential predictor variables, we often need to transform some variables (e.g., change raw counts into proportions) or create new ones (e.g., create a categorical variable out of quantitative data) before fitting the regression model. This process is particularly useful when putting a variable in the model “as-is” may result in interpretation issues.\nChoose one of the variables selected in the previous exercise. For this variable,\n\nTransform the variable or use it to create a new variable. Be sure to save the variable to the childcare_train data frame.\nBriefly explain your reasoning for the transformation or new variable.\nUse visualizations and/or summary statistics to display the distribution of the original variable and the transformed / newly created variable. Note: This is to help ensure the transformation / new variable is what you expect.\n\n\n\n\n\n\n\n\n\n\n\nYou may decide to transform and/or create multiple new variables; however, you will only be graded on the one of them.\n\n\n\n\n\n\nImportant\n\n\n\nYou will use the transformed / new variable (not the original variable) in the model!",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-4",
    "href": "labs/lab-03.html#exercise-4",
    "title": "Lab 03: Multiple Linear Regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nNow let’s conduct bivariate exploratory data analysis. Visualize the relationship between the response variable and one of your predictor variables.\nWrite two distinct observations from the visualization.\n\nTeam Member 2: Knit, commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.\n\n\nAll other team members: Pull to get the updated documents from GitHub. Click on the .qmd file, and you should see the responses to exercises 3 - 4.\nTeam Member 3: It’s your turn! Type the team’s response to exercises 5 - 6.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-5",
    "href": "labs/lab-03.html#exercise-5",
    "title": "Lab 03: Multiple Linear Regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nUse the matrix form of the model to represent the regression model with the variables you selected and transformed/created in exercises 2 and 3 as the predictors. For each symbol in the model\n\ndescribe what it represents, and\nstate the dimensions.\n\nThe description and dimensions should be in the context of these data, not in general.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-6",
    "href": "labs/lab-03.html#exercise-6",
    "title": "Lab 03: Multiple Linear Regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nUse lm() to fit the regression model you described in the previous exercise.\n\nNeatly display the model using a reasonable number of digits.\nInterpret the coefficient for one predictor in the model.\n\n\nTeam Member 3: Knit, commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.\n\n\nAll other team members: Pull to get the updated documents from GitHub. Click on the .qmd file, and you should see the responses to exercises 5 - 6.\nTeam Member 4: It’s your turn! Type the team’s response to exercises 7 - 9.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-7",
    "href": "labs/lab-03.html#exercise-7",
    "title": "Lab 03: Multiple Linear Regression",
    "section": "Exercise 7",
    "text": "Exercise 7\nNow let’s assess the fit of the model.\n\nHow much of the variability in the childcare costs is explained by your chosen predictor variables?\nBased on this, do you think the model explains a significant portion of the variability in childcare costs for preschool-age children in North Carolina? Briefly explain.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-8",
    "href": "labs/lab-03.html#exercise-8",
    "title": "Lab 03: Multiple Linear Regression",
    "section": "Exercise 8",
    "text": "Exercise 8\nNow let’s use the testing data to explore the predictive power of the model.\n\nAdd the variable you created in Exercise 3 to the testing data.\nThen, use the code below to compute the predicted childcare costs for the observations in the testing data using the predict function.\n\n\n# compute predictions\npred &lt;- predict(childcare_fit, childcare_test)\n\n# add predictions to testing data set\nchildcare_test &lt;- childcare_test |&gt;\n  mutate(pred = pred)",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-9",
    "href": "labs/lab-03.html#exercise-9",
    "title": "Lab 03: Multiple Linear Regression",
    "section": "Exercise 9",
    "text": "Exercise 9\n\nCompute the RMSE for the test set, and compare it to the standard deviation of the response variable mc_preschool.\nHow do these values compare?\nBased on this, how would assess the predictive power of the model?\n\n\nTeam Member 4: Render, commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and the rest of the team can see the completed lab.\n\n\nAll other team members: Pull to get the updated documents from GitHub. Click on the .qmd file, and you should see the team’s completed lab!",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-10",
    "href": "labs/lab-03.html#exercise-10",
    "title": "Lab 03: Multiple Linear Regression",
    "section": "Exercise 10",
    "text": "Exercise 10\nIf you haven’t already, make sure you have completed the team agreement (see the instructions in [Meet your team!]).",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#footnotes",
    "href": "labs/lab-03.html#footnotes",
    "title": "Lab 03: Multiple Linear Regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDon’t trust yourself to keep your hands off the keyboard? Put them in your pocket or cross your arms. No matter how silly it might feel, resist the urge to touch your keyboard until otherwise instructed!↩︎",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-00.html",
    "href": "labs/lab-00.html",
    "title": "Lab 00: Getting Started",
    "section": "",
    "text": "Important\n\n\n\nPlease complete all today’s lab tasks before leaving lab today.",
    "crumbs": [
      "Labs",
      "Lab 00"
    ]
  },
  {
    "objectID": "labs/lab-00.html#rstudio",
    "href": "labs/lab-00.html#rstudio",
    "title": "Lab 00: Getting Started",
    "section": "RStudio",
    "text": "RStudio\n\n\n\n\n\n\nNote\n\n\n\nR is the name of the programming language itself and RStudio is a convenient interface.\n\n\n\nReserve RStudio container\n\nGo to https://cmgr.oit.duke.edu/containers. You will log in using your NetID credentials.\nClick “Reserve STA 221” to reserve an RStudio container. Be sure you reserve the container labeled STA 221 to ensure you have the computing set up you need for the class.\n\nYou only need to reserve a container once per semester.\n\n\nOpen RStudio container\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA221 to log into the Docker container. You should now see the RStudio environment.",
    "crumbs": [
      "Labs",
      "Lab 00"
    ]
  },
  {
    "objectID": "labs/lab-00.html#git-and-github",
    "href": "labs/lab-00.html#git-and-github",
    "title": "Lab 00: Getting Started",
    "section": "Git and GitHub",
    "text": "Git and GitHub\nIn addition to R and RStudio, we will use git and GitHub for version control and collaboration.\n\n\n\n\n\n\nNote\n\n\n\nGit is a version control system (like “Track Changes” features from Microsoft Word but more powerful) and GitHub is the home for your Git-based projects on the internet (like DropBox but much better).\n\n\n\nSign up for GitHub account\nYou will need a GitHub account to access the assignments, project, and in-class exercises for the course.\n\nIf you do not have a GitHub account, go to https://github.com and sign up for an account.\n\n\n\n\n\n\n\nTip\n\n\n\nClick here for advice on choosing a username.\n\n\n\nIf you already have a GitHub account, you can move on to the next step.",
    "crumbs": [
      "Labs",
      "Lab 00"
    ]
  },
  {
    "objectID": "labs/lab-00.html#connect-rstudio-and-github",
    "href": "labs/lab-00.html#connect-rstudio-and-github",
    "title": "Lab 00: Getting Started",
    "section": "Connect RStudio and GitHub",
    "text": "Connect RStudio and GitHub\nNow that you have RStudio and a GitHub account, we will configure git so that RStudio and GitHub communicate with one another.\n\nSet up your SSH Key\nYou will authenticate GitHub using SSH. An outline of the authentication steps is below; you are encouraged to follow along as your TA demonstrates the steps.\n\n\n\n\n\n\nNote\n\n\n\nYou only need to do this authentication process one time on a single system.\n\n\n\nStep 0: Open your STA 221 RStudio container.\nStep 1: Type credentials::ssh_setup_github() into the console on the bottom left of the RStudio environment.\nStep 2: R will ask “No SSH key found. Generate one now?” Click 1 for yes.\nStep 3: You will generate a key. It will begin with “ssh-rsa….” R will then ask “Would you like to open a browser now?” Click 1 for yes.\nStep 4: You may be asked to provide your username and password to log into GitHub. This would be the ones associated with your account that you set up. After entering this information, paste the key in and give it a name. You might name it in a way that indicates where the key will be used, e.g., sta221)\n\n\n\nConfigure git\nThe last thing we need to do is configure your git so that RStudio can communicate with GitHub. This requires two pieces of information: your name and email address.\nTo do so, you will use the use_git_config() function from the usethis package.\nType the following lines of code in the console in RStudio filling in your name and the email address associated with your GitHub account.\n\nusethis::use_git_config(\n  user.name = \"Your name\", \n  user.email = \"Email associated with your GitHub account\")\n\nFor example, mine would be\n\nusethis::use_git_config(\n  user.name = \"Maria Tackett\",\n  user.email = \"maria.tackett@duke.edu\")\n\nIt may look like nothing happened but you are now ready interact between GitHub and RStudio!",
    "crumbs": [
      "Labs",
      "Lab 00"
    ]
  },
  {
    "objectID": "labs/lab-00.html#getting-started",
    "href": "labs/lab-00.html#getting-started",
    "title": "Lab 00: Getting Started",
    "section": "Getting started",
    "text": "Getting started\n\nClick here to create your individual lab-00 repo: https://classroom.github.com/a/HJQpdTm_\nClick to open your lab-00 repo.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File → New Project → Version Control → Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-00.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.",
    "crumbs": [
      "Labs",
      "Lab 00"
    ]
  },
  {
    "objectID": "labs/lab-00.html#update-the-quarto-document",
    "href": "labs/lab-00.html#update-the-quarto-document",
    "title": "Lab 00: Getting Started",
    "section": "Update the Quarto document",
    "text": "Update the Quarto document\n\nTask 1: Change the author name at the top of the document to your name. Render the document. You will see your name at the top of the rendered PDF.\nTask 2: The plot shows the relationship between the daily temperature and number of bike rentals in Washington, D.C.’s Capital Bikeshare in 2012.\n\n\n\n\n\n\n\n\n\n\nWrite 1 - 2 observations from the plot. Render the document. You will see your response in the rendered PDF.",
    "crumbs": [
      "Labs",
      "Lab 00"
    ]
  },
  {
    "objectID": "labs/lab-00.html#commit-and-push-changes-to-github",
    "href": "labs/lab-00.html#commit-and-push-changes-to-github",
    "title": "Lab 00: Getting Started",
    "section": "Commit and push changes to GitHub",
    "text": "Commit and push changes to GitHub\n\nOnce you have made your final updates, go to the Git pane in your RStudio instance. This is a tab in the top right corner of the RStudio window.\nCheck the appropriate boxes on every file in the Git pane. All checked files will be sent to GitHub.\nNext, write a meaningful commit message (for instance, “updated author name”) in the Commit message box.\nClick Commit. Note that every commit needs to have a commit message associated with it.\nNow that you have made an update and committed this change, click Push to send the changes to GitHub.\nGo to your GitHub repo and refresh the page. You should see your commit message next to the updated files. If you see this, all your changes are on GitHub and you’re good to go!",
    "crumbs": [
      "Labs",
      "Lab 00"
    ]
  },
  {
    "objectID": "labs/lab-05.html",
    "href": "labs/lab-05.html",
    "title": "Lab 05: Expanding Multiple Linear Regression",
    "section": "",
    "text": "Due date\n\n\n\nThis lab is due on Tuesday, March 4 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your team’s GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "labs/lab-05.html#exercise-1",
    "href": "labs/lab-05.html#exercise-1",
    "title": "Lab 05: Expanding Multiple Linear Regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nWe’ll begin by rescaling the response and some of the predictor variables.\n\nRescale the response variable total_rev_menwomen and the primary predictor variable total_exp_menwomen, so that they are in terms of $100K (100 thousand dollars). Name the new variables rev100k and exp100k, respectively.\nRescale the predictor variable ef_total_count , so it is in terms of thousands of students. Name the new variable students_1k.\nBriefly explain why we might we rescale these variables instead of using them in the original units.",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "labs/lab-05.html#exercise-2",
    "href": "labs/lab-05.html#exercise-2",
    "title": "Lab 05: Expanding Multiple Linear Regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nBefore modeling, let’s do some exploratory data analysis.\n\nMake a visualization of the relationship between revenue and expenditures. Use the plot to describe the relationship between the two variables.\nHigher values of both expenditures and revenues are associated with greater variability. Transform both variables using a log transformation, to deal with the potential violation of an assumption of linear regression. Name the variables log_exp and log_rev, respectively.\nLarger values of expenditures and revenues seem to follow a slightly different trend and are associated with two sports - football and basketball. Create an indicator variable that takes value 1 if the sport is basketball or football and 0 otherwise. Name the variable bball_football.",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "labs/lab-05.html#exercise-3",
    "href": "labs/lab-05.html#exercise-3",
    "title": "Lab 05: Expanding Multiple Linear Regression",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nVisualize the relationship between log_rev and log_exp.\nFrom the visualization, you may notice a lot of observations form a straight diagonal line, indicating a perfect one-to-one relationship between expenses and revenues. Provide a possible interpretation of this phenomenon.\nDo you think it is reasonable to include observations displaying this exact relationship? Briefly explain.\nCreate a new data frame filtering out the observations for which expenditures and revenues are exactly equal. Call the new data frame sports_nolinear.\n\nYou will use sports_nolinear for the remainder of the assignment.",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "labs/lab-05.html#exercise-4",
    "href": "labs/lab-05.html#exercise-4",
    "title": "Lab 05: Expanding Multiple Linear Regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nUse sports_nolinear to fit a regression model with the log-transformed revenue as the response variable and the following predictors: log-transformed expenditures, student enrollment, institution type, sports type, participation in athletics for men, participation in athletics for women, the basketball/football indicator you created in a previous exercise, and the interaction between the log-transformed expenditures and the basketball/football indicator.\nNeatly display the model using 3 digits.",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "labs/lab-05.html#exercise-5",
    "href": "labs/lab-05.html#exercise-5",
    "title": "Lab 05: Expanding Multiple Linear Regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nConsider the regression model from the previous exercise.\n\nWhat type of institution and sport correspond to the intercept?\nYou’ll notice that one coefficient has a missing value. Why is the coefficient missing? What is the technical name of this phenomenon?",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "labs/lab-05.html#exercise-6",
    "href": "labs/lab-05.html#exercise-6",
    "title": "Lab 05: Expanding Multiple Linear Regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nFor the sake of interpretability, it is useful to have a regression model in which no coefficients are missing, and the coefficients for each sport indicator represent the baseline level for such sport. To address this issue, use the code below to fit another regression model that uses the same predictors as before, making sure to drop the unnecessary variables and the intercept (by the the -1 in the formula) to achieve this.\n\nsports_fit_2 &lt;- lm(log_rev ~ -1 + sports + students_1k + sector_name +\n             sum_partic_men + sum_partic_women + log_exp + \n             log_exp*bball_football - bball_football,\n          data = sports_nolinear)\n\n\nWhy is there only one coefficient for institution type, even after the intercept was removed?\nWhich type of institution was chosen to be the baseline in this model?",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "labs/lab-05.html#exercise-7",
    "href": "labs/lab-05.html#exercise-7",
    "title": "Lab 05: Expanding Multiple Linear Regression",
    "section": "Exercise 7",
    "text": "Exercise 7\nNow that we have an interpretable model, let us assess the model fit and perform diagnostics to verify whether our linear regression assumptions are reasonable for this data.\nAs a first step, provide some overall measures of model fit and comment on whether it seems to have an acceptable predictive power on the response of interest.",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "labs/lab-05.html#exercise-8",
    "href": "labs/lab-05.html#exercise-8",
    "title": "Lab 05: Expanding Multiple Linear Regression",
    "section": "Exercise 8",
    "text": "Exercise 8\nNext, let’s take a look at the residuals for the model.\nBecause there are multiple sports at every institution, we may be concerned the residuals within an institution are correlated with each other (thus violating the independence assumption).\nDue to the large number of institutions, we will look at randomly selected subset of 20 institutions to evaluate this.\n\nTake a random sample of 20 institutions. Use set.seed(221) to make your results reproducible.\nPlot the residuals versus fitted values, faceted by institution.\nBased on the faceted plot, do the errors appear to be correlated within institutions? Briefly explain your response.\n\n\n\n\n\n\n\nTip\n\n\n\nClick here for more detail, code, and examples of faceting in ggplot2.\nYou may need to change the size of the figure so that the faceted lot is fully visible. You can do so using the options #| fig-width and #| fig-height in the code chunk.",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "labs/lab-05.html#exercise-9",
    "href": "labs/lab-05.html#exercise-9",
    "title": "Lab 05: Expanding Multiple Linear Regression",
    "section": "Exercise 9",
    "text": "Exercise 9\nAfter an examination of all the residuals, we notice a few things:\n\nThere seems to be two groups of observations.\nInstitutions with larger fitted values correspond to lower variance in the residuals compared to the others.\nThere are institutions with lower fitted values that have large negative residuals, potentially indicating outliers and/or influential points.\n\nWe are concerned that these observations may indicate some model misspecification (i.e., the model does not accurately reflect the trends in the data). Therefore, we take a look at the residuals a different way. We plot the standardized residual versus the fitted values, color the points based Cook’s distance, and use shape to indicate whether the sport is basketball or football.\n\nDescribe what you observe from the plot and how your observations compare to the list above.\nDo you think this model is an appropriate fit for the data or is the model misspecified? Briefly explain.",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "labs/lab-05.html#exercise-10",
    "href": "labs/lab-05.html#exercise-10",
    "title": "Lab 05: Expanding Multiple Linear Regression",
    "section": "Exercise 10",
    "text": "Exercise 10\n\nBased on this model (regardless of your answer to the previous exercise), which variables seem to be useful in explaining the variability in the revenue from collegiate sports?\nInterpret the coefficient for one useful quantitative predictor in terms of the log-transformed revenue.\nInterpret the coefficient for one useful categorical predictor in terms of the log-transformed revenue.",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "labs/lab-06.html",
    "href": "labs/lab-06.html",
    "title": "Lab 06: Maximum likelihood estimation",
    "section": "",
    "text": "Due date\n\n\n\nThis lab is due on Tuesday, March 25 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your team’s GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 06"
    ]
  },
  {
    "objectID": "labs/lab-06.html#exercise-1",
    "href": "labs/lab-06.html#exercise-1",
    "title": "Lab 06: Maximum likelihood estimation",
    "section": "Exercise 1",
    "text": "Exercise 1\nWe’ll start with exploratory data analysis focused on the relationship between the response and predictor variables.\n\nVisualize the relationship between the response variable bill_depth_mm and predictor bill_length_mm .\nNow, visualize the relationship between bill_depth_mm and bill_length_mm by species. Use geom_smooth(method = \"lm\", se = FALSE) to add lines and more clearly visualize the relationship for each species.\nBased on these visualizations, why is it important to include species when in the model of the relationship between bill depth and length? Briefly explain.\nBased on these visualizations, would you include an interaction term between the two predictors? Briefly explain?",
    "crumbs": [
      "Labs",
      "Lab 06"
    ]
  },
  {
    "objectID": "labs/lab-06.html#exercise-2",
    "href": "labs/lab-06.html#exercise-2",
    "title": "Lab 06: Maximum likelihood estimation",
    "section": "Exercise 2",
    "text": "Exercise 2\nWe will fit the main effects model using bill length and species to understand variability in the bill depth.\n\nWrite the form of the statistical (population-level) model in matrix form.\nWrite the dimensions for \\(\\mathbf{y}, \\mathbf{X}, \\boldsymbol{\\beta}, \\boldsymbol{\\epsilon}\\) specific for this problem.",
    "crumbs": [
      "Labs",
      "Lab 06"
    ]
  },
  {
    "objectID": "labs/lab-06.html#exercise-3",
    "href": "labs/lab-06.html#exercise-3",
    "title": "Lab 06: Maximum likelihood estimation",
    "section": "Exercise 3",
    "text": "Exercise 3\nConsider the regression model described in Exercise 2.\n\nWrite the likelihood function \\(L(\\boldsymbol{\\beta}, \\sigma^2_{\\epsilon} | \\mathbf{y}, \\mathbf{X})\\) in matrix form.\nDescribe how each of the four model assumptions is necessary for the form of the likelihood function.",
    "crumbs": [
      "Labs",
      "Lab 06"
    ]
  },
  {
    "objectID": "labs/lab-06.html#exercise-4",
    "href": "labs/lab-06.html#exercise-4",
    "title": "Lab 06: Maximum likelihood estimation",
    "section": "Exercise 4",
    "text": "Exercise 4\nBriefly explain how the process of finding the maximum likelihood estimators for the likelihood function in Exercise 3 is related to the process of finding the least-squares estimators for the model in Exercise 2.",
    "crumbs": [
      "Labs",
      "Lab 06"
    ]
  },
  {
    "objectID": "labs/lab-06.html#exercise-5",
    "href": "labs/lab-06.html#exercise-5",
    "title": "Lab 06: Maximum likelihood estimation",
    "section": "Exercise 5",
    "text": "Exercise 5\nFor the next few exercises, we will compare the results of the maximum likelihood and least-squares procedures.\n\nFit the least-squares regression model described in Exercise 2. Neatly display the results using three digits.\nDescribe the estimated effect of bill length on bill depth in the context of the data.\nDescribe the estimated effect of species on bill depth in the context of the data. Include discussion about whether there is statistical evidence of a difference between species.",
    "crumbs": [
      "Labs",
      "Lab 06"
    ]
  },
  {
    "objectID": "labs/lab-06.html#exercise-6",
    "href": "labs/lab-06.html#exercise-6",
    "title": "Lab 06: Maximum likelihood estimation",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nUse matrix/vector operations to compute the maximum likelihood estimators \\(\\tilde{\\beta}\\) for the model in Exercise 2.\nHow do these estimators compare to the least-squares estimators in the previous exercise?",
    "crumbs": [
      "Labs",
      "Lab 06"
    ]
  },
  {
    "objectID": "labs/lab-06.html#exercise-7",
    "href": "labs/lab-06.html#exercise-7",
    "title": "Lab 06: Maximum likelihood estimation",
    "section": "Exercise 7",
    "text": "Exercise 7\nThe maximum likelihood estimation procedure also produces an estimator for the variance about the regression line, \\(\\sigma^2_\\epsilon\\), which we can write as\n\\[\n\\tilde{\\sigma}^2_{\\epsilon} = \\frac{1}{n} \\mathbf{e}^\\mathsf{T}\\mathbf{e}\n\\]\nWe know that the maximum likelihood estimator and least-squares estimator for \\(\\sigma^2_{\\epsilon}\\) are not equal. Additionally, the least-squares estimator \\(\\hat{\\sigma}^2_{\\epsilon}\\) is unbiased. We want to find a scaling factor \\(c\\) such that the maximum likelihood estimator is unbiased.\nUsing the data and regression estimates for this analysis, compute both the maximum likelihood and least-squares estimators for \\(\\sigma_{\\epsilon}^2\\), and then find \\(c\\) by solving the equation \\[ \\hat\\sigma^2_{\\epsilon} = c \\cdot \\tilde\\sigma^2_{\\epsilon} \\]You can do this last step either computationally or algebraically.",
    "crumbs": [
      "Labs",
      "Lab 06"
    ]
  },
  {
    "objectID": "labs/lab-06.html#exercise-8",
    "href": "labs/lab-06.html#exercise-8",
    "title": "Lab 06: Maximum likelihood estimation",
    "section": "Exercise 8",
    "text": "Exercise 8\nNow we will look into the last property of the maximum likelihood estimator for \\(\\boldsymbol{\\beta}\\), and thus of least-squares estimator - asymptotic normality.\nIn words, this property says that, when the number of samples \\(n\\) is large compared to the number of predictors \\(p\\), the maximum likelihood estimator \\(\\tilde{\\boldsymbol\\beta}\\) follows a (multivariate) normal distribution \\(N\\big(\\boldsymbol\\beta, \\sigma_\\epsilon^2 (\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\big)\\). Let’s use this to construct an approximate confidence interval for \\(\\beta_j\\), the coefficient for speciesChinstrap.\n\nUse \\(\\tilde{\\sigma}^2_{\\epsilon}\\), the maximum likelihood estimator, to compute the approximate confidence interval for \\(\\beta_j\\) . The approximate 95% confidence interval may be computed as\n\n\\[\n\\tilde{\\beta}_j\\pm 2 \\times SE(\\tilde{\\beta}_j)\n\\]\n\nThen interpret this interval in the context of the data.",
    "crumbs": [
      "Labs",
      "Lab 06"
    ]
  },
  {
    "objectID": "labs/lab-06.html#exercise-9",
    "href": "labs/lab-06.html#exercise-9",
    "title": "Lab 06: Maximum likelihood estimation",
    "section": "Exercise 9",
    "text": "Exercise 9\n\nCompute the exact (based on the \\(t\\)-distribution) confidence interval for \\(\\beta_j\\), the coefficient of speciesChinstrap.\nCompare the center and width of the this exact interval with the one you computed in Exercise 8. Do they differ? By how much? Which one is wider, indicating more uncertainty?",
    "crumbs": [
      "Labs",
      "Lab 06"
    ]
  },
  {
    "objectID": "labs/lab-06.html#exercise-10",
    "href": "labs/lab-06.html#exercise-10",
    "title": "Lab 06: Maximum likelihood estimation",
    "section": "Exercise 10",
    "text": "Exercise 10\nTo wrap up, we have seen that both the OLS and the maximum likelihood procedures for linear regression produce the same coefficient estimates, but lead to different estimators for the variance \\(\\sigma_\\epsilon^2\\) and allow for different types of uncertainty quantification.\nBased on the work in this lab, do you think performing inference based on either method would have changed your conclusion about the the relationship between bill depth and Chinstrap species?",
    "crumbs": [
      "Labs",
      "Lab 06"
    ]
  },
  {
    "objectID": "hw/hw-04.html",
    "href": "hw/hw-04.html",
    "title": "HW 04: Logistic regression",
    "section": "",
    "text": "Due date\n\n\n\nThis assignment is due on Thursday, April 10 at 11:59pm.",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#instructions",
    "href": "hw/hw-04.html#instructions",
    "title": "HW 04: Logistic regression",
    "section": "Instructions",
    "text": "Instructions\nThe conceptual exercises are focused on explaining concepts and showing results mathematically. Show your work for each question.\n\nYou may write the answers and associated work for conceptual exercises by hand or type them in your Quarto document.",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#exercise-1",
    "href": "hw/hw-04.html#exercise-1",
    "title": "HW 04: Logistic regression",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nSuppose you have the linear regression model\n\\[\ny_i = \\beta x_i + \\epsilon_i \\hspace{8mm} \\epsilon_i \\sim N(0, \\sigma^2_{\\epsilon})\n\\]\nsuch that \\(\\epsilon_i\\) are i.i.d. and there is no intercept.\n\nFind \\(\\tilde{\\beta}\\) , the MLE of \\(\\beta\\).\nShow that the MLE is unbiased. (Note: You must show this directly and may not use the result from part(c).)\nShow mathematically how \\(\\tilde{\\beta}\\) relates to the least-squares estimator.",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#exercise-2",
    "href": "hw/hw-04.html#exercise-2",
    "title": "HW 04: Logistic regression",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nSuppose there are \\(n\\) observations, such that each \\(y_i\\) is generated from \\(x_i\\) based on the linear model\n\\[\ny_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i, \\hspace{8mm} \\epsilon_i \\sim N(0, \\sigma^2_{\\epsilon})\n\\]\nsuch that \\(\\epsilon_i\\) are i.i.d.\nThe model is reparameterized (redefined) as\n\\[\ny_i = \\beta^{\\prime}_0 + \\beta^{\\prime}_1(x_i - \\bar{x}) + \\epsilon_i\n\\]\nsuch that \\(\\epsilon_i\\) follows the same distribution as the original model.\n\nShow that the MLE of \\(\\beta^{\\prime}_1\\) is equal to the MLE of \\(\\beta_1\\).\nShow that the MLE of \\(\\beta^{\\prime}_0\\) is not equal to the MLE of \\(\\beta_0\\).\n\n\n\n\n\n\n\nTip\n\n\n\nYou do not need to derive the MLEs for \\(\\beta_0\\) and \\(\\beta_1\\). You may use the results from the notes.\nYou do need to show your work / explain your reasoning to get the MLEs for \\(\\beta^{\\prime}_0\\) and \\(\\beta^{\\prime}_1\\) .",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#exercise-31",
    "href": "hw/hw-04.html#exercise-31",
    "title": "HW 04: Logistic regression",
    "section": "Exercise 31",
    "text": "Exercise 31\n\nBerry (2001) examined the effect of a player’s draft position among the pool of potential players in a given year to the probability on eventually being named an all star.\nLet \\(d\\) be the draft position \\((d = 1, 2, 3, \\ldots)\\) and \\(\\pi\\) be the probability of eventually being named an all star. The researcher modeled the relationship between \\(d\\) and \\(\\pi\\) using the following model:\n\\[\n\\log\\Big(\\frac{\\pi_i}{1-\\pi_i}\\Big) = \\beta_0 + \\beta_1 \\log d_i\n\\]\n\nUsing this model, show that the odds of being named an all star are \\(e^{\\beta_0}d^{\\beta_1}\\) . Then, show how to calculate \\(\\pi_i\\) based on this model.\nShow that the odds of being named an all star for a first draft pick are \\(e^{\\beta_0}\\) .\nIn the study, Berry reported that for professional basketball \\(\\hat{\\beta}_0 = 2.3\\) and \\(\\hat{\\beta}_1 = -1.1\\), and for professional baseball \\(\\hat{\\beta}_0 = 0.7\\) and \\(\\hat{\\beta}_1 = -0.6\\) . Explain why this suggests that (1) being a first draft pick is more crucial for being an all star in basketball than in baseball and (2) players picked in high draft positions are relatively less likely to be all stars.",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#exercise-4",
    "href": "hw/hw-04.html#exercise-4",
    "title": "HW 04: Logistic regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nIn the paper “Employing Standardized Risk Assessment in Pretrial Release Decisions: Association With Criminal Justice Outcomes and Racial Equity” Marlowe et al. (2020) analyze the risk predictions produced by a black-box algorithm used to determine whether a defendant is considered “high risk” of being rearrested if they are released while awaiting trial. Such algorithms are used by judges in some states to help determine whether or not defendants are released while awaiting trial.\nThe authors examine the algorithm’s risk predictions and whether a person was rearrested for over 500 defendants released pretrial in a southern state. For each person, the algorithm produced one of the following predictions: “High Risk” or “Low Risk”. The observed outcome was “Rearrested” (coded as 1) or “Not Rearrested” (coded as 0). Below are some results from the analysis:\n\nSensitivity: 86%\nSpecificity: 24%\nPositive predictive power (Precision): 57%\nNegative predictive power: 60%\n\n\n\n\n\n\n\nTip\n\n\n\n\nPositive Predictive Power (Precision): P(Y = 1 | Y classified as 1 from the model)\nNegative Predictive Power: P(Y = 0 | Y classified as 0 from the model)\n\n\n\n\nExplain what each of the following mean in the context of the analysis:\n\nSensitivity\nSpecificity\nPositive predictive power (Precision)\nNegative predictive power\n\nWhat is the false positive rate? What does this value mean in the context of the analysis?",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#instructions-1",
    "href": "hw/hw-04.html#instructions-1",
    "title": "HW 04: Logistic regression",
    "section": "Instructions",
    "text": "Instructions\nThe applied exercises are focused on applying the concepts to analyze data.\nAll work for the applied exercises must be typed in your Quarto document following a reproducible workflow.\nWrite all narrative using complete sentences and include informative axis labels / titles on visualizations.",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#data-understanding-pro-environmental-behavior",
    "href": "hw/hw-04.html#data-understanding-pro-environmental-behavior",
    "title": "HW 04: Logistic regression",
    "section": "Data: Understanding pro-environmental behavior",
    "text": "Data: Understanding pro-environmental behavior\nIbanez and Roussel (2022) conducted an experiment to understand the impact of watching a nature documentary on pro-environmental behavior. The researchers randomly assigned the 113 participants to watch an video about architecture in NYC (control) or a video about Yellowstone National Park (treatment). As part of the experiment, participants played a game in which they had an opportunity to donate to an environmental organization.\nThe data set is available in nature-experiment.csv in the data folder. We will use the following variables:\n\ndonation_binary:\n\n1 - participant donated to environmental organization\n0 - participant did not donate\n\nage: Age in years\ngender: Participant’s reported gender\n\n1 - male\n0 - non-male\n\ntreatment:\n\n“URBAN (T1)” - the control group\n“NATURE (T2)” - the treatment group\n\nnep_high:\n\n1 - score of 4 or higher on the New Ecological Paradigm (NEP)\n0 - score less than 4\n\n\n\n\n\n\n\n\nTip\n\n\n\nSee the Introduction and Methods sections of Ibanez and Roussel (2022) for more detail about the variables.\nClick here to access the paper online.",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#exercise-5",
    "href": "hw/hw-04.html#exercise-5",
    "title": "HW 04: Logistic regression",
    "section": "Exercise 5",
    "text": "Exercise 5\n\nCreate a visualization of the relationship between donating and treatment. Use the visualization to describe the relationship between the two variables.\nCreate a visualization of the relationship between donating and age. Use the visualization to describe the relationship between the two variables.\nWe would like to use the mean-centered value of age in the model. Create a new variable age_cent that contains the mean-centered ages.",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#exercise-6",
    "href": "hw/hw-04.html#exercise-6",
    "title": "HW 04: Logistic regression",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nFit a logistic regression model using age_cent, gender, treatment, and nep_high to predict the likelihood of donating. Neatly display the model using 3 digits.\nThe researchers are most interested in the effect of watching the nature documentary. Describe the effect of treatment in terms of the odds of donating.\nWhat group of participants is described by the intercept? What is the predicted probability a randomly selected individual in this group donates?",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#exercise-7",
    "href": "hw/hw-04.html#exercise-7",
    "title": "HW 04: Logistic regression",
    "section": "Exercise 7",
    "text": "Exercise 7\nProduce the ROC curve for the model from the previous exercise and calculate the area under curve (AUC). Write 1 - 2 sentences describing how well the model fits the data.",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#exercise-8",
    "href": "hw/hw-04.html#exercise-8",
    "title": "HW 04: Logistic regression",
    "section": "Exercise 8",
    "text": "Exercise 8\nThe authors include an interaction effect between nep_high and treatment in one of their models.\n\nExplain what an interaction between nep_high and treatment means in the context of the data.\nCreate a visualization to explore the potential of an interaction effect between these two variables. Based on the visualization, do you think there is an interaction effect? Briefly explain.",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#exercise-9",
    "href": "hw/hw-04.html#exercise-9",
    "title": "HW 04: Logistic regression",
    "section": "Exercise 9",
    "text": "Exercise 9\nConduct a drop-in-deviance test to determine if the interaction between nep_high and treatment should be added to the model fit in Exercise 7. Include the hypotheses in mathematical notation, the output from the test, and the conclusion in the context of the data.",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#footnotes",
    "href": "hw/hw-04.html#footnotes",
    "title": "HW 04: Logistic regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nExercise adapted froman exercise in Categorical Data Analysis by Agresti.↩︎",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-03.html",
    "href": "hw/hw-03.html",
    "title": "HW 03: Conditions and variable transformations",
    "section": "",
    "text": "Due date\n\n\n\nThis assignment is due on Thursday, March 20 at 11:59pm.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#instructions",
    "href": "hw/hw-03.html#instructions",
    "title": "HW 03: Conditions and variable transformations",
    "section": "Instructions",
    "text": "Instructions\nThe conceptual exercises are focused on explaining concepts and showing results mathematically. Show your work for each question.\n\nYou may write the answers and associated work for conceptual exercises by hand or type them in your Quarto document.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-1",
    "href": "hw/hw-03.html#exercise-1",
    "title": "HW 03: Conditions and variable transformations",
    "section": "Exercise 1",
    "text": "Exercise 1\nSuppose we have a model of the form\n\\[\n\\log(y_i) =\\beta_0 + \\beta_1\\log(x_i) + \\epsilon_i \\hspace{10mm} \\epsilon_i \\sim N(0, \\sigma^2_{\\epsilon})\n\\]\nDescribe the expected change in \\(y_i\\) when \\(x_i\\) is multiplied by a constant \\(C\\). Show the work used to obtain the expected change.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-2",
    "href": "hw/hw-03.html#exercise-2",
    "title": "HW 03: Conditions and variable transformations",
    "section": "Exercise 2",
    "text": "Exercise 2\nSuppose we have a model of the form\n\\[\ny_i = \\beta_0 + \\beta_1x_i + \\epsilon_i, \\quad \\epsilon_i \\sim N(0, \\sigma^2_\\epsilon x_i^2)\n\\]\n\nThis model violates which model assumption? Briefly explain why.\nSuppose you refit the model with the transformation on \\(y\\), \\(y^\\prime = y / x\\) . Show that this is a variance-stabilizing transformation, i.e., that the variance of the response does not depend on \\(x\\).",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-3",
    "href": "hw/hw-03.html#exercise-3",
    "title": "HW 03: Conditions and variable transformations",
    "section": "Exercise 3",
    "text": "Exercise 3\nFor each of the following regression models, state whether it can be expressed in the form of a linear model by applying a suitable transformation to both sides of the equation. If so, write the equation for the transformed model.\n\n\\(y_i = \\log(\\beta_1x_{i1}) + \\beta_2x_{i2} + \\epsilon_i\\)\n\\(y_i = [1 + e^{(\\beta_0 + \\beta_1x_{i1} + \\epsilon_i)}]^{-1}\\)",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#instructions-1",
    "href": "hw/hw-03.html#instructions-1",
    "title": "HW 03: Conditions and variable transformations",
    "section": "Instructions",
    "text": "Instructions\nThe applied exercises are focused on applying the concepts to analyze data.\nAll work for the applied exercises must be typed in your Quarto document following a reproducible workflow.\nWrite all narrative using complete sentences and include informative axis labels / titles on visualizations.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#data-age-of-abalones",
    "href": "hw/hw-03.html#data-age-of-abalones",
    "title": "HW 03: Conditions and variable transformations",
    "section": "Data: Age of abalones",
    "text": "Data: Age of abalones\nThe data for this analysis contains measurements for abalones, a type of marine snail. These measurements were collected and analyzed by researchers in Warwick et al. (1994). Click here for the publication.\nThe 4177 abalones in this study can be reasonably treated as a random sample.\nThe data are available in the file abalone.csv in the data folder. This analysis will focus on the following variables:\n\nSex: Male (M), Female (F), Infant (I)\nLength: Longest shell measurement (in millimeters)\nDiameter: Measured perpendicular to length (in millimeters)\nHeight : Measured with meat in shell (in millimeters)\nWhole_Weight: Total weight of abalone (in grams)\nAge: Age (in year)\n\nThe goal of the analysis is to use a variety of measurements from abalones to explain variability in the age.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-4",
    "href": "hw/hw-03.html#exercise-4",
    "title": "HW 03: Conditions and variable transformations",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nFit a model using Sex, Length, Diameter, Height and Whole_Weight to understand variability in Age. Neatly display the model using 3 digits.\nCheck the four model conditions - Linearity, Constant Variance, Normality, and Independence. For each condition: (1) state whether or not it is satisfied; (2) explain your response showing any visualizations and/or statistics used to make your assessment.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-5",
    "href": "hw/hw-03.html#exercise-5",
    "title": "HW 03: Conditions and variable transformations",
    "section": "Exercise 5",
    "text": "Exercise 5\nNow let’s take a look at the model diagnostics.\n\nAre there any influential observations in the data set? Briefly explain, showing any work or output used to make the determination.\nConsider the observation with the highest value for Cook’s distance. What is the value of leverage for this observation? Does this observation have large leverage? Briefly explain, showing any work or output used to make the determination.\nAgain consider the observation with the highest value for Cook’s distance. What is the standardized residual for this observation? Is this observation an outlier? Briefly explain showing any work or output used to make the determination.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-6",
    "href": "hw/hw-03.html#exercise-6",
    "title": "HW 03: Conditions and variable transformations",
    "section": "Exercise 6",
    "text": "Exercise 6\nNow let’s look at the relationship between predictors.\n\nCompute the Variance Inflation Factors (VIF) for the model from Exercise 4. Display the results.\nUse the equation for VIF to “manually” compute the VIF for Whole_Weight.\nWhat predictors appear to be collinear?\nSelect a strategy to fit a model that does not have an issue with multicollinearity.\n\nBriefly describe your strategy.\nSelect a final model.\nBriefly explain your selection, showing the work and statistics used to choose a final model.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#data-2000-u.s.-presidential-election2",
    "href": "hw/hw-03.html#data-2000-u.s.-presidential-election2",
    "title": "HW 03: Conditions and variable transformations",
    "section": "Data: 2000 U.S. Presidential Election2",
    "text": "Data: 2000 U.S. Presidential Election2\n\nWe will examine data about the 2000 U.S. presidential election between George W. Bush and Al Gore. It was one of the closest elections in history that ultimately came down to the state of Florida. One county in particular, Palm Beach County, was at the center of the controversy due to the design of their ballots - the infamous butterfly ballots. It is believed that many people who intended to vote for Al Gore accidentally voted for Pat Buchanan due to how the spots to mark the candidate were arranged next to the names.\nThe variables in the data are\n\nCounty: County name\nBush2000: Number of votes for George W. Bush\nBuchanan2000: Number of votes for Pat Buchanan\n\nThe data are available in the file florida-votes-2000.csv in the data folder of your repo.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-7",
    "href": "hw/hw-03.html#exercise-7",
    "title": "HW 03: Conditions and variable transformations",
    "section": "Exercise 7",
    "text": "Exercise 7\nThe goal is to fit a model that uses the number of votes for Bush to predict the number of votes for Buchanan. Using this model, we’ll investigate whether the data support the claim that votes for Gore may have accidentally gone to Buchanan.\n\nVisualize the relationship between the number of votes for Buchanan versus the number of votes for Bush. Describe what you observe in the visualization, including a description of the relationship between the votes for Buchanan and votes for Bush.\nWhat is the county with the extreme outlier number of votes for Buchanan? Create a new data frame that doesn’t include the outlying county. You will use this updated data frame for the remainder of this exercise and Exercise 8.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-8",
    "href": "hw/hw-03.html#exercise-8",
    "title": "HW 03: Conditions and variable transformations",
    "section": "Exercise 8",
    "text": "Exercise 8\nNow let’s consider potential models with transformations on the response and/or predictor variables. The four candidate models are the following:\n\n\n\nModel\nResponse variable\nPredictor variable\n\n\n\n\n1\nBuchanan2000\nBush2000\n\n\n2\nlog(Buchanan2000)\nBush2000\n\n\n3\nBuchanan2000\nlog(Bush2000)\n\n\n4\nlog(Buchanan2000)\nlog(Bush2000)\n\n\n\nWhich model best fits the data? Briefly explain, showing any work and output used to determine the response. (Note: Use the data set without the outlying county to find the candidate models.)",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-9",
    "href": "hw/hw-03.html#exercise-9",
    "title": "HW 03: Conditions and variable transformations",
    "section": "Exercise 9",
    "text": "Exercise 9\nNow we will use the model to predict the expected number of Buchanan votes for the outlier county.\nSuppose the observed value of the predictor for this county (a new observation) is \\(x_0\\). We define \\(\\mathbf{x}_0^\\mathsf{T} = [1, x_0]\\)\nThen the predicted response is\n\\[\n\\hat{y}_0 = \\mathbf{x}_0^\\mathsf{T}\\hat{\\boldsymbol{\\beta}}\n\\]\nWhere \\(\\hat{\\boldsymbol{\\beta}}\\) is the vector of estimated model coefficients.\nJust as there is uncertainty in our model coefficients, there is uncertainty in our predictions as well. We use a confidence interval to quantify the uncertainty for a model coefficient, and we can use a prediction interval to quantify the uncertainty in the prediction for a new observation.\nThe \\(C\\%\\) prediction interval for the new observation is\n\\[\n\\hat{y}_0 \\pm t^*_{n - p - 1}\\sqrt{\\hat{\\sigma}^2_\\epsilon(1 + \\mathbf{x}_0^\\mathsf{T}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{x}_0)}\n\\]\nwhere \\(t^*_{n-p-1}\\) is the critical value obtained from the \\(t\\) distribution with \\(n - p - 1\\) degrees of freedom, \\(\\mathbf{X}\\) is the design matrix for the model, and \\(\\hat{\\sigma}^2_\\epsilon\\) is the estimated variability about the regression line.\n\nUse the model you chose in the previous exercise to compute the predicted number of votes for Buchanan in the outlying county identified in Exercise 7. If you selected a model with a transformation, be sure to report your answer in terms of votes, not log(votes).\nUse the formula above to “manually” compute the 95% prediction interval for this county (do not obtain the interval using the predict function) . If you selected a model with a transformation, be sure to report your answer in terms of votes, not log(votes).\nIt is assumed that some of the votes for Buchanan in that county were actually intended to be for Gore. Based on your results in the previous question, does your model support this claim?\n\nIf no, briefly explain.\nIf yes, about how many votes were possibly intended for Gore? Show any calculations and output used to determine your answer. If you selected a model with a transformation, be sure to report your answer in terms of votes, not log(votes).",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#footnotes",
    "href": "hw/hw-03.html#footnotes",
    "title": "HW 03: Conditions and variable transformations",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nExercise 2 is adapted from Montgomery, Peck, and Vining (2021) .↩︎\nThis analysis was motivated by exercises in (ledolter2003statistical?).↩︎",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/stats-experience.html",
    "href": "hw/stats-experience.html",
    "title": "Statistics Experience",
    "section": "",
    "text": "Important\n\n\n\nThis assignment is due on Tuesday, April 22 at 11:59pm on Gradescope.\nThe world of statistics and data science is vast and continually growing! The goal of the statistics experience assignments is to help you engage with the statistics and data science communities outside of the classroom.\nYou may submit the statistics experience assignment anytime between now and the deadline.\nEach experience has two parts:\n1️⃣ Have a statistics experience.\n2️⃣ Make a slide reflecting on your experience.\nYou must complete both parts to receive credit. The statistics experience will count as a homework grade.",
    "crumbs": [
      "Homework",
      "Statistics experience"
    ]
  },
  {
    "objectID": "hw/stats-experience.html#part-1-experience-statistics-outside-of-the-classroom",
    "href": "hw/stats-experience.html#part-1-experience-statistics-outside-of-the-classroom",
    "title": "Statistics Experience",
    "section": "Part 1: Experience statistics outside of the classroom",
    "text": "Part 1: Experience statistics outside of the classroom\nComplete an activity in one of the categories below. Under each category are suggested activities. You do not have to do one these suggested activities. You are welcome to find other activities as long as they are related to statistics/data science and they fit in one of the six categories. If there is an activity you’d like to do but you’re not sure if it qualifies for the statistics experience, just ask!\n\nCategory 1: Attend a talk or conference\nAttend an talk, panel, or conference related to statistics or data science. If you are attending a single talk or panel, it must be at least 30 minutes to count towards the statistics experience. The event can be in-person or online.\n\n\nCategory 2: Talk with a statistician/ data scientist\nTalk with someone who uses statistics in their daily work. This could include a professor, professional in industry, graduate student, etc.\n\n\nCategory 3: Listen to a podcast / watch video\nListen to a podcast or watch a video about statistics and data science. The podcasts / videos must be (1) one podcast or video that is at least 30 minutes or (2) multiple podcasts and/or videos that are at least 30 minutes combined.\nA few suggestions are below:\n\nStats + Stories Podcast\nCausal Inference Podcast\nposit::conf talks (formally called rstudio::conf)\n\n2024 conference\n2023 conference\n2022 conference\n2021 conference\n\n\nThis list is not exhaustive. You may listen to other podcasts or watch other statistics/data science videos not included on this list. Ask Professor Tackett if you are unsure whether a particular podcast or video will count towards the statistics experience.\n\n\nCategory 4: Participate in a data science competition or challenge\nParticipate in a statistics or data science competition. You can participate individually or with a team.\nNote: DataFest will be April 4 - 6 in Penn Pavilion. Click here to learn more.\n\n\nCategory 5: Read a book on statistics/data science\nThere are a lot of books about statistics, data science, and related topics. A few suggestions are below. If you decide to read a book that isn’t on this list, ask Professor Tackett to make sure it counts toward the experience. Many of these books are available through Duke library.\n\nWeapons of Math Destruction by Cathy O’Neil\nHow Charts Lie: Getting Smarter about Visual Information by Alberto Cairo\nThe Theory that Would Not Die by Sharon Bertsch McGrayne\nThe Art of Statistics: How to learn from data by David Spiegelhalter\nThe Lady Tasting Tea by David Salsburg\nList of books about data science ethics\n\nThis list is not exhaustive.\n\n\nCategory 6: TidyTuesday\nYou may also participate in a TidyTuesday challenge. New data sets are announced on Monday afternoons.You can find more information about TidyTuesday and see the data in the TidyTuesday GitHub repo.\nA few guidelines:\n✅ Create a GitHub repo for your TidyTuesday submission. Your repo should include\n\nThe R Markdown file with all the code needed to reproduce your visualization.\nA README that includes an image of your final visualization and a short summary (~ 1 paragraph) about your visualization.\n\n✅ The visualization should include features or customization that are beyond what we’ve done in class .\n✅ Include the link to your GitHub repo in the slide summarizing your experience.\n\n\nCategory 7: CURV - connecting, uplifting, and recognizing voices\nCURV is a project by Dr. Jo Hardin at Pomona College to highlight statisticians and data scientists from groups who have been historically marginalized in the discipline.\n\n\n\n\n\n\nFor this statistics experience, you can contribute to the CURV data base. If there is a scholar you would like to suggest for the data base, submit your suggestion as an issue or pull request on the CURV GitHub repo and create a sample CURV page.\nA few guidelines:\n✅ Create a draft of the CURV page for your suggested scholar. For reference, click here for the CURV page for W.E.B. Du Bois. The page must be created in a Quarto document.\n\n\n\n\n\n\nTip\n\n\n\nYou can find the Quarto documents for current scholars in the data base in the CURV GitHub repo. You can use one of these as a template to format your page.\n\n\n✅ Make a pull request to the CURV GitHub repo to add the .qmd file for your suggested scholar, OR open an issue with a link to the .qmd file for your suggested scholar. You can ask a member of the teaching team if you have questions about how to do this.\n✅ Include the URL to your pull request or issue in your one-slide reflection.",
    "crumbs": [
      "Homework",
      "Statistics experience"
    ]
  },
  {
    "objectID": "hw/stats-experience.html#part-2-reflect-on-your-experience",
    "href": "hw/stats-experience.html#part-2-reflect-on-your-experience",
    "title": "Statistics Experience",
    "section": "Part 2: Reflect on your experience",
    "text": "Part 2: Reflect on your experience\nMake one slide summarizing and reflecting on your experience. Submit the slide as a PDF on Gradescope.\nInclude the following on your slide:\n\nDescription of the experience\n\nName and brief description of the event/podcast/competition/etc.\n\nSomething you learned\n\nWrite 2 - 4 sentences about something you learned or found particularly interesting or unexpected.\n\nConnection to STA 221\n\nWrite 2 - 4 sentences about how the experience connects to what we’ve done in the course.\n\nCitation or link to web page for event/competition/etc.\n\nNo citation needed if you do an interview.\n\n\nMake sure the slide includes the information mentioned above and is easily readable (i.e. use a reasonable font size!). Creativity on the experience and slide design is encouraged!",
    "crumbs": [
      "Homework",
      "Statistics experience"
    ]
  },
  {
    "objectID": "hw/stats-experience.html#submission",
    "href": "hw/stats-experience.html#submission",
    "title": "Statistics Experience",
    "section": "Submission",
    "text": "Submission\nThis assignment is due on Tuesday, April 22 on Gradescope. Standard homework late policy applies.",
    "crumbs": [
      "Homework",
      "Statistics experience"
    ]
  },
  {
    "objectID": "prepare/prepare-lec20.html",
    "href": "prepare/prepare-lec20.html",
    "title": "Prepare for Lecture 20: Logistic regression - Prediction",
    "section": "",
    "text": "📖 Classification module in Google Machine Learning Crash Course"
  },
  {
    "objectID": "prepare/prepare-lec09.html",
    "href": "prepare/prepare-lec09.html",
    "title": "Prepare for Lecture 09: Inference for regression cont’d",
    "section": "",
    "text": "📖 Read Inference for Simple Linear Regression:\n\nSections 5.1 - 5.3\nSection 5.6\nSection 5.8\nSection 5.9"
  },
  {
    "objectID": "prepare/prepare-lec05.html",
    "href": "prepare/prepare-lec05.html",
    "title": "Prepare for Lecture 05: SLR - Matrix representation cont’d",
    "section": "",
    "text": "Review linear algebra concepts (as needed)\n\nVector geometry: [slides][video]\n\n\n\n\n\n\n\nNote\n\n\n\nAll linear algebra review materials from Math 218: Matrices and Vectors (Summer 2024) taught by Dr. Brian Fitzpatrick at Duke University"
  },
  {
    "objectID": "prepare/prepare-lec03.html",
    "href": "prepare/prepare-lec03.html",
    "title": "Prepare for Lecture 03: Model assessment",
    "section": "",
    "text": "📖 Read Model assessment\nFor computing introduction / review\n🎥 Watch Meet the Toolkit: R + RStudio\n🎥 Watch Meet the Toolkit: Quarto"
  },
  {
    "objectID": "ae/ae-03-inference.html",
    "href": "ae/ae-03-inference.html",
    "title": "AE 03: Inference",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-03 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE."
  },
  {
    "objectID": "ae/ae-03-inference.html#exercise-1",
    "href": "ae/ae-03-inference.html#exercise-1",
    "title": "AE 03: Inference",
    "section": "Exercise 1",
    "text": "Exercise 1\nWe will use the vector of responses \\(\\mathbf{y}\\) and the design matrix \\(\\mathbf{X}\\) to calculate the values needed for inference.\nGet \\(\\mathbf{y}\\) and \\(\\mathbf{X}\\) from the football data frame. What are their dimensions?"
  },
  {
    "objectID": "ae/ae-03-inference.html#exercise-2",
    "href": "ae/ae-03-inference.html#exercise-2",
    "title": "AE 03: Inference",
    "section": "Exercise 2",
    "text": "Exercise 2\nNext, let’s calculate \\(\\hat{\\sigma}_\\epsilon^2\\) the estimated regression standard error. Use \\(\\mathbf{y}\\) and \\(\\mathbf{X}\\) from the previous exercise to calculate this value."
  },
  {
    "objectID": "ae/ae-03-inference.html#exercise-3",
    "href": "ae/ae-03-inference.html#exercise-3",
    "title": "AE 03: Inference",
    "section": "Exercise 3",
    "text": "Exercise 3\nNow we’re ready to conduct the hypothesis test between enrollment and football expenditures. State the null and alternative hypotheses in words and using mathematical notation."
  },
  {
    "objectID": "ae/ae-03-inference.html#exercise-4",
    "href": "ae/ae-03-inference.html#exercise-4",
    "title": "AE 03: Inference",
    "section": "Exercise 4",
    "text": "Exercise 4\nCalculate \\(SE(\\hat{\\beta}_j)\\), then use this value to calculate the test statistic for the hypothesis test."
  },
  {
    "objectID": "ae/ae-03-inference.html#exercise-5",
    "href": "ae/ae-03-inference.html#exercise-5",
    "title": "AE 03: Inference",
    "section": "Exercise 5",
    "text": "Exercise 5\nNow we need to calculate p-value to help make our final conclusion.\n\nState the distribution used to calculate the p-value.\nFill in the code below to calculate the p-value. Remove #| eval: false once you’ve filled in the code.\n\n\n2 * pt([test-statistic], [df], lower.tail = FALSE)"
  },
  {
    "objectID": "ae/ae-03-inference.html#exercise-6",
    "href": "ae/ae-03-inference.html#exercise-6",
    "title": "AE 03: Inference",
    "section": "Exercise 6",
    "text": "Exercise 6\nState your conclusion in the context of the data. Use a threshold of \\(\\alpha = 0.05\\).\n\n\n\n\n\n\nSubmission\n\n\n\nTo submit the AE:\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your AE repo on GitHub. You’re done! 🎉"
  },
  {
    "objectID": "ae/ae-07-newton-raphson.html",
    "href": "ae/ae-07-newton-raphson.html",
    "title": "AE 07: Newton Raphson",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-07 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE.\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(tidymodels)"
  },
  {
    "objectID": "ae/ae-07-newton-raphson.html#covid-19-infection-prevention-practices-at-food-establishments",
    "href": "ae/ae-07-newton-raphson.html#covid-19-infection-prevention-practices-at-food-establishments",
    "title": "AE 07: Newton Raphson",
    "section": "COVID-19 infection prevention practices at food establishments",
    "text": "COVID-19 infection prevention practices at food establishments\nResearchers at Wollo University in Ethiopia conducted a study in July and August 2020 to understand factors associated with good COVID-19 infection prevention practices at food establishments. Their study is published in Andualem et al. (2022).\nThey were particularly interested in the understanding implementation of prevention practices at food establishments, given the workers’ increased risk due to daily contact with customers.\nWe will use the data from Andualem et al. (2022) to explore the association between age, sex, years of service, and whether someone works at a food establishment with access to personal protective equipment (PPE) as of August 2020. We will use access to PPE as a proxy for wearing PPE.\nThe study participants were selected using a simple random sampling at the selected establishments.\n.\n\ncovid_df &lt;- read_csv(\"data/covid-prevention-study.csv\") |&gt;\n  rename(age = \"Age of food handlers\", \n         years = \"Years of service\", \n         ppe_access = \"Availability of PPEs\") |&gt;\n  mutate(sex = factor(if_else(Sex == 2, \"Female\", \"Male\")),\n         ppe_access = as_factor(ppe_access))"
  },
  {
    "objectID": "ae/ae-07-newton-raphson.html#functions-for-newton-raphson",
    "href": "ae/ae-07-newton-raphson.html#functions-for-newton-raphson",
    "title": "AE 07: Newton Raphson",
    "section": "Functions for Newton-Raphson",
    "text": "Functions for Newton-Raphson\n\n## Calculate the first derivative of logL (score function)\n\ncalc_first_deriv &lt;- function(beta, X, y){\n  first_deriv &lt;- rep(0, length(beta))\n  for(i in 1:length(y)){\n    first_deriv &lt;- first_deriv + as.numeric(y[i] - exp(X[i,] %*% beta)/(1 + exp(X[i,] %*% beta))) %*% X[i,]\n  }\n  return(colSums(first_deriv)) #return values as a vector \n}\n\n## Calculate the second derivative of logL (Hessian)\n\ncalc_second_deriv &lt;- function(beta, X, y){\n  second_deriv &lt;- matrix(0, nrow = length(beta), ncol = length(beta))\n  for(i in 1:length(y)){\n    second_deriv &lt;- second_deriv + as.numeric(1/(1 + exp(X[i,] %*% beta)))*\n      as.numeric((exp(X[i,] %*% beta)/(1 + exp(X[i,] %*% beta)))) * \n      (X[i,]) %*% t(X[i,])\n  }\n  return(second_deriv)\n}"
  },
  {
    "objectID": "ae/ae-07-newton-raphson.html#get-starting-values",
    "href": "ae/ae-07-newton-raphson.html#get-starting-values",
    "title": "AE 07: Newton Raphson",
    "section": "Get starting values",
    "text": "Get starting values\n\n# design matrix\nX &lt;- model.matrix(~ age + sex + years, data = covid_df)\n\n# vector of response\ny &lt;- I(covid_df$ppe_access == 1)\n\n# vector of coefficients\nbeta &lt;- c(0, 0, 0, 0)\n\n# keep track of iterations\niter &lt;- 1\n\n# keep track of difference in estimates\ndelta &lt;- 1\n\n# keep track of estimates at each iteration \ntemp &lt;- matrix(0, nrow = 500, ncol = 4)"
  },
  {
    "objectID": "ae/ae-07-newton-raphson.html#estimate-boldsymbolbeta",
    "href": "ae/ae-07-newton-raphson.html#estimate-boldsymbolbeta",
    "title": "AE 07: Newton Raphson",
    "section": "Estimate \\(\\boldsymbol{\\beta}\\)",
    "text": "Estimate \\(\\boldsymbol{\\beta}\\)\n\nwhile(delta &gt; 0.000001 & iter &lt; 50){\n  old &lt;- beta\n  beta &lt;- old - solve(-1 * calc_second_deriv(beta = beta, X = X, y = y)) %*% \n                calc_first_deriv(beta = beta, X = X, y = y)\n  temp[iter,] &lt;- beta\n  delta &lt;- sqrt(sum((beta - old)^2))\n  iter &lt;- iter + 1\n}"
  },
  {
    "objectID": "ae/ae-07-newton-raphson.html#show-results",
    "href": "ae/ae-07-newton-raphson.html#show-results",
    "title": "AE 07: Newton Raphson",
    "section": "Show results",
    "text": "Show results\n\niter\n\n[1] 7\n\nbeta\n\n                   [,1]\n(Intercept) -2.12709823\nage          0.05586608\nsexMale      0.34070061\nyears        0.26396205\n\n\nNote that \\((\\nabla^2_{\\boldsymbol{\\beta}} \\log L)^{-1}\\)is the estimate for \\(Var(\\boldsymbol{\\hat{\\beta}})\\) . The square root of the diagonal elements are the estimates for \\(SE(\\hat{\\boldsymbol{\\beta}})\\).\n\n#calculate the hessian matrix\nsecond_deriv &lt;- calc_second_deriv(beta = beta, X = X, y = y)\n  \n# take the inverse\ninv_second_deriv &lt;- solve(second_deriv)\n\n# get estimates for SE\nse_beta &lt;- sqrt(diag(inv_second_deriv))\n\nse_beta\n\n[1] 0.45832580 0.01740581 0.22360561 0.06583117"
  },
  {
    "objectID": "ae/ae-07-newton-raphson.html#coefficient-estimates-from-glm",
    "href": "ae/ae-07-newton-raphson.html#coefficient-estimates-from-glm",
    "title": "AE 07: Newton Raphson",
    "section": "Coefficient estimates from glm",
    "text": "Coefficient estimates from glm\n\nppe_model &lt;- glm(ppe_access ~ age + sex + years, \n                 data = covid_df, family = binomial)\ntidy(ppe_model, conf.int = TRUE) |&gt;\n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-2.127\n0.458\n-4.641\n0.000\n-3.058\n-1.257\n\n\nage\n0.056\n0.017\n3.210\n0.001\n0.023\n0.091\n\n\nsexMale\n0.341\n0.224\n1.524\n0.128\n-0.098\n0.780\n\n\nyears\n0.264\n0.066\n4.010\n0.000\n0.143\n0.401"
  },
  {
    "objectID": "ae/ae-01-model-assessment.html",
    "href": "ae/ae-01-model-assessment.html",
    "title": "AE 01: Model assessment",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-01 repo to get started.\nIf you do not see an ae-01 repo, use the link below to create one:\nhttps://classroom.github.com/a/6jpkfA8n\nRender, commit, and push your responses to GitHub by the end of class to submit your AE.\n\n\nThis AE will not count towards your participation grade.\nlibrary(tidyverse)    # data wrangling and visualization\nlibrary(tidymodels)   # broom and yardstick package\nlibrary(knitr)        # format output"
  },
  {
    "objectID": "ae/ae-01-model-assessment.html#exercise-1",
    "href": "ae/ae-01-model-assessment.html#exercise-1",
    "title": "AE 01: Model assessment",
    "section": "Exercise 1",
    "text": "Exercise 1\nFit a model using income equality to understand variability in life expectancy. Neatly display the results using 3 digits.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-01-model-assessment.html#exercise-2",
    "href": "ae/ae-01-model-assessment.html#exercise-2",
    "title": "AE 01: Model assessment",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nInterpret the slope in the context of the data.\nDoes it make sense to interpret the intercept? If so, interpret it in the context of the data. Otherwise, explain why not."
  },
  {
    "objectID": "ae/ae-01-model-assessment.html#exercise-3",
    "href": "ae/ae-01-model-assessment.html#exercise-3",
    "title": "AE 01: Model assessment",
    "section": "Exercise 3",
    "text": "Exercise 3\nFit a model using health_expend to understand variability in life_exp. Compute \\(R^2\\) and \\(RMSE\\) for this model.\n\n# add code here\n\n\nInterpret \\(R^2\\) in the context of the data.\nInterpret \\(RMSE\\) in the context for the data."
  },
  {
    "objectID": "ae/ae-01-model-assessment.html#exercise-4",
    "href": "ae/ae-01-model-assessment.html#exercise-4",
    "title": "AE 01: Model assessment",
    "section": "Exercise 4",
    "text": "Exercise 4\nWhich measure of healthcare expenditure would you choose as a predictor of life expectancy - health_expend or health_pct_gdp? Briefly explain, using \\(R^2\\) and/or \\(RMSE\\) to support your choice.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-multicollinearity.html",
    "href": "ae/ae-04-multicollinearity.html",
    "title": "AE 04: Multicollinearity",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-04 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE.\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(tidymodels)\nlibrary(rms) #calculate VIF"
  },
  {
    "objectID": "ae/ae-04-multicollinearity.html#exercise-1",
    "href": "ae/ae-04-multicollinearity.html#exercise-1",
    "title": "AE 04: Multicollinearity",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nFit the regression model using high temperature, average temperature, season, and precipitation to predict volume.\nAre there any coefficients that may be not what you expected?"
  },
  {
    "objectID": "ae/ae-04-multicollinearity.html#exercise-2",
    "href": "ae/ae-04-multicollinearity.html#exercise-2",
    "title": "AE 04: Multicollinearity",
    "section": "Exercise 2",
    "text": "Exercise 2\nUse the formula\n\\[\nVIF_j = \\frac{1}{1 - R^2_j}\n\\]\nto calculate the VIF for avgtemp."
  },
  {
    "objectID": "ae/ae-04-multicollinearity.html#exercise-3",
    "href": "ae/ae-04-multicollinearity.html#exercise-3",
    "title": "AE 04: Multicollinearity",
    "section": "Exercise 3",
    "text": "Exercise 3\nBased on the VIF from the previous exercise, does avgtemp have a linear dependency with one or more other predictors? Explain."
  },
  {
    "objectID": "ae/ae-04-multicollinearity.html#exercise-4",
    "href": "ae/ae-04-multicollinearity.html#exercise-4",
    "title": "AE 04: Multicollinearity",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nUse the vif function to compute VIF for all the predictors in Exercise 1.\nAre there predictors with near-linear dependencies? If so, which ones?"
  },
  {
    "objectID": "ae/ae-04-multicollinearity.html#exercise-5",
    "href": "ae/ae-04-multicollinearity.html#exercise-5",
    "title": "AE 04: Multicollinearity",
    "section": "Exercise 5",
    "text": "Exercise 5\nLet’s address the issue of multicollinearity. Choose a strategy to address the multicollinearity. Apply it, then use relevant statistics to select a final model."
  },
  {
    "objectID": "support.html",
    "href": "support.html",
    "title": "Course support",
    "section": "",
    "text": "We expect everyone will have questions at some point in the semester, so we want to make sure you can identify when that is and feel comfortable seeking help.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#lectures-and-labs",
    "href": "support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#office-hours",
    "href": "support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage you to take advantage of them!\nMake a pledge to stop by office hours at least once during the first three weeks of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of the teaching team’s office hours here.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#ed-discussion",
    "href": "support.html#ed-discussion",
    "title": "Course support",
    "section": "Ed Discussion",
    "text": "Ed Discussion\nOutside of class and office hours, any general questions about course content or assignments should be posted on Ed Discussion. There is a chance another student has already asked a similar question, so please check the other posts on Ed Discussion before adding a new question. If you know the answer to a question that is posted, I encourage you to respond!",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#email",
    "href": "support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nIf you have questions about personal matters that are not appropriate for the class discussion forum (e.g. illness, accommodations, etc.), you may me at maria.tackett@duke.edu. If you email me, please include “STA 221” in the subject line. Barring extenuating circumstances, I will respond to STA 221 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#academic-support",
    "href": "support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThere are times may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#mental-health-and-wellness",
    "href": "support.html#mental-health-and-wellness",
    "title": "Course support",
    "section": "Mental health and wellness",
    "text": "Mental health and wellness\n\nDukeReach: Provides comprehensive outreach services to identify and support students in managing all aspects of well being. If you have concerns about a student’s behavior or health visit the website for resources and assistance. Go to studentaffairs.duke.edu/dukereach\nCounseling and Psychological Services (CAPS): CAPS services include individual, group, and couples counseling services, health coaching, psychiatric services, and workshops and discussions. (919) 660-1000 or students.duke.edu/wellness/caps\nTimelyCare (formerly known as Blue Devils Care): An online platform that is a convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling. bluedevilscare.duke.edu",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#technology-accommodations",
    "href": "support.html#technology-accommodations",
    "title": "Course support",
    "section": "Technology accommodations",
    "text": "Technology accommodations\nHighly aided students who have limited access to computers may request loaner laptops through the DukeLIFE Technology Assistance Program. Please note that supplies are limited.\nNote that we will be using Duke’s computational resources in this course. These resources are freely available to you. As long as your computer can connect to the internet and open a browser window, you can perform the necessary computing for this course. All software we use is open-source and/or freely available.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#course-materials-costs",
    "href": "support.html#course-materials-costs",
    "title": "Course support",
    "section": "Course materials costs",
    "text": "Course materials costs\nThere are no costs associated with this course. All readings will come from freely available, open resources (open-source textbooks, journal articles, etc.).",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#assistance-with-zoom-or-canvas",
    "href": "support.html#assistance-with-zoom-or-canvas",
    "title": "Course support",
    "section": "Assistance with Zoom or Canvas",
    "text": "Assistance with Zoom or Canvas\nFor technical help with Canvas or Zoom, contact the Duke OIT Service Desk at oit.duke.edu/help. You can also access the self-service help documentation for Zoom here and for Canvas here.\nZoom will be used for online office hours as well as as a backup option should we need to hold the course online instead of in person.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "To access computing resources for the introductory data science courses offered by the Duke University Department of Statistical Science, go to the Duke Container Manager website, cmgr.oit.duke.edu/containers.\nIf this is your first time accessing the containers, click on reserve STA221 on the Reservations available menu on the right. You only need to do this once, and when you do, you’ll see this container moved to the My reservations menu on the left.\nNext, click on STA221 under My reservations to access the RStudio instance you’ll use for the course.",
    "crumbs": [
      "Computing",
      "Access"
    ]
  },
  {
    "objectID": "slides/lab-02.html#goals",
    "href": "slides/lab-02.html#goals",
    "title": "Lab 02",
    "section": "Goals",
    "text": "Goals\n\nLaTex in this course\nLab 02: Linear regression"
  },
  {
    "objectID": "slides/lab-02.html#latex-in-this-class",
    "href": "slides/lab-02.html#latex-in-this-class",
    "title": "Lab 02",
    "section": "LaTex in this class",
    "text": "LaTex in this class\nFor this class you will need to be able to…\n\nProperly write mathematical symbols, e.g., \\(\\beta_1\\) not B1, \\(R^2\\) not R2\nWrite basic regression equations, e.g., \\(\\hat{y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2\\)\nWrite matrix equations: \\(\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\\)\nWrite hypotheses (we’ll start this next week), e.g., \\(H_0: \\beta = 0\\)\n\nYou are welcome to but not required to write math proofs using LaTex."
  },
  {
    "objectID": "slides/lab-02.html#writing-latex",
    "href": "slides/lab-02.html#writing-latex",
    "title": "Lab 02",
    "section": "Writing LaTex",
    "text": "Writing LaTex\nInline: Your mathematics will display within the line of text.\n\nUse $ to start and end your LaTex syntax. You can also use the menu: Insert -&gt; LaTex Math -&gt; Inline Math.\nExample: The text The linear regression model is $\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}$ produces\nThe linear regression model is \\(\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\\)"
  },
  {
    "objectID": "slides/lab-02.html#writing-latex-1",
    "href": "slides/lab-02.html#writing-latex-1",
    "title": "Lab 02",
    "section": "Writing LaTex",
    "text": "Writing LaTex\nDisplay: Your mathematics will display outside the line of text\n\nUse a $$ to start and end your LaTex syntax. You can also use the menu: Insert -&gt; LaTex Math -&gt; Display Math.\nExample: The text The estimated regression equation is $$\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}$$ produces\nThe estimated regression equation is\n\n\\[\n\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}\n\\]\n\n\n\n\n\n\nTip\n\n\nClick here for a quick reference of LaTex code."
  },
  {
    "objectID": "slides/lab-02.html#describing-bivariate-relationships",
    "href": "slides/lab-02.html#describing-bivariate-relationships",
    "title": "Lab 02",
    "section": "Describing bivariate relationships",
    "text": "Describing bivariate relationships\nDescribe the relationship between the price and width of Ikea sofas, armchairs, and bookcases/shelving."
  },
  {
    "objectID": "slides/lab-02.html#lab-02-linear-regression",
    "href": "slides/lab-02.html#lab-02-linear-regression",
    "title": "Lab 02",
    "section": "Lab 02: Linear regression",
    "text": "Lab 02: Linear regression\nToday’s lab focuses on using simple and multiple linear regression to understand variability in coffee quality ratings.\n\n🔗 sta221-sp25.netlify.app/labs/lab-02.html"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html",
    "href": "slides/15-transformations-contd-notes.html",
    "title": "Variable transformations cont’d",
    "section": "",
    "text": "HW 03 due March 20 at 11:59pm\nNext project milestone: Exploratory data analysis due March 20\n\nWork on it in lab March 7\n\n\n\n\nHave a good spring break! 😎"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#announcements",
    "href": "slides/15-transformations-contd-notes.html#announcements",
    "title": "Variable transformations cont’d",
    "section": "",
    "text": "HW 03 due March 20 at 11:59pm\nNext project milestone: Exploratory data analysis due March 20\n\nWork on it in lab March 7\n\n\n\n\nHave a good spring break! 😎"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#computing-set-up",
    "href": "slides/15-transformations-contd-notes.html#computing-set-up",
    "title": "Variable transformations cont’d",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#topics",
    "href": "slides/15-transformations-contd-notes.html#topics",
    "title": "Variable transformations cont’d",
    "section": "Topics",
    "text": "Topics\n\nLog-transformation on the predictor\nIdentify linear models"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#data-life-expectancy-in-140-countries",
    "href": "slides/15-transformations-contd-notes.html#data-life-expectancy-in-140-countries",
    "title": "Variable transformations cont’d",
    "section": "Data: Life expectancy in 140 countries",
    "text": "Data: Life expectancy in 140 countries\nThe data set comes from Zarulli et al. (2021) who analyze the effects of a country’s healthcare expenditures and other factors on the country’s life expectancy. The data are originally from the Human Development Database and World Health Organization.\nThere are 140 countries (observations) in the data set.\n\n\nClick here for the original research paper."
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#variables",
    "href": "slides/15-transformations-contd-notes.html#variables",
    "title": "Variable transformations cont’d",
    "section": "Variables",
    "text": "Variables\n\nlife_exp: The average number of years that a newborn could expect to live, if he or she were to pass through life exposed to the sex- and age-specific death rates prevailing at the time of his or her birth, for a specific year, in a given country, territory, or geographic income_inequality. ( from the World Health Organization)\nincome_inequality: Measure of the deviation of the distribution of income among individuals or households within a country from a perfectly equal distribution. A value of 0 represents absolute equality, a value of 100 absolute inequality (based on Gini coefficient). (from Zarulli et al. (2021))"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#variables-1",
    "href": "slides/15-transformations-contd-notes.html#variables-1",
    "title": "Variable transformations cont’d",
    "section": "Variables",
    "text": "Variables\n\neducation: Indicator of whether a country’s education index is above (High) or below (Low) the median index for the 140 countries in the data set.\n\nEducation index: Average of mean years of schooling (of adults) and expected years of school (of children), both expressed as an index obtained by scaling wit the corresponding maxima.\n\nhealth_expend: Per capita current spending on on healthcare goods and services, expressed in respective currency - international Purchasing Power Parity (PPP) dollar (from the World Health Organization)"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#variability-in-life-expectancy",
    "href": "slides/15-transformations-contd-notes.html#variability-in-life-expectancy",
    "title": "Variable transformations cont’d",
    "section": "Variability in life expectancy",
    "text": "Variability in life expectancy\nLet’s consider a model using a country’s healthcare expenditure, income inequality, and education to predict its life expectancy"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#original-model",
    "href": "slides/15-transformations-contd-notes.html#original-model",
    "title": "Variable transformations cont’d",
    "section": "Original model",
    "text": "Original model\n\nlife_exp_fit &lt;- lm(life_exp ~ health_expenditure + income_inequality + education, \n                   data = health_data)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n78.575\n1.775\n44.274\n0.000\n\n\nhealth_expenditure\n0.001\n0.000\n4.522\n0.000\n\n\nincome_inequality\n-0.484\n0.061\n-7.900\n0.000\n\n\neducationHigh\n2.020\n1.168\n1.730\n0.086"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#original-model-residuals",
    "href": "slides/15-transformations-contd-notes.html#original-model-residuals",
    "title": "Variable transformations cont’d",
    "section": "Original model: Residuals",
    "text": "Original model: Residuals\n\n\n\n\n\n\n\n\n\n\nLook at residuals vs. each predictor to determine which variable has non-linear relationship with life expectancy."
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#residuals-vs.-predictors",
    "href": "slides/15-transformations-contd-notes.html#residuals-vs.-predictors",
    "title": "Variable transformations cont’d",
    "section": "Residuals vs. predictors",
    "text": "Residuals vs. predictors\n\n\n\n\n\n\n\n\n\n. . .\n\nThere is a non-linear relationship is between health expenditure and life expectancy."
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#log-transformation-on-x",
    "href": "slides/15-transformations-contd-notes.html#log-transformation-on-x",
    "title": "Variable transformations cont’d",
    "section": "Log Transformation on \\(X\\)",
    "text": "Log Transformation on \\(X\\)\nTry a transformation on \\(X\\) if the scatterplot in EDA shows non-linear relationship and residuals vs. fitted looks parabolic"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#eda",
    "href": "slides/15-transformations-contd-notes.html#eda",
    "title": "Variable transformations cont’d",
    "section": "EDA",
    "text": "EDA"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#model-with-transformation-on-x_j",
    "href": "slides/15-transformations-contd-notes.html#model-with-transformation-on-x_j",
    "title": "Variable transformations cont’d",
    "section": "Model with Transformation on \\(X_j\\)",
    "text": "Model with Transformation on \\(X_j\\)\nWhen we fit a model with predictor \\(\\log(X_j)\\), we fit a model of the form\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}, \\quad \\boldsymbol{\\epsilon} \\sim N(\\mathbf{0}, \\sigma^2_{\\epsilon}\\mathbf{I})\n\\]\nsuch that \\(\\mathbf{X}\\) has a column for \\(\\log(X_j)\\) .\n. . .\nThe estimated regression model is\n\\[\n\\begin{aligned}\n\\hat{\\mathbf{y}} &= \\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\\\[8pt]\n\\Rightarrow \\quad &\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1x_{i1} + \\ldots + \\hat{\\beta}_j\\log(x_{ij}) + \\dots + \\hat{\\beta}_px_{ip}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#model-interpretation",
    "href": "slides/15-transformations-contd-notes.html#model-interpretation",
    "title": "Variable transformations cont’d",
    "section": "Model interpretation",
    "text": "Model interpretation\n\\[\n\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1x_{i1} + \\ldots + \\hat{\\beta}_j\\log(x_{ij}) + \\dots + \\hat{\\beta}_px_{ip}\n\\]\n\n\nIntercept: When \\(x_{i1} = \\dots = \\log(x_{ij}) = \\dots = x_{ip} = 0\\) , \\(y_i\\) is expected to be \\(\\hat{\\beta}_0\\), on average.\n\n\\(\\log(x_{ij}) = 0\\) when \\(x_{ij} = 1\\)\n\nCoefficient of \\(X_j\\): When \\(x_{ij}\\) is multiplied by a factor of \\(C\\), \\(y_i\\) is expected to change by \\(\\hat{\\beta}_j\\log(C)\\) units, on average, holding all else constant.\n\nExample: When \\(x_{ij}\\) is multiplied by a factor of 2, \\(y_i\\) is expected to increase by \\(\\hat{\\beta}_j\\log(2)\\) units, on average, holding all else constant."
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#model-with-logx",
    "href": "slides/15-transformations-contd-notes.html#model-with-logx",
    "title": "Variable transformations cont’d",
    "section": "Model with log(X)",
    "text": "Model with log(X)\n\nlife_exp_logx_fit &lt;- lm(life_exp ~ log(health_expenditure) + income_inequality \n                        + education, data = health_data)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n59.151\n3.184\n18.576\n0.000\n\n\nlog(health_expenditure)\n3.092\n0.396\n7.814\n0.000\n\n\nincome_inequality\n-0.362\n0.058\n-6.225\n0.000\n\n\neducationHigh\n-0.168\n1.103\n-0.152\n0.879\n\n\n\n\n\n\n\n\nInterpret the intercept in the context of the data.\nInterpret the effect of health expenditure in the context of the data.\nInterpret the effect of education in the context of the data."
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#model-with-logx-residuals",
    "href": "slides/15-transformations-contd-notes.html#model-with-logx-residuals",
    "title": "Variable transformations cont’d",
    "section": "Model with log(X): Residuals",
    "text": "Model with log(X): Residuals"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#comparing-residual-plots",
    "href": "slides/15-transformations-contd-notes.html#comparing-residual-plots",
    "title": "Variable transformations cont’d",
    "section": "Comparing residual plots",
    "text": "Comparing residual plots\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs a model with log-transformed response and/or predictor still a “linear” model?"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#linear-model",
    "href": "slides/15-transformations-contd-notes.html#linear-model",
    "title": "Variable transformations cont’d",
    "section": "“Linear” model",
    "text": "“Linear” model\nWhat does it mean for a model to be a “linear” model?\n\nLinear models are linear in the parameters, i.e. given an observation \\(y_i\\)\n\\[\ny_i = \\beta_0 + \\beta_1f(x_{i1}) + \\dots + \\beta_pf(x_{ip}) + \\epsilon_i\n\\]\nThe functions \\(f_1, \\ldots, f_p\\) can be non-linear as long as \\(\\beta_0, \\beta_1, \\ldots, \\beta_p\\) are linear in \\(Y\\)"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#identify-the-linear-models",
    "href": "slides/15-transformations-contd-notes.html#identify-the-linear-models",
    "title": "Variable transformations cont’d",
    "section": "Identify the linear models",
    "text": "Identify the linear models\n\n\n\n\\(y_i = \\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i1}^2 + \\beta_3x_{i2}  + \\epsilon_i\\)\n\\(y_i = \\beta_1x_{i1} + \\beta_2x_{i2} + \\beta_3x_{i1}x_{i2} + \\epsilon_i\\)\n\\(y_i = \\beta_0  + \\beta_1\\sin(x_{i1} + \\beta_2x_{i2}) + \\beta_3x_{i3} + \\epsilon_i\\)\n\\(y_i = \\beta_0 + \\beta_1e^{x_{i1}} + \\beta_2e^{x_{i2}} + \\epsilon_i\\)\n\\(y_i =e^{(\\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i2} + \\beta_3x_{i3})} + \\epsilon_i\\)"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#learn-more",
    "href": "slides/15-transformations-contd-notes.html#learn-more",
    "title": "Variable transformations cont’d",
    "section": "Learn more",
    "text": "Learn more\nSee Log Transformations in Linear Regression for more details about interpreting regression models with log-transformed variables."
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#recap",
    "href": "slides/15-transformations-contd-notes.html#recap",
    "title": "Variable transformations cont’d",
    "section": "Recap",
    "text": "Recap\n\nIntroduced log-transformation on the predictor\nIdentified linear models"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#remaining-questions",
    "href": "slides/15-transformations-contd-notes.html#remaining-questions",
    "title": "Variable transformations cont’d",
    "section": "Remaining questions?",
    "text": "Remaining questions?\nPlease submit any questions you have about multicollinearity and variable transformations."
  },
  {
    "objectID": "slides/15-transformations-contd.html#announcements",
    "href": "slides/15-transformations-contd.html#announcements",
    "title": "Variable transformations cont’d",
    "section": "Announcements",
    "text": "Announcements\n\nHW 03 due March 20 at 11:59pm\nNext project milestone: Exploratory data analysis due March 20\n\nWork on it in lab March 7\n\n\n\n\nHave a good spring break! 😎"
  },
  {
    "objectID": "slides/15-transformations-contd.html#computing-set-up",
    "href": "slides/15-transformations-contd.html#computing-set-up",
    "title": "Variable transformations cont’d",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/15-transformations-contd.html#topics",
    "href": "slides/15-transformations-contd.html#topics",
    "title": "Variable transformations cont’d",
    "section": "Topics",
    "text": "Topics\n\nLog-transformation on the predictor\nIdentify linear models"
  },
  {
    "objectID": "slides/15-transformations-contd.html#data-life-expectancy-in-140-countries",
    "href": "slides/15-transformations-contd.html#data-life-expectancy-in-140-countries",
    "title": "Variable transformations cont’d",
    "section": "Data: Life expectancy in 140 countries",
    "text": "Data: Life expectancy in 140 countries\nThe data set comes from Zarulli et al. (2021) who analyze the effects of a country’s healthcare expenditures and other factors on the country’s life expectancy. The data are originally from the Human Development Database and World Health Organization.\nThere are 140 countries (observations) in the data set.\n\n\nClick here for the original research paper."
  },
  {
    "objectID": "slides/15-transformations-contd.html#variables",
    "href": "slides/15-transformations-contd.html#variables",
    "title": "Variable transformations cont’d",
    "section": "Variables",
    "text": "Variables\n\nlife_exp: The average number of years that a newborn could expect to live, if he or she were to pass through life exposed to the sex- and age-specific death rates prevailing at the time of his or her birth, for a specific year, in a given country, territory, or geographic income_inequality. ( from the World Health Organization)\nincome_inequality: Measure of the deviation of the distribution of income among individuals or households within a country from a perfectly equal distribution. A value of 0 represents absolute equality, a value of 100 absolute inequality (based on Gini coefficient). (from Zarulli et al. (2021))"
  },
  {
    "objectID": "slides/15-transformations-contd.html#variables-1",
    "href": "slides/15-transformations-contd.html#variables-1",
    "title": "Variable transformations cont’d",
    "section": "Variables",
    "text": "Variables\n\neducation: Indicator of whether a country’s education index is above (High) or below (Low) the median index for the 140 countries in the data set.\n\nEducation index: Average of mean years of schooling (of adults) and expected years of school (of children), both expressed as an index obtained by scaling wit the corresponding maxima.\n\nhealth_expend: Per capita current spending on on healthcare goods and services, expressed in respective currency - international Purchasing Power Parity (PPP) dollar (from the World Health Organization)"
  },
  {
    "objectID": "slides/15-transformations-contd.html#variability-in-life-expectancy",
    "href": "slides/15-transformations-contd.html#variability-in-life-expectancy",
    "title": "Variable transformations cont’d",
    "section": "Variability in life expectancy",
    "text": "Variability in life expectancy\nLet’s consider a model using a country’s healthcare expenditure, income inequality, and education to predict its life expectancy"
  },
  {
    "objectID": "slides/15-transformations-contd.html#original-model",
    "href": "slides/15-transformations-contd.html#original-model",
    "title": "Variable transformations cont’d",
    "section": "Original model",
    "text": "Original model\n\nlife_exp_fit &lt;- lm(life_exp ~ health_expenditure + income_inequality + education, \n                   data = health_data)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n78.575\n1.775\n44.274\n0.000\n\n\nhealth_expenditure\n0.001\n0.000\n4.522\n0.000\n\n\nincome_inequality\n-0.484\n0.061\n-7.900\n0.000\n\n\neducationHigh\n2.020\n1.168\n1.730\n0.086"
  },
  {
    "objectID": "slides/15-transformations-contd.html#original-model-residuals",
    "href": "slides/15-transformations-contd.html#original-model-residuals",
    "title": "Variable transformations cont’d",
    "section": "Original model: Residuals",
    "text": "Original model: Residuals\n\n\nLook at residuals vs. each predictor to determine which variable has non-linear relationship with life expectancy."
  },
  {
    "objectID": "slides/15-transformations-contd.html#residuals-vs.-predictors",
    "href": "slides/15-transformations-contd.html#residuals-vs.-predictors",
    "title": "Variable transformations cont’d",
    "section": "Residuals vs. predictors",
    "text": "Residuals vs. predictors\n\n\n\nThere is a non-linear relationship is between health expenditure and life expectancy."
  },
  {
    "objectID": "slides/15-transformations-contd.html#log-transformation-on-x",
    "href": "slides/15-transformations-contd.html#log-transformation-on-x",
    "title": "Variable transformations cont’d",
    "section": "Log Transformation on \\(X\\)",
    "text": "Log Transformation on \\(X\\)\nTry a transformation on \\(X\\) if the scatterplot in EDA shows non-linear relationship and residuals vs. fitted looks parabolic"
  },
  {
    "objectID": "slides/15-transformations-contd.html#eda",
    "href": "slides/15-transformations-contd.html#eda",
    "title": "Variable transformations cont’d",
    "section": "EDA",
    "text": "EDA"
  },
  {
    "objectID": "slides/15-transformations-contd.html#model-with-transformation-on-x_j",
    "href": "slides/15-transformations-contd.html#model-with-transformation-on-x_j",
    "title": "Variable transformations cont’d",
    "section": "Model with Transformation on \\(X_j\\)",
    "text": "Model with Transformation on \\(X_j\\)\nWhen we fit a model with predictor \\(\\log(X_j)\\), we fit a model of the form\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}, \\quad \\boldsymbol{\\epsilon} \\sim N(\\mathbf{0}, \\sigma^2_{\\epsilon}\\mathbf{I})\n\\]\nsuch that \\(\\mathbf{X}\\) has a column for \\(\\log(X_j)\\) .\n\nThe estimated regression model is\n\\[\n\\begin{aligned}\n\\hat{\\mathbf{y}} &= \\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\\\[8pt]\n\\Rightarrow \\quad &\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1x_{i1} + \\ldots + \\hat{\\beta}_j\\log(x_{ij}) + \\dots + \\hat{\\beta}_px_{ip}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/15-transformations-contd.html#model-interpretation",
    "href": "slides/15-transformations-contd.html#model-interpretation",
    "title": "Variable transformations cont’d",
    "section": "Model interpretation",
    "text": "Model interpretation\n\\[\n\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1x_{i1} + \\ldots + \\hat{\\beta}_j\\log(x_{ij}) + \\dots + \\hat{\\beta}_px_{ip}\n\\]\n\n\nIntercept: When \\(x_{i1} = \\dots = \\log(x_{ij}) = \\dots = x_{ip} = 0\\) , \\(y_i\\) is expected to be \\(\\hat{\\beta}_0\\), on average.\n\n\\(\\log(x_{ij}) = 0\\) when \\(x_{ij} = 1\\)\n\nCoefficient of \\(X_j\\): When \\(x_{ij}\\) is multiplied by a factor of \\(C\\), \\(y_i\\) is expected to change by \\(\\hat{\\beta}_j\\log(C)\\) units, on average, holding all else constant.\n\nExample: When \\(x_{ij}\\) is multiplied by a factor of 2, \\(y_i\\) is expected to increase by \\(\\hat{\\beta}_j\\log(2)\\) units, on average, holding all else constant."
  },
  {
    "objectID": "slides/15-transformations-contd.html#model-with-logx",
    "href": "slides/15-transformations-contd.html#model-with-logx",
    "title": "Variable transformations cont’d",
    "section": "Model with log(X)",
    "text": "Model with log(X)\n\nlife_exp_logx_fit &lt;- lm(life_exp ~ log(health_expenditure) + income_inequality \n                        + education, data = health_data)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n59.151\n3.184\n18.576\n0.000\n\n\nlog(health_expenditure)\n3.092\n0.396\n7.814\n0.000\n\n\nincome_inequality\n-0.362\n0.058\n-6.225\n0.000\n\n\neducationHigh\n-0.168\n1.103\n-0.152\n0.879\n\n\n\n\n\n\n\n\nInterpret the intercept in the context of the data.\nInterpret the effect of health expenditure in the context of the data.\nInterpret the effect of education in the context of the data."
  },
  {
    "objectID": "slides/15-transformations-contd.html#model-with-logx-residuals",
    "href": "slides/15-transformations-contd.html#model-with-logx-residuals",
    "title": "Variable transformations cont’d",
    "section": "Model with log(X): Residuals",
    "text": "Model with log(X): Residuals"
  },
  {
    "objectID": "slides/15-transformations-contd.html#comparing-residual-plots",
    "href": "slides/15-transformations-contd.html#comparing-residual-plots",
    "title": "Variable transformations cont’d",
    "section": "Comparing residual plots",
    "text": "Comparing residual plots"
  },
  {
    "objectID": "slides/15-transformations-contd.html#linear-model",
    "href": "slides/15-transformations-contd.html#linear-model",
    "title": "Variable transformations cont’d",
    "section": "“Linear” model",
    "text": "“Linear” model\nWhat does it mean for a model to be a “linear” model?\n\nLinear models are linear in the parameters, i.e. given an observation \\(y_i\\)\n\\[\ny_i = \\beta_0 + \\beta_1f(x_{i1}) + \\dots + \\beta_pf(x_{ip}) + \\epsilon_i\n\\]\nThe functions \\(f_1, \\ldots, f_p\\) can be non-linear as long as \\(\\beta_0, \\beta_1, \\ldots, \\beta_p\\) are linear in \\(Y\\)"
  },
  {
    "objectID": "slides/15-transformations-contd.html#identify-the-linear-models",
    "href": "slides/15-transformations-contd.html#identify-the-linear-models",
    "title": "Variable transformations cont’d",
    "section": "Identify the linear models",
    "text": "Identify the linear models\n\n\n\n\\(y_i = \\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i1}^2 + \\beta_3x_{i2}  + \\epsilon_i\\)\n\\(y_i = \\beta_1x_{i1} + \\beta_2x_{i2} + \\beta_3x_{i1}x_{i2} + \\epsilon_i\\)\n\\(y_i = \\beta_0  + \\beta_1\\sin(x_{i1} + \\beta_2x_{i2}) + \\beta_3x_{i3} + \\epsilon_i\\)\n\\(y_i = \\beta_0 + \\beta_1e^{x_{i1}} + \\beta_2e^{x_{i2}} + \\epsilon_i\\)\n\\(y_i =e^{(\\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i2} + \\beta_3x_{i3})} + \\epsilon_i\\)"
  },
  {
    "objectID": "slides/15-transformations-contd.html#learn-more",
    "href": "slides/15-transformations-contd.html#learn-more",
    "title": "Variable transformations cont’d",
    "section": "Learn more",
    "text": "Learn more\nSee Log Transformations in Linear Regression for more details about interpreting regression models with log-transformed variables."
  },
  {
    "objectID": "slides/15-transformations-contd.html#recap",
    "href": "slides/15-transformations-contd.html#recap",
    "title": "Variable transformations cont’d",
    "section": "Recap",
    "text": "Recap\n\nIntroduced log-transformation on the predictor\nIdentified linear models"
  },
  {
    "objectID": "slides/15-transformations-contd.html#remaining-questions",
    "href": "slides/15-transformations-contd.html#remaining-questions",
    "title": "Variable transformations cont’d",
    "section": "Remaining questions?",
    "text": "Remaining questions?\nPlease submit any questions you have about multicollinearity and variable transformations."
  },
  {
    "objectID": "slides/15-transformations-contd.html#references",
    "href": "slides/15-transformations-contd.html#references",
    "title": "Variable transformations cont’d",
    "section": "References",
    "text": "References\n\n\n\n\nZarulli, Virginia, Elizaveta Sopina, Veronica Toffolutti, and Adam Lenart. 2021. “Health Care System Efficiency and Life Expectancy: A 140-Country Study.” Edited by Srinivas Goli. PLOS ONE 16 (7): e0253450. https://doi.org/10.1371/journal.pone.0253450."
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html",
    "href": "slides/13-multicollinearity-notes.html",
    "title": "Multicollinearity",
    "section": "",
    "text": "Exam corrections (optional) due Tuesday, March 4 at 11:59pm\n\nSee assignment on Canvas\n\nTeam Feedback (email from TEAMMATES) due Tuesday, March 4 at 11:59pm (check email)\nDataFest: April 4 - 6 - https://dukestatsci.github.io/datafest/"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#announcements",
    "href": "slides/13-multicollinearity-notes.html#announcements",
    "title": "Multicollinearity",
    "section": "",
    "text": "Exam corrections (optional) due Tuesday, March 4 at 11:59pm\n\nSee assignment on Canvas\n\nTeam Feedback (email from TEAMMATES) due Tuesday, March 4 at 11:59pm (check email)\nDataFest: April 4 - 6 - https://dukestatsci.github.io/datafest/"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#computing-set-up",
    "href": "slides/13-multicollinearity-notes.html#computing-set-up",
    "title": "Multicollinearity",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)\nlibrary(GGally)   # for pairwise plot matrix\nlibrary(corrplot) # for correlation matrix\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#topics",
    "href": "slides/13-multicollinearity-notes.html#topics",
    "title": "Multicollinearity",
    "section": "Topics",
    "text": "Topics\n\nMulticollinearity\n\nDefinition\nHow it impacts the model\nHow to detect it\nWhat to do about it"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#data-trail-users",
    "href": "slides/13-multicollinearity-notes.html#data-trail-users",
    "title": "Multicollinearity",
    "section": "Data: Trail users",
    "text": "Data: Trail users\n\nThe Pioneer Valley Planning Commission (PVPC) collected data at the beginning a trail in Florence, MA for ninety days from April 5, 2005 to November 15, 2005 to\nData collectors set up a laser sensor, with breaks in the laser beam recording when a rail-trail user passed the data collection station.\n\n\n\n# A tibble: 5 × 7\n  volume hightemp avgtemp season cloudcover precip day_type\n   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   \n1    501       83    66.5 Summer       7.60  0     Weekday \n2    419       73    61   Summer       6.30  0.290 Weekday \n3    397       74    63   Spring       7.5   0.320 Weekday \n4    385       95    78   Summer       2.60  0     Weekend \n5    200       44    48   Spring      10     0.140 Weekday \n\n\nSource: Pioneer Valley Planning Commission via the mosaicData package."
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#variables",
    "href": "slides/13-multicollinearity-notes.html#variables",
    "title": "Multicollinearity",
    "section": "Variables",
    "text": "Variables\nOutcome:\n\nvolume estimated number of trail users that day (number of breaks recorded)\n\nPredictors\n\nhightemp daily high temperature (in degrees Fahrenheit)\navgtemp average of daily low and daily high temperature (in degrees Fahrenheit)\nseason one of “Fall”, “Spring”, or “Summer”\nprecip measure of precipitation (in inches)"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#eda-relationship-between-predictors",
    "href": "slides/13-multicollinearity-notes.html#eda-relationship-between-predictors",
    "title": "Multicollinearity",
    "section": "EDA: Relationship between predictors",
    "text": "EDA: Relationship between predictors\nWe can create a pairwise plot matrix using the ggpairs function from the GGally R package\n\nrail_trail |&gt;\n  select(hightemp, avgtemp, season, precip) |&gt;\n  ggpairs()"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#eda-relationship-between-predictors-1",
    "href": "slides/13-multicollinearity-notes.html#eda-relationship-between-predictors-1",
    "title": "Multicollinearity",
    "section": "EDA: Relationship between predictors",
    "text": "EDA: Relationship between predictors"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#eda-correlation-matrix",
    "href": "slides/13-multicollinearity-notes.html#eda-correlation-matrix",
    "title": "Multicollinearity",
    "section": "EDA: Correlation matrix",
    "text": "EDA: Correlation matrix\nWe can. use corrplot() in the corrplot R package to make a matrix of pairwise correlations between quantitative predictors\n\ncorrelations &lt;- rail_trail |&gt;\n  select(hightemp, avgtemp, precip) |&gt;\n  cor()\n\ncorrplot(correlations, method = \"number\")"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#eda-correlation-matrix-1",
    "href": "slides/13-multicollinearity-notes.html#eda-correlation-matrix-1",
    "title": "Multicollinearity",
    "section": "EDA: Correlation matrix",
    "text": "EDA: Correlation matrix\n\n\n\n\n\n\n\n\n\n\nWhat might be a potential concern with a model that uses high temperature, average temperature, season, and precipitation to predict volume?"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#multicollinearity-1",
    "href": "slides/13-multicollinearity-notes.html#multicollinearity-1",
    "title": "Multicollinearity",
    "section": "Multicollinearity",
    "text": "Multicollinearity\n\n\nIdeally the predictors are orthogonal, meaning they are completely independent of one another\nIn practice, there is typically some dependence between predictors but it is often not a major issue in the model\nIf there is linear dependence among (a subset of) the predictors, we cannot find estimate \\(\\hat{\\boldsymbol{\\beta}}\\)\nIf there are near-linear dependencies, we can find \\(\\hat{\\boldsymbol{\\beta}}\\) but there may be other issues with the model\nMulticollinearity: near-linear dependence among predictors"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#sources-of-multicollinearity",
    "href": "slides/13-multicollinearity-notes.html#sources-of-multicollinearity",
    "title": "Multicollinearity",
    "section": "Sources of multicollinearity",
    "text": "Sources of multicollinearity\n\n\nData collection method - only sample from a subspace of the region of predictors\nConstraints in the population - e.g., predictors family income and size of house\nChoice of model - e.g., adding high order terms to the model\nOverdefined model - have more predictors than observations\n\n\n\n\nSource: Montgomery, Peck, and Vining (2021)"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#detecting-multicollinearity",
    "href": "slides/13-multicollinearity-notes.html#detecting-multicollinearity",
    "title": "Multicollinearity",
    "section": "Detecting multicollinearity",
    "text": "Detecting multicollinearity\n\n\nRecall \\(Var(\\hat{\\boldsymbol{\\beta}}) = \\sigma^2_{\\epsilon}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\)\nLet \\(\\mathbf{C} = (\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\). Then \\(Var(\\hat{\\beta}_j) = \\sigma^2_{\\epsilon}C_{jj}\\)\nWhen there are near-linear dependencies, \\(C_{jj}\\) increases and thus \\(Var(\\hat{\\beta}_j)\\) becomes inflated\n\\(C_{jj}\\) is associated with how much \\(Var(\\hat{\\beta}_j)\\) is inflated due to \\(x_j\\) dependencies with other predictors"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#variance-inflation-factor",
    "href": "slides/13-multicollinearity-notes.html#variance-inflation-factor",
    "title": "Multicollinearity",
    "section": "Variance inflation factor",
    "text": "Variance inflation factor\n\nThe variance inflation factor (VIF) measures how much the linear dependencies impact the variance of the predictors\n\n\\[\nVIF_{j} = \\frac{1}{1 - R^2_j}\n\\]\nwhere \\(R^2_j\\) is the proportion of variation in \\(x_j\\) that is explained by a linear combination of all the other predictors\n. . .\n\nWhen the response and predictors are scaled in a particular way, \\(C_{jj} = VIF_{j}\\). Click here to see how."
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#detecting-multicollinearity-1",
    "href": "slides/13-multicollinearity-notes.html#detecting-multicollinearity-1",
    "title": "Multicollinearity",
    "section": "Detecting multicollinearity",
    "text": "Detecting multicollinearity\n\nCommon practice uses threshold \\(VIF &gt; 10\\) as indication of concerning multicollinearity (some say VIF &gt; 5 is worth investigation)\nVariables with similar values of VIF are typically the ones correlated with each other\nUse the vif() function in the rms R package to calculate VIF\n\n\nlibrary(rms)\n\ntrail_fit &lt;- lm(volume ~ hightemp + avgtemp + precip, data = rail_trail)\n\nvif(trail_fit)\n\nhightemp  avgtemp   precip \n7.161882 7.597154 1.193431"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#how-multicollinearity-impacts-model",
    "href": "slides/13-multicollinearity-notes.html#how-multicollinearity-impacts-model",
    "title": "Multicollinearity",
    "section": "How multicollinearity impacts model",
    "text": "How multicollinearity impacts model\n\n\nLarge variance for the model coefficients that are collinear\n\nDifferent combinations of coefficient estimates produce equally good model fits\n\nUnreliable statistical inference results\n\nMay conclude coefficients are not statistically significant when there is, in fact, a relationship between the predictors and response\n\nInterpretation of coefficient is no longer “holding all other variables constant”, since this would be impossible for correlated predictors"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#dealing-with-multicollinearity",
    "href": "slides/13-multicollinearity-notes.html#dealing-with-multicollinearity",
    "title": "Multicollinearity",
    "section": "Dealing with multicollinearity",
    "text": "Dealing with multicollinearity\n\n\nCollect more data (often not feasible given practical constraints)\nRedefine the correlated predictors to keep the information from predictors but eliminate collinearity\n\ne.g., if \\(x_1, x_2, x_3\\) are correlated, use a new variable \\((x_1 + x_2) / x_3\\) in the model\n\nFor categorical predictors, avoid using levels with very few observations as the baseline\nRemove one of the correlated variables\n\nBe careful about substantially reducing predictive power of the model"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#recap",
    "href": "slides/13-multicollinearity-notes.html#recap",
    "title": "Multicollinearity",
    "section": "Recap",
    "text": "Recap\n\nIntroduced multicollinearity\n\nDefinition\nHow it impacts the model\nHow to detect it\nWhat to do about it"
  },
  {
    "objectID": "slides/13-multicollinearity.html#announcements",
    "href": "slides/13-multicollinearity.html#announcements",
    "title": "Multicollinearity",
    "section": "Announcements",
    "text": "Announcements\n\nExam corrections (optional) due Tuesday, March 4 at 11:59pm\n\nSee assignment on Canvas\n\nTeam Feedback (email from TEAMMATES) due Tuesday, March 4 at 11:59pm (check email)\nDataFest: April 4 - 6 - https://dukestatsci.github.io/datafest/"
  },
  {
    "objectID": "slides/13-multicollinearity.html#computing-set-up",
    "href": "slides/13-multicollinearity.html#computing-set-up",
    "title": "Multicollinearity",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)\nlibrary(GGally)   # for pairwise plot matrix\nlibrary(corrplot) # for correlation matrix\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/13-multicollinearity.html#topics",
    "href": "slides/13-multicollinearity.html#topics",
    "title": "Multicollinearity",
    "section": "Topics",
    "text": "Topics\n\nMulticollinearity\n\nDefinition\nHow it impacts the model\nHow to detect it\nWhat to do about it"
  },
  {
    "objectID": "slides/13-multicollinearity.html#data-trail-users",
    "href": "slides/13-multicollinearity.html#data-trail-users",
    "title": "Multicollinearity",
    "section": "Data: Trail users",
    "text": "Data: Trail users\n\nThe Pioneer Valley Planning Commission (PVPC) collected data at the beginning a trail in Florence, MA for ninety days from April 5, 2005 to November 15, 2005 to\nData collectors set up a laser sensor, with breaks in the laser beam recording when a rail-trail user passed the data collection station.\n\n\n\n# A tibble: 5 × 7\n  volume hightemp avgtemp season cloudcover precip day_type\n   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   \n1    501       83    66.5 Summer       7.60  0     Weekday \n2    419       73    61   Summer       6.30  0.290 Weekday \n3    397       74    63   Spring       7.5   0.320 Weekday \n4    385       95    78   Summer       2.60  0     Weekend \n5    200       44    48   Spring      10     0.140 Weekday \n\n\nSource: Pioneer Valley Planning Commission via the mosaicData package."
  },
  {
    "objectID": "slides/13-multicollinearity.html#variables",
    "href": "slides/13-multicollinearity.html#variables",
    "title": "Multicollinearity",
    "section": "Variables",
    "text": "Variables\nOutcome:\n\nvolume estimated number of trail users that day (number of breaks recorded)\n\nPredictors\n\nhightemp daily high temperature (in degrees Fahrenheit)\navgtemp average of daily low and daily high temperature (in degrees Fahrenheit)\nseason one of “Fall”, “Spring”, or “Summer”\nprecip measure of precipitation (in inches)"
  },
  {
    "objectID": "slides/13-multicollinearity.html#eda-relationship-between-predictors",
    "href": "slides/13-multicollinearity.html#eda-relationship-between-predictors",
    "title": "Multicollinearity",
    "section": "EDA: Relationship between predictors",
    "text": "EDA: Relationship between predictors\nWe can create a pairwise plot matrix using the ggpairs function from the GGally R package\n\nrail_trail |&gt;\n  select(hightemp, avgtemp, season, precip) |&gt;\n  ggpairs()"
  },
  {
    "objectID": "slides/13-multicollinearity.html#eda-relationship-between-predictors-1",
    "href": "slides/13-multicollinearity.html#eda-relationship-between-predictors-1",
    "title": "Multicollinearity",
    "section": "EDA: Relationship between predictors",
    "text": "EDA: Relationship between predictors"
  },
  {
    "objectID": "slides/13-multicollinearity.html#eda-correlation-matrix",
    "href": "slides/13-multicollinearity.html#eda-correlation-matrix",
    "title": "Multicollinearity",
    "section": "EDA: Correlation matrix",
    "text": "EDA: Correlation matrix\nWe can. use corrplot() in the corrplot R package to make a matrix of pairwise correlations between quantitative predictors\n\ncorrelations &lt;- rail_trail |&gt;\n  select(hightemp, avgtemp, precip) |&gt;\n  cor()\n\ncorrplot(correlations, method = \"number\")"
  },
  {
    "objectID": "slides/13-multicollinearity.html#eda-correlation-matrix-1",
    "href": "slides/13-multicollinearity.html#eda-correlation-matrix-1",
    "title": "Multicollinearity",
    "section": "EDA: Correlation matrix",
    "text": "EDA: Correlation matrix\n\n\nWhat might be a potential concern with a model that uses high temperature, average temperature, season, and precipitation to predict volume?"
  },
  {
    "objectID": "slides/13-multicollinearity.html#multicollinearity-1",
    "href": "slides/13-multicollinearity.html#multicollinearity-1",
    "title": "Multicollinearity",
    "section": "Multicollinearity",
    "text": "Multicollinearity\n\n\nIdeally the predictors are orthogonal, meaning they are completely independent of one another\nIn practice, there is typically some dependence between predictors but it is often not a major issue in the model\nIf there is linear dependence among (a subset of) the predictors, we cannot find estimate \\(\\hat{\\boldsymbol{\\beta}}\\)\nIf there are near-linear dependencies, we can find \\(\\hat{\\boldsymbol{\\beta}}\\) but there may be other issues with the model\nMulticollinearity: near-linear dependence among predictors"
  },
  {
    "objectID": "slides/13-multicollinearity.html#sources-of-multicollinearity",
    "href": "slides/13-multicollinearity.html#sources-of-multicollinearity",
    "title": "Multicollinearity",
    "section": "Sources of multicollinearity",
    "text": "Sources of multicollinearity\n\n\nData collection method - only sample from a subspace of the region of predictors\nConstraints in the population - e.g., predictors family income and size of house\nChoice of model - e.g., adding high order terms to the model\nOverdefined model - have more predictors than observations\n\n\n\n\nSource: Montgomery, Peck, and Vining (2021)"
  },
  {
    "objectID": "slides/13-multicollinearity.html#detecting-multicollinearity",
    "href": "slides/13-multicollinearity.html#detecting-multicollinearity",
    "title": "Multicollinearity",
    "section": "Detecting multicollinearity",
    "text": "Detecting multicollinearity\n\n\nRecall \\(Var(\\hat{\\boldsymbol{\\beta}}) = \\sigma^2_{\\epsilon}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\)\nLet \\(\\mathbf{C} = (\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\). Then \\(Var(\\hat{\\beta}_j) = \\sigma^2_{\\epsilon}C_{jj}\\)\nWhen there are near-linear dependencies, \\(C_{jj}\\) increases and thus \\(Var(\\hat{\\beta}_j)\\) becomes inflated\n\\(C_{jj}\\) is associated with how much \\(Var(\\hat{\\beta}_j)\\) is inflated due to \\(x_j\\) dependencies with other predictors"
  },
  {
    "objectID": "slides/13-multicollinearity.html#variance-inflation-factor",
    "href": "slides/13-multicollinearity.html#variance-inflation-factor",
    "title": "Multicollinearity",
    "section": "Variance inflation factor",
    "text": "Variance inflation factor\n\nThe variance inflation factor (VIF) measures how much the linear dependencies impact the variance of the predictors\n\n\\[\nVIF_{j} = \\frac{1}{1 - R^2_j}\n\\]\nwhere \\(R^2_j\\) is the proportion of variation in \\(x_j\\) that is explained by a linear combination of all the other predictors\n\n\nWhen the response and predictors are scaled in a particular way, \\(C_{jj} = VIF_{j}\\). Click here to see how."
  },
  {
    "objectID": "slides/13-multicollinearity.html#detecting-multicollinearity-1",
    "href": "slides/13-multicollinearity.html#detecting-multicollinearity-1",
    "title": "Multicollinearity",
    "section": "Detecting multicollinearity",
    "text": "Detecting multicollinearity\n\nCommon practice uses threshold \\(VIF &gt; 10\\) as indication of concerning multicollinearity (some say VIF &gt; 5 is worth investigation)\nVariables with similar values of VIF are typically the ones correlated with each other\nUse the vif() function in the rms R package to calculate VIF\n\n\nlibrary(rms)\n\ntrail_fit &lt;- lm(volume ~ hightemp + avgtemp + precip, data = rail_trail)\n\nvif(trail_fit)\n\nhightemp  avgtemp   precip \n7.161882 7.597154 1.193431"
  },
  {
    "objectID": "slides/13-multicollinearity.html#how-multicollinearity-impacts-model",
    "href": "slides/13-multicollinearity.html#how-multicollinearity-impacts-model",
    "title": "Multicollinearity",
    "section": "How multicollinearity impacts model",
    "text": "How multicollinearity impacts model\n\n\nLarge variance for the model coefficients that are collinear\n\nDifferent combinations of coefficient estimates produce equally good model fits\n\nUnreliable statistical inference results\n\nMay conclude coefficients are not statistically significant when there is, in fact, a relationship between the predictors and response\n\nInterpretation of coefficient is no longer “holding all other variables constant”, since this would be impossible for correlated predictors"
  },
  {
    "objectID": "slides/13-multicollinearity.html#dealing-with-multicollinearity",
    "href": "slides/13-multicollinearity.html#dealing-with-multicollinearity",
    "title": "Multicollinearity",
    "section": "Dealing with multicollinearity",
    "text": "Dealing with multicollinearity\n\n\nCollect more data (often not feasible given practical constraints)\nRedefine the correlated predictors to keep the information from predictors but eliminate collinearity\n\ne.g., if \\(x_1, x_2, x_3\\) are correlated, use a new variable \\((x_1 + x_2) / x_3\\) in the model\n\nFor categorical predictors, avoid using levels with very few observations as the baseline\nRemove one of the correlated variables\n\nBe careful about substantially reducing predictive power of the model"
  },
  {
    "objectID": "slides/13-multicollinearity.html#recap",
    "href": "slides/13-multicollinearity.html#recap",
    "title": "Multicollinearity",
    "section": "Recap",
    "text": "Recap\n\nIntroduced multicollinearity\n\nDefinition\nHow it impacts the model\nHow to detect it\nWhat to do about it"
  },
  {
    "objectID": "slides/13-multicollinearity.html#references",
    "href": "slides/13-multicollinearity.html#references",
    "title": "Multicollinearity",
    "section": "References",
    "text": "References\n\n\n\n\nMontgomery, Douglas C, Elizabeth A Peck, and G Geoffrey Vining. 2021. Introduction to Linear Regression Analysis. John Wiley & Sons."
  },
  {
    "objectID": "slides/lab-00.html#meet-your-tas",
    "href": "slides/lab-00.html#meet-your-tas",
    "title": "Welcome to STA 221 labs!",
    "section": "Meet your TAs!",
    "text": "Meet your TAs!"
  },
  {
    "objectID": "slides/lab-00.html#meet-each-other",
    "href": "slides/lab-00.html#meet-each-other",
    "title": "Welcome to STA 221 labs!",
    "section": "Meet each other!",
    "text": "Meet each other!\n\n\nGet into groups of 2 or 3\nIntroduce yourself: Name, year, major (or academic interest), a highlight from winter break or something you’re looking forward to this semester\nIntroduce your partner to the class\n\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/lab-00.html#what-to-expect-in-lab",
    "href": "slides/lab-00.html#what-to-expect-in-lab",
    "title": "Welcome to STA 221 labs!",
    "section": "What to expect in lab",
    "text": "What to expect in lab\n\nIntroduction to the lab assignment (~ 5 - 10 minutes)\nReview lecture content, as needed (~ 10 minutes)\nWork on the lab assignment (individual in the beginning and in teams for the remainder of the semester)\nStarting with Lab 01, you will find the starter materials for lab in your repo in the course GitHub organization."
  },
  {
    "objectID": "slides/lab-00.html#todays-lab",
    "href": "slides/lab-00.html#todays-lab",
    "title": "Welcome to STA 221 labs!",
    "section": "Today’s lab",
    "text": "Today’s lab\nThe rest of the today’s lab is focused on setting up the computing for the course and completing the class survey. Click the link below for the Lab 00 instructions. The instructions are available on the course website.\nYour TA will demonstrate the steps to set up computing and interact with RStudio and GitHub.\n\n🔗 sta221-sp25.netlify.app/labs/lab-00.html"
  },
  {
    "objectID": "slides/02-slr-notes.html",
    "href": "slides/02-slr-notes.html",
    "title": "Simple linear regression",
    "section": "",
    "text": "Complete Lab 00\nOffice hours start this week\n\nAlan’s office hours start January 27\n\nIntroduction to R workshops at Duke library\n\nData wrangling with dplyr - Thu, Jan 16 at 12pm\nData visualization with ggplot2 - Thu, Jan 23 at 12pm"
  },
  {
    "objectID": "slides/02-slr-notes.html#announcements",
    "href": "slides/02-slr-notes.html#announcements",
    "title": "Simple linear regression",
    "section": "",
    "text": "Complete Lab 00\nOffice hours start this week\n\nAlan’s office hours start January 27\n\nIntroduction to R workshops at Duke library\n\nData wrangling with dplyr - Thu, Jan 16 at 12pm\nData visualization with ggplot2 - Thu, Jan 23 at 12pm"
  },
  {
    "objectID": "slides/02-slr-notes.html#topics",
    "href": "slides/02-slr-notes.html#topics",
    "title": "Simple linear regression",
    "section": "Topics",
    "text": "Topics\n\nHow regression is used to understand the relationship between multiple variables\nLeast squares estimation for the slope and intercept\nInterpret the slope and intercept\nPredict the response given a value of the predictor"
  },
  {
    "objectID": "slides/02-slr-notes.html#computing-set-up",
    "href": "slides/02-slr-notes.html#computing-set-up",
    "title": "Simple linear regression",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)        # for data wrangling\nlibrary(broom)            # for formatting regression output\nlibrary(fivethirtyeight)  # for the fandango dataset\nlibrary(knitr)            # for formatting tables\nlibrary(patchwork)        # for arranging graphs\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))\n\n# set default figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 8,\n  fig.asp = 0.618,\n  fig.retina = 3,\n  dpi = 300,\n  out.width = \"80%\"\n)\n\n\n\n\n\nSource: R for Data Science with additions from The Art of Statistics: How to Learn from Data.\n\n\n\n\n\n\nSource:R for Data Science"
  },
  {
    "objectID": "slides/02-slr-notes.html#movie-scores",
    "href": "slides/02-slr-notes.html#movie-scores",
    "title": "Simple linear regression",
    "section": "Movie scores",
    "text": "Movie scores\n\n\n\nData behind the FiveThirtyEight story Be Suspicious Of Online Movie Ratings, Especially Fandango’s\nIn the fivethirtyeight package: fandango\nContains every film released in 2014 and 2015 that has at least 30 fan reviews on Fandango, an IMDb score, Rotten Tomatoes critic and user ratings, and Metacritic critic and user scores"
  },
  {
    "objectID": "slides/02-slr-notes.html#data-prep",
    "href": "slides/02-slr-notes.html#data-prep",
    "title": "Simple linear regression",
    "section": "Data prep",
    "text": "Data prep\n\nRename Rotten Tomatoes columns as critics and audience\nRename the data set as movie_scores\n\n\nmovie_scores &lt;- fandango |&gt;\n  rename(critics = rottentomatoes, \n         audience = rottentomatoes_user)"
  },
  {
    "objectID": "slides/02-slr-notes.html#data-overview",
    "href": "slides/02-slr-notes.html#data-overview",
    "title": "Simple linear regression",
    "section": "Data overview",
    "text": "Data overview\n\nglimpse(movie_scores)\n\nRows: 146\nColumns: 23\n$ film                       &lt;chr&gt; \"Avengers: Age of Ultron\", \"Cinderella\", \"A…\n$ year                       &lt;dbl&gt; 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2…\n$ critics                    &lt;int&gt; 74, 85, 80, 18, 14, 63, 42, 86, 99, 89, 84,…\n$ audience                   &lt;int&gt; 86, 80, 90, 84, 28, 62, 53, 64, 82, 87, 77,…\n$ metacritic                 &lt;int&gt; 66, 67, 64, 22, 29, 50, 53, 81, 81, 80, 71,…\n$ metacritic_user            &lt;dbl&gt; 7.1, 7.5, 8.1, 4.7, 3.4, 6.8, 7.6, 6.8, 8.8…\n$ imdb                       &lt;dbl&gt; 7.8, 7.1, 7.8, 5.4, 5.1, 7.2, 6.9, 6.5, 7.4…\n$ fandango_stars             &lt;dbl&gt; 5.0, 5.0, 5.0, 5.0, 3.5, 4.5, 4.0, 4.0, 4.5…\n$ fandango_ratingvalue       &lt;dbl&gt; 4.5, 4.5, 4.5, 4.5, 3.0, 4.0, 3.5, 3.5, 4.0…\n$ rt_norm                    &lt;dbl&gt; 3.70, 4.25, 4.00, 0.90, 0.70, 3.15, 2.10, 4…\n$ rt_user_norm               &lt;dbl&gt; 4.30, 4.00, 4.50, 4.20, 1.40, 3.10, 2.65, 3…\n$ metacritic_norm            &lt;dbl&gt; 3.30, 3.35, 3.20, 1.10, 1.45, 2.50, 2.65, 4…\n$ metacritic_user_nom        &lt;dbl&gt; 3.55, 3.75, 4.05, 2.35, 1.70, 3.40, 3.80, 3…\n$ imdb_norm                  &lt;dbl&gt; 3.90, 3.55, 3.90, 2.70, 2.55, 3.60, 3.45, 3…\n$ rt_norm_round              &lt;dbl&gt; 3.5, 4.5, 4.0, 1.0, 0.5, 3.0, 2.0, 4.5, 5.0…\n$ rt_user_norm_round         &lt;dbl&gt; 4.5, 4.0, 4.5, 4.0, 1.5, 3.0, 2.5, 3.0, 4.0…\n$ metacritic_norm_round      &lt;dbl&gt; 3.5, 3.5, 3.0, 1.0, 1.5, 2.5, 2.5, 4.0, 4.0…\n$ metacritic_user_norm_round &lt;dbl&gt; 3.5, 4.0, 4.0, 2.5, 1.5, 3.5, 4.0, 3.5, 4.5…\n$ imdb_norm_round            &lt;dbl&gt; 4.0, 3.5, 4.0, 2.5, 2.5, 3.5, 3.5, 3.5, 3.5…\n$ metacritic_user_vote_count &lt;int&gt; 1330, 249, 627, 31, 88, 34, 17, 124, 62, 54…\n$ imdb_user_vote_count       &lt;int&gt; 271107, 65709, 103660, 3136, 19560, 39373, …\n$ fandango_votes             &lt;int&gt; 14846, 12640, 12055, 1793, 1021, 397, 252, …\n$ fandango_difference        &lt;dbl&gt; 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5…"
  },
  {
    "objectID": "slides/02-slr-notes.html#univariate-exploratory-data-analysis-eda",
    "href": "slides/02-slr-notes.html#univariate-exploratory-data-analysis-eda",
    "title": "Simple linear regression",
    "section": "Univariate exploratory data analysis (EDA)",
    "text": "Univariate exploratory data analysis (EDA)\nThe data set contains the “Tomatometer” score (critics) and audience score (audience) for 146 movies rated on rottentomatoes.com."
  },
  {
    "objectID": "slides/02-slr-notes.html#bivariate-eda",
    "href": "slides/02-slr-notes.html#bivariate-eda",
    "title": "Simple linear regression",
    "section": "Bivariate EDA",
    "text": "Bivariate EDA"
  },
  {
    "objectID": "slides/02-slr-notes.html#bivariate-eda-1",
    "href": "slides/02-slr-notes.html#bivariate-eda-1",
    "title": "Simple linear regression",
    "section": "Bivariate EDA",
    "text": "Bivariate EDA\nGoal: Fit a line to describe the relationship between the critics score and audience score."
  },
  {
    "objectID": "slides/02-slr-notes.html#why-fit-a-line",
    "href": "slides/02-slr-notes.html#why-fit-a-line",
    "title": "Simple linear regression",
    "section": "Why fit a line?",
    "text": "Why fit a line?\nWe fit a line to accomplish one or both of the following:\n\n. . .\n\nPrediction\n\n\nWhat is an example of a prediction question for this data set?\n\n\n. . .\n\nInference\n\n\nWhat is an example of an inference question for this data set?"
  },
  {
    "objectID": "slides/02-slr-notes.html#terminology",
    "href": "slides/02-slr-notes.html#terminology",
    "title": "Simple linear regression",
    "section": "Terminology",
    "text": "Terminology\n\n\n\nResponse, \\(Y\\): variable describing the outcome of interest\nPredictor, \\(X\\): variable we use to help understand the variability in the response"
  },
  {
    "objectID": "slides/02-slr-notes.html#regression-model",
    "href": "slides/02-slr-notes.html#regression-model",
    "title": "Simple linear regression",
    "section": "Regression model",
    "text": "Regression model\nA regression model is a function that describes the relationship between the response, \\(Y\\), and the predictor, \\(X\\).\n\\[\\begin{aligned} Y &= \\color{black}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{black}{f(X)} + \\epsilon \\\\[8pt]\n& = \\color{black}{E(Y|X)} + \\epsilon \\\\[8pt]\n&= \\color{black}{\\mu_{Y|X}} + \\epsilon \\end{aligned}\\]"
  },
  {
    "objectID": "slides/02-slr-notes.html#regression-model-1",
    "href": "slides/02-slr-notes.html#regression-model-1",
    "title": "Simple linear regression",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\\begin{aligned} Y &= \\color{purple}{\\textbf{Model}} + \\color{black}\\text{Error} \\\\[8pt]\n&= \\color{purple}{f(X)} + \\color{black}\\epsilon \\\\[8pt]\n&= \\color{purple}{E(Y|X)} + \\color{black}\\epsilon \\\\[8pt]\n&= \\color{purple}{\\mu_{Y|X}} + \\color{black}\\epsilon \\end{aligned}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\\(E(Y|X) = \\mu_{Y|X}\\), the mean value of \\(Y\\) given a particular value of \\(X\\)."
  },
  {
    "objectID": "slides/02-slr-notes.html#regression-model-2",
    "href": "slides/02-slr-notes.html#regression-model-2",
    "title": "Simple linear regression",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\n\\begin{aligned} Y &= \\color{purple}{\\textbf{Model}} + \\color{blue}{\\textbf{Error}} \\\\[8pt]\n&= \\color{purple}{f(X)} + \\color{blue}{\\epsilon}\\\\[8pt]\n&= \\color{purple}{E(Y|X)} + \\color{blue}{\\epsilon}\\\\[8pt]\n&= \\color{purple}{\\mu_{Y|X}} + \\color{blue}{\\epsilon} \\\\\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/02-slr-notes.html#determine-fx",
    "href": "slides/02-slr-notes.html#determine-fx",
    "title": "Simple linear regression",
    "section": "Determine \\(f(X)\\)",
    "text": "Determine \\(f(X)\\)\n\nGoal: Determine \\(f(X)\\)\nHow do we determine \\(f(X)\\)\n\nMake an assumption about the functional form \\(f(X)\\) (parametric model)\nUse the data to fit a model based on that form"
  },
  {
    "objectID": "slides/02-slr-notes.html#slr-statistical-model-population",
    "href": "slides/02-slr-notes.html#slr-statistical-model-population",
    "title": "Simple linear regression",
    "section": "SLR: Statistical model (population)",
    "text": "SLR: Statistical model (population)\nWhen we have a quantitative response, \\(Y\\), and a single quantitative predictor, \\(X\\), we can use a (simple) linear regression model to describe the relationship between \\(Y\\) and \\(X\\). \\[Y = \\beta_0 + \\beta_1X + \\epsilon\\]\n. . .\n\n\\(\\beta_1\\): Population (true) slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\beta_0\\): Population (true) intercept of the relationship between \\(X\\) and \\(Y\\)\n\\(\\epsilon\\): Error terms with mean 0 and variance \\(\\sigma^2_{\\epsilon}\\)"
  },
  {
    "objectID": "slides/02-slr-notes.html#slr-regression-equation-sample",
    "href": "slides/02-slr-notes.html#slr-regression-equation-sample",
    "title": "Simple linear regression",
    "section": "SLR: Regression equation (sample)",
    "text": "SLR: Regression equation (sample)\n\\[\\hat{Y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 X\\]\n\n\\(\\hat{\\beta}_1\\): Estimated (sample) slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\hat{\\beta}_0\\): Estimated (sample) intercept of the relationship between \\(X\\) and \\(Y\\)\nNo error term!\n\n. . .\n\nWhy is there no error term in the estimated regression equation?"
  },
  {
    "objectID": "slides/02-slr-notes.html#estimating-hatbeta_1-and-hatbeta_0",
    "href": "slides/02-slr-notes.html#estimating-hatbeta_1-and-hatbeta_0",
    "title": "Simple linear regression",
    "section": "Estimating \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\)",
    "text": "Estimating \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\)"
  },
  {
    "objectID": "slides/02-slr-notes.html#residuals",
    "href": "slides/02-slr-notes.html#residuals",
    "title": "Simple linear regression",
    "section": "Residuals",
    "text": "Residuals\n\n\n\n\n\n\n\n\n\n\\[\\text{residual} = \\text{observed} - \\text{predicted} = y_i - \\hat{y}_i\\]"
  },
  {
    "objectID": "slides/02-slr-notes.html#least-squares-line",
    "href": "slides/02-slr-notes.html#least-squares-line",
    "title": "Simple linear regression",
    "section": "Least squares line",
    "text": "Least squares line\n\nThe residual for the \\(i^{th}\\) observation is\n\n\\[e_i = \\text{observed} - \\text{predicted}\n= y_i - \\hat{y}_i\\]\n\nThe sum of squared residuals is\n\n\\[e^2_1 + e^2_2 + \\dots + e^2_n\\]\n\nThe Ordinary Least Squares (OLS) line is the one that minimizes the sum of squared residuals"
  },
  {
    "objectID": "slides/02-slr-notes.html#least-squares-estimate-of-hatbeta_0",
    "href": "slides/02-slr-notes.html#least-squares-estimate-of-hatbeta_0",
    "title": "Simple linear regression",
    "section": "Least-squares estimate of \\(\\hat{\\beta}_0\\)",
    "text": "Least-squares estimate of \\(\\hat{\\beta}_0\\)\n\n\nClick here for full details on estimating \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) ."
  },
  {
    "objectID": "slides/02-slr-notes.html#properties-of-least-squares-regression",
    "href": "slides/02-slr-notes.html#properties-of-least-squares-regression",
    "title": "Simple linear regression",
    "section": "Properties of least squares regression",
    "text": "Properties of least squares regression\n\n\nThe regression line goes through the center of mass point, the coordinates corresponding to mean \\(X\\) and mean \\(Y\\): \\(\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1\\bar{X}\\)\nThe slope has the same sign as the correlation coefficient: \\(\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}\\)\nThe sum of the residuals is approximately zero: \\(\\sum_{i = 1}^n e_i \\approx 0\\)\nThe residuals and \\(X\\) values are uncorrelated"
  },
  {
    "objectID": "slides/02-slr-notes.html#estimating-the-slope",
    "href": "slides/02-slr-notes.html#estimating-the-slope",
    "title": "Simple linear regression",
    "section": "Estimating the slope",
    "text": "Estimating the slope\n\\[\\large{\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}}\\]\n\n. . .\n\\[\n\\begin{aligned} s_X = 30.1688  \\hspace{15mm} &s_Y =  20.0244 \\hspace{15mm} r  = 0.7814 \\\\[10pt]\\hat{\\beta}_1  &= 0.7814 \\times \\frac{20.0244}{30.1688} \\\\&= \\mathbf{0.5187}\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/02-slr-notes.html#estimating-the-intercept",
    "href": "slides/02-slr-notes.html#estimating-the-intercept",
    "title": "Simple linear regression",
    "section": "Estimating the intercept",
    "text": "Estimating the intercept\n\\[\\large{\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1\\bar{X}}\\]\n\n. . .\n\\[\n\\begin{aligned}\\bar{x} = 60.8493 & \\hspace{15mm} \\bar{y} = 63.8767 \\hspace{15mm} \\hat{\\beta}_1 = 0.5187 \\\\[10pt]\n\\hat{\\beta}_0 &= 63.8767 - 0.5187 \\times 60.8493 \\\\\n&= \\mathbf{32.3142}\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/02-slr-notes.html#interpretation",
    "href": "slides/02-slr-notes.html#interpretation",
    "title": "Simple linear regression",
    "section": "Interpretation",
    "text": "Interpretation\n\nQuestionSubmit\n\n\n\n\nSubmit your answers to the following questions on Ed Discussion:\n\nThe slope of the model for predicting audience score from critics score is 0.5187 . Which of the following is the best interpretation of this value?\n32.3142 is the predicted mean audience score for what type of movies?\n\n\n\n\n\n\n\n\n\n🔗 https://edstem.org/us/courses/70811/discussion/5967675"
  },
  {
    "objectID": "slides/02-slr-notes.html#does-it-make-sense-to-interpret-the-intercept",
    "href": "slides/02-slr-notes.html#does-it-make-sense-to-interpret-the-intercept",
    "title": "Simple linear regression",
    "section": "Does it make sense to interpret the intercept?",
    "text": "Does it make sense to interpret the intercept?\n. . .\n✅ The intercept is meaningful in the context of the data if\n\nthe predictor can feasibly take values equal to or near zero, or\nthere are values near zero in the observed data.\n\n. . .\n🛑 Otherwise, the intercept may not be meaningful!"
  },
  {
    "objectID": "slides/02-slr-notes.html#making-a-prediction",
    "href": "slides/02-slr-notes.html#making-a-prediction",
    "title": "Simple linear regression",
    "section": "Making a prediction",
    "text": "Making a prediction\nSuppose that a movie has a critics score of 70. According to this model, what is the movie’s predicted audience score?\n\\[\\begin{aligned}\n\\widehat{\\text{audience}} &= 32.3142 + 0.5187 \\times \\text{critics} \\\\\n&= 32.3142 + 0.5187 \\times 70 \\\\\n&= \\mathbf{68.6232}\n\\end{aligned}\\]"
  },
  {
    "objectID": "slides/02-slr-notes.html#fit-the-model",
    "href": "slides/02-slr-notes.html#fit-the-model",
    "title": "Simple linear regression",
    "section": "Fit the model",
    "text": "Fit the model\nUse the lm() function to fit a linear regression model\n\n\nmovie_fit &lt;- lm(audience ~ critics, data = movie_scores)\nmovie_fit\n\n\nCall:\nlm(formula = audience ~ critics, data = movie_scores)\n\nCoefficients:\n(Intercept)      critics  \n    32.3155       0.5187"
  },
  {
    "objectID": "slides/02-slr-notes.html#tidy-results",
    "href": "slides/02-slr-notes.html#tidy-results",
    "title": "Simple linear regression",
    "section": "Tidy results",
    "text": "Tidy results\nUse the tidy() function from the broom R package to “tidy” the model output\n\n\nmovie_fit &lt;- lm(audience ~ critics, data = movie_scores)\ntidy(movie_fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   32.3      2.34        13.8 4.03e-28\n2 critics        0.519    0.0345      15.0 2.70e-31"
  },
  {
    "objectID": "slides/02-slr-notes.html#format-results",
    "href": "slides/02-slr-notes.html#format-results",
    "title": "Simple linear regression",
    "section": "Format results",
    "text": "Format results\nUse the kable() function from the knitr package to neatly format the results\n\n\n\nmovie_fit &lt;- lm(audience ~ critics, data = movie_scores)\ntidy(movie_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n32.316\n2.343\n13.795\n0\n\n\ncritics\n0.519\n0.035\n15.028\n0"
  },
  {
    "objectID": "slides/02-slr-notes.html#prediction-1",
    "href": "slides/02-slr-notes.html#prediction-1",
    "title": "Simple linear regression",
    "section": "Prediction",
    "text": "Prediction\nUse the predict() function to calculate predictions for new observations\n\nSingle observation\n\nnew_movie &lt;- tibble(critics = 70)\npredict(movie_fit, new_movie)\n\n       1 \n68.62297"
  },
  {
    "objectID": "slides/02-slr-notes.html#prediction-2",
    "href": "slides/02-slr-notes.html#prediction-2",
    "title": "Simple linear regression",
    "section": "Prediction",
    "text": "Prediction\nUse the predict() function to calculate predictions for new observations\n\nMultiple observations\n\nmore_new_movies &lt;- tibble(critics = c(24,70, 85))\npredict(movie_fit, more_new_movies)\n\n       1        2        3 \n44.76379 68.62297 76.40313"
  },
  {
    "objectID": "slides/02-slr-notes.html#recap",
    "href": "slides/02-slr-notes.html#recap",
    "title": "Simple linear regression",
    "section": "Recap",
    "text": "Recap\n\nDescribed how regression is used to understand the relationship between multiple variables\nUsed least squares to estimate the slope and intercept\nInterpreted the slope and intercept for simple linear regression\nPredicted the response given a value of the predictor"
  },
  {
    "objectID": "slides/02-slr-notes.html#next-time",
    "href": "slides/02-slr-notes.html#next-time",
    "title": "Simple linear regression",
    "section": "Next time",
    "text": "Next time\n\nModel assessment for simple linear regression\n\nComplete Lec 03: Model Assessment prepare\n\nBring fully-charged laptop or device with keyboard for in-class application exercise (AE)"
  },
  {
    "objectID": "slides/02-slr.html#announcements",
    "href": "slides/02-slr.html#announcements",
    "title": "Simple linear regression",
    "section": "Announcements",
    "text": "Announcements\n\nComplete Lab 00\nOffice hours start this week\n\nAlan’s office hours start January 27\n\nIntroduction to R workshops at Duke library\n\nData wrangling with dplyr - Thu, Jan 16 at 12pm\nData visualization with ggplot2 - Thu, Jan 23 at 12pm"
  },
  {
    "objectID": "slides/02-slr.html#topics",
    "href": "slides/02-slr.html#topics",
    "title": "Simple linear regression",
    "section": "Topics",
    "text": "Topics\n\nHow regression is used to understand the relationship between multiple variables\nLeast squares estimation for the slope and intercept\nInterpret the slope and intercept\nPredict the response given a value of the predictor"
  },
  {
    "objectID": "slides/02-slr.html#computing-set-up",
    "href": "slides/02-slr.html#computing-set-up",
    "title": "Simple linear regression",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)        # for data wrangling\nlibrary(broom)            # for formatting regression output\nlibrary(fivethirtyeight)  # for the fandango dataset\nlibrary(knitr)            # for formatting tables\nlibrary(patchwork)        # for arranging graphs\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))\n\n# set default figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 8,\n  fig.asp = 0.618,\n  fig.retina = 3,\n  dpi = 300,\n  out.width = \"80%\"\n)"
  },
  {
    "objectID": "slides/02-slr.html#movie-scores",
    "href": "slides/02-slr.html#movie-scores",
    "title": "Simple linear regression",
    "section": "Movie scores",
    "text": "Movie scores\n\n\n\nData behind the FiveThirtyEight story Be Suspicious Of Online Movie Ratings, Especially Fandango’s\nIn the fivethirtyeight package: fandango\nContains every film released in 2014 and 2015 that has at least 30 fan reviews on Fandango, an IMDb score, Rotten Tomatoes critic and user ratings, and Metacritic critic and user scores"
  },
  {
    "objectID": "slides/02-slr.html#data-prep",
    "href": "slides/02-slr.html#data-prep",
    "title": "Simple linear regression",
    "section": "Data prep",
    "text": "Data prep\n\nRename Rotten Tomatoes columns as critics and audience\nRename the data set as movie_scores\n\n\nmovie_scores &lt;- fandango |&gt;\n  rename(critics = rottentomatoes, \n         audience = rottentomatoes_user)"
  },
  {
    "objectID": "slides/02-slr.html#data-overview",
    "href": "slides/02-slr.html#data-overview",
    "title": "Simple linear regression",
    "section": "Data overview",
    "text": "Data overview\n\nglimpse(movie_scores)\n\nRows: 146\nColumns: 23\n$ film                       &lt;chr&gt; \"Avengers: Age of Ultron\", \"Cinderella\", \"A…\n$ year                       &lt;dbl&gt; 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2…\n$ critics                    &lt;int&gt; 74, 85, 80, 18, 14, 63, 42, 86, 99, 89, 84,…\n$ audience                   &lt;int&gt; 86, 80, 90, 84, 28, 62, 53, 64, 82, 87, 77,…\n$ metacritic                 &lt;int&gt; 66, 67, 64, 22, 29, 50, 53, 81, 81, 80, 71,…\n$ metacritic_user            &lt;dbl&gt; 7.1, 7.5, 8.1, 4.7, 3.4, 6.8, 7.6, 6.8, 8.8…\n$ imdb                       &lt;dbl&gt; 7.8, 7.1, 7.8, 5.4, 5.1, 7.2, 6.9, 6.5, 7.4…\n$ fandango_stars             &lt;dbl&gt; 5.0, 5.0, 5.0, 5.0, 3.5, 4.5, 4.0, 4.0, 4.5…\n$ fandango_ratingvalue       &lt;dbl&gt; 4.5, 4.5, 4.5, 4.5, 3.0, 4.0, 3.5, 3.5, 4.0…\n$ rt_norm                    &lt;dbl&gt; 3.70, 4.25, 4.00, 0.90, 0.70, 3.15, 2.10, 4…\n$ rt_user_norm               &lt;dbl&gt; 4.30, 4.00, 4.50, 4.20, 1.40, 3.10, 2.65, 3…\n$ metacritic_norm            &lt;dbl&gt; 3.30, 3.35, 3.20, 1.10, 1.45, 2.50, 2.65, 4…\n$ metacritic_user_nom        &lt;dbl&gt; 3.55, 3.75, 4.05, 2.35, 1.70, 3.40, 3.80, 3…\n$ imdb_norm                  &lt;dbl&gt; 3.90, 3.55, 3.90, 2.70, 2.55, 3.60, 3.45, 3…\n$ rt_norm_round              &lt;dbl&gt; 3.5, 4.5, 4.0, 1.0, 0.5, 3.0, 2.0, 4.5, 5.0…\n$ rt_user_norm_round         &lt;dbl&gt; 4.5, 4.0, 4.5, 4.0, 1.5, 3.0, 2.5, 3.0, 4.0…\n$ metacritic_norm_round      &lt;dbl&gt; 3.5, 3.5, 3.0, 1.0, 1.5, 2.5, 2.5, 4.0, 4.0…\n$ metacritic_user_norm_round &lt;dbl&gt; 3.5, 4.0, 4.0, 2.5, 1.5, 3.5, 4.0, 3.5, 4.5…\n$ imdb_norm_round            &lt;dbl&gt; 4.0, 3.5, 4.0, 2.5, 2.5, 3.5, 3.5, 3.5, 3.5…\n$ metacritic_user_vote_count &lt;int&gt; 1330, 249, 627, 31, 88, 34, 17, 124, 62, 54…\n$ imdb_user_vote_count       &lt;int&gt; 271107, 65709, 103660, 3136, 19560, 39373, …\n$ fandango_votes             &lt;int&gt; 14846, 12640, 12055, 1793, 1021, 397, 252, …\n$ fandango_difference        &lt;dbl&gt; 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5…"
  },
  {
    "objectID": "slides/02-slr.html#univariate-exploratory-data-analysis-eda",
    "href": "slides/02-slr.html#univariate-exploratory-data-analysis-eda",
    "title": "Simple linear regression",
    "section": "Univariate exploratory data analysis (EDA)",
    "text": "Univariate exploratory data analysis (EDA)\nThe data set contains the “Tomatometer” score (critics) and audience score (audience) for 146 movies rated on rottentomatoes.com."
  },
  {
    "objectID": "slides/02-slr.html#bivariate-eda",
    "href": "slides/02-slr.html#bivariate-eda",
    "title": "Simple linear regression",
    "section": "Bivariate EDA",
    "text": "Bivariate EDA"
  },
  {
    "objectID": "slides/02-slr.html#bivariate-eda-1",
    "href": "slides/02-slr.html#bivariate-eda-1",
    "title": "Simple linear regression",
    "section": "Bivariate EDA",
    "text": "Bivariate EDA\nGoal: Fit a line to describe the relationship between the critics score and audience score."
  },
  {
    "objectID": "slides/02-slr.html#why-fit-a-line",
    "href": "slides/02-slr.html#why-fit-a-line",
    "title": "Simple linear regression",
    "section": "Why fit a line?",
    "text": "Why fit a line?\nWe fit a line to accomplish one or both of the following:\n\n\n\nPrediction\n\n\nWhat is an example of a prediction question for this data set?\n\n\n\n\n\nInference\n\n\nWhat is an example of an inference question for this data set?"
  },
  {
    "objectID": "slides/02-slr.html#terminology",
    "href": "slides/02-slr.html#terminology",
    "title": "Simple linear regression",
    "section": "Terminology",
    "text": "Terminology\n\n\n\nResponse, \\(Y\\): variable describing the outcome of interest\nPredictor, \\(X\\): variable we use to help understand the variability in the response"
  },
  {
    "objectID": "slides/02-slr.html#regression-model",
    "href": "slides/02-slr.html#regression-model",
    "title": "Simple linear regression",
    "section": "Regression model",
    "text": "Regression model\nA regression model is a function that describes the relationship between the response, \\(Y\\), and the predictor, \\(X\\).\n\\[\\begin{aligned} Y &= \\color{black}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{black}{f(X)} + \\epsilon \\\\[8pt]\n& = \\color{black}{E(Y|X)} + \\epsilon \\\\[8pt]\n&= \\color{black}{\\mu_{Y|X}} + \\epsilon \\end{aligned}\\]"
  },
  {
    "objectID": "slides/02-slr.html#regression-model-1",
    "href": "slides/02-slr.html#regression-model-1",
    "title": "Simple linear regression",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\\begin{aligned} Y &= \\color{purple}{\\textbf{Model}} + \\color{black}\\text{Error} \\\\[8pt]\n&= \\color{purple}{f(X)} + \\color{black}\\epsilon \\\\[8pt]\n&= \\color{purple}{E(Y|X)} + \\color{black}\\epsilon \\\\[8pt]\n&= \\color{purple}{\\mu_{Y|X}} + \\color{black}\\epsilon \\end{aligned}\\]\n\n\n\n\n\n\n\n\n\n\n\n\\(E(Y|X) = \\mu_{Y|X}\\), the mean value of \\(Y\\) given a particular value of \\(X\\)."
  },
  {
    "objectID": "slides/02-slr.html#regression-model-2",
    "href": "slides/02-slr.html#regression-model-2",
    "title": "Simple linear regression",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\n\\begin{aligned} Y &= \\color{purple}{\\textbf{Model}} + \\color{blue}{\\textbf{Error}} \\\\[8pt]\n&= \\color{purple}{f(X)} + \\color{blue}{\\epsilon}\\\\[8pt]\n&= \\color{purple}{E(Y|X)} + \\color{blue}{\\epsilon}\\\\[8pt]\n&= \\color{purple}{\\mu_{Y|X}} + \\color{blue}{\\epsilon} \\\\\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/02-slr.html#determine-fx",
    "href": "slides/02-slr.html#determine-fx",
    "title": "Simple linear regression",
    "section": "Determine \\(f(X)\\)",
    "text": "Determine \\(f(X)\\)\n\nGoal: Determine \\(f(X)\\)\nHow do we determine \\(f(X)\\)\n\nMake an assumption about the functional form \\(f(X)\\) (parametric model)\nUse the data to fit a model based on that form"
  },
  {
    "objectID": "slides/02-slr.html#slr-statistical-model-population",
    "href": "slides/02-slr.html#slr-statistical-model-population",
    "title": "Simple linear regression",
    "section": "SLR: Statistical model (population)",
    "text": "SLR: Statistical model (population)\nWhen we have a quantitative response, \\(Y\\), and a single quantitative predictor, \\(X\\), we can use a (simple) linear regression model to describe the relationship between \\(Y\\) and \\(X\\). \\[Y = \\beta_0 + \\beta_1X + \\epsilon\\]\n\n\n\\(\\beta_1\\): Population (true) slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\beta_0\\): Population (true) intercept of the relationship between \\(X\\) and \\(Y\\)\n\\(\\epsilon\\): Error terms with mean 0 and variance \\(\\sigma^2_{\\epsilon}\\)"
  },
  {
    "objectID": "slides/02-slr.html#slr-regression-equation-sample",
    "href": "slides/02-slr.html#slr-regression-equation-sample",
    "title": "Simple linear regression",
    "section": "SLR: Regression equation (sample)",
    "text": "SLR: Regression equation (sample)\n\\[\\hat{Y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 X\\]\n\n\\(\\hat{\\beta}_1\\): Estimated (sample) slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\hat{\\beta}_0\\): Estimated (sample) intercept of the relationship between \\(X\\) and \\(Y\\)\nNo error term!\n\n\n\nWhy is there no error term in the estimated regression equation?"
  },
  {
    "objectID": "slides/02-slr.html#estimating-hatbeta_1-and-hatbeta_0",
    "href": "slides/02-slr.html#estimating-hatbeta_1-and-hatbeta_0",
    "title": "Simple linear regression",
    "section": "Estimating \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\)",
    "text": "Estimating \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\)"
  },
  {
    "objectID": "slides/02-slr.html#residuals",
    "href": "slides/02-slr.html#residuals",
    "title": "Simple linear regression",
    "section": "Residuals",
    "text": "Residuals\n\n\\[\\text{residual} = \\text{observed} - \\text{predicted} = y_i - \\hat{y}_i\\]"
  },
  {
    "objectID": "slides/02-slr.html#least-squares-line",
    "href": "slides/02-slr.html#least-squares-line",
    "title": "Simple linear regression",
    "section": "Least squares line",
    "text": "Least squares line\n\nThe residual for the \\(i^{th}\\) observation is\n\n\\[e_i = \\text{observed} - \\text{predicted}\n= y_i - \\hat{y}_i\\]\n\nThe sum of squared residuals is\n\n\\[e^2_1 + e^2_2 + \\dots + e^2_n\\]\n\nThe Ordinary Least Squares (OLS) line is the one that minimizes the sum of squared residuals"
  },
  {
    "objectID": "slides/02-slr.html#least-squares-estimate-of-hatbeta_0",
    "href": "slides/02-slr.html#least-squares-estimate-of-hatbeta_0",
    "title": "Simple linear regression",
    "section": "Least-squares estimate of \\(\\hat{\\beta}_0\\)",
    "text": "Least-squares estimate of \\(\\hat{\\beta}_0\\)\n\n\nClick here for full details on estimating \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) ."
  },
  {
    "objectID": "slides/02-slr.html#properties-of-least-squares-regression",
    "href": "slides/02-slr.html#properties-of-least-squares-regression",
    "title": "Simple linear regression",
    "section": "Properties of least squares regression",
    "text": "Properties of least squares regression\n\n\nThe regression line goes through the center of mass point, the coordinates corresponding to mean \\(X\\) and mean \\(Y\\): \\(\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1\\bar{X}\\)\nThe slope has the same sign as the correlation coefficient: \\(\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}\\)\nThe sum of the residuals is approximately zero: \\(\\sum_{i = 1}^n e_i \\approx 0\\)\nThe residuals and \\(X\\) values are uncorrelated"
  },
  {
    "objectID": "slides/02-slr.html#estimating-the-slope",
    "href": "slides/02-slr.html#estimating-the-slope",
    "title": "Simple linear regression",
    "section": "Estimating the slope",
    "text": "Estimating the slope\n\\[\\large{\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}}\\]\n\n\n\\[\n\\begin{aligned} s_X = 30.1688  \\hspace{15mm} &s_Y =  20.0244 \\hspace{15mm} r  = 0.7814 \\\\[10pt]\\hat{\\beta}_1  &= 0.7814 \\times \\frac{20.0244}{30.1688} \\\\&= \\mathbf{0.5187}\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/02-slr.html#estimating-the-intercept",
    "href": "slides/02-slr.html#estimating-the-intercept",
    "title": "Simple linear regression",
    "section": "Estimating the intercept",
    "text": "Estimating the intercept\n\\[\\large{\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1\\bar{X}}\\]\n\n\n\\[\n\\begin{aligned}\\bar{x} = 60.8493 & \\hspace{15mm} \\bar{y} = 63.8767 \\hspace{15mm} \\hat{\\beta}_1 = 0.5187 \\\\[10pt]\n\\hat{\\beta}_0 &= 63.8767 - 0.5187 \\times 60.8493 \\\\\n&= \\mathbf{32.3142}\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/02-slr.html#interpretation",
    "href": "slides/02-slr.html#interpretation",
    "title": "Simple linear regression",
    "section": "Interpretation",
    "text": "Interpretation\n\nQuestionSubmit\n\n\n\n\nSubmit your answers to the following questions on Ed Discussion:\n\nThe slope of the model for predicting audience score from critics score is 0.5187 . Which of the following is the best interpretation of this value?\n32.3142 is the predicted mean audience score for what type of movies?\n\n\n\n\n\n\n\n\n\n🔗 https://edstem.org/us/courses/70811/discussion/5967675"
  },
  {
    "objectID": "slides/02-slr.html#does-it-make-sense-to-interpret-the-intercept",
    "href": "slides/02-slr.html#does-it-make-sense-to-interpret-the-intercept",
    "title": "Simple linear regression",
    "section": "Does it make sense to interpret the intercept?",
    "text": "Does it make sense to interpret the intercept?\n\n✅ The intercept is meaningful in the context of the data if\n\nthe predictor can feasibly take values equal to or near zero, or\nthere are values near zero in the observed data.\n\n\n\n🛑 Otherwise, the intercept may not be meaningful!"
  },
  {
    "objectID": "slides/02-slr.html#making-a-prediction",
    "href": "slides/02-slr.html#making-a-prediction",
    "title": "Simple linear regression",
    "section": "Making a prediction",
    "text": "Making a prediction\nSuppose that a movie has a critics score of 70. According to this model, what is the movie’s predicted audience score?\n\\[\\begin{aligned}\n\\widehat{\\text{audience}} &= 32.3142 + 0.5187 \\times \\text{critics} \\\\\n&= 32.3142 + 0.5187 \\times 70 \\\\\n&= \\mathbf{68.6232}\n\\end{aligned}\\]"
  },
  {
    "objectID": "slides/02-slr.html#fit-the-model",
    "href": "slides/02-slr.html#fit-the-model",
    "title": "Simple linear regression",
    "section": "Fit the model",
    "text": "Fit the model\nUse the lm() function to fit a linear regression model\n\n\nmovie_fit &lt;- lm(audience ~ critics, data = movie_scores)\nmovie_fit\n\n\nCall:\nlm(formula = audience ~ critics, data = movie_scores)\n\nCoefficients:\n(Intercept)      critics  \n    32.3155       0.5187"
  },
  {
    "objectID": "slides/02-slr.html#tidy-results",
    "href": "slides/02-slr.html#tidy-results",
    "title": "Simple linear regression",
    "section": "Tidy results",
    "text": "Tidy results\nUse the tidy() function from the broom R package to “tidy” the model output\n\n\nmovie_fit &lt;- lm(audience ~ critics, data = movie_scores)\ntidy(movie_fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   32.3      2.34        13.8 4.03e-28\n2 critics        0.519    0.0345      15.0 2.70e-31"
  },
  {
    "objectID": "slides/02-slr.html#format-results",
    "href": "slides/02-slr.html#format-results",
    "title": "Simple linear regression",
    "section": "Format results",
    "text": "Format results\nUse the kable() function from the knitr package to neatly format the results\n\n\n\nmovie_fit &lt;- lm(audience ~ critics, data = movie_scores)\ntidy(movie_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n32.316\n2.343\n13.795\n0\n\n\ncritics\n0.519\n0.035\n15.028\n0"
  },
  {
    "objectID": "slides/02-slr.html#prediction-1",
    "href": "slides/02-slr.html#prediction-1",
    "title": "Simple linear regression",
    "section": "Prediction",
    "text": "Prediction\nUse the predict() function to calculate predictions for new observations\n\nSingle observation\n\nnew_movie &lt;- tibble(critics = 70)\npredict(movie_fit, new_movie)\n\n       1 \n68.62297"
  },
  {
    "objectID": "slides/02-slr.html#prediction-2",
    "href": "slides/02-slr.html#prediction-2",
    "title": "Simple linear regression",
    "section": "Prediction",
    "text": "Prediction\nUse the predict() function to calculate predictions for new observations\n\nMultiple observations\n\nmore_new_movies &lt;- tibble(critics = c(24,70, 85))\npredict(movie_fit, more_new_movies)\n\n       1        2        3 \n44.76379 68.62297 76.40313"
  },
  {
    "objectID": "slides/02-slr.html#recap",
    "href": "slides/02-slr.html#recap",
    "title": "Simple linear regression",
    "section": "Recap",
    "text": "Recap\n\nDescribed how regression is used to understand the relationship between multiple variables\nUsed least squares to estimate the slope and intercept\nInterpreted the slope and intercept for simple linear regression\nPredicted the response given a value of the predictor"
  },
  {
    "objectID": "slides/02-slr.html#next-time",
    "href": "slides/02-slr.html#next-time",
    "title": "Simple linear regression",
    "section": "Next time",
    "text": "Next time\n\nModel assessment for simple linear regression\n\nComplete Lec 03: Model Assessment prepare\n\nBring fully-charged laptop or device with keyboard for in-class application exercise (AE)"
  },
  {
    "objectID": "slides/lab-05.html#todays-lab",
    "href": "slides/lab-05.html#todays-lab",
    "title": "Lab 05",
    "section": "Today’s lab",
    "text": "Today’s lab\n\nProject\nMid-semester survey\nLab 05: Expanding multiple linear regression"
  },
  {
    "objectID": "slides/lab-05.html#project",
    "href": "slides/lab-05.html#project",
    "title": "Lab 05",
    "section": "Project",
    "text": "Project\n\nFeedback on your project proposal is posted as an Issue in your project repo\nPlease let your lab TA know if you have any questions\nNext milestone: Exploratory Data Analysis due March 20\n\nTime to work on it in next week’s lab"
  },
  {
    "objectID": "slides/lab-05.html#mid-semester-feedback",
    "href": "slides/lab-05.html#mid-semester-feedback",
    "title": "Lab 05",
    "section": "Mid-semester feedback",
    "text": "Mid-semester feedback\n\nPurpose: To give the teaching team feedback on what is working well (or not as well) in helping you learn the course content\nThe feedback is anonymous and will not be graded\nIt will be available until Sunday, March 2 at 11:59pm\n\nPlease take a few minutes to fill it out during lab today\n\n\nWe (the teaching team) appreciate your feedback!\n🔗 https://duke.qualtrics.com/jfe/form/SV_88lXoqudX60C9cq"
  },
  {
    "objectID": "slides/lab-05.html#lab-05-expanding-multiple-linear-regression",
    "href": "slides/lab-05.html#lab-05-expanding-multiple-linear-regression",
    "title": "Lab 05",
    "section": "Lab 05: Expanding multiple linear regression",
    "text": "Lab 05: Expanding multiple linear regression\nThis lab focuses on\n\nmodeling complex data using variable transformations, categorical predictors and interactions, and various model specifications.\nevaluating model diagnostics and conditions.\n\n🔗 https://sta221-sp25.netlify.app/labs/lab-05"
  },
  {
    "objectID": "slides/lab-05.html#reminder-tips-for-working-on-a-team",
    "href": "slides/lab-05.html#reminder-tips-for-working-on-a-team",
    "title": "Lab 05",
    "section": "Reminder: Tips for working on a team",
    "text": "Reminder: Tips for working on a team\n\nDo not pressure each other to finish early; use the time wisely to really learn the material and produce a quality report.\nThe labs are structured to help you learn the steps of a data analysis. Do not split up the lab among the team members; work on it together in its entirety.\nEveryone has something to contribute! Use the lab groups as an opportunity to share ideas and learn from each other."
  },
  {
    "objectID": "slides/01-welcome-notes.html",
    "href": "slides/01-welcome-notes.html",
    "title": "Welcome to STA 221!",
    "section": "",
    "text": "Education and career journey\n\nBS in Math and MS in Statistics from University of Tennessee\nStatistician at Capital One\nPhD in Statistics from University of Virginia\nAssistant Professor of the Practice, Department of Statistical Science at Duke\n\nWork focuses on statistics education and sense of belonging in introductory math and statistics classes\nCo-leader of the Bass Connections team Mental Health and the Justice System in Durham County\nMom of 2-year-old twins 🙂\n\n\n\n\n\n\n\nKat Husar (PhD): Head TA + Lab 01 leader\nKelly Huang (UG): Classroom TA\nJanice Kim (MS): Classroom TA\nCathy Lee (PhD): Lab 02 leader\nAlan Wang (UG): Lab 01 helper\n\n\n\n\n\nClick on the link or scan the QR code to answer the Ed Discussion poll\nhttps://edstem.org/us/courses/70811/discussion/5950645\n\n\n\n\n\n\n\n\n\nIntroduction to the course\nSyllabus activity\nReproducibility"
  },
  {
    "objectID": "slides/01-welcome-notes.html#meet-prof.-tackett",
    "href": "slides/01-welcome-notes.html#meet-prof.-tackett",
    "title": "Welcome to STA 221!",
    "section": "",
    "text": "Education and career journey\n\nBS in Math and MS in Statistics from University of Tennessee\nStatistician at Capital One\nPhD in Statistics from University of Virginia\nAssistant Professor of the Practice, Department of Statistical Science at Duke\n\nWork focuses on statistics education and sense of belonging in introductory math and statistics classes\nCo-leader of the Bass Connections team Mental Health and the Justice System in Durham County\nMom of 2-year-old twins 🙂"
  },
  {
    "objectID": "slides/01-welcome-notes.html#meet-the-teaching-assistants-tas",
    "href": "slides/01-welcome-notes.html#meet-the-teaching-assistants-tas",
    "title": "Welcome to STA 221!",
    "section": "",
    "text": "Kat Husar (PhD): Head TA + Lab 01 leader\nKelly Huang (UG): Classroom TA\nJanice Kim (MS): Classroom TA\nCathy Lee (PhD): Lab 02 leader\nAlan Wang (UG): Lab 01 helper"
  },
  {
    "objectID": "slides/01-welcome-notes.html#check-in-on-ed-discussion",
    "href": "slides/01-welcome-notes.html#check-in-on-ed-discussion",
    "title": "Welcome to STA 221!",
    "section": "",
    "text": "Click on the link or scan the QR code to answer the Ed Discussion poll\nhttps://edstem.org/us/courses/70811/discussion/5950645"
  },
  {
    "objectID": "slides/01-welcome-notes.html#topics",
    "href": "slides/01-welcome-notes.html#topics",
    "title": "Welcome to STA 221!",
    "section": "",
    "text": "Introduction to the course\nSyllabus activity\nReproducibility"
  },
  {
    "objectID": "slides/01-welcome-notes.html#what-is-regression-analysis",
    "href": "slides/01-welcome-notes.html#what-is-regression-analysis",
    "title": "Welcome to STA 221!",
    "section": "What is regression analysis?",
    "text": "What is regression analysis?\n\n\nRegression analysis is a statistical method used to examine the relationship between a response variable and one or more predictor variables. It is used for predicting future values, understanding relationships between variables, and identifying key predictors. It also helps in modeling trends, assessing the impact of changes, and detecting outliers in data.\n\nSource: ChatGPT (with modification)"
  },
  {
    "objectID": "slides/01-welcome-notes.html#regression-in-practice",
    "href": "slides/01-welcome-notes.html#regression-in-practice",
    "title": "Welcome to STA 221!",
    "section": "Regression in practice",
    "text": "Regression in practice\n\n\n\n\n\n\n\nRodgers, J. L. (2024). Reading Harry Potter in French: Using Regression to Evaluate Foreign Language Vocabulary Learning by an Old Guy. CHANCE, 37(3), 13–21."
  },
  {
    "objectID": "slides/01-welcome-notes.html#regression-in-practice-1",
    "href": "slides/01-welcome-notes.html#regression-in-practice-1",
    "title": "Welcome to STA 221!",
    "section": "Regression in practice",
    "text": "Regression in practice\n\n\n\n\n\n\\[\n\\text{Lookups} = 23.0 - 0.04 \\times \\text{Page Number}\n\\]\n\n\nRodgers, J. L. (2024). Reading Harry Potter in French: Using Regression to Evaluate Foreign Language Vocabulary Learning by an Old Guy. CHANCE, 37(3), 13–21."
  },
  {
    "objectID": "slides/01-welcome-notes.html#example-rent-vs.-commute-time",
    "href": "slides/01-welcome-notes.html#example-rent-vs.-commute-time",
    "title": "Welcome to STA 221!",
    "section": "Example: Rent vs. commute time",
    "text": "Example: Rent vs. commute time\n\\[\n\\text{Lookups} = \\beta_0 + \\beta_1 ~ \\text{Page Number} + \\epsilon\n\\]\n\n. . .\n\\[\n\\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix} =\n\\begin{bmatrix}\n1 & x_1 \\\\\n1 & x_2 \\\\\n\\vdots & \\vdots \\\\\n1 & x_n\n\\end{bmatrix}\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\end{bmatrix} +  \\begin{bmatrix}\n\\epsilon_1 \\\\\n\\epsilon_2 \\\\\n\\vdots \\\\\n\\epsilon_n\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/01-welcome-notes.html#what-is-sta-221",
    "href": "slides/01-welcome-notes.html#what-is-sta-221",
    "title": "Welcome to STA 221!",
    "section": "What is STA 221?",
    "text": "What is STA 221?\n\n\n\n\n\n STA 210 \n\nApplication\n\n\n\n\n+\n\n\n\n\n\nSTA 211\n\nMathematical theory\n\n\n\n\nPrerequisites: Introductory statistics or probability course and linear algebra\nRecommended corequisite: Probability course at Duke"
  },
  {
    "objectID": "slides/01-welcome-notes.html#course-learning-objectives",
    "href": "slides/01-welcome-notes.html#course-learning-objectives",
    "title": "Welcome to STA 221!",
    "section": "Course learning objectives",
    "text": "Course learning objectives\nBy the end of the semester, you will be able to…\n\nanalyze data to explore real-world multivariable relationships.\nfit, interpret, and draw conclusions from linear and logistic regression models.\nimplement a reproducible analysis workflow using R for analysis, Quarto to write reports and GitHub for version control and collaboration.\nexplain the mathematical foundations of linear and logistic regression.\neffectively communicate statistical results to a general audience.\nassess the ethical considerations and implications of analysis decisions."
  },
  {
    "objectID": "slides/01-welcome-notes.html#course-topics",
    "href": "slides/01-welcome-notes.html#course-topics",
    "title": "Welcome to STA 221!",
    "section": "Course topics",
    "text": "Course topics\n\n\n\n\nLinear regression\n\nCoefficient estimation and interpretation\nPrediction\nModel assessment\nMatrix representation of regression\nModel conditions and diagnostics\nModel comparison\nDifferent types of predictor variables\nProperties of estimators\n\n\n\n\n\n\nLogistic regression\n\nCoefficient estimation and interpretation\nPrediction\nModel assessment\nInference\n\n\n\n\n\nGeneral topics\n\nComputing using R and GitHub\nPresenting statistical results\nCollaboration and teamwork"
  },
  {
    "objectID": "slides/01-welcome-notes.html#course-toolkit",
    "href": "slides/01-welcome-notes.html#course-toolkit",
    "title": "Welcome to STA 221!",
    "section": "Course toolkit",
    "text": "Course toolkit\n\nWebsite: https://sta221-sp25.netlify.app\n\nCentral hub for the course!\nTour of the website\n\nCanvas: https://canvas.duke.edu/courses/51767\n\nGradebook\nOffice hours\nAnnouncements\nGradescope\nEd Discussion\n\nGitHub: https://github.com/sta221-sp25\n\nDistribute assignments\nPlatform for version control and collaboration"
  },
  {
    "objectID": "slides/01-welcome-notes.html#computing-toolkit",
    "href": "slides/01-welcome-notes.html#computing-toolkit",
    "title": "Welcome to STA 221!",
    "section": "Computing toolkit",
    "text": "Computing toolkit\n\n\n\n\n\n\n\n\n\n\n\nAll analyses using R, a statistical programming language\nWrite reproducible reports in Quarto\nAccess RStudio through STA 221 Docker Containers\n\n\n\n\n\n\n\n\n\n\n\n\nAccess assignments\nFacilitates version control and collaboration\nAll work in STA 221 course organization"
  },
  {
    "objectID": "slides/01-welcome-notes.html#classroom-community",
    "href": "slides/01-welcome-notes.html#classroom-community",
    "title": "Welcome to STA 221!",
    "section": "Classroom community",
    "text": "Classroom community\n\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\nIf you have a name that differs from those that appear in your official Duke records, please let me know.\nPlease let me know your preferred pronouns, if you are comfortable sharing.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your advisers and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said or done in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "slides/01-welcome-notes.html#accessibility",
    "href": "slides/01-welcome-notes.html#accessibility",
    "title": "Welcome to STA 221!",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nIf you have documented accommodations from SDAO, please send the documentation as soon as possible.\nI am committed to making all course activities and materials accessible. If any course component is not accessible to you in any way, please don’t hesitate to let me know."
  },
  {
    "objectID": "slides/01-welcome-notes.html#syllabus-activity",
    "href": "slides/01-welcome-notes.html#syllabus-activity",
    "title": "Welcome to STA 221!",
    "section": "Syllabus activity",
    "text": "Syllabus activity\n\n\nRead the portion of the syllabus assigned to your group.\nDiscuss the key points and questions you my have with your neighbors.\nWe’ll ask for volunteers to share a summary with the class."
  },
  {
    "objectID": "slides/01-welcome-notes.html#syllabus-activity-assignments",
    "href": "slides/01-welcome-notes.html#syllabus-activity-assignments",
    "title": "Welcome to STA 221!",
    "section": "Syllabus activity assignments",
    "text": "Syllabus activity assignments\n\nGroup 1: What to expect in lectures and labs\nGroup 2: Homework and lab assignments\nGroup 3: Exams and project\nGroup 4: Participation\nGroup 5: Academic honesty (except AI policy)\nGroup 6: Artificial intelligence policy\nGroup 7: Late work policy and waiver for extenuating circumstances\nGroup 8: Attendance and lecture recording request\nGroup 9: Getting help in the course"
  },
  {
    "objectID": "slides/01-welcome-notes.html#syllabus-activity-report-out",
    "href": "slides/01-welcome-notes.html#syllabus-activity-report-out",
    "title": "Welcome to STA 221!",
    "section": "Syllabus activity report out",
    "text": "Syllabus activity report out\n\n\nGroup 1: What to expect in lectures and labs\nGroup 2: Homework and lab assignments\nGroup 3: Exams and project\nGroup 4: Participation\nGroup 5: Academic honesty (except AI policy)\nGroup 6: Artificial intelligence policy\nGroup 7: Late work policy and waiver for extenuating circumstances\nGroup 8: Attendance and lecture recording request\nGroup 9: Getting help in the course"
  },
  {
    "objectID": "slides/01-welcome-notes.html#grading",
    "href": "slides/01-welcome-notes.html#grading",
    "title": "Welcome to STA 221!",
    "section": "Grading",
    "text": "Grading\n\n\n\nCategory\nPercentage\n\n\n\n\nHomework\n30%\n\n\nFinal project\n15%\n\n\nLab\n10%\n\n\nExams (2 midterms)\n40%\n\n\nParticipation (AEs + Teamwork)\n5%\n\n\nTotal\n100%"
  },
  {
    "objectID": "slides/01-welcome-notes.html#five-tips-for-success-in-sta-221",
    "href": "slides/01-welcome-notes.html#five-tips-for-success-in-sta-221",
    "title": "Welcome to STA 221!",
    "section": "Five tips for success in STA 221",
    "text": "Five tips for success in STA 221\n\nComplete all the preparation work before class.\nAsk questions in class, office hours, and on Ed Discussion.\nDo the homework and labs; get started on homework early when possible.\nDon’t procrastinate and don’t let a week pass by with lingering questions.\nStay up-to-date on announcements on Ed Discussion and sent via email."
  },
  {
    "objectID": "slides/01-welcome-notes.html#reproducibility-checklist",
    "href": "slides/01-welcome-notes.html#reproducibility-checklist",
    "title": "Welcome to STA 221!",
    "section": "Reproducibility checklist",
    "text": "Reproducibility checklist\n\nWhat does it mean for an analysis to be reproducible?\n\n. . .\nNear term goals:\n✔️ Can the tables and figures be exactly reproduced from the code and data?\n✔️ Does the code actually do what you think it does?\n✔️ In addition to what was done, is it clear why it was done?\n. . .\nLong term goals:\n✔️ Can the code be used for other data?\n✔️ Can you extend the code to do other things?"
  },
  {
    "objectID": "slides/01-welcome-notes.html#why-is-reproducibility-important",
    "href": "slides/01-welcome-notes.html#why-is-reproducibility-important",
    "title": "Welcome to STA 221!",
    "section": "Why is reproducibility important?",
    "text": "Why is reproducibility important?\n\nResults produced are more reliable and trustworthy (Ostblom and Timbers 2022)\nFacilitates more effective collaboration (Ostblom and Timbers 2022)\nContributing to science, which builds and organizes knowledge in terms of testable hypotheses (Alexander 2023)\nPossible to identify and correct errors or biases in the analysis process (Alexander 2023)"
  },
  {
    "objectID": "slides/01-welcome-notes.html#why-is-reproducibility-important-1",
    "href": "slides/01-welcome-notes.html#why-is-reproducibility-important-1",
    "title": "Welcome to STA 221!",
    "section": "Why is reproducibility important?",
    "text": "Why is reproducibility important?\n\n\n\n\n\n\n\nOriginally reported “the intervention, compared with usual care, resulted in a fewer number of mean COPD-related hospitalizations and emergency department visits at 6 months per participant.”\nThere were actually more COPD-related hospitalizations and emergency department visits in the intervention group compared to the control group\nMixed up the intervention vs. control group using “0/1” coding\n\n\n\n\n\nhttps://jamanetwork.com/journals/jama/fullarticle/2752474"
  },
  {
    "objectID": "slides/01-welcome-notes.html#toolkit",
    "href": "slides/01-welcome-notes.html#toolkit",
    "title": "Welcome to STA 221!",
    "section": "Toolkit",
    "text": "Toolkit\n\nScriptability \\(\\rightarrow\\) R\nLiterate programming (code, narrative, output in one place) \\(\\rightarrow\\) Quarto\nVersion control \\(\\rightarrow\\) Git / GitHub"
  },
  {
    "objectID": "slides/01-welcome-notes.html#r-and-rstudio",
    "href": "slides/01-welcome-notes.html#r-and-rstudio",
    "title": "Welcome to STA 221!",
    "section": "R and RStudio",
    "text": "R and RStudio\n\nR is a statistical programming language\nRStudio is a convenient interface for R (an integrated development environment, IDE)\n\n\n\n\nSource: Statistical Inference via Data Science"
  },
  {
    "objectID": "slides/01-welcome-notes.html#rstudio-ide",
    "href": "slides/01-welcome-notes.html#rstudio-ide",
    "title": "Welcome to STA 221!",
    "section": "RStudio IDE",
    "text": "RStudio IDE"
  },
  {
    "objectID": "slides/01-welcome-notes.html#quarto",
    "href": "slides/01-welcome-notes.html#quarto",
    "title": "Welcome to STA 221!",
    "section": "Quarto",
    "text": "Quarto\n\nFully reproducible reports – the analysis is run from the beginning each time you render\nCode goes in chunks and narrative goes outside of chunks\nVisual editor to make document editing experience similar to a word processor (Google docs, Word, Pages, etc.)"
  },
  {
    "objectID": "slides/01-welcome-notes.html#quarto-1",
    "href": "slides/01-welcome-notes.html#quarto-1",
    "title": "Welcome to STA 221!",
    "section": "Quarto",
    "text": "Quarto"
  },
  {
    "objectID": "slides/01-welcome-notes.html#how-will-we-use-quarto",
    "href": "slides/01-welcome-notes.html#how-will-we-use-quarto",
    "title": "Welcome to STA 221!",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n\nEvery application exercise and assignment is written in a Quarto document\nYou’ll have a template Quarto document to start with\nThe amount of scaffolding in the template will decrease over the semester"
  },
  {
    "objectID": "slides/01-welcome-notes.html#what-is-versioning",
    "href": "slides/01-welcome-notes.html#what-is-versioning",
    "title": "Welcome to STA 221!",
    "section": "What is versioning?",
    "text": "What is versioning?"
  },
  {
    "objectID": "slides/01-welcome-notes.html#what-is-versioning-1",
    "href": "slides/01-welcome-notes.html#what-is-versioning-1",
    "title": "Welcome to STA 221!",
    "section": "What is versioning?",
    "text": "What is versioning?\nwith human readable messages"
  },
  {
    "objectID": "slides/01-welcome-notes.html#why-do-we-need-version-control",
    "href": "slides/01-welcome-notes.html#why-do-we-need-version-control",
    "title": "Welcome to STA 221!",
    "section": "Why do we need version control?",
    "text": "Why do we need version control?\n\n\n\n\n\n\n\n\nProvides a clear record of how the analysis methods evolved. This makes analysis auditable and thus more trustworthy and reliable. (Ostblom and Timbers 2022)"
  },
  {
    "objectID": "slides/01-welcome-notes.html#git-and-github",
    "href": "slides/01-welcome-notes.html#git-and-github",
    "title": "Welcome to STA 221!",
    "section": "git and GitHub",
    "text": "git and GitHub\n\n\n\n\n\n\ngit is a version control system – like “Track Changes” features from Microsoft Word.\nGitHub is the home for your git-based projects on the internet (like DropBox but much better).\nThere are a lot of git commands and very few people know them all. 99% of the time you will use git to add, commit, push, and pull."
  },
  {
    "objectID": "slides/01-welcome-notes.html#before-next-class",
    "href": "slides/01-welcome-notes.html#before-next-class",
    "title": "Welcome to STA 221!",
    "section": "Before next class",
    "text": "Before next class\n\nComplete Lecture 02: Simple linear regression prepare\nReview syllabus\nOffice hours start Monday, January 13\n\nAlan’s office hours start January 27"
  },
  {
    "objectID": "slides/01-welcome.html#meet-prof.-tackett",
    "href": "slides/01-welcome.html#meet-prof.-tackett",
    "title": "Welcome to STA 221!",
    "section": "Meet Prof. Tackett!",
    "text": "Meet Prof. Tackett!\n\n\nEducation and career journey\n\nBS in Math and MS in Statistics from University of Tennessee\nStatistician at Capital One\nPhD in Statistics from University of Virginia\nAssistant Professor of the Practice, Department of Statistical Science at Duke\n\nWork focuses on statistics education and sense of belonging in introductory math and statistics classes\nCo-leader of the Bass Connections team Mental Health and the Justice System in Durham County\nMom of 2-year-old twins 🙂"
  },
  {
    "objectID": "slides/01-welcome.html#meet-the-teaching-assistants-tas",
    "href": "slides/01-welcome.html#meet-the-teaching-assistants-tas",
    "title": "Welcome to STA 221!",
    "section": "Meet the Teaching Assistants (TAs)!",
    "text": "Meet the Teaching Assistants (TAs)!\n\nKat Husar (PhD): Head TA + Lab 01 leader\nKelly Huang (UG): Classroom TA\nJanice Kim (MS): Classroom TA\nCathy Lee (PhD): Lab 02 leader\nAlan Wang (UG): Lab 01 helper"
  },
  {
    "objectID": "slides/01-welcome.html#check-in-on-ed-discussion",
    "href": "slides/01-welcome.html#check-in-on-ed-discussion",
    "title": "Welcome to STA 221!",
    "section": "Check-in on Ed Discussion!",
    "text": "Check-in on Ed Discussion!\n\nClick on the link or scan the QR code to answer the Ed Discussion poll\nhttps://edstem.org/us/courses/70811/discussion/5950645"
  },
  {
    "objectID": "slides/01-welcome.html#topics",
    "href": "slides/01-welcome.html#topics",
    "title": "Welcome to STA 221!",
    "section": "Topics",
    "text": "Topics\n\nIntroduction to the course\nSyllabus activity\nReproducibility"
  },
  {
    "objectID": "slides/01-welcome.html#what-is-regression-analysis",
    "href": "slides/01-welcome.html#what-is-regression-analysis",
    "title": "Welcome to STA 221!",
    "section": "What is regression analysis?",
    "text": "What is regression analysis?\n\n\nRegression analysis is a statistical method used to examine the relationship between a response variable and one or more predictor variables. It is used for predicting future values, understanding relationships between variables, and identifying key predictors. It also helps in modeling trends, assessing the impact of changes, and detecting outliers in data.\n\nSource: ChatGPT (with modification)"
  },
  {
    "objectID": "slides/01-welcome.html#regression-in-practice",
    "href": "slides/01-welcome.html#regression-in-practice",
    "title": "Welcome to STA 221!",
    "section": "Regression in practice",
    "text": "Regression in practice\n\n\n\n\n\n\n\nRodgers, J. L. (2024). Reading Harry Potter in French: Using Regression to Evaluate Foreign Language Vocabulary Learning by an Old Guy. CHANCE, 37(3), 13–21."
  },
  {
    "objectID": "slides/01-welcome.html#regression-in-practice-1",
    "href": "slides/01-welcome.html#regression-in-practice-1",
    "title": "Welcome to STA 221!",
    "section": "Regression in practice",
    "text": "Regression in practice\n\n\n\n\n\n\\[\n\\text{Lookups} = 23.0 - 0.04 \\times \\text{Page Number}\n\\]\n\n\nRodgers, J. L. (2024). Reading Harry Potter in French: Using Regression to Evaluate Foreign Language Vocabulary Learning by an Old Guy. CHANCE, 37(3), 13–21."
  },
  {
    "objectID": "slides/01-welcome.html#example-rent-vs.-commute-time",
    "href": "slides/01-welcome.html#example-rent-vs.-commute-time",
    "title": "Welcome to STA 221!",
    "section": "Example: Rent vs. commute time",
    "text": "Example: Rent vs. commute time\n\\[\n\\text{Lookups} = \\beta_0 + \\beta_1 ~ \\text{Page Number} + \\epsilon\n\\]\n\n\n\\[\n\\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix} =\n\\begin{bmatrix}\n1 & x_1 \\\\\n1 & x_2 \\\\\n\\vdots & \\vdots \\\\\n1 & x_n\n\\end{bmatrix}\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\end{bmatrix} +  \\begin{bmatrix}\n\\epsilon_1 \\\\\n\\epsilon_2 \\\\\n\\vdots \\\\\n\\epsilon_n\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/01-welcome.html#what-is-sta-221",
    "href": "slides/01-welcome.html#what-is-sta-221",
    "title": "Welcome to STA 221!",
    "section": "What is STA 221?",
    "text": "What is STA 221?\n\n\n\n\n\n STA 210 \n\nApplication\n\n\n\n\n+\n\n\n\n\n\nSTA 211\n\nMathematical theory\n\n\n\nPrerequisites: Introductory statistics or probability course and linear algebra\nRecommended corequisite: Probability course at Duke"
  },
  {
    "objectID": "slides/01-welcome.html#course-learning-objectives",
    "href": "slides/01-welcome.html#course-learning-objectives",
    "title": "Welcome to STA 221!",
    "section": "Course learning objectives",
    "text": "Course learning objectives\nBy the end of the semester, you will be able to…\n\nanalyze data to explore real-world multivariable relationships.\nfit, interpret, and draw conclusions from linear and logistic regression models.\nimplement a reproducible analysis workflow using R for analysis, Quarto to write reports and GitHub for version control and collaboration.\nexplain the mathematical foundations of linear and logistic regression.\neffectively communicate statistical results to a general audience.\nassess the ethical considerations and implications of analysis decisions."
  },
  {
    "objectID": "slides/01-welcome.html#course-topics",
    "href": "slides/01-welcome.html#course-topics",
    "title": "Welcome to STA 221!",
    "section": "Course topics",
    "text": "Course topics\n\n\n\nLinear regression\n\nCoefficient estimation and interpretation\nPrediction\nModel assessment\nMatrix representation of regression\nModel conditions and diagnostics\nModel comparison\nDifferent types of predictor variables\nProperties of estimators\n\n\n\n\nLogistic regression\n\nCoefficient estimation and interpretation\nPrediction\nModel assessment\nInference\n\n\n\nGeneral topics\n\nComputing using R and GitHub\nPresenting statistical results\nCollaboration and teamwork"
  },
  {
    "objectID": "slides/01-welcome.html#course-toolkit",
    "href": "slides/01-welcome.html#course-toolkit",
    "title": "Welcome to STA 221!",
    "section": "Course toolkit",
    "text": "Course toolkit\n\nWebsite: https://sta221-sp25.netlify.app\n\nCentral hub for the course!\nTour of the website\n\nCanvas: https://canvas.duke.edu/courses/51767\n\nGradebook\nOffice hours\nAnnouncements\nGradescope\nEd Discussion\n\nGitHub: https://github.com/sta221-sp25\n\nDistribute assignments\nPlatform for version control and collaboration"
  },
  {
    "objectID": "slides/01-welcome.html#computing-toolkit",
    "href": "slides/01-welcome.html#computing-toolkit",
    "title": "Welcome to STA 221!",
    "section": "Computing toolkit",
    "text": "Computing toolkit\n\n\n\n\n\n\n\n\n\n\n\nAll analyses using R, a statistical programming language\nWrite reproducible reports in Quarto\nAccess RStudio through STA 221 Docker Containers\n\n\n\n\n\n\n\n\n\n\n\n\nAccess assignments\nFacilitates version control and collaboration\nAll work in STA 221 course organization"
  },
  {
    "objectID": "slides/01-welcome.html#classroom-community",
    "href": "slides/01-welcome.html#classroom-community",
    "title": "Welcome to STA 221!",
    "section": "Classroom community",
    "text": "Classroom community\n\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\nIf you have a name that differs from those that appear in your official Duke records, please let me know.\nPlease let me know your preferred pronouns, if you are comfortable sharing.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your advisers and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said or done in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "slides/01-welcome.html#accessibility",
    "href": "slides/01-welcome.html#accessibility",
    "title": "Welcome to STA 221!",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nIf you have documented accommodations from SDAO, please send the documentation as soon as possible.\nI am committed to making all course activities and materials accessible. If any course component is not accessible to you in any way, please don’t hesitate to let me know."
  },
  {
    "objectID": "slides/01-welcome.html#syllabus-activity",
    "href": "slides/01-welcome.html#syllabus-activity",
    "title": "Welcome to STA 221!",
    "section": "Syllabus activity",
    "text": "Syllabus activity\n\n\nRead the portion of the syllabus assigned to your group.\nDiscuss the key points and questions you my have with your neighbors.\nWe’ll ask for volunteers to share a summary with the class."
  },
  {
    "objectID": "slides/01-welcome.html#syllabus-activity-assignments",
    "href": "slides/01-welcome.html#syllabus-activity-assignments",
    "title": "Welcome to STA 221!",
    "section": "Syllabus activity assignments",
    "text": "Syllabus activity assignments\n\nGroup 1: What to expect in lectures and labs\nGroup 2: Homework and lab assignments\nGroup 3: Exams and project\nGroup 4: Participation\nGroup 5: Academic honesty (except AI policy)\nGroup 6: Artificial intelligence policy\nGroup 7: Late work policy and waiver for extenuating circumstances\nGroup 8: Attendance and lecture recording request\nGroup 9: Getting help in the course"
  },
  {
    "objectID": "slides/01-welcome.html#syllabus-activity-report-out",
    "href": "slides/01-welcome.html#syllabus-activity-report-out",
    "title": "Welcome to STA 221!",
    "section": "Syllabus activity report out",
    "text": "Syllabus activity report out\n\n\nGroup 1: What to expect in lectures and labs\nGroup 2: Homework and lab assignments\nGroup 3: Exams and project\nGroup 4: Participation\nGroup 5: Academic honesty (except AI policy)\nGroup 6: Artificial intelligence policy\nGroup 7: Late work policy and waiver for extenuating circumstances\nGroup 8: Attendance and lecture recording request\nGroup 9: Getting help in the course"
  },
  {
    "objectID": "slides/01-welcome.html#grading",
    "href": "slides/01-welcome.html#grading",
    "title": "Welcome to STA 221!",
    "section": "Grading",
    "text": "Grading\n\n\n\nCategory\nPercentage\n\n\n\n\nHomework\n30%\n\n\nFinal project\n15%\n\n\nLab\n10%\n\n\nExams (2 midterms)\n40%\n\n\nParticipation (AEs + Teamwork)\n5%\n\n\nTotal\n100%"
  },
  {
    "objectID": "slides/01-welcome.html#five-tips-for-success-in-sta-221",
    "href": "slides/01-welcome.html#five-tips-for-success-in-sta-221",
    "title": "Welcome to STA 221!",
    "section": "Five tips for success in STA 221",
    "text": "Five tips for success in STA 221\n\nComplete all the preparation work before class.\nAsk questions in class, office hours, and on Ed Discussion.\nDo the homework and labs; get started on homework early when possible.\nDon’t procrastinate and don’t let a week pass by with lingering questions.\nStay up-to-date on announcements on Ed Discussion and sent via email."
  },
  {
    "objectID": "slides/01-welcome.html#reproducibility-checklist",
    "href": "slides/01-welcome.html#reproducibility-checklist",
    "title": "Welcome to STA 221!",
    "section": "Reproducibility checklist",
    "text": "Reproducibility checklist\n\nWhat does it mean for an analysis to be reproducible?\n\n\nNear term goals:\n✔️ Can the tables and figures be exactly reproduced from the code and data?\n✔️ Does the code actually do what you think it does?\n✔️ In addition to what was done, is it clear why it was done?\n\n\nLong term goals:\n✔️ Can the code be used for other data?\n✔️ Can you extend the code to do other things?"
  },
  {
    "objectID": "slides/01-welcome.html#why-is-reproducibility-important",
    "href": "slides/01-welcome.html#why-is-reproducibility-important",
    "title": "Welcome to STA 221!",
    "section": "Why is reproducibility important?",
    "text": "Why is reproducibility important?\n\nResults produced are more reliable and trustworthy (Ostblom and Timbers 2022)\nFacilitates more effective collaboration (Ostblom and Timbers 2022)\nContributing to science, which builds and organizes knowledge in terms of testable hypotheses (Alexander 2023)\nPossible to identify and correct errors or biases in the analysis process (Alexander 2023)"
  },
  {
    "objectID": "slides/01-welcome.html#why-is-reproducibility-important-1",
    "href": "slides/01-welcome.html#why-is-reproducibility-important-1",
    "title": "Welcome to STA 221!",
    "section": "Why is reproducibility important?",
    "text": "Why is reproducibility important?\n\n\n\n\n\n\n\nOriginally reported “the intervention, compared with usual care, resulted in a fewer number of mean COPD-related hospitalizations and emergency department visits at 6 months per participant.”\nThere were actually more COPD-related hospitalizations and emergency department visits in the intervention group compared to the control group\nMixed up the intervention vs. control group using “0/1” coding\n\n\n\n\n\nhttps://jamanetwork.com/journals/jama/fullarticle/2752474"
  },
  {
    "objectID": "slides/01-welcome.html#toolkit",
    "href": "slides/01-welcome.html#toolkit",
    "title": "Welcome to STA 221!",
    "section": "Toolkit",
    "text": "Toolkit\n\nScriptability \\(\\rightarrow\\) R\nLiterate programming (code, narrative, output in one place) \\(\\rightarrow\\) Quarto\nVersion control \\(\\rightarrow\\) Git / GitHub"
  },
  {
    "objectID": "slides/01-welcome.html#r-and-rstudio",
    "href": "slides/01-welcome.html#r-and-rstudio",
    "title": "Welcome to STA 221!",
    "section": "R and RStudio",
    "text": "R and RStudio\n\nR is a statistical programming language\nRStudio is a convenient interface for R (an integrated development environment, IDE)\n\n\nSource: Statistical Inference via Data Science"
  },
  {
    "objectID": "slides/01-welcome.html#rstudio-ide",
    "href": "slides/01-welcome.html#rstudio-ide",
    "title": "Welcome to STA 221!",
    "section": "RStudio IDE",
    "text": "RStudio IDE"
  },
  {
    "objectID": "slides/01-welcome.html#quarto",
    "href": "slides/01-welcome.html#quarto",
    "title": "Welcome to STA 221!",
    "section": "Quarto",
    "text": "Quarto\n\nFully reproducible reports – the analysis is run from the beginning each time you render\nCode goes in chunks and narrative goes outside of chunks\nVisual editor to make document editing experience similar to a word processor (Google docs, Word, Pages, etc.)"
  },
  {
    "objectID": "slides/01-welcome.html#quarto-1",
    "href": "slides/01-welcome.html#quarto-1",
    "title": "Welcome to STA 221!",
    "section": "Quarto",
    "text": "Quarto"
  },
  {
    "objectID": "slides/01-welcome.html#how-will-we-use-quarto",
    "href": "slides/01-welcome.html#how-will-we-use-quarto",
    "title": "Welcome to STA 221!",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n\nEvery application exercise and assignment is written in a Quarto document\nYou’ll have a template Quarto document to start with\nThe amount of scaffolding in the template will decrease over the semester"
  },
  {
    "objectID": "slides/01-welcome.html#what-is-versioning",
    "href": "slides/01-welcome.html#what-is-versioning",
    "title": "Welcome to STA 221!",
    "section": "What is versioning?",
    "text": "What is versioning?"
  },
  {
    "objectID": "slides/01-welcome.html#what-is-versioning-1",
    "href": "slides/01-welcome.html#what-is-versioning-1",
    "title": "Welcome to STA 221!",
    "section": "What is versioning?",
    "text": "What is versioning?\nwith human readable messages"
  },
  {
    "objectID": "slides/01-welcome.html#why-do-we-need-version-control",
    "href": "slides/01-welcome.html#why-do-we-need-version-control",
    "title": "Welcome to STA 221!",
    "section": "Why do we need version control?",
    "text": "Why do we need version control?\n\n\n\n\n\n\n\n\nProvides a clear record of how the analysis methods evolved. This makes analysis auditable and thus more trustworthy and reliable. (Ostblom and Timbers 2022)"
  },
  {
    "objectID": "slides/01-welcome.html#git-and-github",
    "href": "slides/01-welcome.html#git-and-github",
    "title": "Welcome to STA 221!",
    "section": "git and GitHub",
    "text": "git and GitHub\n\n\ngit is a version control system – like “Track Changes” features from Microsoft Word.\nGitHub is the home for your git-based projects on the internet (like DropBox but much better).\nThere are a lot of git commands and very few people know them all. 99% of the time you will use git to add, commit, push, and pull."
  },
  {
    "objectID": "slides/01-welcome.html#before-next-class",
    "href": "slides/01-welcome.html#before-next-class",
    "title": "Welcome to STA 221!",
    "section": "Before next class",
    "text": "Before next class\n\nComplete Lecture 02: Simple linear regression prepare\nReview syllabus\nOffice hours start Monday, January 13\n\nAlan’s office hours start January 27"
  },
  {
    "objectID": "slides/01-welcome.html#references",
    "href": "slides/01-welcome.html#references",
    "title": "Welcome to STA 221!",
    "section": "References",
    "text": "References\n\n\n\n\nAlexander, Rohan. 2023. “Telling Stories with Data,” June. https://doi.org/10.1201/9781003229407.\n\n\nOstblom, Joel, and Tiffany Timbers. 2022. “Opinionated Practices for Teaching Reproducibility: Motivation, Guided Instruction and Practice.” Journal of Statistics and Data Science Education 30 (3): 241–50. https://doi.org/10.1080/26939169.2022.2074922."
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html",
    "href": "slides/09-inference-pt2-notes.html",
    "title": "Inference for regression",
    "section": "",
    "text": "HW 02 due Thursday, February 13 at 11:59pm\n\nReleased after class\n\nLecture recordings available until start of exam, February 18 at 10:05am\n\nSee link under “Exam 01” on menu of course website\n\nStatistics experience due Tuesday, April 22"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#announcements",
    "href": "slides/09-inference-pt2-notes.html#announcements",
    "title": "Inference for regression",
    "section": "",
    "text": "HW 02 due Thursday, February 13 at 11:59pm\n\nReleased after class\n\nLecture recordings available until start of exam, February 18 at 10:05am\n\nSee link under “Exam 01” on menu of course website\n\nStatistics experience due Tuesday, April 22"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#topics",
    "href": "slides/09-inference-pt2-notes.html#topics",
    "title": "Inference for regression",
    "section": "Topics",
    "text": "Topics\n\nUnderstand statistical inference in the context of regression\nDescribe the assumptions for regression\nUnderstand connection between distribution of residuals and inferential procedures\nConduct inference on a single coefficient"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#computing-setup",
    "href": "slides/09-inference-pt2-notes.html#computing-setup",
    "title": "Inference for regression",
    "section": "Computing setup",
    "text": "Computing setup\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(kableExtra)  \nlibrary(patchwork)   \n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#data-ncaa-football-expenditures",
    "href": "slides/09-inference-pt2-notes.html#data-ncaa-football-expenditures",
    "title": "Inference for regression",
    "section": "Data: NCAA Football expenditures",
    "text": "Data: NCAA Football expenditures\nToday’s data come from Equity in Athletics Data Analysis and includes information about sports expenditures and revenues for colleges and universities in the United States. This data set was featured in a March 2022 Tidy Tuesday.\nWe will focus on the 2019 - 2020 season expenditures on football for institutions in the NCAA - Division 1 FBS. The variables are :\n\ntotal_exp_m: Total expenditures on football in the 2019 - 2020 academic year (in millions USD)\nenrollment_th: Total student enrollment in the 2019 - 2020 academic year (in thousands)\ntype: institution type (Public or Private)\n\n\nfootball &lt;- read_csv(\"data/ncaa-football-exp.csv\")"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#univariate-eda",
    "href": "slides/09-inference-pt2-notes.html#univariate-eda",
    "title": "Inference for regression",
    "section": "Univariate EDA",
    "text": "Univariate EDA"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#bivariate-eda",
    "href": "slides/09-inference-pt2-notes.html#bivariate-eda",
    "title": "Inference for regression",
    "section": "Bivariate EDA",
    "text": "Bivariate EDA"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#regression-model",
    "href": "slides/09-inference-pt2-notes.html#regression-model",
    "title": "Inference for regression",
    "section": "Regression model",
    "text": "Regression model\n\nexp_fit &lt;- lm(total_exp_m ~ enrollment_th + type, data = football)\ntidy(exp_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0\n\n\n\n\n\n\nFor every additional 1,000 students, we expect an institution’s total expenditures on football to increase by $780,000, on average, holding institution type constant."
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#from-sample-to-population",
    "href": "slides/09-inference-pt2-notes.html#from-sample-to-population",
    "title": "Inference for regression",
    "section": "From sample to population",
    "text": "From sample to population\n\nFor every additional 1,000 students, we expect an institution’s total expenditures on football to increase by $780,000, on average, holding institution type constant.\n\n. . .\n\n\nThis estimate is valid for the single sample of 127 higher education institutions in the 2019 - 2020 academic year.\nBut what if we’re not interested quantifying the relationship between student enrollment, institution type, and football expenditures for this single sample?\nWhat if we want to say something about the relationship between these variables for all colleges and universities with football programs and across different years?"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#statistical-inference",
    "href": "slides/09-inference-pt2-notes.html#statistical-inference",
    "title": "Inference for regression",
    "section": "Statistical inference",
    "text": "Statistical inference\n\n\n\n\nStatistical inference provides methods and tools so we can use the single observed sample to make valid statements (inferences) about the population it comes from\nFor our inferences to be valid, the sample should be representative (ideally random) of the population we’re interested in\n\n\n\n\n\n\nImage source: Eugene Morgan © Penn State"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#linear-regression-model",
    "href": "slides/09-inference-pt2-notes.html#linear-regression-model",
    "title": "Inference for regression",
    "section": "Linear regression model",
    "text": "Linear regression model\n\\[\\begin{aligned}\n\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}, \\hspace{8mm} \\boldsymbol{\\epsilon} \\sim N(\\mathbf{0}, \\sigma^2_{\\epsilon}\\mathbf{I})\n\\end{aligned}\n\\]\nsuch that the errors are independent and normally distributed.\n. . .\n\nIndependent: Knowing the error term for one observation doesn’t tell us about the error term for another observation\nNormally distributed: The distribution follows a particular mathematical model that is unimodal and symmetric"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#visualizing-distribution-of-mathbfymathbfx",
    "href": "slides/09-inference-pt2-notes.html#visualizing-distribution-of-mathbfymathbfx",
    "title": "Inference for regression",
    "section": "Visualizing distribution of \\(\\mathbf{y}|\\mathbf{X}\\)",
    "text": "Visualizing distribution of \\(\\mathbf{y}|\\mathbf{X}\\)\n\\[\n\\mathbf{y}|\\mathbf{X} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma_\\epsilon^2\\mathbf{I})\n\\]\n\n\n\nImage source: Introduction to the Practice of Statistics (5th ed)"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#linear-transformation-of-normal-random-variable",
    "href": "slides/09-inference-pt2-notes.html#linear-transformation-of-normal-random-variable",
    "title": "Inference for regression",
    "section": "Linear transformation of normal random variable",
    "text": "Linear transformation of normal random variable\nSuppose \\(\\mathbf{z}\\) is a (multivariate) normal random variable such that \\(\\mathbf{z} \\sim N(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\\), \\(\\mathbf{A}\\) is a matrix of constants, and \\(\\mathbf{b}\\) is a vector of constants.\n\nA linear transformation of \\(\\mathbf{z}\\) is also multivariate normal, such that\n\\[\n\\mathbf{A}\\mathbf{z} + \\mathbf{b} \\sim N(\\mathbf{A}\\boldsymbol{\\mu} + \\mathbf{b}, \\mathbf{A}\\boldsymbol{\\Sigma}\\mathbf{A}^\\mathsf{T})\n\\]\n\nExplain why \\(\\mathbf{y}|\\mathbf{X}\\) is normally distributed."
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#assumptions-for-regression",
    "href": "slides/09-inference-pt2-notes.html#assumptions-for-regression",
    "title": "Inference for regression",
    "section": "Assumptions for regression",
    "text": "Assumptions for regression\n\n\n\\[\n\\mathbf{y}|\\mathbf{X} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma_\\epsilon^2\\mathbf{I})\n\\]\n\n\n\nImage source: Introduction to the Practice of Statistics (5th ed)\n\n\n\n\nLinearity: There is a linear relationship between the response and predictor variables.\nConstant Variance: The variability about the least squares line is generally constant.\nNormality: The distribution of the residuals is approximately normal.\nIndependence: The residuals are independent from one another."
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#estimating-sigma2_epsilon",
    "href": "slides/09-inference-pt2-notes.html#estimating-sigma2_epsilon",
    "title": "Inference for regression",
    "section": "Estimating \\(\\sigma^2_{\\epsilon}\\)",
    "text": "Estimating \\(\\sigma^2_{\\epsilon}\\)\n\nOnce we fit the model, we can use the residuals to estimate \\(\\sigma_{\\epsilon}^2\\)\nThe estimated value \\(\\hat{\\sigma}^2_{\\epsilon}\\) is needed for hypothesis testing and constructing confidence intervals for regression\n\n\\[\n\\hat{\\sigma}^2_\\epsilon = \\frac{SSR}{n - p - 1} = \\frac{\\mathbf{e}^\\mathsf{T}\\mathbf{e}}{n-p-1}\n\\]\n. . .\n\nThe regression standard error \\(\\hat{\\sigma}_{\\epsilon}\\) is a measure of the average distance between the observations and regression line\n\n\\[\n\\hat{\\sigma}_\\epsilon = \\sqrt{\\frac{SSR}{n - p - 1}} = \\hat{\\sigma}_\\epsilon = \\sqrt{\\frac{\\mathbf{e}^\\mathsf{T}\\mathbf{e}}{n - p - 1}}\n\\]"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#inference-for-beta_j",
    "href": "slides/09-inference-pt2-notes.html#inference-for-beta_j",
    "title": "Inference for regression",
    "section": "Inference for \\(\\beta_j\\)",
    "text": "Inference for \\(\\beta_j\\)\nWe often want to conduct inference on individual model coefficients\n\nHypothesis test: Is there a linear relationship between the response and \\(x_j\\)?\nConfidence interval: What is a plausible range of values \\(\\beta_j\\) can take?\n\n. . .\nBut first we need to understand the distribution of \\(\\hat{\\beta}_j\\)"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#sampling-distribution-of-hatbeta",
    "href": "slides/09-inference-pt2-notes.html#sampling-distribution-of-hatbeta",
    "title": "Inference for regression",
    "section": "Sampling distribution of \\(\\hat{\\beta}\\)",
    "text": "Sampling distribution of \\(\\hat{\\beta}\\)\n\nA sampling distribution is the probability distribution of a statistic for a large number of random samples of size \\(n\\) from a population\nThe sampling distribution of \\(\\hat{\\boldsymbol{\\beta}}\\) is the probability distribution of the estimated coefficients if we repeatedly took samples of size \\(n\\) and fit the regression model\n\n\\[\n\\hat{\\boldsymbol{\\beta}} \\sim N(\\boldsymbol{\\beta}, \\sigma^2_\\epsilon(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1})\n\\]\n. . .\nThe estimated coefficients \\(\\hat{\\boldsymbol{\\beta}}\\) are normally distributed with\n\\[\nE(\\hat{\\boldsymbol{\\beta}}) = \\boldsymbol{\\beta} \\hspace{10mm} Var(\\hat{\\boldsymbol{\\beta}}) = \\sigma^2_{\\epsilon}(\\boldsymbol{X}^\\mathsf{T}\\boldsymbol{X})^{-1}\n\\]"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#expected-value-of-boldsymbolhatbeta",
    "href": "slides/09-inference-pt2-notes.html#expected-value-of-boldsymbolhatbeta",
    "title": "Inference for regression",
    "section": "Expected value of \\(\\boldsymbol{\\hat{\\beta}}\\)",
    "text": "Expected value of \\(\\boldsymbol{\\hat{\\beta}}\\)\n\nShow\n\\[E(\\hat{\\boldsymbol{\\beta}}) = \\boldsymbol{\\beta}\\]\n\n\nWill show \\(Var(\\hat{\\boldsymbol{\\beta}})\\) in homework"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#sampling-distribution-of-hatbeta_j",
    "href": "slides/09-inference-pt2-notes.html#sampling-distribution-of-hatbeta_j",
    "title": "Inference for regression",
    "section": "Sampling distribution of \\(\\hat{\\beta}_j\\)",
    "text": "Sampling distribution of \\(\\hat{\\beta}_j\\)\n\\[\n\\hat{\\boldsymbol{\\beta}} \\sim N(\\boldsymbol{\\beta}, \\sigma^2_\\epsilon(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1})\n\\]\nLet \\(\\mathbf{C} = (\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\). Then, for each coefficient \\(\\hat{\\beta}_j\\),\n\n\n\\(E(\\hat{\\beta}_j) = \\boldsymbol{\\beta}_j\\), the \\(j^{th}\\) element of \\(\\boldsymbol{\\beta}\\)\n\\(Var(\\hat{\\beta}_j) = \\sigma^2_{\\epsilon}C_{jj}\\)\n\\(Cov(\\hat{\\beta}_i, \\hat{\\beta}_j) = \\sigma^2_{\\epsilon}C_{ij}\\)"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#varhatboldsymbolbeta-for-ncaa-data",
    "href": "slides/09-inference-pt2-notes.html#varhatboldsymbolbeta-for-ncaa-data",
    "title": "Inference for regression",
    "section": "\\(Var(\\hat{\\boldsymbol{\\beta}})\\) for NCAA data",
    "text": "\\(Var(\\hat{\\boldsymbol{\\beta}})\\) for NCAA data\n\nX &lt;- model.matrix(total_exp_m ~ enrollment_th + type, \n                  data = football)\nsigma_sq &lt;- glance(exp_fit)$sigma^2\n\nvar_beta &lt;- sigma_sq * solve(t(X) %*% X)\nvar_beta\n\n              (Intercept) enrollment_th typePublic\n(Intercept)     8.9054556   -0.13323338 -6.0899556\nenrollment_th  -0.1332334    0.01216984 -0.1239408\ntypePublic     -6.0899556   -0.12394079  9.9388370"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#sehatboldsymbolbeta-for-ncaa-data",
    "href": "slides/09-inference-pt2-notes.html#sehatboldsymbolbeta-for-ncaa-data",
    "title": "Inference for regression",
    "section": "\\(SE(\\hat{\\boldsymbol{\\beta}})\\) for NCAA data",
    "text": "\\(SE(\\hat{\\boldsymbol{\\beta}})\\) for NCAA data\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0\n\n\n\n\n\n\n\nsqrt(diag(var_beta))\n\n  (Intercept) enrollment_th    typePublic \n     2.984201      0.110317      3.152592"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#steps-for-a-hypothesis-test",
    "href": "slides/09-inference-pt2-notes.html#steps-for-a-hypothesis-test",
    "title": "Inference for regression",
    "section": "Steps for a hypothesis test",
    "text": "Steps for a hypothesis test\n\nState the null and alternative hypotheses.\nCalculate a test statistic.\nCalculate the p-value.\nState the conclusion."
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#hypothesis-test-for-beta_j-hypotheses",
    "href": "slides/09-inference-pt2-notes.html#hypothesis-test-for-beta_j-hypotheses",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Hypotheses",
    "text": "Hypothesis test for \\(\\beta_j\\): Hypotheses\nWe will generally test the hypotheses:\n\\[\n\\begin{aligned}\n&H_0: \\beta_j = 0 \\\\\n&H_a: \\beta_j \\neq 0\n\\end{aligned}\n\\]\n\nState these hypotheses in words."
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#hypothesis-test-for-beta_j-test-statistic",
    "href": "slides/09-inference-pt2-notes.html#hypothesis-test-for-beta_j-test-statistic",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Test statistic",
    "text": "Hypothesis test for \\(\\beta_j\\): Test statistic\nTest statistic: Number of standard errors the estimate is away from the null\n\\[\n\\text{Test Statistic} = \\frac{\\text{Estimate - Null}}{\\text{Standard error}} \\\\\n\\]\n. . .\nIf \\(\\sigma^2_{\\epsilon}\\) was known, the test statistic would be\n\\[Z = \\frac{\\hat{\\beta}_j - 0}{SE(\\hat{\\beta}_j)} ~ = ~\\frac{\\hat{\\beta}_j - 0}{\\sqrt{\\sigma^2_\\epsilon C_{jj}}} ~\\sim ~ N(0, 1)\n\\]\n. . .\nIn general, \\(\\sigma^2_{\\epsilon}\\) is not known, so we use \\(\\hat{\\sigma}_{\\epsilon}^2\\) to calculate \\(SE(\\hat{\\beta}_j)\\)\n\\[T = \\frac{\\hat{\\beta}_j - 0}{SE(\\hat{\\beta}_j)} ~ = ~\\frac{\\hat{\\beta}_j - 0}{\\sqrt{\\hat{\\sigma}^2_\\epsilon C_{jj}}} ~\\sim ~ t_{n-p-1}\n\\]"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#hypothesis-test-for-beta_j-test-statistic-1",
    "href": "slides/09-inference-pt2-notes.html#hypothesis-test-for-beta_j-test-statistic-1",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Test statistic",
    "text": "Hypothesis test for \\(\\beta_j\\): Test statistic\n\nThe test statistic \\(T\\) follows a \\(t\\) distribution with \\(n - p -1\\) degrees of freedom.\nWe need to account for the additional variability introduced by calculating \\(SE(\\hat{\\beta}_j)\\) using an estimated value instead of a constant"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#t-vs.-n01",
    "href": "slides/09-inference-pt2-notes.html#t-vs.-n01",
    "title": "Inference for regression",
    "section": "t vs. N(0,1)",
    "text": "t vs. N(0,1)\n\n\n\n\n\n\n\n\nFigure 1: Standard normal vs. t distributions"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#hypothesis-test-for-beta_j-p-value",
    "href": "slides/09-inference-pt2-notes.html#hypothesis-test-for-beta_j-p-value",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): P-value",
    "text": "Hypothesis test for \\(\\beta_j\\): P-value\nThe p-value is the probability of observing a test statistic at least as extreme (in the direction of the alternative hypothesis) from the null value as the one observed\n\\[\np-value = P(|t| &gt; |\\text{test statistic}|),\n\\]\ncalculated from a \\(t\\) distribution with \\(n- p - 1\\) degrees of freedom\n. . .\n\nWhy do we take into account “extreme” on both the high and low ends?"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#understanding-the-p-value",
    "href": "slides/09-inference-pt2-notes.html#understanding-the-p-value",
    "title": "Inference for regression",
    "section": "Understanding the p-value",
    "text": "Understanding the p-value\n\n\n\nMagnitude of p-value\nInterpretation\n\n\n\n\np-value &lt; 0.01\nstrong evidence against \\(H_0\\)\n\n\n0.01 &lt; p-value &lt; 0.05\nmoderate evidence against \\(H_0\\)\n\n\n0.05 &lt; p-value &lt; 0.1\nweak evidence against \\(H_0\\)\n\n\np-value &gt; 0.1\neffectively no evidence against \\(H_0\\)\n\n\n\n\nThese are general guidelines. The strength of evidence depends on the context of the problem."
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#hypothesis-test-for-beta_j-conclusion",
    "href": "slides/09-inference-pt2-notes.html#hypothesis-test-for-beta_j-conclusion",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Conclusion",
    "text": "Hypothesis test for \\(\\beta_j\\): Conclusion\nThere are two parts to the conclusion\n\nMake a conclusion by comparing the p-value to a predetermined decision-making threshold called the significance level ( \\(\\alpha\\) level)\n\nIf \\(\\text{P-value} &lt; \\alpha\\): Reject \\(H_0\\)\nIf \\(\\text{P-value} \\geq \\alpha\\): Fail to reject \\(H_0\\)\n\nState the conclusion in the context of the data"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#confidence-interval-for-beta_j-1",
    "href": "slides/09-inference-pt2-notes.html#confidence-interval-for-beta_j-1",
    "title": "Inference for regression",
    "section": "Confidence interval for \\(\\beta_j\\)",
    "text": "Confidence interval for \\(\\beta_j\\)\n\n\nA plausible range of values for a population parameter is called a confidence interval\nUsing only a single point estimate is like fishing in a murky lake with a spear, and using a confidence interval is like fishing with a net\n\nWe can throw a spear where we saw a fish but we will probably miss, if we toss a net in that area, we have a good chance of catching the fish\nSimilarly, if we report a point estimate, we probably will not hit the exact population parameter, but if we report a range of plausible values we have a good shot at capturing the parameter"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#what-confidence-means",
    "href": "slides/09-inference-pt2-notes.html#what-confidence-means",
    "title": "Inference for regression",
    "section": "What “confidence” means",
    "text": "What “confidence” means\n\n\nWe will construct \\(C\\%\\) confidence intervals.\n\nThe confidence level impacts the width of the interval\n\n\n\n\n“Confident” means if we were to take repeated samples of the same size as our data, fit regression lines using the same predictors, and calculate \\(C\\%\\) CIs for the coefficient of \\(x_j\\), then \\(C\\%\\) of those intervals will contain the true value of the coefficient \\(\\beta_j\\)\n\n\n\nBalance precision and accuracy when selecting a confidence level"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#confidence-interval-for-beta_j-2",
    "href": "slides/09-inference-pt2-notes.html#confidence-interval-for-beta_j-2",
    "title": "Inference for regression",
    "section": "Confidence interval for \\(\\beta_j\\)",
    "text": "Confidence interval for \\(\\beta_j\\)\n\\[\n\\text{Estimate} \\pm \\text{ (critical value) } \\times \\text{SE}\n\\]\n\n. . .\n\\[\n\\hat{\\beta}_1 \\pm t^* \\times SE({\\hat{\\beta}_j})\n\\]\nwhere \\(t^*\\) is calculated from a \\(t\\) distribution with \\(n-p-1\\) degrees of freedom"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#confidence-interval-critical-value",
    "href": "slides/09-inference-pt2-notes.html#confidence-interval-critical-value",
    "title": "Inference for regression",
    "section": "Confidence interval: Critical value",
    "text": "Confidence interval: Critical value\n\n\n# confidence level: 95%\nqt(0.975, df = nrow(football) - 2 - 1)\n\n[1] 1.97928\n\n\n\n\n\n\n# confidence level: 90%\nqt(0.95, df = nrow(football) - 2 - 1)\n\n[1] 1.657235\n\n\n\n\n\n\n# confidence level: 99%\nqt(0.995, df = nrow(football) - 2 - 1)\n\n[1] 2.61606"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#ci-for-beta_j-calculation",
    "href": "slides/09-inference-pt2-notes.html#ci-for-beta_j-calculation",
    "title": "Inference for regression",
    "section": "95% CI for \\(\\beta_j\\): Calculation",
    "text": "95% CI for \\(\\beta_j\\): Calculation\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#ci-for-beta_j-in-r",
    "href": "slides/09-inference-pt2-notes.html#ci-for-beta_j-in-r",
    "title": "Inference for regression",
    "section": "95% CI for \\(\\beta_j\\) in R",
    "text": "95% CI for \\(\\beta_j\\) in R\n\ntidy(exp_fit, conf.int = TRUE, conf.level = 0.95) |&gt; \n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n13.426\n25.239\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n0.562\n0.999\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0\n-19.466\n-6.986\n\n\n\n\n\n\nInterpretation: We are 95% confident that for each additional 1,000 students enrolled, the institution’s expenditures on football will be greater by $562,000 to $999,000, on average, holding institution type constant."
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#recap",
    "href": "slides/09-inference-pt2-notes.html#recap",
    "title": "Inference for regression",
    "section": "Recap",
    "text": "Recap\n\nIntroduced statistical inference in the context of regression\nDescribed the assumptions for regression\nConnected the distribution of residuals and inferential procedures\nConducted inference on a single coefficient"
  },
  {
    "objectID": "slides/09-inference-pt2-notes.html#next-class",
    "href": "slides/09-inference-pt2-notes.html#next-class",
    "title": "Inference for regression",
    "section": "Next class",
    "text": "Next class\n\nHypothesis testing based on ANOVA"
  },
  {
    "objectID": "slides/09-inference-pt2.html#announcements",
    "href": "slides/09-inference-pt2.html#announcements",
    "title": "Inference for regression",
    "section": "Announcements",
    "text": "Announcements\n\nHW 02 due Thursday, February 13 at 11:59pm\n\nReleased after class\n\nLecture recordings available until start of exam, February 18 at 10:05am\n\nSee link under “Exam 01” on menu of course website\n\nStatistics experience due Tuesday, April 22"
  },
  {
    "objectID": "slides/09-inference-pt2.html#topics",
    "href": "slides/09-inference-pt2.html#topics",
    "title": "Inference for regression",
    "section": "Topics",
    "text": "Topics\n\nUnderstand statistical inference in the context of regression\nDescribe the assumptions for regression\nUnderstand connection between distribution of residuals and inferential procedures\nConduct inference on a single coefficient"
  },
  {
    "objectID": "slides/09-inference-pt2.html#computing-setup",
    "href": "slides/09-inference-pt2.html#computing-setup",
    "title": "Inference for regression",
    "section": "Computing setup",
    "text": "Computing setup\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(kableExtra)  \nlibrary(patchwork)   \n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/09-inference-pt2.html#data-ncaa-football-expenditures",
    "href": "slides/09-inference-pt2.html#data-ncaa-football-expenditures",
    "title": "Inference for regression",
    "section": "Data: NCAA Football expenditures",
    "text": "Data: NCAA Football expenditures\nToday’s data come from Equity in Athletics Data Analysis and includes information about sports expenditures and revenues for colleges and universities in the United States. This data set was featured in a March 2022 Tidy Tuesday.\nWe will focus on the 2019 - 2020 season expenditures on football for institutions in the NCAA - Division 1 FBS. The variables are :\n\ntotal_exp_m: Total expenditures on football in the 2019 - 2020 academic year (in millions USD)\nenrollment_th: Total student enrollment in the 2019 - 2020 academic year (in thousands)\ntype: institution type (Public or Private)\n\n\nfootball &lt;- read_csv(\"data/ncaa-football-exp.csv\")"
  },
  {
    "objectID": "slides/09-inference-pt2.html#univariate-eda",
    "href": "slides/09-inference-pt2.html#univariate-eda",
    "title": "Inference for regression",
    "section": "Univariate EDA",
    "text": "Univariate EDA"
  },
  {
    "objectID": "slides/09-inference-pt2.html#bivariate-eda",
    "href": "slides/09-inference-pt2.html#bivariate-eda",
    "title": "Inference for regression",
    "section": "Bivariate EDA",
    "text": "Bivariate EDA"
  },
  {
    "objectID": "slides/09-inference-pt2.html#regression-model",
    "href": "slides/09-inference-pt2.html#regression-model",
    "title": "Inference for regression",
    "section": "Regression model",
    "text": "Regression model\n\nexp_fit &lt;- lm(total_exp_m ~ enrollment_th + type, data = football)\ntidy(exp_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0\n\n\n\n\n\n\nFor every additional 1,000 students, we expect an institution’s total expenditures on football to increase by $780,000, on average, holding institution type constant."
  },
  {
    "objectID": "slides/09-inference-pt2.html#from-sample-to-population",
    "href": "slides/09-inference-pt2.html#from-sample-to-population",
    "title": "Inference for regression",
    "section": "From sample to population",
    "text": "From sample to population\n\nFor every additional 1,000 students, we expect an institution’s total expenditures on football to increase by $780,000, on average, holding institution type constant.\n\n\n\n\nThis estimate is valid for the single sample of 127 higher education institutions in the 2019 - 2020 academic year.\nBut what if we’re not interested quantifying the relationship between student enrollment, institution type, and football expenditures for this single sample?\nWhat if we want to say something about the relationship between these variables for all colleges and universities with football programs and across different years?"
  },
  {
    "objectID": "slides/09-inference-pt2.html#statistical-inference",
    "href": "slides/09-inference-pt2.html#statistical-inference",
    "title": "Inference for regression",
    "section": "Statistical inference",
    "text": "Statistical inference\n\n\n\n\nStatistical inference provides methods and tools so we can use the single observed sample to make valid statements (inferences) about the population it comes from\nFor our inferences to be valid, the sample should be representative (ideally random) of the population we’re interested in\n\n\n\n\n\n\nImage source: Eugene Morgan © Penn State"
  },
  {
    "objectID": "slides/09-inference-pt2.html#linear-regression-model",
    "href": "slides/09-inference-pt2.html#linear-regression-model",
    "title": "Inference for regression",
    "section": "Linear regression model",
    "text": "Linear regression model\n\\[\\begin{aligned}\n\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}, \\hspace{8mm} \\boldsymbol{\\epsilon} \\sim N(\\mathbf{0}, \\sigma^2_{\\epsilon}\\mathbf{I})\n\\end{aligned}\n\\]\nsuch that the errors are independent and normally distributed.\n\n\nIndependent: Knowing the error term for one observation doesn’t tell us about the error term for another observation\nNormally distributed: The distribution follows a particular mathematical model that is unimodal and symmetric"
  },
  {
    "objectID": "slides/09-inference-pt2.html#visualizing-distribution-of-mathbfymathbfx",
    "href": "slides/09-inference-pt2.html#visualizing-distribution-of-mathbfymathbfx",
    "title": "Inference for regression",
    "section": "Visualizing distribution of \\(\\mathbf{y}|\\mathbf{X}\\)",
    "text": "Visualizing distribution of \\(\\mathbf{y}|\\mathbf{X}\\)\n\\[\n\\mathbf{y}|\\mathbf{X} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma_\\epsilon^2\\mathbf{I})\n\\]\n\nImage source: Introduction to the Practice of Statistics (5th ed)"
  },
  {
    "objectID": "slides/09-inference-pt2.html#linear-transformation-of-normal-random-variable",
    "href": "slides/09-inference-pt2.html#linear-transformation-of-normal-random-variable",
    "title": "Inference for regression",
    "section": "Linear transformation of normal random variable",
    "text": "Linear transformation of normal random variable\nSuppose \\(\\mathbf{z}\\) is a (multivariate) normal random variable such that \\(\\mathbf{z} \\sim N(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\\), \\(\\mathbf{A}\\) is a matrix of constants, and \\(\\mathbf{b}\\) is a vector of constants.\n\nA linear transformation of \\(\\mathbf{z}\\) is also multivariate normal, such that\n\\[\n\\mathbf{A}\\mathbf{z} + \\mathbf{b} \\sim N(\\mathbf{A}\\boldsymbol{\\mu} + \\mathbf{b}, \\mathbf{A}\\boldsymbol{\\Sigma}\\mathbf{A}^\\mathsf{T})\n\\]\n\nExplain why \\(\\mathbf{y}|\\mathbf{X}\\) is normally distributed."
  },
  {
    "objectID": "slides/09-inference-pt2.html#assumptions-for-regression",
    "href": "slides/09-inference-pt2.html#assumptions-for-regression",
    "title": "Inference for regression",
    "section": "Assumptions for regression",
    "text": "Assumptions for regression\n\n\n\\[\n\\mathbf{y}|\\mathbf{X} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma_\\epsilon^2\\mathbf{I})\n\\]\n\n\n\nImage source: Introduction to the Practice of Statistics (5th ed)\n\n\n\n\nLinearity: There is a linear relationship between the response and predictor variables.\nConstant Variance: The variability about the least squares line is generally constant.\nNormality: The distribution of the residuals is approximately normal.\nIndependence: The residuals are independent from one another."
  },
  {
    "objectID": "slides/09-inference-pt2.html#estimating-sigma2_epsilon",
    "href": "slides/09-inference-pt2.html#estimating-sigma2_epsilon",
    "title": "Inference for regression",
    "section": "Estimating \\(\\sigma^2_{\\epsilon}\\)",
    "text": "Estimating \\(\\sigma^2_{\\epsilon}\\)\n\nOnce we fit the model, we can use the residuals to estimate \\(\\sigma_{\\epsilon}^2\\)\nThe estimated value \\(\\hat{\\sigma}^2_{\\epsilon}\\) is needed for hypothesis testing and constructing confidence intervals for regression\n\n\\[\n\\hat{\\sigma}^2_\\epsilon = \\frac{SSR}{n - p - 1} = \\frac{\\mathbf{e}^\\mathsf{T}\\mathbf{e}}{n-p-1}\n\\]\n\n\nThe regression standard error \\(\\hat{\\sigma}_{\\epsilon}\\) is a measure of the average distance between the observations and regression line\n\n\\[\n\\hat{\\sigma}_\\epsilon = \\sqrt{\\frac{SSR}{n - p - 1}} = \\hat{\\sigma}_\\epsilon = \\sqrt{\\frac{\\mathbf{e}^\\mathsf{T}\\mathbf{e}}{n - p - 1}}\n\\]"
  },
  {
    "objectID": "slides/09-inference-pt2.html#inference-for-beta_j",
    "href": "slides/09-inference-pt2.html#inference-for-beta_j",
    "title": "Inference for regression",
    "section": "Inference for \\(\\beta_j\\)",
    "text": "Inference for \\(\\beta_j\\)\nWe often want to conduct inference on individual model coefficients\n\nHypothesis test: Is there a linear relationship between the response and \\(x_j\\)?\nConfidence interval: What is a plausible range of values \\(\\beta_j\\) can take?\n\n\nBut first we need to understand the distribution of \\(\\hat{\\beta}_j\\)"
  },
  {
    "objectID": "slides/09-inference-pt2.html#sampling-distribution-of-hatbeta",
    "href": "slides/09-inference-pt2.html#sampling-distribution-of-hatbeta",
    "title": "Inference for regression",
    "section": "Sampling distribution of \\(\\hat{\\beta}\\)",
    "text": "Sampling distribution of \\(\\hat{\\beta}\\)\n\nA sampling distribution is the probability distribution of a statistic for a large number of random samples of size \\(n\\) from a population\nThe sampling distribution of \\(\\hat{\\boldsymbol{\\beta}}\\) is the probability distribution of the estimated coefficients if we repeatedly took samples of size \\(n\\) and fit the regression model\n\n\\[\n\\hat{\\boldsymbol{\\beta}} \\sim N(\\boldsymbol{\\beta}, \\sigma^2_\\epsilon(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1})\n\\]\n\nThe estimated coefficients \\(\\hat{\\boldsymbol{\\beta}}\\) are normally distributed with\n\\[\nE(\\hat{\\boldsymbol{\\beta}}) = \\boldsymbol{\\beta} \\hspace{10mm} Var(\\hat{\\boldsymbol{\\beta}}) = \\sigma^2_{\\epsilon}(\\boldsymbol{X}^\\mathsf{T}\\boldsymbol{X})^{-1}\n\\]"
  },
  {
    "objectID": "slides/09-inference-pt2.html#expected-value-of-boldsymbolhatbeta",
    "href": "slides/09-inference-pt2.html#expected-value-of-boldsymbolhatbeta",
    "title": "Inference for regression",
    "section": "Expected value of \\(\\boldsymbol{\\hat{\\beta}}\\)",
    "text": "Expected value of \\(\\boldsymbol{\\hat{\\beta}}\\)\n\nShow\n\\[E(\\hat{\\boldsymbol{\\beta}}) = \\boldsymbol{\\beta}\\]\n\n\nWill show \\(Var(\\hat{\\boldsymbol{\\beta}})\\) in homework"
  },
  {
    "objectID": "slides/09-inference-pt2.html#sampling-distribution-of-hatbeta_j",
    "href": "slides/09-inference-pt2.html#sampling-distribution-of-hatbeta_j",
    "title": "Inference for regression",
    "section": "Sampling distribution of \\(\\hat{\\beta}_j\\)",
    "text": "Sampling distribution of \\(\\hat{\\beta}_j\\)\n\\[\n\\hat{\\boldsymbol{\\beta}} \\sim N(\\boldsymbol{\\beta}, \\sigma^2_\\epsilon(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1})\n\\]\nLet \\(\\mathbf{C} = (\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\). Then, for each coefficient \\(\\hat{\\beta}_j\\),\n\n\n\\(E(\\hat{\\beta}_j) = \\boldsymbol{\\beta}_j\\), the \\(j^{th}\\) element of \\(\\boldsymbol{\\beta}\\)\n\\(Var(\\hat{\\beta}_j) = \\sigma^2_{\\epsilon}C_{jj}\\)\n\\(Cov(\\hat{\\beta}_i, \\hat{\\beta}_j) = \\sigma^2_{\\epsilon}C_{ij}\\)"
  },
  {
    "objectID": "slides/09-inference-pt2.html#varhatboldsymbolbeta-for-ncaa-data",
    "href": "slides/09-inference-pt2.html#varhatboldsymbolbeta-for-ncaa-data",
    "title": "Inference for regression",
    "section": "\\(Var(\\hat{\\boldsymbol{\\beta}})\\) for NCAA data",
    "text": "\\(Var(\\hat{\\boldsymbol{\\beta}})\\) for NCAA data\n\nX &lt;- model.matrix(total_exp_m ~ enrollment_th + type, \n                  data = football)\nsigma_sq &lt;- glance(exp_fit)$sigma^2\n\nvar_beta &lt;- sigma_sq * solve(t(X) %*% X)\nvar_beta\n\n              (Intercept) enrollment_th typePublic\n(Intercept)     8.9054556   -0.13323338 -6.0899556\nenrollment_th  -0.1332334    0.01216984 -0.1239408\ntypePublic     -6.0899556   -0.12394079  9.9388370"
  },
  {
    "objectID": "slides/09-inference-pt2.html#sehatboldsymbolbeta-for-ncaa-data",
    "href": "slides/09-inference-pt2.html#sehatboldsymbolbeta-for-ncaa-data",
    "title": "Inference for regression",
    "section": "\\(SE(\\hat{\\boldsymbol{\\beta}})\\) for NCAA data",
    "text": "\\(SE(\\hat{\\boldsymbol{\\beta}})\\) for NCAA data\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0\n\n\n\n\n\n\n\nsqrt(diag(var_beta))\n\n  (Intercept) enrollment_th    typePublic \n     2.984201      0.110317      3.152592"
  },
  {
    "objectID": "slides/09-inference-pt2.html#steps-for-a-hypothesis-test",
    "href": "slides/09-inference-pt2.html#steps-for-a-hypothesis-test",
    "title": "Inference for regression",
    "section": "Steps for a hypothesis test",
    "text": "Steps for a hypothesis test\n\nState the null and alternative hypotheses.\nCalculate a test statistic.\nCalculate the p-value.\nState the conclusion."
  },
  {
    "objectID": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-hypotheses",
    "href": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-hypotheses",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Hypotheses",
    "text": "Hypothesis test for \\(\\beta_j\\): Hypotheses\nWe will generally test the hypotheses:\n\\[\n\\begin{aligned}\n&H_0: \\beta_j = 0 \\\\\n&H_a: \\beta_j \\neq 0\n\\end{aligned}\n\\]\n\nState these hypotheses in words."
  },
  {
    "objectID": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-test-statistic",
    "href": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-test-statistic",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Test statistic",
    "text": "Hypothesis test for \\(\\beta_j\\): Test statistic\nTest statistic: Number of standard errors the estimate is away from the null\n\\[\n\\text{Test Statistic} = \\frac{\\text{Estimate - Null}}{\\text{Standard error}} \\\\\n\\]\n\nIf \\(\\sigma^2_{\\epsilon}\\) was known, the test statistic would be\n\\[Z = \\frac{\\hat{\\beta}_j - 0}{SE(\\hat{\\beta}_j)} ~ = ~\\frac{\\hat{\\beta}_j - 0}{\\sqrt{\\sigma^2_\\epsilon C_{jj}}} ~\\sim ~ N(0, 1)\n\\]\n\n\nIn general, \\(\\sigma^2_{\\epsilon}\\) is not known, so we use \\(\\hat{\\sigma}_{\\epsilon}^2\\) to calculate \\(SE(\\hat{\\beta}_j)\\)\n\\[T = \\frac{\\hat{\\beta}_j - 0}{SE(\\hat{\\beta}_j)} ~ = ~\\frac{\\hat{\\beta}_j - 0}{\\sqrt{\\hat{\\sigma}^2_\\epsilon C_{jj}}} ~\\sim ~ t_{n-p-1}\n\\]"
  },
  {
    "objectID": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-test-statistic-1",
    "href": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-test-statistic-1",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Test statistic",
    "text": "Hypothesis test for \\(\\beta_j\\): Test statistic\n\nThe test statistic \\(T\\) follows a \\(t\\) distribution with \\(n - p -1\\) degrees of freedom.\nWe need to account for the additional variability introduced by calculating \\(SE(\\hat{\\beta}_j)\\) using an estimated value instead of a constant"
  },
  {
    "objectID": "slides/09-inference-pt2.html#t-vs.-n01",
    "href": "slides/09-inference-pt2.html#t-vs.-n01",
    "title": "Inference for regression",
    "section": "t vs. N(0,1)",
    "text": "t vs. N(0,1)\n\n\nFigure 1: Standard normal vs. t distributions"
  },
  {
    "objectID": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-p-value",
    "href": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-p-value",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): P-value",
    "text": "Hypothesis test for \\(\\beta_j\\): P-value\nThe p-value is the probability of observing a test statistic at least as extreme (in the direction of the alternative hypothesis) from the null value as the one observed\n\\[\np-value = P(|t| &gt; |\\text{test statistic}|),\n\\]\ncalculated from a \\(t\\) distribution with \\(n- p - 1\\) degrees of freedom\n\n\nWhy do we take into account “extreme” on both the high and low ends?"
  },
  {
    "objectID": "slides/09-inference-pt2.html#understanding-the-p-value",
    "href": "slides/09-inference-pt2.html#understanding-the-p-value",
    "title": "Inference for regression",
    "section": "Understanding the p-value",
    "text": "Understanding the p-value\n\n\n\nMagnitude of p-value\nInterpretation\n\n\n\n\np-value &lt; 0.01\nstrong evidence against \\(H_0\\)\n\n\n0.01 &lt; p-value &lt; 0.05\nmoderate evidence against \\(H_0\\)\n\n\n0.05 &lt; p-value &lt; 0.1\nweak evidence against \\(H_0\\)\n\n\np-value &gt; 0.1\neffectively no evidence against \\(H_0\\)\n\n\n\n\nThese are general guidelines. The strength of evidence depends on the context of the problem."
  },
  {
    "objectID": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-conclusion",
    "href": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-conclusion",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Conclusion",
    "text": "Hypothesis test for \\(\\beta_j\\): Conclusion\nThere are two parts to the conclusion\n\nMake a conclusion by comparing the p-value to a predetermined decision-making threshold called the significance level ( \\(\\alpha\\) level)\n\nIf \\(\\text{P-value} &lt; \\alpha\\): Reject \\(H_0\\)\nIf \\(\\text{P-value} \\geq \\alpha\\): Fail to reject \\(H_0\\)\n\nState the conclusion in the context of the data"
  },
  {
    "objectID": "slides/09-inference-pt2.html#confidence-interval-for-beta_j-1",
    "href": "slides/09-inference-pt2.html#confidence-interval-for-beta_j-1",
    "title": "Inference for regression",
    "section": "Confidence interval for \\(\\beta_j\\)",
    "text": "Confidence interval for \\(\\beta_j\\)\n\n\nA plausible range of values for a population parameter is called a confidence interval\nUsing only a single point estimate is like fishing in a murky lake with a spear, and using a confidence interval is like fishing with a net\n\nWe can throw a spear where we saw a fish but we will probably miss, if we toss a net in that area, we have a good chance of catching the fish\nSimilarly, if we report a point estimate, we probably will not hit the exact population parameter, but if we report a range of plausible values we have a good shot at capturing the parameter"
  },
  {
    "objectID": "slides/09-inference-pt2.html#what-confidence-means",
    "href": "slides/09-inference-pt2.html#what-confidence-means",
    "title": "Inference for regression",
    "section": "What “confidence” means",
    "text": "What “confidence” means\n\n\nWe will construct \\(C\\%\\) confidence intervals.\n\nThe confidence level impacts the width of the interval\n\n\n\n\n“Confident” means if we were to take repeated samples of the same size as our data, fit regression lines using the same predictors, and calculate \\(C\\%\\) CIs for the coefficient of \\(x_j\\), then \\(C\\%\\) of those intervals will contain the true value of the coefficient \\(\\beta_j\\)\n\n\n\nBalance precision and accuracy when selecting a confidence level"
  },
  {
    "objectID": "slides/09-inference-pt2.html#confidence-interval-for-beta_j-2",
    "href": "slides/09-inference-pt2.html#confidence-interval-for-beta_j-2",
    "title": "Inference for regression",
    "section": "Confidence interval for \\(\\beta_j\\)",
    "text": "Confidence interval for \\(\\beta_j\\)\n\\[\n\\text{Estimate} \\pm \\text{ (critical value) } \\times \\text{SE}\n\\]\n\n\n\\[\n\\hat{\\beta}_1 \\pm t^* \\times SE({\\hat{\\beta}_j})\n\\]\nwhere \\(t^*\\) is calculated from a \\(t\\) distribution with \\(n-p-1\\) degrees of freedom"
  },
  {
    "objectID": "slides/09-inference-pt2.html#confidence-interval-critical-value",
    "href": "slides/09-inference-pt2.html#confidence-interval-critical-value",
    "title": "Inference for regression",
    "section": "Confidence interval: Critical value",
    "text": "Confidence interval: Critical value\n\n\n# confidence level: 95%\nqt(0.975, df = nrow(football) - 2 - 1)\n\n[1] 1.97928\n\n\n\n\n\n\n# confidence level: 90%\nqt(0.95, df = nrow(football) - 2 - 1)\n\n[1] 1.657235\n\n\n\n\n\n\n# confidence level: 99%\nqt(0.995, df = nrow(football) - 2 - 1)\n\n[1] 2.61606"
  },
  {
    "objectID": "slides/09-inference-pt2.html#ci-for-beta_j-calculation",
    "href": "slides/09-inference-pt2.html#ci-for-beta_j-calculation",
    "title": "Inference for regression",
    "section": "95% CI for \\(\\beta_j\\): Calculation",
    "text": "95% CI for \\(\\beta_j\\): Calculation\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0"
  },
  {
    "objectID": "slides/09-inference-pt2.html#ci-for-beta_j-in-r",
    "href": "slides/09-inference-pt2.html#ci-for-beta_j-in-r",
    "title": "Inference for regression",
    "section": "95% CI for \\(\\beta_j\\) in R",
    "text": "95% CI for \\(\\beta_j\\) in R\n\ntidy(exp_fit, conf.int = TRUE, conf.level = 0.95) |&gt; \n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n13.426\n25.239\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n0.562\n0.999\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0\n-19.466\n-6.986\n\n\n\n\n\n\nInterpretation: We are 95% confident that for each additional 1,000 students enrolled, the institution’s expenditures on football will be greater by $562,000 to $999,000, on average, holding institution type constant."
  },
  {
    "objectID": "slides/09-inference-pt2.html#recap",
    "href": "slides/09-inference-pt2.html#recap",
    "title": "Inference for regression",
    "section": "Recap",
    "text": "Recap\n\nIntroduced statistical inference in the context of regression\nDescribed the assumptions for regression\nConnected the distribution of residuals and inferential procedures\nConducted inference on a single coefficient"
  },
  {
    "objectID": "slides/09-inference-pt2.html#next-class",
    "href": "slides/09-inference-pt2.html#next-class",
    "title": "Inference for regression",
    "section": "Next class",
    "text": "Next class\n\nHypothesis testing based on ANOVA"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html",
    "href": "slides/12-conditions-diagnostics-notes.html",
    "title": "Model conditions + diagnostics",
    "section": "",
    "text": "Exam corrections (optional) due Tuesday, March 4 at 11:59pm\n\nSee assignment on Canvas\n\nProject proposal due TODAY at 11:59pm"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#announcements",
    "href": "slides/12-conditions-diagnostics-notes.html#announcements",
    "title": "Model conditions + diagnostics",
    "section": "",
    "text": "Exam corrections (optional) due Tuesday, March 4 at 11:59pm\n\nSee assignment on Canvas\n\nProject proposal due TODAY at 11:59pm"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#computing-set-up",
    "href": "slides/12-conditions-diagnostics-notes.html#computing-set-up",
    "title": "Model conditions + diagnostics",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)   \nlibrary(viridis)\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#topics",
    "href": "slides/12-conditions-diagnostics-notes.html#topics",
    "title": "Model conditions + diagnostics",
    "section": "Topics",
    "text": "Topics\n\nModel conditions\nInfluential points\nModel diagnostics\n\nLeverage\nStudentized residuals\nCook’s Distance"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#data-duke-lemurs",
    "href": "slides/12-conditions-diagnostics-notes.html#data-duke-lemurs",
    "title": "Model conditions + diagnostics",
    "section": "Data: Duke lemurs",
    "text": "Data: Duke lemurs\nToday’s data contains a subset of the original Duke Lemur data set available in the TidyTuesday GitHub repo. This data includes information on “young adult” lemurs from the Coquerel’s sifaka species (PCOQ), the largest species at the Duke Lemur Center. The analysis will focus on the following variables:\n\nage_at_wt_mo: Age in months: Age of the animal when the weight was taken, in months (((Weight_Date-DOB)/365)*12)\nweight_g: Weight: Animal weight, in grams. Weights under 500g generally to nearest 0.1-1g; Weights &gt;500g generally to the nearest 1-20g.\n\nThe goal of the analysis is to use the age of the lemurs to understand variability in the weight."
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#eda",
    "href": "slides/12-conditions-diagnostics-notes.html#eda",
    "title": "Model conditions + diagnostics",
    "section": "EDA",
    "text": "EDA"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#eda-1",
    "href": "slides/12-conditions-diagnostics-notes.html#eda-1",
    "title": "Model conditions + diagnostics",
    "section": "EDA",
    "text": "EDA"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#fit-model",
    "href": "slides/12-conditions-diagnostics-notes.html#fit-model",
    "title": "Model conditions + diagnostics",
    "section": "Fit model",
    "text": "Fit model\n\nlemurs_fit &lt;- lm(weight_g ~ age_at_wt_mo, data = lemurs)\n\ntidy(lemurs_fit) |&gt; \n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-12314.360\n4252.696\n-2.896\n0.005\n\n\nage_at_wt_mo\n496.591\n131.225\n3.784\n0.000"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#assumptions-for-regression",
    "href": "slides/12-conditions-diagnostics-notes.html#assumptions-for-regression",
    "title": "Model conditions + diagnostics",
    "section": "Assumptions for regression",
    "text": "Assumptions for regression\n\\[\n\\mathbf{y}|\\mathbf{X} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma_\\epsilon^2\\mathbf{I})\n\\]\n\nLinearity: There is a linear relationship between the response and predictor variables.\nConstant Variance: The variability about the least squares line is generally constant.\nNormality: The distribution of the errors (residuals) is approximately normal.\nIndependence: The errors (residuals) are independent from one another.\n\n. . .\n\nHow do we know if these assumptions hold in our data?"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#linearity",
    "href": "slides/12-conditions-diagnostics-notes.html#linearity",
    "title": "Model conditions + diagnostics",
    "section": "Linearity",
    "text": "Linearity\n\nLook at plot of residuals versus fitted (predicted) values.\nLinearity is satisfied if there is no discernible pattern in the plot (i.e., points randomly scattered around \\(residuals = 0\\)\n\n. . .\n\n\n\n\n\n\n\n\n\n. . .\n\nLinearity is satisfied"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#example-linearity-not-satisfied",
    "href": "slides/12-conditions-diagnostics-notes.html#example-linearity-not-satisfied",
    "title": "Model conditions + diagnostics",
    "section": "Example: Linearity not satisfied",
    "text": "Example: Linearity not satisfied\n\n\n\n\n\n\n\n\n\n. . .\n\nIf linearity is not satisfied, examine the plots of residuals versus each predictor.\nAdd higher order term(s), as needed."
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#constant-variance",
    "href": "slides/12-conditions-diagnostics-notes.html#constant-variance",
    "title": "Model conditions + diagnostics",
    "section": "Constant variance",
    "text": "Constant variance\n\nLook at plot of residuals versus fitted (predicted) values.\nConstant variance is satisfied if the vertical spread of the points is approximately equal for all fitted values\n\n. . .\n\n\n\n\n\n\n\n\n\n. . .\n\nConstant variance is satisfied"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#example-constant-variance-not-satisfied",
    "href": "slides/12-conditions-diagnostics-notes.html#example-constant-variance-not-satisfied",
    "title": "Model conditions + diagnostics",
    "section": "Example: Constant variance not satisfied",
    "text": "Example: Constant variance not satisfied\n\n\n\n\n\n\n\n\n\n. . .\n\nConstant variance is critical for reliable inference\nAddress violations by applying transformation on the response"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#normality",
    "href": "slides/12-conditions-diagnostics-notes.html#normality",
    "title": "Model conditions + diagnostics",
    "section": "Normality",
    "text": "Normality\n\nLook at the distribution of the residuals\nNormality is satisfied if the distribution is approximately unimodal and symmetric. Inference robust to violations if \\(n &gt; 30\\)\n\n\n\n\n\n\n\n\n\n\n. . .\n\nDistribution approximately unimodal and symmetric, aside from the outlier. There are 62 observations, so inference robust to departures."
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#independence",
    "href": "slides/12-conditions-diagnostics-notes.html#independence",
    "title": "Model conditions + diagnostics",
    "section": "Independence",
    "text": "Independence\n\nWe can often check the independence condition based on the context of the data and how the observations were collected.\nIf the data were collected in a particular order, examine a scatterplot of the residuals versus order in which the data were collected.\nIf data has spatial element, plot residuals on a map to examine potential spatial correlation.\n\n. . .\n\nThe independence condition is satisfied. The lemurs could reasonably be treated as independent."
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#model-diagnostics-1",
    "href": "slides/12-conditions-diagnostics-notes.html#model-diagnostics-1",
    "title": "Model conditions + diagnostics",
    "section": "Model diagnostics",
    "text": "Model diagnostics\n\nlemurs_aug &lt;- augment(lemurs_fit)\n\nlemurs_aug |&gt; slice(1:10)\n\n# A tibble: 10 × 8\n   weight_g age_at_wt_mo .fitted .resid   .hat .sigma  .cooksd .std.resid\n      &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1     3400         32.0   3557. -157.  0.0302   494. 0.00164      -0.324\n 2     3620         33.0   4063. -443.  0.0399   491. 0.0176       -0.922\n 3     3720         32.4   3800.  -80.0 0.0163   495. 0.000224     -0.164\n 4     4440         32.6   3850.  590.  0.0177   489. 0.0132        1.21 \n 5     3770         31.8   3457.  313.  0.0458   493. 0.0102        0.652\n 6     3920         31.9   3522.  398.  0.0350   492. 0.0124        0.826\n 7     4520         32.8   3979.  541.  0.0279   490. 0.0180        1.12 \n 8     3700         33.2   4177. -477.  0.0626   491. 0.0337       -1.01 \n 9     3690         31.9   3537.  153.  0.0329   494. 0.00172       0.318\n10     3790         32.8   3949. -159.  0.0247   494. 0.00136      -0.328"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#model-diagnostics-in-r",
    "href": "slides/12-conditions-diagnostics-notes.html#model-diagnostics-in-r",
    "title": "Model conditions + diagnostics",
    "section": "Model diagnostics in R",
    "text": "Model diagnostics in R\nUse the augment() function in the broom package to output the model diagnostics (along with the predicted values and residuals)\n\nresponse and predictor variables in the model\n.fitted: predicted values\n.se.fit: standard errors of predicted values\n.resid: residuals\n.hat: leverage\n.sigma: estimate of residual standard deviation when the corresponding observation is dropped from model\n.cooksd: Cook’s distance\n.std.resid: standardized residuals"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#influential-point",
    "href": "slides/12-conditions-diagnostics-notes.html#influential-point",
    "title": "Model conditions + diagnostics",
    "section": "Influential Point",
    "text": "Influential Point\nAn observation is influential if removing has a noticeable impact on the regression coefficients"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#influential-points",
    "href": "slides/12-conditions-diagnostics-notes.html#influential-points",
    "title": "Model conditions + diagnostics",
    "section": "Influential points",
    "text": "Influential points\n\n\nInfluential points have a noticeable impact on the coefficients and standard errors used for inference\nThese points can sometimes be identified in a scatterplot if there is only one predictor variable\n\nThis is often not the case when there are multiple predictors\n\nWe will use measures to quantify an individual observation’s influence on the regression model\n\nleverage, standardized & studentized residuals, and Cook’s distance"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#motivating-cooks-distance",
    "href": "slides/12-conditions-diagnostics-notes.html#motivating-cooks-distance",
    "title": "Model conditions + diagnostics",
    "section": "Motivating Cook’s Distance",
    "text": "Motivating Cook’s Distance\n\nAn observation’s influence on the regression line depends on\n\nHow close it lies to the general trend of the data\nIts leverage\n\nCook’s Distance is a statistic that includes both of these components to measure an observation’s overall impact on the model"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#cooks-distance-1",
    "href": "slides/12-conditions-diagnostics-notes.html#cooks-distance-1",
    "title": "Model conditions + diagnostics",
    "section": "Cook’s Distance",
    "text": "Cook’s Distance\nCook’s distance for the \\(i^{th}\\) observation is\n\\[\nD_i = \\frac{r^2_i}{p + 1}\\Big(\\frac{h_{ii}}{1 - h_{ii}}\\Big)\n\\]\nwhere \\(r_i\\) is the studentized residual and \\(h_{ii}\\) is the leverage for the \\(i^{th}\\) observation\n. . .\nThis measure is a combination of\n\nHow well the model fits the \\(i^{th}\\) observation (magnitude of residuals)\nHow far the \\(i^{th}\\) observation is from the rest of the data (where the point is in the \\(x\\) space)"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#using-cooks-distance",
    "href": "slides/12-conditions-diagnostics-notes.html#using-cooks-distance",
    "title": "Model conditions + diagnostics",
    "section": "Using Cook’s Distance",
    "text": "Using Cook’s Distance\n\nAn observation with large value of \\(D_i\\) is said to have a strong influence on the predicted values\nGeneral thresholds .An observation with\n\n\\(D_i &gt; 0.5\\) is moderately influential\n\\(D_i &gt; 1\\) is very influential"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#cooks-distance-2",
    "href": "slides/12-conditions-diagnostics-notes.html#cooks-distance-2",
    "title": "Model conditions + diagnostics",
    "section": "Cook’s Distance",
    "text": "Cook’s Distance\nCook’s Distance is in the column .cooksd in the output from the augment() function"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#comparing-models",
    "href": "slides/12-conditions-diagnostics-notes.html#comparing-models",
    "title": "Model conditions + diagnostics",
    "section": "Comparing models",
    "text": "Comparing models\nWith influential point\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-12314.360\n4252.696\n-2.896\n0.005\n\n\nage_at_wt_mo\n496.591\n131.225\n3.784\n0.000\n\n\n\n\n\n\nWithout influential point\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-6670.958\n3495.136\n-1.909\n0.061\n\n\nage_at_wt_mo\n321.209\n107.904\n2.977\n0.004\n\n\n\n\n\n. . .\n\nLet’s better understand the influential point."
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#leverage-1",
    "href": "slides/12-conditions-diagnostics-notes.html#leverage-1",
    "title": "Model conditions + diagnostics",
    "section": "Leverage",
    "text": "Leverage\n\n\nRecall the hat matrix \\(\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}\\)\nWe focus on the diagonal elements\n\\[\nh_{ii} = \\mathbf{x}_i^\\mathsf{T}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{x}_i\n\\]such that \\(\\mathbf{x}^\\mathsf{T}_i\\) is the \\(i^{th}\\) row of \\(\\mathbf{X}\\)\n\\(h_{ii}\\) is the leverage: a measure of the distance of the \\(i^{th}\\) observation from the center (or centroid) of the \\(x\\) space\nObservations with large values of \\(h_{ii}\\) are far away from the typical value (or combination of values) of the predictors in the data"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#large-leverage",
    "href": "slides/12-conditions-diagnostics-notes.html#large-leverage",
    "title": "Model conditions + diagnostics",
    "section": "Large leverage",
    "text": "Large leverage\n\n\nThe sum of the leverages for all points is \\(p + 1\\), where \\(p\\) is the number of predictors in the model . More specifically\n\\[\n\\sum_{i=1}^n h_{ii} = \\text{rank}(\\mathbf{H}) = \\text{rank}(\\mathbf{X}) = p+1\n\\]\nThe average value of leverage, \\(h_{ii}\\), is \\(\\bar{h} =  \\frac{(p+1)}{n}\\)\nAn observation has large leverage if \\[h_{ii} &gt; \\frac{2(p+1)}{n}\\]"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#lemurs-leverage",
    "href": "slides/12-conditions-diagnostics-notes.html#lemurs-leverage",
    "title": "Model conditions + diagnostics",
    "section": "Lemurs: Leverage",
    "text": "Lemurs: Leverage\n\nh_threshold &lt;- 2 * 2 / nrow(lemurs)\nh_threshold\n\n[1] 0.06451613\n\n\n. . .\n\nlemurs_aug |&gt;\n  filter(.hat &gt; h_threshold)\n\n# A tibble: 2 × 8\n  weight_g age_at_wt_mo .fitted .resid   .hat .sigma .cooksd .std.resid\n     &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n1     4040         33.5   4336.  -296. 0.107    493.  0.0244     -0.639\n2     6519         33.4   4272.  2247. 0.0871   389.  1.10        4.79 \n\n\n\n. . .\n\nWhy do you think these points have large leverage?"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#lets-look-at-the-data",
    "href": "slides/12-conditions-diagnostics-notes.html#lets-look-at-the-data",
    "title": "Model conditions + diagnostics",
    "section": "Let’s look at the data",
    "text": "Let’s look at the data"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#large-leverage-1",
    "href": "slides/12-conditions-diagnostics-notes.html#large-leverage-1",
    "title": "Model conditions + diagnostics",
    "section": "Large leverage",
    "text": "Large leverage\nIf there is point with high leverage, ask\n\n❓ Is there a data entry error?\n❓ Is this observation within the scope of individuals for which you want to make predictions and draw conclusions?\n❓ Is this observation impacting the estimates of the model coefficients? (Need more information!)\n\n. . .\nJust because a point has high leverage does not necessarily mean it will have a substantial impact on the regression. Therefore we need to check other measures."
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#scaled-residuals-1",
    "href": "slides/12-conditions-diagnostics-notes.html#scaled-residuals-1",
    "title": "Model conditions + diagnostics",
    "section": "Scaled residuals",
    "text": "Scaled residuals\n\n\nWhat is the best way to identify outlier points that don’t fit the pattern from the regression line?\n\nLook for points that have large residuals\n\nWe can rescale residuals and put them on a common scale to more easily identify “large” residuals\nWe will consider two types of scaled residuals: standardized residuals and studentized residuals"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#standardized-residuals",
    "href": "slides/12-conditions-diagnostics-notes.html#standardized-residuals",
    "title": "Model conditions + diagnostics",
    "section": "Standardized residuals",
    "text": "Standardized residuals\n\n\nThe variance of the residuals can be estimated by the mean squared residuals (MSR) \\(= \\frac{SSR}{n - p - 1} = \\hat{\\sigma}^2_{\\epsilon}\\)\nWe can use MSR to compute standardized residuals\n\\[\nstd.res_i = \\frac{e_i}{\\sqrt{MSR}}\n\\]\nStandardized residuals are produced by augment() in the column .std.resid"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#using-standardized-residuals",
    "href": "slides/12-conditions-diagnostics-notes.html#using-standardized-residuals",
    "title": "Model conditions + diagnostics",
    "section": "Using standardized residuals",
    "text": "Using standardized residuals\nWe can examine the standardized residuals directly from the output from the augment() function\n\n\n\n\n\n\n\n\n\n\nAn observation is a potential outlier if its standardized residual is beyond \\(\\pm 3\\)"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#digging-in-to-the-data",
    "href": "slides/12-conditions-diagnostics-notes.html#digging-in-to-the-data",
    "title": "Model conditions + diagnostics",
    "section": "Digging in to the data",
    "text": "Digging in to the data\nLet’s look at the value of the response variable to better understand potential outliers"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#studentized-residuals",
    "href": "slides/12-conditions-diagnostics-notes.html#studentized-residuals",
    "title": "Model conditions + diagnostics",
    "section": "Studentized residuals",
    "text": "Studentized residuals\n\n\nMSR is an approximation of the variance of the residuals.\nThe variance of the residuals is \\(Var(\\mathbf{e}) = \\sigma^2_{\\epsilon}(\\mathbf{I} - \\mathbf{H})\\)\n\nThe variance of the \\(i^{th}\\) residual is \\(Var(e_i) = \\sigma^2_{\\epsilon}(1 - h_{ii})\\)\n\nThe studentized residual is the residual rescaled by the more exact calculation for variance\n\n\n\\[\nr_i = \\frac{e_{i}}{\\sqrt{\\hat{\\sigma}^2_{\\epsilon}(1 - h_{ii})}}\n\\]\n\nStandardized and studentized residuals provide similar information about which points are outliers in the response.\n\nStudentized residuals are used to compute Cook’s Distance."
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#using-these-measures",
    "href": "slides/12-conditions-diagnostics-notes.html#using-these-measures",
    "title": "Model conditions + diagnostics",
    "section": "Using these measures",
    "text": "Using these measures\n\nStandardized residuals, leverage, and Cook’s Distance should all be examined together\nExamine plots of the measures to identify observations that are outliers, high leverage, and may potentially impact the model."
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#back-to-the-influential-point",
    "href": "slides/12-conditions-diagnostics-notes.html#back-to-the-influential-point",
    "title": "Model conditions + diagnostics",
    "section": "Back to the influential point",
    "text": "Back to the influential point"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#what-to-do-with-outliersinfluential-points",
    "href": "slides/12-conditions-diagnostics-notes.html#what-to-do-with-outliersinfluential-points",
    "title": "Model conditions + diagnostics",
    "section": "What to do with outliers/influential points?",
    "text": "What to do with outliers/influential points?\n\n\nFirst consider if the outlier is a result of a data entry error.\nIf not, you may consider dropping an observation if it’s an outlier in the predictor variables if…\n\nIt is meaningful to drop the observation given the context of the problem\nYou intended to build a model on a smaller range of the predictor variables. Mention this in the write up of the results and be careful to avoid extrapolation when making predictions"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#what-to-do-with-outliersinfluential-points-1",
    "href": "slides/12-conditions-diagnostics-notes.html#what-to-do-with-outliersinfluential-points-1",
    "title": "Model conditions + diagnostics",
    "section": "What to do with outliers/influential points?",
    "text": "What to do with outliers/influential points?\n\n\nIt is generally not good practice to drop observations that ar outliers in the value of the response variable\n\nThese are legitimate observations and should be in the model\nYou can try transformations or increasing the sample size by collecting more data\n\nA general strategy when there are influential points is to fit the model with and without the influential points and compare the outcomes"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#recap",
    "href": "slides/12-conditions-diagnostics-notes.html#recap",
    "title": "Model conditions + diagnostics",
    "section": "Recap",
    "text": "Recap\n\nModel conditions\nInfluential points\nModel diagnostics\n\nLeverage\nStudentized residuals\n\n\nCook’s Distance"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#announcements",
    "href": "slides/12-conditions-diagnostics.html#announcements",
    "title": "Model conditions + diagnostics",
    "section": "Announcements",
    "text": "Announcements\n\nExam corrections (optional) due Tuesday, March 4 at 11:59pm\n\nSee assignment on Canvas\n\nProject proposal due TODAY at 11:59pm"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#computing-set-up",
    "href": "slides/12-conditions-diagnostics.html#computing-set-up",
    "title": "Model conditions + diagnostics",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)   \nlibrary(viridis)\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#topics",
    "href": "slides/12-conditions-diagnostics.html#topics",
    "title": "Model conditions + diagnostics",
    "section": "Topics",
    "text": "Topics\n\nModel conditions\nInfluential points\nModel diagnostics\n\nLeverage\nStudentized residuals\nCook’s Distance"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#data-duke-lemurs",
    "href": "slides/12-conditions-diagnostics.html#data-duke-lemurs",
    "title": "Model conditions + diagnostics",
    "section": "Data: Duke lemurs",
    "text": "Data: Duke lemurs\nToday’s data contains a subset of the original Duke Lemur data set available in the TidyTuesday GitHub repo. This data includes information on “young adult” lemurs from the Coquerel’s sifaka species (PCOQ), the largest species at the Duke Lemur Center. The analysis will focus on the following variables:\n\nage_at_wt_mo: Age in months: Age of the animal when the weight was taken, in months (((Weight_Date-DOB)/365)*12)\nweight_g: Weight: Animal weight, in grams. Weights under 500g generally to nearest 0.1-1g; Weights &gt;500g generally to the nearest 1-20g.\n\nThe goal of the analysis is to use the age of the lemurs to understand variability in the weight."
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#eda",
    "href": "slides/12-conditions-diagnostics.html#eda",
    "title": "Model conditions + diagnostics",
    "section": "EDA",
    "text": "EDA"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#eda-1",
    "href": "slides/12-conditions-diagnostics.html#eda-1",
    "title": "Model conditions + diagnostics",
    "section": "EDA",
    "text": "EDA"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#fit-model",
    "href": "slides/12-conditions-diagnostics.html#fit-model",
    "title": "Model conditions + diagnostics",
    "section": "Fit model",
    "text": "Fit model\n\nlemurs_fit &lt;- lm(weight_g ~ age_at_wt_mo, data = lemurs)\n\ntidy(lemurs_fit) |&gt; \n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-12314.360\n4252.696\n-2.896\n0.005\n\n\nage_at_wt_mo\n496.591\n131.225\n3.784\n0.000"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#assumptions-for-regression",
    "href": "slides/12-conditions-diagnostics.html#assumptions-for-regression",
    "title": "Model conditions + diagnostics",
    "section": "Assumptions for regression",
    "text": "Assumptions for regression\n\\[\n\\mathbf{y}|\\mathbf{X} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma_\\epsilon^2\\mathbf{I})\n\\]\n\nLinearity: There is a linear relationship between the response and predictor variables.\nConstant Variance: The variability about the least squares line is generally constant.\nNormality: The distribution of the errors (residuals) is approximately normal.\nIndependence: The errors (residuals) are independent from one another.\n\n\n\nHow do we know if these assumptions hold in our data?"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#linearity",
    "href": "slides/12-conditions-diagnostics.html#linearity",
    "title": "Model conditions + diagnostics",
    "section": "Linearity",
    "text": "Linearity\n\nLook at plot of residuals versus fitted (predicted) values.\nLinearity is satisfied if there is no discernible pattern in the plot (i.e., points randomly scattered around \\(residuals = 0\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinearity is satisfied"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#example-linearity-not-satisfied",
    "href": "slides/12-conditions-diagnostics.html#example-linearity-not-satisfied",
    "title": "Model conditions + diagnostics",
    "section": "Example: Linearity not satisfied",
    "text": "Example: Linearity not satisfied\n\n\n\nIf linearity is not satisfied, examine the plots of residuals versus each predictor.\nAdd higher order term(s), as needed."
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#constant-variance",
    "href": "slides/12-conditions-diagnostics.html#constant-variance",
    "title": "Model conditions + diagnostics",
    "section": "Constant variance",
    "text": "Constant variance\n\nLook at plot of residuals versus fitted (predicted) values.\nConstant variance is satisfied if the vertical spread of the points is approximately equal for all fitted values\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant variance is satisfied"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#example-constant-variance-not-satisfied",
    "href": "slides/12-conditions-diagnostics.html#example-constant-variance-not-satisfied",
    "title": "Model conditions + diagnostics",
    "section": "Example: Constant variance not satisfied",
    "text": "Example: Constant variance not satisfied\n\n\n\nConstant variance is critical for reliable inference\nAddress violations by applying transformation on the response"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#normality",
    "href": "slides/12-conditions-diagnostics.html#normality",
    "title": "Model conditions + diagnostics",
    "section": "Normality",
    "text": "Normality\n\nLook at the distribution of the residuals\nNormality is satisfied if the distribution is approximately unimodal and symmetric. Inference robust to violations if \\(n &gt; 30\\)\n\n\n\n\nDistribution approximately unimodal and symmetric, aside from the outlier. There are 62 observations, so inference robust to departures."
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#independence",
    "href": "slides/12-conditions-diagnostics.html#independence",
    "title": "Model conditions + diagnostics",
    "section": "Independence",
    "text": "Independence\n\nWe can often check the independence condition based on the context of the data and how the observations were collected.\nIf the data were collected in a particular order, examine a scatterplot of the residuals versus order in which the data were collected.\nIf data has spatial element, plot residuals on a map to examine potential spatial correlation.\n\n\n\nThe independence condition is satisfied. The lemurs could reasonably be treated as independent."
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#model-diagnostics-1",
    "href": "slides/12-conditions-diagnostics.html#model-diagnostics-1",
    "title": "Model conditions + diagnostics",
    "section": "Model diagnostics",
    "text": "Model diagnostics\n\nlemurs_aug &lt;- augment(lemurs_fit)\n\nlemurs_aug |&gt; slice(1:10)\n\n# A tibble: 10 × 8\n   weight_g age_at_wt_mo .fitted .resid   .hat .sigma  .cooksd .std.resid\n      &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1     3400         32.0   3557. -157.  0.0302   494. 0.00164      -0.324\n 2     3620         33.0   4063. -443.  0.0399   491. 0.0176       -0.922\n 3     3720         32.4   3800.  -80.0 0.0163   495. 0.000224     -0.164\n 4     4440         32.6   3850.  590.  0.0177   489. 0.0132        1.21 \n 5     3770         31.8   3457.  313.  0.0458   493. 0.0102        0.652\n 6     3920         31.9   3522.  398.  0.0350   492. 0.0124        0.826\n 7     4520         32.8   3979.  541.  0.0279   490. 0.0180        1.12 \n 8     3700         33.2   4177. -477.  0.0626   491. 0.0337       -1.01 \n 9     3690         31.9   3537.  153.  0.0329   494. 0.00172       0.318\n10     3790         32.8   3949. -159.  0.0247   494. 0.00136      -0.328"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#model-diagnostics-in-r",
    "href": "slides/12-conditions-diagnostics.html#model-diagnostics-in-r",
    "title": "Model conditions + diagnostics",
    "section": "Model diagnostics in R",
    "text": "Model diagnostics in R\nUse the augment() function in the broom package to output the model diagnostics (along with the predicted values and residuals)\n\nresponse and predictor variables in the model\n.fitted: predicted values\n.se.fit: standard errors of predicted values\n.resid: residuals\n.hat: leverage\n.sigma: estimate of residual standard deviation when the corresponding observation is dropped from model\n.cooksd: Cook’s distance\n.std.resid: standardized residuals"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#influential-point",
    "href": "slides/12-conditions-diagnostics.html#influential-point",
    "title": "Model conditions + diagnostics",
    "section": "Influential Point",
    "text": "Influential Point\nAn observation is influential if removing has a noticeable impact on the regression coefficients"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#influential-points",
    "href": "slides/12-conditions-diagnostics.html#influential-points",
    "title": "Model conditions + diagnostics",
    "section": "Influential points",
    "text": "Influential points\n\n\nInfluential points have a noticeable impact on the coefficients and standard errors used for inference\nThese points can sometimes be identified in a scatterplot if there is only one predictor variable\n\nThis is often not the case when there are multiple predictors\n\nWe will use measures to quantify an individual observation’s influence on the regression model\n\nleverage, standardized & studentized residuals, and Cook’s distance"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#motivating-cooks-distance",
    "href": "slides/12-conditions-diagnostics.html#motivating-cooks-distance",
    "title": "Model conditions + diagnostics",
    "section": "Motivating Cook’s Distance",
    "text": "Motivating Cook’s Distance\n\nAn observation’s influence on the regression line depends on\n\nHow close it lies to the general trend of the data\nIts leverage\n\nCook’s Distance is a statistic that includes both of these components to measure an observation’s overall impact on the model"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#cooks-distance-1",
    "href": "slides/12-conditions-diagnostics.html#cooks-distance-1",
    "title": "Model conditions + diagnostics",
    "section": "Cook’s Distance",
    "text": "Cook’s Distance\nCook’s distance for the \\(i^{th}\\) observation is\n\\[\nD_i = \\frac{r^2_i}{p + 1}\\Big(\\frac{h_{ii}}{1 - h_{ii}}\\Big)\n\\]\nwhere \\(r_i\\) is the studentized residual and \\(h_{ii}\\) is the leverage for the \\(i^{th}\\) observation\n\nThis measure is a combination of\n\nHow well the model fits the \\(i^{th}\\) observation (magnitude of residuals)\nHow far the \\(i^{th}\\) observation is from the rest of the data (where the point is in the \\(x\\) space)"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#using-cooks-distance",
    "href": "slides/12-conditions-diagnostics.html#using-cooks-distance",
    "title": "Model conditions + diagnostics",
    "section": "Using Cook’s Distance",
    "text": "Using Cook’s Distance\n\nAn observation with large value of \\(D_i\\) is said to have a strong influence on the predicted values\nGeneral thresholds .An observation with\n\n\\(D_i &gt; 0.5\\) is moderately influential\n\\(D_i &gt; 1\\) is very influential"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#cooks-distance-2",
    "href": "slides/12-conditions-diagnostics.html#cooks-distance-2",
    "title": "Model conditions + diagnostics",
    "section": "Cook’s Distance",
    "text": "Cook’s Distance\nCook’s Distance is in the column .cooksd in the output from the augment() function"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#comparing-models",
    "href": "slides/12-conditions-diagnostics.html#comparing-models",
    "title": "Model conditions + diagnostics",
    "section": "Comparing models",
    "text": "Comparing models\nWith influential point\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-12314.360\n4252.696\n-2.896\n0.005\n\n\nage_at_wt_mo\n496.591\n131.225\n3.784\n0.000\n\n\n\n\n\n\nWithout influential point\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-6670.958\n3495.136\n-1.909\n0.061\n\n\nage_at_wt_mo\n321.209\n107.904\n2.977\n0.004\n\n\n\n\n\n\n\nLet’s better understand the influential point."
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#leverage-1",
    "href": "slides/12-conditions-diagnostics.html#leverage-1",
    "title": "Model conditions + diagnostics",
    "section": "Leverage",
    "text": "Leverage\n\n\nRecall the hat matrix \\(\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}\\)\nWe focus on the diagonal elements\n\\[\nh_{ii} = \\mathbf{x}_i^\\mathsf{T}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{x}_i\n\\]such that \\(\\mathbf{x}^\\mathsf{T}_i\\) is the \\(i^{th}\\) row of \\(\\mathbf{X}\\)\n\\(h_{ii}\\) is the leverage: a measure of the distance of the \\(i^{th}\\) observation from the center (or centroid) of the \\(x\\) space\nObservations with large values of \\(h_{ii}\\) are far away from the typical value (or combination of values) of the predictors in the data"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#large-leverage",
    "href": "slides/12-conditions-diagnostics.html#large-leverage",
    "title": "Model conditions + diagnostics",
    "section": "Large leverage",
    "text": "Large leverage\n\n\nThe sum of the leverages for all points is \\(p + 1\\), where \\(p\\) is the number of predictors in the model . More specifically\n\\[\n\\sum_{i=1}^n h_{ii} = \\text{rank}(\\mathbf{H}) = \\text{rank}(\\mathbf{X}) = p+1\n\\]\nThe average value of leverage, \\(h_{ii}\\), is \\(\\bar{h} =  \\frac{(p+1)}{n}\\)\nAn observation has large leverage if \\[h_{ii} &gt; \\frac{2(p+1)}{n}\\]"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#lemurs-leverage",
    "href": "slides/12-conditions-diagnostics.html#lemurs-leverage",
    "title": "Model conditions + diagnostics",
    "section": "Lemurs: Leverage",
    "text": "Lemurs: Leverage\n\nh_threshold &lt;- 2 * 2 / nrow(lemurs)\nh_threshold\n\n[1] 0.06451613\n\n\n\n\nlemurs_aug |&gt;\n  filter(.hat &gt; h_threshold)\n\n# A tibble: 2 × 8\n  weight_g age_at_wt_mo .fitted .resid   .hat .sigma .cooksd .std.resid\n     &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n1     4040         33.5   4336.  -296. 0.107    493.  0.0244     -0.639\n2     6519         33.4   4272.  2247. 0.0871   389.  1.10        4.79 \n\n\n\n\n\n\nWhy do you think these points have large leverage?"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#lets-look-at-the-data",
    "href": "slides/12-conditions-diagnostics.html#lets-look-at-the-data",
    "title": "Model conditions + diagnostics",
    "section": "Let’s look at the data",
    "text": "Let’s look at the data"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#large-leverage-1",
    "href": "slides/12-conditions-diagnostics.html#large-leverage-1",
    "title": "Model conditions + diagnostics",
    "section": "Large leverage",
    "text": "Large leverage\nIf there is point with high leverage, ask\n\n❓ Is there a data entry error?\n❓ Is this observation within the scope of individuals for which you want to make predictions and draw conclusions?\n❓ Is this observation impacting the estimates of the model coefficients? (Need more information!)\n\n\nJust because a point has high leverage does not necessarily mean it will have a substantial impact on the regression. Therefore we need to check other measures."
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#scaled-residuals-1",
    "href": "slides/12-conditions-diagnostics.html#scaled-residuals-1",
    "title": "Model conditions + diagnostics",
    "section": "Scaled residuals",
    "text": "Scaled residuals\n\n\nWhat is the best way to identify outlier points that don’t fit the pattern from the regression line?\n\nLook for points that have large residuals\n\nWe can rescale residuals and put them on a common scale to more easily identify “large” residuals\nWe will consider two types of scaled residuals: standardized residuals and studentized residuals"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#standardized-residuals",
    "href": "slides/12-conditions-diagnostics.html#standardized-residuals",
    "title": "Model conditions + diagnostics",
    "section": "Standardized residuals",
    "text": "Standardized residuals\n\n\nThe variance of the residuals can be estimated by the mean squared residuals (MSR) \\(= \\frac{SSR}{n - p - 1} = \\hat{\\sigma}^2_{\\epsilon}\\)\nWe can use MSR to compute standardized residuals\n\\[\nstd.res_i = \\frac{e_i}{\\sqrt{MSR}}\n\\]\nStandardized residuals are produced by augment() in the column .std.resid"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#using-standardized-residuals",
    "href": "slides/12-conditions-diagnostics.html#using-standardized-residuals",
    "title": "Model conditions + diagnostics",
    "section": "Using standardized residuals",
    "text": "Using standardized residuals\nWe can examine the standardized residuals directly from the output from the augment() function\n\n\nAn observation is a potential outlier if its standardized residual is beyond \\(\\pm 3\\)"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#digging-in-to-the-data",
    "href": "slides/12-conditions-diagnostics.html#digging-in-to-the-data",
    "title": "Model conditions + diagnostics",
    "section": "Digging in to the data",
    "text": "Digging in to the data\nLet’s look at the value of the response variable to better understand potential outliers"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#studentized-residuals",
    "href": "slides/12-conditions-diagnostics.html#studentized-residuals",
    "title": "Model conditions + diagnostics",
    "section": "Studentized residuals",
    "text": "Studentized residuals\n\n\nMSR is an approximation of the variance of the residuals.\nThe variance of the residuals is \\(Var(\\mathbf{e}) = \\sigma^2_{\\epsilon}(\\mathbf{I} - \\mathbf{H})\\)\n\nThe variance of the \\(i^{th}\\) residual is \\(Var(e_i) = \\sigma^2_{\\epsilon}(1 - h_{ii})\\)\n\nThe studentized residual is the residual rescaled by the more exact calculation for variance\n\n\n\\[\nr_i = \\frac{e_{i}}{\\sqrt{\\hat{\\sigma}^2_{\\epsilon}(1 - h_{ii})}}\n\\]\n\nStandardized and studentized residuals provide similar information about which points are outliers in the response.\n\nStudentized residuals are used to compute Cook’s Distance."
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#using-these-measures",
    "href": "slides/12-conditions-diagnostics.html#using-these-measures",
    "title": "Model conditions + diagnostics",
    "section": "Using these measures",
    "text": "Using these measures\n\nStandardized residuals, leverage, and Cook’s Distance should all be examined together\nExamine plots of the measures to identify observations that are outliers, high leverage, and may potentially impact the model."
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#back-to-the-influential-point",
    "href": "slides/12-conditions-diagnostics.html#back-to-the-influential-point",
    "title": "Model conditions + diagnostics",
    "section": "Back to the influential point",
    "text": "Back to the influential point"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#what-to-do-with-outliersinfluential-points",
    "href": "slides/12-conditions-diagnostics.html#what-to-do-with-outliersinfluential-points",
    "title": "Model conditions + diagnostics",
    "section": "What to do with outliers/influential points?",
    "text": "What to do with outliers/influential points?\n\n\nFirst consider if the outlier is a result of a data entry error.\nIf not, you may consider dropping an observation if it’s an outlier in the predictor variables if…\n\nIt is meaningful to drop the observation given the context of the problem\nYou intended to build a model on a smaller range of the predictor variables. Mention this in the write up of the results and be careful to avoid extrapolation when making predictions"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#what-to-do-with-outliersinfluential-points-1",
    "href": "slides/12-conditions-diagnostics.html#what-to-do-with-outliersinfluential-points-1",
    "title": "Model conditions + diagnostics",
    "section": "What to do with outliers/influential points?",
    "text": "What to do with outliers/influential points?\n\n\nIt is generally not good practice to drop observations that ar outliers in the value of the response variable\n\nThese are legitimate observations and should be in the model\nYou can try transformations or increasing the sample size by collecting more data\n\nA general strategy when there are influential points is to fit the model with and without the influential points and compare the outcomes"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#recap",
    "href": "slides/12-conditions-diagnostics.html#recap",
    "title": "Model conditions + diagnostics",
    "section": "Recap",
    "text": "Recap\n\nModel conditions\nInfluential points\nModel diagnostics\n\nLeverage\nStudentized residuals\n\n\nCook’s Distance"
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html",
    "href": "slides/07-mlr-pt3-notes.html",
    "title": "Multiple linear regression",
    "section": "",
    "text": "HW 01 due TODAY at 11:59pm\nTeam labs start on Friday\nClick here to learn more about the Academic Resource Center\nStatistics experience due Tuesday, April 22"
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#announcements",
    "href": "slides/07-mlr-pt3-notes.html#announcements",
    "title": "Multiple linear regression",
    "section": "",
    "text": "HW 01 due TODAY at 11:59pm\nTeam labs start on Friday\nClick here to learn more about the Academic Resource Center\nStatistics experience due Tuesday, April 22"
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#topics",
    "href": "slides/07-mlr-pt3-notes.html#topics",
    "title": "Multiple linear regression",
    "section": "Topics",
    "text": "Topics\n\nCentering quantitative predictors\nStandardizing quantitative predictors\nInteraction terms\nModel comparison\n\nRMSE\n\\(Adj. R^2\\)"
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#computing-setup",
    "href": "slides/07-mlr-pt3-notes.html#computing-setup",
    "title": "Multiple linear regression",
    "section": "Computing setup",
    "text": "Computing setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(viridis) #adjust color palette\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))"
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#data-peer-to-peer-lender",
    "href": "slides/07-mlr-pt3-notes.html#data-peer-to-peer-lender",
    "title": "Multiple linear regression",
    "section": "Data: Peer-to-peer lender",
    "text": "Data: Peer-to-peer lender\nToday’s data is a sample of 50 loans made through a peer-to-peer lending club. The data is in the loan50 data frame in the openintro R package.\n\n\n# A tibble: 50 × 4\n   annual_income_th debt_to_income verified_income interest_rate\n              &lt;dbl&gt;          &lt;dbl&gt; &lt;fct&gt;                   &lt;dbl&gt;\n 1             59           0.558  Not Verified            10.9 \n 2             60           1.31   Not Verified             9.92\n 3             75           1.06   Verified                26.3 \n 4             75           0.574  Not Verified             9.92\n 5            254           0.238  Not Verified             9.43\n 6             67           1.08   Source Verified          9.92\n 7             28.8         0.0997 Source Verified         17.1 \n 8             80           0.351  Not Verified             6.08\n 9             34           0.698  Not Verified             7.97\n10             80           0.167  Source Verified         12.6 \n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#variables",
    "href": "slides/07-mlr-pt3-notes.html#variables",
    "title": "Multiple linear regression",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\n\nannual_income_th: Annual income (in $1000s)\ndebt_to_income: Debt-to-income ratio, i.e. the percentage of a borrower’s total debt divided by their total income\nverified_income: Whether borrower’s income source and amount have been verified (Not Verified, Source Verified, Verified)\n\n\nResponse: interest_rate: Interest rate for the loan"
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#response-vs.-predictors",
    "href": "slides/07-mlr-pt3-notes.html#response-vs.-predictors",
    "title": "Multiple linear regression",
    "section": "Response vs. predictors",
    "text": "Response vs. predictors\n\n\n\n\n\n\n\n\n\nGoal: Use these predictors in a single model to understand variability in interest rate."
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#model-fit-in-r",
    "href": "slides/07-mlr-pt3-notes.html#model-fit-in-r",
    "title": "Multiple linear regression",
    "section": "Model fit in R",
    "text": "Model fit in R\n\nint_fit &lt;- lm(interest_rate ~ debt_to_income + verified_income  + annual_income_th,\n              data = loan50)\n\ntidy(int_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n10.726\n1.507\n7.116\n0.000\n\n\ndebt_to_income\n0.671\n0.676\n0.993\n0.326\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n\n\nannual_income_th\n-0.021\n0.011\n-1.804\n0.078"
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#interpreting-verified_income",
    "href": "slides/07-mlr-pt3-notes.html#interpreting-verified_income",
    "title": "Multiple linear regression",
    "section": "Interpreting verified_income",
    "text": "Interpreting verified_income\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n10.726\n1.507\n7.116\n0.000\n7.690\n13.762\n\n\ndebt_to_income\n0.671\n0.676\n0.993\n0.326\n-0.690\n2.033\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n-0.606\n5.028\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n3.253\n10.508\n\n\nannual_income_th\n-0.021\n0.011\n-1.804\n0.078\n-0.043\n0.002\n\n\n\n\n\n\n\n\n\nThe baseline level is Not verified.\nPeople with source verified income are expected to take a loan with an interest rate that is 2.211% higher, on average, than the rate on loans to those whose income is not verified, holding all else constant."
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#centering",
    "href": "slides/07-mlr-pt3-notes.html#centering",
    "title": "Multiple linear regression",
    "section": "Centering",
    "text": "Centering\n\nCentering a quantitative predictor means shifting every value by some constant \\(C\\)\n\n\\[\nX_{cent} = X  - C\n\\]\n\nOne common type of centering is mean-centering, in which every value of a predictor is shifted by its mean\nOnly quantitative predictors are centered\nCenter all quantitative predictors in the model for ease of interpretation\n\n\nWhat is one reason one might want to center the quantitative predictors? What is are the units of centered variables?"
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#centering-1",
    "href": "slides/07-mlr-pt3-notes.html#centering-1",
    "title": "Multiple linear regression",
    "section": "Centering",
    "text": "Centering\nUse the scale() function with center = TRUE and scale = FALSE to mean-center variables\n\nloan50 &lt;- loan50 |&gt;\n  mutate(debt_to_inc_cent = scale(debt_to_income, center = TRUE, scale = FALSE), \n         annual_inc_cent = scale(annual_income_th, center = TRUE, scale = FALSE))\n\nlm(interest_rate ~ debt_to_inc_cent + verified_income + annual_inc_cent, data = loan50) |&gt; \n  tidy() |&gt; kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n9.444\n0.977\n9.663\n0.000\n\n\ndebt_to_inc_cent\n0.671\n0.676\n0.993\n0.326\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n\n\nannual_inc_cent\n-0.021\n0.011\n-1.804\n0.078"
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#centering-2",
    "href": "slides/07-mlr-pt3-notes.html#centering-2",
    "title": "Multiple linear regression",
    "section": "Centering",
    "text": "Centering\n\n\n\n\n\nTerm\nOriginal Model\nCentered Model\n\n\n\n\n(Intercept)\n10.726\n9.444\n\n\ndebt_to_income\n0.671\n0.671\n\n\nverified_incomeSource Verified\n2.211\n2.211\n\n\nverified_incomeVerified\n6.880\n6.880\n\n\nannual_income_th\n-0.021\n-0.021\n\n\n\n\n\n\nHow has the model changed? How has the model remained the same?"
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#standardizing",
    "href": "slides/07-mlr-pt3-notes.html#standardizing",
    "title": "Multiple linear regression",
    "section": "Standardizing",
    "text": "Standardizing\n\nStandardizing a quantitative predictor mean shifting every value by the mean and dividing by the standard deviation of that variable\n\n\\[\nX_{std} = \\frac{X - \\bar{X}}{S_X}\n\\]\n\nOnly quantitative predictors are standardized\nStandardize all quantitative predictors in the model for ease of interpretation\n\n\nWhat is one reason one might want to standardize the quantitative predictors? What is are the units of standardized variables?"
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#standardizing-1",
    "href": "slides/07-mlr-pt3-notes.html#standardizing-1",
    "title": "Multiple linear regression",
    "section": "Standardizing",
    "text": "Standardizing\nUse the scale() function with center = TRUE and scale = TRUE to standardized variables\n\nloan50 &lt;- loan50 |&gt;\n  mutate(debt_to_inc_std = scale(debt_to_income, center = TRUE, scale = TRUE), \n         annual_inc_std = scale(annual_income_th, center = TRUE, scale = TRUE))\n\nlm(interest_rate ~ debt_to_inc_std + verified_income + annual_inc_std, data = loan50) |&gt;\n  tidy() |&gt; kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n9.444\n0.977\n9.663\n0.000\n\n\ndebt_to_inc_std\n0.643\n0.648\n0.993\n0.326\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n\n\nannual_inc_std\n-1.180\n0.654\n-1.804\n0.078"
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#standardizing-2",
    "href": "slides/07-mlr-pt3-notes.html#standardizing-2",
    "title": "Multiple linear regression",
    "section": "Standardizing",
    "text": "Standardizing\n\n\n\n\n\nTerm\nOriginal Model\nStandardized Model\n\n\n\n\n(Intercept)\n10.726\n9.444\n\n\ndebt_to_income\n0.671\n0.643\n\n\nverified_incomeSource Verified\n2.211\n2.211\n\n\nverified_incomeVerified\n6.880\n6.880\n\n\nannual_income_th\n-0.021\n-1.180\n\n\n\n\n\n\nHow has the model changed? How has the model remained the same?"
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#interaction-terms-1",
    "href": "slides/07-mlr-pt3-notes.html#interaction-terms-1",
    "title": "Multiple linear regression",
    "section": "Interaction terms",
    "text": "Interaction terms\n\nSometimes the relationship between a predictor variable and the response depends on the value of another predictor variable.\nThis is an interaction effect.\nTo account for this, we can include interaction terms in the model."
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#interest-rate-vs.-annual-income",
    "href": "slides/07-mlr-pt3-notes.html#interest-rate-vs.-annual-income",
    "title": "Multiple linear regression",
    "section": "Interest rate vs. annual income",
    "text": "Interest rate vs. annual income\nThe lines are not parallel indicating there is a potential interaction effect. The slope of annual income potentially differs based on the income verification."
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#interaction-term-in-model",
    "href": "slides/07-mlr-pt3-notes.html#interaction-term-in-model",
    "title": "Multiple linear regression",
    "section": "Interaction term in model",
    "text": "Interaction term in model\n\nint_fit_2 &lt;- lm(interest_rate ~ debt_to_income + verified_income + annual_income_th + verified_income * annual_income_th,\n      data = loan50)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n9.560\n2.034\n4.700\n0.000\n\n\ndebt_to_income\n0.691\n0.685\n1.009\n0.319\n\n\nverified_incomeSource Verified\n3.577\n2.539\n1.409\n0.166\n\n\nverified_incomeVerified\n9.923\n3.654\n2.716\n0.009\n\n\nannual_income_th\n-0.007\n0.020\n-0.341\n0.735\n\n\nverified_incomeSource Verified:annual_income_th\n-0.016\n0.026\n-0.643\n0.523\n\n\nverified_incomeVerified:annual_income_th\n-0.032\n0.033\n-0.979\n0.333"
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#interaction-term-in-model-1",
    "href": "slides/07-mlr-pt3-notes.html#interaction-term-in-model-1",
    "title": "Multiple linear regression",
    "section": "Interaction term in model",
    "text": "Interaction term in model\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n9.560\n2.034\n4.700\n0.000\n\n\ndebt_to_income\n0.691\n0.685\n1.009\n0.319\n\n\nverified_incomeSource Verified\n3.577\n2.539\n1.409\n0.166\n\n\nverified_incomeVerified\n9.923\n3.654\n2.716\n0.009\n\n\nannual_income_th\n-0.007\n0.020\n-0.341\n0.735\n\n\nverified_incomeSource Verified:annual_income_th\n-0.016\n0.026\n-0.643\n0.523\n\n\nverified_incomeVerified:annual_income_th\n-0.032\n0.033\n-0.979\n0.333\n\n\n\n\n\n\n\n\n\nWrite the regression equation for the people with Not Verified income.\nWrite the regression equation for people with Verified income."
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#interpreting-interaction-terms",
    "href": "slides/07-mlr-pt3-notes.html#interpreting-interaction-terms",
    "title": "Multiple linear regression",
    "section": "Interpreting interaction terms",
    "text": "Interpreting interaction terms\n\nWhat the interaction means: The effect of annual income on the interest rate differs by -0.016 when the income is source verified compared to when it is not verified, holding all else constant.\nInterpreting annual_income for source verified: If the income is source verified, we expect the interest rate to decrease by 0.023% (-0.007 + -0.016) for each additional thousand dollars in annual income, holding all else constant."
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#summary",
    "href": "slides/07-mlr-pt3-notes.html#summary",
    "title": "Multiple linear regression",
    "section": "Summary",
    "text": "Summary\n\nIn general, how do\n\nindicators for categorical predictors impact the model equation?\ninteraction terms impact the model equation?"
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#model-assessment-rmse-r2",
    "href": "slides/07-mlr-pt3-notes.html#model-assessment-rmse-r2",
    "title": "Multiple linear regression",
    "section": "Model assessment: RMSE & \\(R^2\\)",
    "text": "Model assessment: RMSE & \\(R^2\\)\n\nRoot mean square error, RMSE: A measure of the average error (average difference between observed and predicted values of the outcome)\nR-squared, \\(R^2\\) : Percentage of variability in the outcome explained by the regression model"
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#comparing-models",
    "href": "slides/07-mlr-pt3-notes.html#comparing-models",
    "title": "Multiple linear regression",
    "section": "Comparing models",
    "text": "Comparing models\n\n\nWhen comparing models, do we prefer the model with the lower or higher RMSE?\nThough we use \\(R^2\\) to assess the model fit, it is generally unreliable for comparing models with different number of predictors. Why?\n\n\\(R^2\\) will stay the same or increase as we add more variables to the model . Let’s show why this is true.\nIf we only use \\(R^2\\) to choose a best fit model, we will be prone to choose the model with the most predictor variables."
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#adjusted-r2",
    "href": "slides/07-mlr-pt3-notes.html#adjusted-r2",
    "title": "Multiple linear regression",
    "section": "Adjusted \\(R^2\\)",
    "text": "Adjusted \\(R^2\\)\n\nAdjusted \\(R^2\\): measure that includes a penalty for unnecessary predictor variables\nSimilar to \\(R^2\\), it is a measure of the amount of variation in the response that is explained by the regression model\nUse the glance() function to get \\(Adj. R^2\\) in R\n\n\nglance(int_fit)$adj.r.squared\n\n[1] 0.215841"
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#r2-and-adjusted-r2",
    "href": "slides/07-mlr-pt3-notes.html#r2-and-adjusted-r2",
    "title": "Multiple linear regression",
    "section": "\\(R^2\\) and Adjusted \\(R^2\\)",
    "text": "\\(R^2\\) and Adjusted \\(R^2\\)\n\\[R^2 = \\frac{SSM}{SST} = 1 - \\frac{SSR}{SST}\\]\n\n. . .\n\\[R^2_{adj} = 1 - \\frac{SSR/(n-p-1)}{SST/(n-1)}\\]\nwhere\n\n\\(n\\) is the number of observations used to fit the model\n\\(p\\) is the number of terms (not including the intercept) in the model"
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#using-r2-and-adjusted-r2",
    "href": "slides/07-mlr-pt3-notes.html#using-r2-and-adjusted-r2",
    "title": "Multiple linear regression",
    "section": "Using \\(R^2\\) and Adjusted \\(R^2\\)",
    "text": "Using \\(R^2\\) and Adjusted \\(R^2\\)\n\nAdjusted \\(R^2\\) can be used as a quick assessment to compare the fit of multiple models; however, it should not be the only assessment!\nUse \\(R^2\\) when describing the relationship between the response and predictor variables"
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#comparing-interest-rate-models",
    "href": "slides/07-mlr-pt3-notes.html#comparing-interest-rate-models",
    "title": "Multiple linear regression",
    "section": "Comparing interest rate models",
    "text": "Comparing interest rate models\n\n\nModel without interaction\n\n# r-squared\nglance(int_fit)$r.squared\n\n[1] 0.279854\n\n\n\n\n# adj-r-squared\nglance(int_fit)$adj.r.squared\n\n[1] 0.215841\n\n\n\nModel with interaction\n\n# r-squared\nglance(int_fit_2)$r.squared\n\n[1] 0.2963437\n\n\n\n\n# adj-r-squared\nglance(int_fit_2)$adj.r.squared\n\n[1] 0.1981591"
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#recap",
    "href": "slides/07-mlr-pt3-notes.html#recap",
    "title": "Multiple linear regression",
    "section": "Recap",
    "text": "Recap\n\nFit and interpreted models with centered and standardized variables\nInterpreted interaction terms\nUsed RMSE and \\(Adj. R^2\\) to compare models"
  },
  {
    "objectID": "slides/07-mlr-pt3-notes.html#next-class",
    "href": "slides/07-mlr-pt3-notes.html#next-class",
    "title": "Multiple linear regression",
    "section": "Next class",
    "text": "Next class\n\nInference for regression\nSee Prepare for Lecture 08"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#announcements",
    "href": "slides/07-mlr-pt3.html#announcements",
    "title": "Multiple linear regression",
    "section": "Announcements",
    "text": "Announcements\n\nHW 01 due TODAY at 11:59pm\nTeam labs start on Friday\nClick here to learn more about the Academic Resource Center\nStatistics experience due Tuesday, April 22"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#topics",
    "href": "slides/07-mlr-pt3.html#topics",
    "title": "Multiple linear regression",
    "section": "Topics",
    "text": "Topics\n\nCentering quantitative predictors\nStandardizing quantitative predictors\nInteraction terms\nModel comparison\n\nRMSE\n\\(Adj. R^2\\)"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#computing-setup",
    "href": "slides/07-mlr-pt3.html#computing-setup",
    "title": "Multiple linear regression",
    "section": "Computing setup",
    "text": "Computing setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(viridis) #adjust color palette\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#data-peer-to-peer-lender",
    "href": "slides/07-mlr-pt3.html#data-peer-to-peer-lender",
    "title": "Multiple linear regression",
    "section": "Data: Peer-to-peer lender",
    "text": "Data: Peer-to-peer lender\nToday’s data is a sample of 50 loans made through a peer-to-peer lending club. The data is in the loan50 data frame in the openintro R package.\n\n\n# A tibble: 50 × 4\n   annual_income_th debt_to_income verified_income interest_rate\n              &lt;dbl&gt;          &lt;dbl&gt; &lt;fct&gt;                   &lt;dbl&gt;\n 1             59           0.558  Not Verified            10.9 \n 2             60           1.31   Not Verified             9.92\n 3             75           1.06   Verified                26.3 \n 4             75           0.574  Not Verified             9.92\n 5            254           0.238  Not Verified             9.43\n 6             67           1.08   Source Verified          9.92\n 7             28.8         0.0997 Source Verified         17.1 \n 8             80           0.351  Not Verified             6.08\n 9             34           0.698  Not Verified             7.97\n10             80           0.167  Source Verified         12.6 \n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#variables",
    "href": "slides/07-mlr-pt3.html#variables",
    "title": "Multiple linear regression",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\n\nannual_income_th: Annual income (in $1000s)\ndebt_to_income: Debt-to-income ratio, i.e. the percentage of a borrower’s total debt divided by their total income\nverified_income: Whether borrower’s income source and amount have been verified (Not Verified, Source Verified, Verified)\n\n\nResponse: interest_rate: Interest rate for the loan"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#response-vs.-predictors",
    "href": "slides/07-mlr-pt3.html#response-vs.-predictors",
    "title": "Multiple linear regression",
    "section": "Response vs. predictors",
    "text": "Response vs. predictors\n\nGoal: Use these predictors in a single model to understand variability in interest rate."
  },
  {
    "objectID": "slides/07-mlr-pt3.html#model-fit-in-r",
    "href": "slides/07-mlr-pt3.html#model-fit-in-r",
    "title": "Multiple linear regression",
    "section": "Model fit in R",
    "text": "Model fit in R\n\nint_fit &lt;- lm(interest_rate ~ debt_to_income + verified_income  + annual_income_th,\n              data = loan50)\n\ntidy(int_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n10.726\n1.507\n7.116\n0.000\n\n\ndebt_to_income\n0.671\n0.676\n0.993\n0.326\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n\n\nannual_income_th\n-0.021\n0.011\n-1.804\n0.078"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#interpreting-verified_income",
    "href": "slides/07-mlr-pt3.html#interpreting-verified_income",
    "title": "Multiple linear regression",
    "section": "Interpreting verified_income",
    "text": "Interpreting verified_income\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n10.726\n1.507\n7.116\n0.000\n7.690\n13.762\n\n\ndebt_to_income\n0.671\n0.676\n0.993\n0.326\n-0.690\n2.033\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n-0.606\n5.028\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n3.253\n10.508\n\n\nannual_income_th\n-0.021\n0.011\n-1.804\n0.078\n-0.043\n0.002\n\n\n\n\n\n\n\n\n\nThe baseline level is Not verified.\nPeople with source verified income are expected to take a loan with an interest rate that is 2.211% higher, on average, than the rate on loans to those whose income is not verified, holding all else constant."
  },
  {
    "objectID": "slides/07-mlr-pt3.html#centering",
    "href": "slides/07-mlr-pt3.html#centering",
    "title": "Multiple linear regression",
    "section": "Centering",
    "text": "Centering\n\nCentering a quantitative predictor means shifting every value by some constant \\(C\\)\n\n\\[\nX_{cent} = X  - C\n\\]\n\nOne common type of centering is mean-centering, in which every value of a predictor is shifted by its mean\nOnly quantitative predictors are centered\nCenter all quantitative predictors in the model for ease of interpretation\n\n\nWhat is one reason one might want to center the quantitative predictors? What is are the units of centered variables?"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#centering-1",
    "href": "slides/07-mlr-pt3.html#centering-1",
    "title": "Multiple linear regression",
    "section": "Centering",
    "text": "Centering\nUse the scale() function with center = TRUE and scale = FALSE to mean-center variables\n\nloan50 &lt;- loan50 |&gt;\n  mutate(debt_to_inc_cent = scale(debt_to_income, center = TRUE, scale = FALSE), \n         annual_inc_cent = scale(annual_income_th, center = TRUE, scale = FALSE))\n\nlm(interest_rate ~ debt_to_inc_cent + verified_income + annual_inc_cent, data = loan50) |&gt; \n  tidy() |&gt; kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n9.444\n0.977\n9.663\n0.000\n\n\ndebt_to_inc_cent\n0.671\n0.676\n0.993\n0.326\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n\n\nannual_inc_cent\n-0.021\n0.011\n-1.804\n0.078"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#centering-2",
    "href": "slides/07-mlr-pt3.html#centering-2",
    "title": "Multiple linear regression",
    "section": "Centering",
    "text": "Centering\n\n\n\n\n\nTerm\nOriginal Model\nCentered Model\n\n\n\n\n(Intercept)\n10.726\n9.444\n\n\ndebt_to_income\n0.671\n0.671\n\n\nverified_incomeSource Verified\n2.211\n2.211\n\n\nverified_incomeVerified\n6.880\n6.880\n\n\nannual_income_th\n-0.021\n-0.021\n\n\n\n\n\n\nHow has the model changed? How has the model remained the same?"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#standardizing",
    "href": "slides/07-mlr-pt3.html#standardizing",
    "title": "Multiple linear regression",
    "section": "Standardizing",
    "text": "Standardizing\n\nStandardizing a quantitative predictor mean shifting every value by the mean and dividing by the standard deviation of that variable\n\n\\[\nX_{std} = \\frac{X - \\bar{X}}{S_X}\n\\]\n\nOnly quantitative predictors are standardized\nStandardize all quantitative predictors in the model for ease of interpretation\n\n\nWhat is one reason one might want to standardize the quantitative predictors? What is are the units of standardized variables?"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#standardizing-1",
    "href": "slides/07-mlr-pt3.html#standardizing-1",
    "title": "Multiple linear regression",
    "section": "Standardizing",
    "text": "Standardizing\nUse the scale() function with center = TRUE and scale = TRUE to standardized variables\n\nloan50 &lt;- loan50 |&gt;\n  mutate(debt_to_inc_std = scale(debt_to_income, center = TRUE, scale = TRUE), \n         annual_inc_std = scale(annual_income_th, center = TRUE, scale = TRUE))\n\nlm(interest_rate ~ debt_to_inc_std + verified_income + annual_inc_std, data = loan50) |&gt;\n  tidy() |&gt; kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n9.444\n0.977\n9.663\n0.000\n\n\ndebt_to_inc_std\n0.643\n0.648\n0.993\n0.326\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n\n\nannual_inc_std\n-1.180\n0.654\n-1.804\n0.078"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#standardizing-2",
    "href": "slides/07-mlr-pt3.html#standardizing-2",
    "title": "Multiple linear regression",
    "section": "Standardizing",
    "text": "Standardizing\n\n\n\n\n\nTerm\nOriginal Model\nStandardized Model\n\n\n\n\n(Intercept)\n10.726\n9.444\n\n\ndebt_to_income\n0.671\n0.643\n\n\nverified_incomeSource Verified\n2.211\n2.211\n\n\nverified_incomeVerified\n6.880\n6.880\n\n\nannual_income_th\n-0.021\n-1.180\n\n\n\n\n\n\nHow has the model changed? How has the model remained the same?"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#interaction-terms-1",
    "href": "slides/07-mlr-pt3.html#interaction-terms-1",
    "title": "Multiple linear regression",
    "section": "Interaction terms",
    "text": "Interaction terms\n\nSometimes the relationship between a predictor variable and the response depends on the value of another predictor variable.\nThis is an interaction effect.\nTo account for this, we can include interaction terms in the model."
  },
  {
    "objectID": "slides/07-mlr-pt3.html#interest-rate-vs.-annual-income",
    "href": "slides/07-mlr-pt3.html#interest-rate-vs.-annual-income",
    "title": "Multiple linear regression",
    "section": "Interest rate vs. annual income",
    "text": "Interest rate vs. annual income\nThe lines are not parallel indicating there is a potential interaction effect. The slope of annual income potentially differs based on the income verification."
  },
  {
    "objectID": "slides/07-mlr-pt3.html#interaction-term-in-model",
    "href": "slides/07-mlr-pt3.html#interaction-term-in-model",
    "title": "Multiple linear regression",
    "section": "Interaction term in model",
    "text": "Interaction term in model\n\nint_fit_2 &lt;- lm(interest_rate ~ debt_to_income + verified_income + annual_income_th + verified_income * annual_income_th,\n      data = loan50)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n9.560\n2.034\n4.700\n0.000\n\n\ndebt_to_income\n0.691\n0.685\n1.009\n0.319\n\n\nverified_incomeSource Verified\n3.577\n2.539\n1.409\n0.166\n\n\nverified_incomeVerified\n9.923\n3.654\n2.716\n0.009\n\n\nannual_income_th\n-0.007\n0.020\n-0.341\n0.735\n\n\nverified_incomeSource Verified:annual_income_th\n-0.016\n0.026\n-0.643\n0.523\n\n\nverified_incomeVerified:annual_income_th\n-0.032\n0.033\n-0.979\n0.333"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#interaction-term-in-model-1",
    "href": "slides/07-mlr-pt3.html#interaction-term-in-model-1",
    "title": "Multiple linear regression",
    "section": "Interaction term in model",
    "text": "Interaction term in model\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n9.560\n2.034\n4.700\n0.000\n\n\ndebt_to_income\n0.691\n0.685\n1.009\n0.319\n\n\nverified_incomeSource Verified\n3.577\n2.539\n1.409\n0.166\n\n\nverified_incomeVerified\n9.923\n3.654\n2.716\n0.009\n\n\nannual_income_th\n-0.007\n0.020\n-0.341\n0.735\n\n\nverified_incomeSource Verified:annual_income_th\n-0.016\n0.026\n-0.643\n0.523\n\n\nverified_incomeVerified:annual_income_th\n-0.032\n0.033\n-0.979\n0.333\n\n\n\n\n\n\n\n\n\nWrite the regression equation for the people with Not Verified income.\nWrite the regression equation for people with Verified income."
  },
  {
    "objectID": "slides/07-mlr-pt3.html#interpreting-interaction-terms",
    "href": "slides/07-mlr-pt3.html#interpreting-interaction-terms",
    "title": "Multiple linear regression",
    "section": "Interpreting interaction terms",
    "text": "Interpreting interaction terms\n\nWhat the interaction means: The effect of annual income on the interest rate differs by -0.016 when the income is source verified compared to when it is not verified, holding all else constant.\nInterpreting annual_income for source verified: If the income is source verified, we expect the interest rate to decrease by 0.023% (-0.007 + -0.016) for each additional thousand dollars in annual income, holding all else constant."
  },
  {
    "objectID": "slides/07-mlr-pt3.html#summary",
    "href": "slides/07-mlr-pt3.html#summary",
    "title": "Multiple linear regression",
    "section": "Summary",
    "text": "Summary\n\nIn general, how do\n\nindicators for categorical predictors impact the model equation?\ninteraction terms impact the model equation?"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#model-assessment-rmse-r2",
    "href": "slides/07-mlr-pt3.html#model-assessment-rmse-r2",
    "title": "Multiple linear regression",
    "section": "Model assessment: RMSE & \\(R^2\\)",
    "text": "Model assessment: RMSE & \\(R^2\\)\n\nRoot mean square error, RMSE: A measure of the average error (average difference between observed and predicted values of the outcome)\nR-squared, \\(R^2\\) : Percentage of variability in the outcome explained by the regression model"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#comparing-models",
    "href": "slides/07-mlr-pt3.html#comparing-models",
    "title": "Multiple linear regression",
    "section": "Comparing models",
    "text": "Comparing models\n\n\nWhen comparing models, do we prefer the model with the lower or higher RMSE?\nThough we use \\(R^2\\) to assess the model fit, it is generally unreliable for comparing models with different number of predictors. Why?\n\n\\(R^2\\) will stay the same or increase as we add more variables to the model . Let’s show why this is true.\nIf we only use \\(R^2\\) to choose a best fit model, we will be prone to choose the model with the most predictor variables."
  },
  {
    "objectID": "slides/07-mlr-pt3.html#adjusted-r2",
    "href": "slides/07-mlr-pt3.html#adjusted-r2",
    "title": "Multiple linear regression",
    "section": "Adjusted \\(R^2\\)",
    "text": "Adjusted \\(R^2\\)\n\nAdjusted \\(R^2\\): measure that includes a penalty for unnecessary predictor variables\nSimilar to \\(R^2\\), it is a measure of the amount of variation in the response that is explained by the regression model\nUse the glance() function to get \\(Adj. R^2\\) in R\n\n\nglance(int_fit)$adj.r.squared\n\n[1] 0.215841"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#r2-and-adjusted-r2",
    "href": "slides/07-mlr-pt3.html#r2-and-adjusted-r2",
    "title": "Multiple linear regression",
    "section": "\\(R^2\\) and Adjusted \\(R^2\\)",
    "text": "\\(R^2\\) and Adjusted \\(R^2\\)\n\\[R^2 = \\frac{SSM}{SST} = 1 - \\frac{SSR}{SST}\\]\n\n\n\\[R^2_{adj} = 1 - \\frac{SSR/(n-p-1)}{SST/(n-1)}\\]\nwhere\n\n\\(n\\) is the number of observations used to fit the model\n\\(p\\) is the number of terms (not including the intercept) in the model"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#using-r2-and-adjusted-r2",
    "href": "slides/07-mlr-pt3.html#using-r2-and-adjusted-r2",
    "title": "Multiple linear regression",
    "section": "Using \\(R^2\\) and Adjusted \\(R^2\\)",
    "text": "Using \\(R^2\\) and Adjusted \\(R^2\\)\n\nAdjusted \\(R^2\\) can be used as a quick assessment to compare the fit of multiple models; however, it should not be the only assessment!\nUse \\(R^2\\) when describing the relationship between the response and predictor variables"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#comparing-interest-rate-models",
    "href": "slides/07-mlr-pt3.html#comparing-interest-rate-models",
    "title": "Multiple linear regression",
    "section": "Comparing interest rate models",
    "text": "Comparing interest rate models\n\n\nModel without interaction\n\n# r-squared\nglance(int_fit)$r.squared\n\n[1] 0.279854\n\n\n\n\n# adj-r-squared\nglance(int_fit)$adj.r.squared\n\n[1] 0.215841\n\n\n\nModel with interaction\n\n# r-squared\nglance(int_fit_2)$r.squared\n\n[1] 0.2963437\n\n\n\n\n# adj-r-squared\nglance(int_fit_2)$adj.r.squared\n\n[1] 0.1981591"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#recap",
    "href": "slides/07-mlr-pt3.html#recap",
    "title": "Multiple linear regression",
    "section": "Recap",
    "text": "Recap\n\nFit and interpreted models with centered and standardized variables\nInterpreted interaction terms\nUsed RMSE and \\(Adj. R^2\\) to compare models"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#next-class",
    "href": "slides/07-mlr-pt3.html#next-class",
    "title": "Multiple linear regression",
    "section": "Next class",
    "text": "Next class\n\nInference for regression\nSee Prepare for Lecture 08"
  },
  {
    "objectID": "slides/05-geometry-notes.html",
    "href": "slides/05-geometry-notes.html",
    "title": "Geometric interpretation of least-squares regression",
    "section": "",
    "text": "HW 01 due Thursday, January 30 at 11:59pm\n\nReleased after class.\nMake sure you are a member of the course GitHub organization\n\nIf you can see the number of people in the org, then you are a member!"
  },
  {
    "objectID": "slides/05-geometry-notes.html#announcements",
    "href": "slides/05-geometry-notes.html#announcements",
    "title": "Geometric interpretation of least-squares regression",
    "section": "",
    "text": "HW 01 due Thursday, January 30 at 11:59pm\n\nReleased after class.\nMake sure you are a member of the course GitHub organization\n\nIf you can see the number of people in the org, then you are a member!"
  },
  {
    "objectID": "slides/05-geometry-notes.html#topics",
    "href": "slides/05-geometry-notes.html#topics",
    "title": "Geometric interpretation of least-squares regression",
    "section": "Topics",
    "text": "Topics\n\nGeometric interpretation of least-squares regression"
  },
  {
    "objectID": "slides/05-geometry-notes.html#recap-regression-in-matrix-from",
    "href": "slides/05-geometry-notes.html#recap-regression-in-matrix-from",
    "title": "Geometric interpretation of least-squares regression",
    "section": "Recap: Regression in matrix from",
    "text": "Recap: Regression in matrix from\nThe simple linear regression model can be represented using vectors and matrices as\n\n\\[\n\\large{\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}}\n\\]\n\n\n\\(\\mathbf{y}\\) : Vector of responses\n\\(\\mathbf{X}\\): Design matrix (columns for predictors + intercept)\n\\(\\boldsymbol{\\beta}\\): Vector of model coefficients\n\\(\\boldsymbol{\\epsilon}\\): Vector of error terms centered at \\(\\mathbf{0}\\) with variance \\(\\sigma^2_{\\epsilon}\\mathbf{I}\\)"
  },
  {
    "objectID": "slides/05-geometry-notes.html#recap-derive-hatboldsymbolbeta",
    "href": "slides/05-geometry-notes.html#recap-derive-hatboldsymbolbeta",
    "title": "Geometric interpretation of least-squares regression",
    "section": "Recap: Derive \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Recap: Derive \\(\\hat{\\boldsymbol{\\beta}}\\)\nWe used matrix calculus to derive the estimator \\(\\hat{\\boldsymbol{\\beta}}\\) that minimizes \\(\\boldsymbol{\\epsilon}^\\mathsf{T}\\boldsymbol{\\epsilon}\\)\n\n\\[\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}\\mathbf{y}\\]\n\n. . .\nNow let’s consider how to derive the least-squares estimator using a geometric interpretation of regression"
  },
  {
    "objectID": "slides/05-geometry-notes.html#geometry-of-least-squares-regression",
    "href": "slides/05-geometry-notes.html#geometry-of-least-squares-regression",
    "title": "Geometric interpretation of least-squares regression",
    "section": "Geometry of least-squares regression",
    "text": "Geometry of least-squares regression\n\n\nLet \\(\\text{Col}(\\mathbf{X})\\) be the column space of \\(\\mathbf{X}\\): the set all possible linear combinations (span) of the columns of \\(\\mathbf{X}\\)\nThe vector of responses \\(\\mathbf{y}\\) is not in \\(\\text{Col}(\\mathbf{X})\\).\nGoal: Find another vector \\(\\mathbf{z} = \\mathbf{Xb}\\) that is in \\(\\text{Col}(\\mathbf{X})\\) and is as close as possible to \\(\\mathbf{y}\\).\n\n\\(\\mathbf{z}\\) is a projection of \\(\\mathbf{y}\\) onto \\(\\text{Col}(\\mathbf{X})\\) ."
  },
  {
    "objectID": "slides/05-geometry-notes.html#geometry-of-least-squares-regression-1",
    "href": "slides/05-geometry-notes.html#geometry-of-least-squares-regression-1",
    "title": "Geometric interpretation of least-squares regression",
    "section": "Geometry of least-squares regression",
    "text": "Geometry of least-squares regression\n\n\nFor any \\(\\mathbf{z} = \\mathbf{Xb}\\) in \\(\\text{Col}(\\mathbf{X})\\), the vector \\(\\mathbf{e} = \\mathbf{y} - \\mathbf{Xb}\\) is the difference between \\(\\mathbf{y}\\) and \\(\\mathbf{Xb}\\).\n\nWe want to find \\(\\mathbf{b}\\) such that \\(\\mathbf{z} = \\mathbf{Xb}\\) is as close as possible to \\(\\mathbf{y}\\), i.e, we want to minimize the difference \\(\\mathbf{e} = \\mathbf{y} - \\mathbf{Xb}\\)\n\nThis distance is minimized when \\(\\mathbf{e}\\) is orthogonal to \\(\\text{Col}(\\mathbf{X})\\)"
  },
  {
    "objectID": "slides/05-geometry-notes.html#geometry-of-least-squares-regression-2",
    "href": "slides/05-geometry-notes.html#geometry-of-least-squares-regression-2",
    "title": "Geometric interpretation of least-squares regression",
    "section": "Geometry of least-squares regression",
    "text": "Geometry of least-squares regression\n\nNote: If \\(\\mathbf{A}\\), an \\(n \\times k\\) matrix, is orthogonal to an \\(n \\times 1\\) vector \\(\\mathbf{c}\\), then \\(\\mathbf{A}^\\mathsf{T}\\mathbf{c} = \\mathbf{0}\\)\nTherefore, we have \\(\\mathbf{X}^\\mathsf{T}\\mathbf{e} = \\mathbf{0}\\) , and thus\n\\[\n\\mathbf{X}^\\mathsf{T}(\\mathbf{y} - \\mathbf{Xb}) = \\mathbf{0}\n\\]\n\n\nSolve for \\(\\mathbf{b}\\) ."
  },
  {
    "objectID": "slides/05-geometry-notes.html#hat-matrix",
    "href": "slides/05-geometry-notes.html#hat-matrix",
    "title": "Geometric interpretation of least-squares regression",
    "section": "Hat matrix",
    "text": "Hat matrix\n\nRecall the hat matrix \\(\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}\\).\n\\(\\hat{\\mathbf{y}} = \\mathbf{Hy}\\), so \\(\\mathbf{H}\\) is a projection of \\(\\mathbf{y}\\) onto \\(\\mathbf{Xb}\\)\nProperties of \\(\\mathbf{H}\\), a projection matrix\n\n\\(\\mathbf{H}\\) is symmetric (\\(\\mathbf{H}^\\mathsf{T} = \\mathbf{H}\\))\n\\(\\mathbf{H}\\) is idempotent (\\(\\mathbf{H}^2 = \\mathbf{H}\\))\nIf \\(\\mathbf{v}\\) in \\(\\text{Col}(\\mathbf{X})\\), then \\(\\mathbf{Hv} = \\mathbf{v}\\)\nIf \\(\\mathbf{v}\\) is orthogonal to \\(\\text{Col}(\\mathbf{X})\\), then \\(\\mathbf{Hv} = \\mathbf{0}\\)"
  },
  {
    "objectID": "slides/05-geometry.html#announcements",
    "href": "slides/05-geometry.html#announcements",
    "title": "Geometric interpretation of least-squares regression",
    "section": "Announcements",
    "text": "Announcements\n\nHW 01 due Thursday, January 30 at 11:59pm\n\nReleased after class.\nMake sure you are a member of the course GitHub organization\n\nIf you can see the number of people in the org, then you are a member!"
  },
  {
    "objectID": "slides/05-geometry.html#topics",
    "href": "slides/05-geometry.html#topics",
    "title": "Geometric interpretation of least-squares regression",
    "section": "Topics",
    "text": "Topics\n\nGeometric interpretation of least-squares regression"
  },
  {
    "objectID": "slides/05-geometry.html#recap-regression-in-matrix-from",
    "href": "slides/05-geometry.html#recap-regression-in-matrix-from",
    "title": "Geometric interpretation of least-squares regression",
    "section": "Recap: Regression in matrix from",
    "text": "Recap: Regression in matrix from\nThe simple linear regression model can be represented using vectors and matrices as\n\n\\[\n\\large{\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}}\n\\]\n\n\n\\(\\mathbf{y}\\) : Vector of responses\n\\(\\mathbf{X}\\): Design matrix (columns for predictors + intercept)\n\\(\\boldsymbol{\\beta}\\): Vector of model coefficients\n\\(\\boldsymbol{\\epsilon}\\): Vector of error terms centered at \\(\\mathbf{0}\\) with variance \\(\\sigma^2_{\\epsilon}\\mathbf{I}\\)"
  },
  {
    "objectID": "slides/05-geometry.html#recap-derive-hatboldsymbolbeta",
    "href": "slides/05-geometry.html#recap-derive-hatboldsymbolbeta",
    "title": "Geometric interpretation of least-squares regression",
    "section": "Recap: Derive \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Recap: Derive \\(\\hat{\\boldsymbol{\\beta}}\\)\nWe used matrix calculus to derive the estimator \\(\\hat{\\boldsymbol{\\beta}}\\) that minimizes \\(\\boldsymbol{\\epsilon}^\\mathsf{T}\\boldsymbol{\\epsilon}\\)\n\n\\[\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}\\mathbf{y}\\]\n\n\nNow let’s consider how to derive the least-squares estimator using a geometric interpretation of regression"
  },
  {
    "objectID": "slides/05-geometry.html#geometry-of-least-squares-regression",
    "href": "slides/05-geometry.html#geometry-of-least-squares-regression",
    "title": "Geometric interpretation of least-squares regression",
    "section": "Geometry of least-squares regression",
    "text": "Geometry of least-squares regression\n\n\nLet \\(\\text{Col}(\\mathbf{X})\\) be the column space of \\(\\mathbf{X}\\): the set all possible linear combinations (span) of the columns of \\(\\mathbf{X}\\)\nThe vector of responses \\(\\mathbf{y}\\) is not in \\(\\text{Col}(\\mathbf{X})\\).\nGoal: Find another vector \\(\\mathbf{z} = \\mathbf{Xb}\\) that is in \\(\\text{Col}(\\mathbf{X})\\) and is as close as possible to \\(\\mathbf{y}\\).\n\n\\(\\mathbf{z}\\) is a projection of \\(\\mathbf{y}\\) onto \\(\\text{Col}(\\mathbf{X})\\) ."
  },
  {
    "objectID": "slides/05-geometry.html#geometry-of-least-squares-regression-1",
    "href": "slides/05-geometry.html#geometry-of-least-squares-regression-1",
    "title": "Geometric interpretation of least-squares regression",
    "section": "Geometry of least-squares regression",
    "text": "Geometry of least-squares regression\n\n\nFor any \\(\\mathbf{z} = \\mathbf{Xb}\\) in \\(\\text{Col}(\\mathbf{X})\\), the vector \\(\\mathbf{e} = \\mathbf{y} - \\mathbf{Xb}\\) is the difference between \\(\\mathbf{y}\\) and \\(\\mathbf{Xb}\\).\n\nWe want to find \\(\\mathbf{b}\\) such that \\(\\mathbf{z} = \\mathbf{Xb}\\) is as close as possible to \\(\\mathbf{y}\\), i.e, we want to minimize the difference \\(\\mathbf{e} = \\mathbf{y} - \\mathbf{Xb}\\)\n\nThis distance is minimized when \\(\\mathbf{e}\\) is orthogonal to \\(\\text{Col}(\\mathbf{X})\\)"
  },
  {
    "objectID": "slides/05-geometry.html#geometry-of-least-squares-regression-2",
    "href": "slides/05-geometry.html#geometry-of-least-squares-regression-2",
    "title": "Geometric interpretation of least-squares regression",
    "section": "Geometry of least-squares regression",
    "text": "Geometry of least-squares regression\n\nNote: If \\(\\mathbf{A}\\), an \\(n \\times k\\) matrix, is orthogonal to an \\(n \\times 1\\) vector \\(\\mathbf{c}\\), then \\(\\mathbf{A}^\\mathsf{T}\\mathbf{c} = \\mathbf{0}\\)\nTherefore, we have \\(\\mathbf{X}^\\mathsf{T}\\mathbf{e} = \\mathbf{0}\\) , and thus\n\\[\n\\mathbf{X}^\\mathsf{T}(\\mathbf{y} - \\mathbf{Xb}) = \\mathbf{0}\n\\]\n\n\nSolve for \\(\\mathbf{b}\\) ."
  },
  {
    "objectID": "slides/05-geometry.html#hat-matrix",
    "href": "slides/05-geometry.html#hat-matrix",
    "title": "Geometric interpretation of least-squares regression",
    "section": "Hat matrix",
    "text": "Hat matrix\n\nRecall the hat matrix \\(\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}\\).\n\\(\\hat{\\mathbf{y}} = \\mathbf{Hy}\\), so \\(\\mathbf{H}\\) is a projection of \\(\\mathbf{y}\\) onto \\(\\mathbf{Xb}\\)\nProperties of \\(\\mathbf{H}\\), a projection matrix\n\n\\(\\mathbf{H}\\) is symmetric (\\(\\mathbf{H}^\\mathsf{T} = \\mathbf{H}\\))\n\\(\\mathbf{H}\\) is idempotent (\\(\\mathbf{H}^2 = \\mathbf{H}\\))\nIf \\(\\mathbf{v}\\) in \\(\\text{Col}(\\mathbf{X})\\), then \\(\\mathbf{Hv} = \\mathbf{v}\\)\nIf \\(\\mathbf{v}\\) is orthogonal to \\(\\text{Col}(\\mathbf{X})\\), then \\(\\mathbf{Hv} = \\mathbf{0}\\)"
  },
  {
    "objectID": "slides/04-slr-matrix-notes.html",
    "href": "slides/04-slr-matrix-notes.html",
    "title": "SLR: Matrix representation",
    "section": "",
    "text": "Lab 01 due on TODAY at 11:59pm\n\nPush work to GitHub repo\nSubmit final PDF on Gradescope + mark pages for each question\n\nHW 01 will be assigned on Thursday"
  },
  {
    "objectID": "slides/04-slr-matrix-notes.html#announcements",
    "href": "slides/04-slr-matrix-notes.html#announcements",
    "title": "SLR: Matrix representation",
    "section": "",
    "text": "Lab 01 due on TODAY at 11:59pm\n\nPush work to GitHub repo\nSubmit final PDF on Gradescope + mark pages for each question\n\nHW 01 will be assigned on Thursday"
  },
  {
    "objectID": "slides/04-slr-matrix-notes.html#topics",
    "href": "slides/04-slr-matrix-notes.html#topics",
    "title": "SLR: Matrix representation",
    "section": "Topics",
    "text": "Topics\n\nApplication exercise on model assessment\nMatrix representation of simple linear regression\n\nModel form\nLeast square estimate\nPredicted (fitted) values\nResiduals"
  },
  {
    "objectID": "slides/04-slr-matrix-notes.html#two-statistics",
    "href": "slides/04-slr-matrix-notes.html#two-statistics",
    "title": "SLR: Matrix representation",
    "section": "Two statistics",
    "text": "Two statistics\n\nRoot mean square error, RMSE: A measure of the average error (average difference between observed and predicted values of the outcome)\n\\[\nRMSE = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n}} = \\sqrt{\\frac{\\sum_{i=1}^ne_i^2}{n}}\n\\]\nR-squared, \\(R^2\\) : Percentage of variability in the outcome explained by the regression model (in the context of SLR, the predictor)\n\n\\[R^2 = \\frac{SSM}{SST} = 1 - \\frac{SSR}{SST}\\]"
  },
  {
    "objectID": "slides/04-slr-matrix-notes.html#slr-statistical-model-population",
    "href": "slides/04-slr-matrix-notes.html#slr-statistical-model-population",
    "title": "SLR: Matrix representation",
    "section": "SLR: Statistical model (population)",
    "text": "SLR: Statistical model (population)\nWhen we have a quantitative response, \\(Y\\), and a single quantitative predictor, \\(X\\), we can use a simple linear regression model to describe the relationship between \\(Y\\) and \\(X\\).\n\\[Y = \\beta_0 + \\beta_1 X + \\epsilon\\]\n\n\n\\(\\beta_1\\): Population (true) slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\beta_0\\): Population (true) intercept of the relationship between \\(X\\) and \\(Y\\)\n\\(\\epsilon\\): Error terms centered at 0 with variance \\(\\sigma^2_{\\epsilon}\\)"
  },
  {
    "objectID": "slides/04-slr-matrix-notes.html#slr-in-matrix-form",
    "href": "slides/04-slr-matrix-notes.html#slr-in-matrix-form",
    "title": "SLR: Matrix representation",
    "section": "SLR in matrix form",
    "text": "SLR in matrix form\nThe simple linear regression model can be represented using vectors and matrices as\n\n\\[\n\\large{\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}}\n\\]\n\n\n\\(\\mathbf{y}\\) : Vector of responses\n\\(\\mathbf{X}\\): Design matrix (columns for predictors + intercept)\n\\(\\boldsymbol{\\beta}\\): Vector of model coefficients\n\\(\\boldsymbol{\\epsilon}\\): Vector of error terms centered at \\(\\mathbf{0}\\) with variance \\(\\sigma^2_{\\epsilon}\\mathbf{I}\\)"
  },
  {
    "objectID": "slides/04-slr-matrix-notes.html#slr-in-matrix-form-1",
    "href": "slides/04-slr-matrix-notes.html#slr-in-matrix-form-1",
    "title": "SLR: Matrix representation",
    "section": "SLR in matrix form",
    "text": "SLR in matrix form\n\\[\n\\underbrace{\n\\begin{bmatrix}\ny_1 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix} }_\n{\\mathbf{y}} \\hspace{3mm}\n=\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n1 &x_1 \\\\\n\\vdots &  \\vdots \\\\\n1 &  x_n\n\\end{bmatrix}\n}_{\\mathbf{X}}\n\\hspace{2mm}\n\\underbrace{\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1\n\\end{bmatrix}\n}_{\\boldsymbol{\\beta}}\n\\hspace{3mm}\n+\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n\\epsilon_1 \\\\\n\\vdots\\\\\n\\epsilon_n\n\\end{bmatrix}\n}_\\boldsymbol{\\epsilon}\n\\]\n\n\nWhat are the dimensions of \\(\\mathbf{y}\\), \\(\\mathbf{X}\\), \\(\\boldsymbol{\\beta}\\), and \\(\\boldsymbol{\\epsilon}\\)?"
  },
  {
    "objectID": "slides/04-slr-matrix-notes.html#derive-least-squares-estimator-for-boldsymbolbeta",
    "href": "slides/04-slr-matrix-notes.html#derive-least-squares-estimator-for-boldsymbolbeta",
    "title": "SLR: Matrix representation",
    "section": "Derive least squares estimator for \\(\\boldsymbol{\\beta}\\)",
    "text": "Derive least squares estimator for \\(\\boldsymbol{\\beta}\\)\nGoal: Find estimator \\(\\hat{\\boldsymbol{\\beta}}= \\begin{bmatrix}\\hat{\\beta}_0 \\\\ \\hat{\\beta}_1 \\end{bmatrix}\\) that minimizes the sum of squared errors \\[\n\\sum_{i=1}^n \\epsilon_i^2 = \\mathbf{\\epsilon}^\\mathsf{T}\\mathbf{\\epsilon} = (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^\\mathsf{T}(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix-notes.html#gradient",
    "href": "slides/04-slr-matrix-notes.html#gradient",
    "title": "SLR: Matrix representation",
    "section": "Gradient",
    "text": "Gradient\nLet \\(\\mathbf{x} = \\begin{bmatrix}x_1 \\\\ x_2 \\\\ \\vdots \\\\x_k\\end{bmatrix}\\)be a \\(k \\times 1\\) vector and \\(f(\\mathbf{x})\\) be a function of \\(\\mathbf{x}\\).\n. . .\nThen \\(\\nabla_\\mathbf{x}f\\), the gradient of \\(f\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x}f = \\begin{bmatrix}\\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial x_k}\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix-notes.html#property-1",
    "href": "slides/04-slr-matrix-notes.html#property-1",
    "title": "SLR: Matrix representation",
    "section": "Property 1",
    "text": "Property 1\nLet \\(\\mathbf{x}\\) be a \\(k \\times 1\\) vector and \\(\\mathbf{z}\\) be a \\(k \\times 1\\) vector, such that \\(\\mathbf{z}\\) is not a function of \\(\\mathbf{x}\\) .\n\n\nThe gradient of \\(\\mathbf{x}^\\mathsf{T}\\mathbf{z}\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x} \\hspace{1mm} \\mathbf{x}^\\mathsf{T}\\mathbf{z} = \\mathbf{z}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix-notes.html#side-note-property-1",
    "href": "slides/04-slr-matrix-notes.html#side-note-property-1",
    "title": "SLR: Matrix representation",
    "section": "Side note: Property 1",
    "text": "Side note: Property 1\n\\[\n\\begin{aligned}\n\\mathbf{x}^\\mathsf{T}\\mathbf{z} &= \\class{fragment}{\\begin{bmatrix}x_1 & x_2 & \\dots &x_k\\end{bmatrix}\n\\begin{bmatrix}z_1 \\\\ z_2 \\\\ \\vdots \\\\z_k\\end{bmatrix}} \\\\[10pt]\n&\\class{fragment}{= x_1z_1 + x_2z_2 + \\dots + x_kz_k} \\\\\n&\\class{fragment}{= \\sum_{i=1}^k x_iz_i}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix-notes.html#side-note-property-1-1",
    "href": "slides/04-slr-matrix-notes.html#side-note-property-1-1",
    "title": "SLR: Matrix representation",
    "section": "Side note: Property 1",
    "text": "Side note: Property 1\n\\[\n\\nabla_\\mathbf{x}\\hspace{1mm}\\mathbf{x}^\\mathsf{T}\\mathbf{z} = \\class{fragment}{\\begin{bmatrix}\\frac{\\partial \\mathbf{x}^\\mathsf{T}\\mathbf{z}}{\\partial x_1} \\\\ \\frac{\\partial \\mathbf{x}^\\mathsf{T}\\mathbf{z}}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial \\mathbf{x}^\\mathsf{T}\\mathbf{z}}{\\partial x_k}\\end{bmatrix}}  \n= \\class{fragment}{\\begin{bmatrix}\\frac{\\partial}{\\partial x_1} (x_1z_1 + x_2z_2 + \\dots + x_kz_k) \\\\ \\frac{\\partial}{\\partial x_2} (x_1z_1 + x_2z_2 + \\dots + x_kz_k)\\\\ \\vdots \\\\ \\frac{\\partial}{\\partial x_k} (x_1z_1 + x_2z_2 + \\dots + x_kz_k)\\end{bmatrix}}\n= \\class{fragment}{\\begin{bmatrix} z_1 \\\\ z_2 \\\\ \\vdots \\\\ z_k\\end{bmatrix} = \\mathbf{z}}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix-notes.html#property-2",
    "href": "slides/04-slr-matrix-notes.html#property-2",
    "title": "SLR: Matrix representation",
    "section": "Property 2",
    "text": "Property 2\nLet \\(\\mathbf{x}\\) be a \\(k \\times 1\\) vector and \\(\\mathbf{A}\\) be a \\(k \\times k\\) matrix, such that \\(\\mathbf{A}\\) is not a function of \\(\\mathbf{x}\\) .\n\n\nThen the gradient of \\(\\mathbf{x}^\\mathsf{T}\\mathbf{A}\\mathbf{x}\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x} \\hspace{1mm} \\mathbf{x}^\\mathsf{T}\\mathbf{A}\\mathbf{x} = (\\mathbf{A}\\mathbf{x} + \\mathbf{A}^\\mathsf{T} \\mathbf{x}) = (\\mathbf{A} + \\mathbf{A}^\\mathsf{T})\\mathbf{x}\n\\]\n\n\nIf \\(\\mathbf{A}\\) is symmetric, then\n\\[\n(\\mathbf{A} + \\mathbf{A}^\\mathsf{T})\\mathbf{x} = 2\\mathbf{A}\\mathbf{x}\n\\]\n\nProof in HW 01."
  },
  {
    "objectID": "slides/04-slr-matrix-notes.html#derive-least-squares-estimator",
    "href": "slides/04-slr-matrix-notes.html#derive-least-squares-estimator",
    "title": "SLR: Matrix representation",
    "section": "Derive least squares estimator",
    "text": "Derive least squares estimator\nFind \\(\\hat{\\boldsymbol{\\beta}}\\) that minimizes\n\\[\n\\begin{aligned}\n\\boldsymbol{\\epsilon}^\\mathsf{T}\\boldsymbol{\\epsilon} &= (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^\\mathsf{T}(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) \\\\[10pt]\n&= (\\mathbf{y}^\\mathsf{T} - \\boldsymbol{\\beta}^\\mathsf{T}\\mathbf{X}^\\mathsf{T})(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\\\[10pt]\n&=\\mathbf{y}^\\mathsf{T}\\mathbf{y} - \\mathbf{y}^\\mathsf{T}\\mathbf{X}\\boldsymbol{\\beta} - \\boldsymbol{\\beta}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{y} + \\boldsymbol{\\beta}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{X}\\boldsymbol{\\beta}\\\\[10pt]\n&=\\mathbf{y}^\\mathsf{T}\\mathbf{y} - 2\\boldsymbol{\\beta}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{y} + \\boldsymbol{\\beta}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{X}\\boldsymbol{\\beta}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix-notes.html#derive-least-squares-estimator-1",
    "href": "slides/04-slr-matrix-notes.html#derive-least-squares-estimator-1",
    "title": "SLR: Matrix representation",
    "section": "Derive least squares estimator",
    "text": "Derive least squares estimator\n\\[\\begin{aligned}\n\\nabla_{\\beta}\\boldsymbol{\\epsilon}^\\mathsf{T}\\boldsymbol{\\epsilon} &= \\nabla_{\\boldsymbol{\\beta}}( \\mathbf{y}^\\mathsf{T}\\mathbf{y} - 2\\boldsymbol{\\beta}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{y} + \\boldsymbol{\\beta}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{X}\\boldsymbol{\\beta}) \\\\[10pt]\n& = -2\\mathbf{X}^\\mathsf{T}\\mathbf{y} + 2\\mathbf{X}^\\mathsf{T}\\mathbf{X}\\boldsymbol{\\beta}\n\\end{aligned}\n\\]\nFind \\(\\hat{\\boldsymbol{\\beta}}\\) that satisfies\n\\[\n-2\\mathbf{X}^\\mathsf{T}\\mathbf{y} + 2\\mathbf{X}^\\mathsf{T}\\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\mathbf{0}\n\\]\n\n\\[\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}\\mathbf{y}\\]"
  },
  {
    "objectID": "slides/04-slr-matrix-notes.html#hessian-matrix",
    "href": "slides/04-slr-matrix-notes.html#hessian-matrix",
    "title": "SLR: Matrix representation",
    "section": "Hessian matrix",
    "text": "Hessian matrix\nThe Hessian matrix, \\(\\nabla_\\mathbf{x}^2f\\) is a \\(k \\times k\\) matrix of partial second derivatives\n\\[\n\\nabla_{\\mathbf{x}}^2f = \\begin{bmatrix} \\frac{\\partial^2f}{\\partial x_1^2} & \\frac{\\partial^2f}{\\partial x_1 \\partial x_2} & \\dots & \\frac{\\partial^2f}{\\partial x_1\\partial x_k} \\\\\n\\frac{\\partial^2f}{\\partial\\ x_2 \\partial x_1} & \\frac{\\partial^2f}{\\partial x_2^2} & \\dots & \\frac{\\partial^2f}{\\partial x_2 \\partial x_k} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial^2f}{\\partial x_k\\partial x_1} & \\frac{\\partial^2f}{\\partial x_k\\partial x_2} & \\dots & \\frac{\\partial^2f}{\\partial x_k^2} \\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix-notes.html#using-the-hessian-matrix",
    "href": "slides/04-slr-matrix-notes.html#using-the-hessian-matrix",
    "title": "SLR: Matrix representation",
    "section": "Using the Hessian matrix",
    "text": "Using the Hessian matrix\nIf the Hessian matrix is…\n\npositive-definite, then we have found a minimum.\nnegative-definite, then we have found a maximum.\nneither positive or negative-definite, then we have found a saddle point"
  },
  {
    "objectID": "slides/04-slr-matrix-notes.html#did-we-find-a-minimum-1",
    "href": "slides/04-slr-matrix-notes.html#did-we-find-a-minimum-1",
    "title": "SLR: Matrix representation",
    "section": "Did we find a minimum?",
    "text": "Did we find a minimum?\n\\[\n\\begin{aligned}\n\\nabla^2_{\\boldsymbol{\\beta}} \\boldsymbol{\\epsilon}^\\mathsf{T}\\boldsymbol{\\epsilon} &= \\nabla_{\\boldsymbol{\\beta}} (-2\\mathbf{X}^\\mathsf{T}\\mathbf{y} + 2\\mathbf{X}^\\mathsf{T}\\mathbf{X}\\boldsymbol{\\beta}) \\\\[10pt]\n&{=-2\\nabla_{\\boldsymbol{\\beta}}(\\mathbf{X}^\\mathsf{T}\\mathbf{y}) + 2\\nabla_{\\boldsymbol{\\beta}}(\\mathbf{X}^\\mathsf{T}\\mathbf{X}\\mathbf{\\beta})} \\\\[10pt]\n&{\\propto \\mathbf{X}^\\mathsf{T}\\mathbf{X}}\n\\end{aligned}\n\\]\n\nShow that \\(\\mathbf{X}^\\mathsf{T}\\mathbf{X}\\) is positive definite in HW 01."
  },
  {
    "objectID": "slides/04-slr-matrix-notes.html#predicted-fitted-values",
    "href": "slides/04-slr-matrix-notes.html#predicted-fitted-values",
    "title": "SLR: Matrix representation",
    "section": "Predicted (fitted) values",
    "text": "Predicted (fitted) values\nNow that we have \\(\\hat{\\boldsymbol{\\beta}}\\), let’s predict values of \\(\\mathbf{y}\\) using the model\n\\[\n\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\underbrace{\\mathbf{X}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}}_{\\mathbf{H}}\\mathbf{y} = \\mathbf{H}\\mathbf{y}\n\\]\n. . .\n\nHat matrix: \\(\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}\\)\n\n. . .\n\n\\(\\mathbf{H}\\) is an \\(n\\times n\\) matrix\nMaps vector of observed values \\(\\mathbf{y}\\) to a vector of fitted values \\(\\hat{\\mathbf{y}}\\)\nIt is only a function of \\(\\mathbf{X}\\) not \\(\\mathbf{y}\\)"
  },
  {
    "objectID": "slides/04-slr-matrix-notes.html#residuals",
    "href": "slides/04-slr-matrix-notes.html#residuals",
    "title": "SLR: Matrix representation",
    "section": "Residuals",
    "text": "Residuals\nRecall that the residuals are the difference between the observed and predicted values\n\\[\n\\begin{aligned}\n\\mathbf{e} &= \\mathbf{y} - \\hat{\\mathbf{y}}\\\\[10pt]\n&\\class{fragment}{ = \\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}} \\\\[10pt]\n&\\class{fragment}{ = \\mathbf{y} - \\mathbf{H}\\mathbf{y}} \\\\[20pt]\n\\class{fragment}{\\color{#993399}{\\mathbf{e}}} &\\class{fragment}{\\color{#993399}{=(\\mathbf{I} - \\mathbf{H})\\mathbf{y}}} \\\\[10pt]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix-notes.html#recap",
    "href": "slides/04-slr-matrix-notes.html#recap",
    "title": "SLR: Matrix representation",
    "section": "Recap",
    "text": "Recap\n\nIntroduced matrix representation for simple linear regression\n\nModel form\nLeast square estimate\nPredicted (fitted) values\nResiduals"
  },
  {
    "objectID": "slides/04-slr-matrix-notes.html#for-next-class",
    "href": "slides/04-slr-matrix-notes.html#for-next-class",
    "title": "SLR: Matrix representation",
    "section": "For next class",
    "text": "For next class\n\nComplete Prepare for Lecture 05 - SLR: matrix representation cont’d"
  },
  {
    "objectID": "slides/04-slr-matrix.html#announcements",
    "href": "slides/04-slr-matrix.html#announcements",
    "title": "SLR: Matrix representation",
    "section": "Announcements",
    "text": "Announcements\n\nLab 01 due on TODAY at 11:59pm\n\nPush work to GitHub repo\nSubmit final PDF on Gradescope + mark pages for each question\n\nHW 01 will be assigned on Thursday"
  },
  {
    "objectID": "slides/04-slr-matrix.html#topics",
    "href": "slides/04-slr-matrix.html#topics",
    "title": "SLR: Matrix representation",
    "section": "Topics",
    "text": "Topics\n\nApplication exercise on model assessment\nMatrix representation of simple linear regression\n\nModel form\nLeast square estimate\nPredicted (fitted) values\nResiduals"
  },
  {
    "objectID": "slides/04-slr-matrix.html#two-statistics",
    "href": "slides/04-slr-matrix.html#two-statistics",
    "title": "SLR: Matrix representation",
    "section": "Two statistics",
    "text": "Two statistics\n\nRoot mean square error, RMSE: A measure of the average error (average difference between observed and predicted values of the outcome)\n\\[\nRMSE = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n}} = \\sqrt{\\frac{\\sum_{i=1}^ne_i^2}{n}}\n\\]\nR-squared, \\(R^2\\) : Percentage of variability in the outcome explained by the regression model (in the context of SLR, the predictor)\n\n\\[R^2 = \\frac{SSM}{SST} = 1 - \\frac{SSR}{SST}\\]"
  },
  {
    "objectID": "slides/04-slr-matrix.html#slr-statistical-model-population",
    "href": "slides/04-slr-matrix.html#slr-statistical-model-population",
    "title": "SLR: Matrix representation",
    "section": "SLR: Statistical model (population)",
    "text": "SLR: Statistical model (population)\nWhen we have a quantitative response, \\(Y\\), and a single quantitative predictor, \\(X\\), we can use a simple linear regression model to describe the relationship between \\(Y\\) and \\(X\\).\n\\[Y = \\beta_0 + \\beta_1 X + \\epsilon\\]\n\n\n\\(\\beta_1\\): Population (true) slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\beta_0\\): Population (true) intercept of the relationship between \\(X\\) and \\(Y\\)\n\\(\\epsilon\\): Error terms centered at 0 with variance \\(\\sigma^2_{\\epsilon}\\)"
  },
  {
    "objectID": "slides/04-slr-matrix.html#slr-in-matrix-form",
    "href": "slides/04-slr-matrix.html#slr-in-matrix-form",
    "title": "SLR: Matrix representation",
    "section": "SLR in matrix form",
    "text": "SLR in matrix form\nThe simple linear regression model can be represented using vectors and matrices as\n\n\\[\n\\large{\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}}\n\\]\n\n\n\\(\\mathbf{y}\\) : Vector of responses\n\\(\\mathbf{X}\\): Design matrix (columns for predictors + intercept)\n\\(\\boldsymbol{\\beta}\\): Vector of model coefficients\n\\(\\boldsymbol{\\epsilon}\\): Vector of error terms centered at \\(\\mathbf{0}\\) with variance \\(\\sigma^2_{\\epsilon}\\mathbf{I}\\)"
  },
  {
    "objectID": "slides/04-slr-matrix.html#slr-in-matrix-form-1",
    "href": "slides/04-slr-matrix.html#slr-in-matrix-form-1",
    "title": "SLR: Matrix representation",
    "section": "SLR in matrix form",
    "text": "SLR in matrix form\n\\[\n\\underbrace{\n\\begin{bmatrix}\ny_1 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix} }_\n{\\mathbf{y}} \\hspace{3mm}\n=\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n1 &x_1 \\\\\n\\vdots &  \\vdots \\\\\n1 &  x_n\n\\end{bmatrix}\n}_{\\mathbf{X}}\n\\hspace{2mm}\n\\underbrace{\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1\n\\end{bmatrix}\n}_{\\boldsymbol{\\beta}}\n\\hspace{3mm}\n+\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n\\epsilon_1 \\\\\n\\vdots\\\\\n\\epsilon_n\n\\end{bmatrix}\n}_\\boldsymbol{\\epsilon}\n\\]\n\n\nWhat are the dimensions of \\(\\mathbf{y}\\), \\(\\mathbf{X}\\), \\(\\boldsymbol{\\beta}\\), and \\(\\boldsymbol{\\epsilon}\\)?"
  },
  {
    "objectID": "slides/04-slr-matrix.html#derive-least-squares-estimator-for-boldsymbolbeta",
    "href": "slides/04-slr-matrix.html#derive-least-squares-estimator-for-boldsymbolbeta",
    "title": "SLR: Matrix representation",
    "section": "Derive least squares estimator for \\(\\boldsymbol{\\beta}\\)",
    "text": "Derive least squares estimator for \\(\\boldsymbol{\\beta}\\)\nGoal: Find estimator \\(\\hat{\\boldsymbol{\\beta}}= \\begin{bmatrix}\\hat{\\beta}_0 \\\\ \\hat{\\beta}_1 \\end{bmatrix}\\) that minimizes the sum of squared errors \\[\n\\sum_{i=1}^n \\epsilon_i^2 = \\mathbf{\\epsilon}^\\mathsf{T}\\mathbf{\\epsilon} = (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^\\mathsf{T}(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix.html#gradient",
    "href": "slides/04-slr-matrix.html#gradient",
    "title": "SLR: Matrix representation",
    "section": "Gradient",
    "text": "Gradient\nLet \\(\\mathbf{x} = \\begin{bmatrix}x_1 \\\\ x_2 \\\\ \\vdots \\\\x_k\\end{bmatrix}\\)be a \\(k \\times 1\\) vector and \\(f(\\mathbf{x})\\) be a function of \\(\\mathbf{x}\\).\n\nThen \\(\\nabla_\\mathbf{x}f\\), the gradient of \\(f\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x}f = \\begin{bmatrix}\\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial x_k}\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix.html#property-1",
    "href": "slides/04-slr-matrix.html#property-1",
    "title": "SLR: Matrix representation",
    "section": "Property 1",
    "text": "Property 1\nLet \\(\\mathbf{x}\\) be a \\(k \\times 1\\) vector and \\(\\mathbf{z}\\) be a \\(k \\times 1\\) vector, such that \\(\\mathbf{z}\\) is not a function of \\(\\mathbf{x}\\) .\n\n\nThe gradient of \\(\\mathbf{x}^\\mathsf{T}\\mathbf{z}\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x} \\hspace{1mm} \\mathbf{x}^\\mathsf{T}\\mathbf{z} = \\mathbf{z}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix.html#side-note-property-1",
    "href": "slides/04-slr-matrix.html#side-note-property-1",
    "title": "SLR: Matrix representation",
    "section": "Side note: Property 1",
    "text": "Side note: Property 1\n\\[\n\\begin{aligned}\n\\mathbf{x}^\\mathsf{T}\\mathbf{z} &= \\class{fragment}{\\begin{bmatrix}x_1 & x_2 & \\dots &x_k\\end{bmatrix}\n\\begin{bmatrix}z_1 \\\\ z_2 \\\\ \\vdots \\\\z_k\\end{bmatrix}} \\\\[10pt]\n&\\class{fragment}{= x_1z_1 + x_2z_2 + \\dots + x_kz_k} \\\\\n&\\class{fragment}{= \\sum_{i=1}^k x_iz_i}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix.html#side-note-property-1-1",
    "href": "slides/04-slr-matrix.html#side-note-property-1-1",
    "title": "SLR: Matrix representation",
    "section": "Side note: Property 1",
    "text": "Side note: Property 1\n\\[\n\\nabla_\\mathbf{x}\\hspace{1mm}\\mathbf{x}^\\mathsf{T}\\mathbf{z} = \\class{fragment}{\\begin{bmatrix}\\frac{\\partial \\mathbf{x}^\\mathsf{T}\\mathbf{z}}{\\partial x_1} \\\\ \\frac{\\partial \\mathbf{x}^\\mathsf{T}\\mathbf{z}}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial \\mathbf{x}^\\mathsf{T}\\mathbf{z}}{\\partial x_k}\\end{bmatrix}}  \n= \\class{fragment}{\\begin{bmatrix}\\frac{\\partial}{\\partial x_1} (x_1z_1 + x_2z_2 + \\dots + x_kz_k) \\\\ \\frac{\\partial}{\\partial x_2} (x_1z_1 + x_2z_2 + \\dots + x_kz_k)\\\\ \\vdots \\\\ \\frac{\\partial}{\\partial x_k} (x_1z_1 + x_2z_2 + \\dots + x_kz_k)\\end{bmatrix}}\n= \\class{fragment}{\\begin{bmatrix} z_1 \\\\ z_2 \\\\ \\vdots \\\\ z_k\\end{bmatrix} = \\mathbf{z}}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix.html#property-2",
    "href": "slides/04-slr-matrix.html#property-2",
    "title": "SLR: Matrix representation",
    "section": "Property 2",
    "text": "Property 2\nLet \\(\\mathbf{x}\\) be a \\(k \\times 1\\) vector and \\(\\mathbf{A}\\) be a \\(k \\times k\\) matrix, such that \\(\\mathbf{A}\\) is not a function of \\(\\mathbf{x}\\) .\n\n\nThen the gradient of \\(\\mathbf{x}^\\mathsf{T}\\mathbf{A}\\mathbf{x}\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x} \\hspace{1mm} \\mathbf{x}^\\mathsf{T}\\mathbf{A}\\mathbf{x} = (\\mathbf{A}\\mathbf{x} + \\mathbf{A}^\\mathsf{T} \\mathbf{x}) = (\\mathbf{A} + \\mathbf{A}^\\mathsf{T})\\mathbf{x}\n\\]\n\n\nIf \\(\\mathbf{A}\\) is symmetric, then\n\\[\n(\\mathbf{A} + \\mathbf{A}^\\mathsf{T})\\mathbf{x} = 2\\mathbf{A}\\mathbf{x}\n\\]\n\nProof in HW 01."
  },
  {
    "objectID": "slides/04-slr-matrix.html#derive-least-squares-estimator",
    "href": "slides/04-slr-matrix.html#derive-least-squares-estimator",
    "title": "SLR: Matrix representation",
    "section": "Derive least squares estimator",
    "text": "Derive least squares estimator\nFind \\(\\hat{\\boldsymbol{\\beta}}\\) that minimizes\n\\[\n\\begin{aligned}\n\\boldsymbol{\\epsilon}^\\mathsf{T}\\boldsymbol{\\epsilon} &= (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^\\mathsf{T}(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) \\\\[10pt]\n&= (\\mathbf{y}^\\mathsf{T} - \\boldsymbol{\\beta}^\\mathsf{T}\\mathbf{X}^\\mathsf{T})(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\\\[10pt]\n&=\\mathbf{y}^\\mathsf{T}\\mathbf{y} - \\mathbf{y}^\\mathsf{T}\\mathbf{X}\\boldsymbol{\\beta} - \\boldsymbol{\\beta}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{y} + \\boldsymbol{\\beta}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{X}\\boldsymbol{\\beta}\\\\[10pt]\n&=\\mathbf{y}^\\mathsf{T}\\mathbf{y} - 2\\boldsymbol{\\beta}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{y} + \\boldsymbol{\\beta}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{X}\\boldsymbol{\\beta}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix.html#derive-least-squares-estimator-1",
    "href": "slides/04-slr-matrix.html#derive-least-squares-estimator-1",
    "title": "SLR: Matrix representation",
    "section": "Derive least squares estimator",
    "text": "Derive least squares estimator\n\\[\\begin{aligned}\n\\nabla_{\\beta}\\boldsymbol{\\epsilon}^\\mathsf{T}\\boldsymbol{\\epsilon} &= \\nabla_{\\boldsymbol{\\beta}}( \\mathbf{y}^\\mathsf{T}\\mathbf{y} - 2\\boldsymbol{\\beta}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{y} + \\boldsymbol{\\beta}^\\mathsf{T}\\mathbf{X}^\\mathsf{T}\\mathbf{X}\\boldsymbol{\\beta}) \\\\[10pt]\n& = -2\\mathbf{X}^\\mathsf{T}\\mathbf{y} + 2\\mathbf{X}^\\mathsf{T}\\mathbf{X}\\boldsymbol{\\beta}\n\\end{aligned}\n\\]\nFind \\(\\hat{\\boldsymbol{\\beta}}\\) that satisfies\n\\[\n-2\\mathbf{X}^\\mathsf{T}\\mathbf{y} + 2\\mathbf{X}^\\mathsf{T}\\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\mathbf{0}\n\\]\n\n\\[\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}\\mathbf{y}\\]"
  },
  {
    "objectID": "slides/04-slr-matrix.html#hessian-matrix",
    "href": "slides/04-slr-matrix.html#hessian-matrix",
    "title": "SLR: Matrix representation",
    "section": "Hessian matrix",
    "text": "Hessian matrix\nThe Hessian matrix, \\(\\nabla_\\mathbf{x}^2f\\) is a \\(k \\times k\\) matrix of partial second derivatives\n\\[\n\\nabla_{\\mathbf{x}}^2f = \\begin{bmatrix} \\frac{\\partial^2f}{\\partial x_1^2} & \\frac{\\partial^2f}{\\partial x_1 \\partial x_2} & \\dots & \\frac{\\partial^2f}{\\partial x_1\\partial x_k} \\\\\n\\frac{\\partial^2f}{\\partial\\ x_2 \\partial x_1} & \\frac{\\partial^2f}{\\partial x_2^2} & \\dots & \\frac{\\partial^2f}{\\partial x_2 \\partial x_k} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial^2f}{\\partial x_k\\partial x_1} & \\frac{\\partial^2f}{\\partial x_k\\partial x_2} & \\dots & \\frac{\\partial^2f}{\\partial x_k^2} \\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix.html#using-the-hessian-matrix",
    "href": "slides/04-slr-matrix.html#using-the-hessian-matrix",
    "title": "SLR: Matrix representation",
    "section": "Using the Hessian matrix",
    "text": "Using the Hessian matrix\nIf the Hessian matrix is…\n\npositive-definite, then we have found a minimum.\nnegative-definite, then we have found a maximum.\nneither positive or negative-definite, then we have found a saddle point"
  },
  {
    "objectID": "slides/04-slr-matrix.html#did-we-find-a-minimum-1",
    "href": "slides/04-slr-matrix.html#did-we-find-a-minimum-1",
    "title": "SLR: Matrix representation",
    "section": "Did we find a minimum?",
    "text": "Did we find a minimum?\n\\[\n\\begin{aligned}\n\\nabla^2_{\\boldsymbol{\\beta}} \\boldsymbol{\\epsilon}^\\mathsf{T}\\boldsymbol{\\epsilon} &= \\nabla_{\\boldsymbol{\\beta}} (-2\\mathbf{X}^\\mathsf{T}\\mathbf{y} + 2\\mathbf{X}^\\mathsf{T}\\mathbf{X}\\boldsymbol{\\beta}) \\\\[10pt]\n&{=-2\\nabla_{\\boldsymbol{\\beta}}(\\mathbf{X}^\\mathsf{T}\\mathbf{y}) + 2\\nabla_{\\boldsymbol{\\beta}}(\\mathbf{X}^\\mathsf{T}\\mathbf{X}\\mathbf{\\beta})} \\\\[10pt]\n&{\\propto \\mathbf{X}^\\mathsf{T}\\mathbf{X}}\n\\end{aligned}\n\\]\n\nShow that \\(\\mathbf{X}^\\mathsf{T}\\mathbf{X}\\) is positive definite in HW 01."
  },
  {
    "objectID": "slides/04-slr-matrix.html#predicted-fitted-values",
    "href": "slides/04-slr-matrix.html#predicted-fitted-values",
    "title": "SLR: Matrix representation",
    "section": "Predicted (fitted) values",
    "text": "Predicted (fitted) values\nNow that we have \\(\\hat{\\boldsymbol{\\beta}}\\), let’s predict values of \\(\\mathbf{y}\\) using the model\n\\[\n\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\underbrace{\\mathbf{X}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}}_{\\mathbf{H}}\\mathbf{y} = \\mathbf{H}\\mathbf{y}\n\\]\n\n\nHat matrix: \\(\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathsf{T}\\)\n\n\n\n\n\\(\\mathbf{H}\\) is an \\(n\\times n\\) matrix\nMaps vector of observed values \\(\\mathbf{y}\\) to a vector of fitted values \\(\\hat{\\mathbf{y}}\\)\nIt is only a function of \\(\\mathbf{X}\\) not \\(\\mathbf{y}\\)"
  },
  {
    "objectID": "slides/04-slr-matrix.html#residuals",
    "href": "slides/04-slr-matrix.html#residuals",
    "title": "SLR: Matrix representation",
    "section": "Residuals",
    "text": "Residuals\nRecall that the residuals are the difference between the observed and predicted values\n\\[\n\\begin{aligned}\n\\mathbf{e} &= \\mathbf{y} - \\hat{\\mathbf{y}}\\\\[10pt]\n&\\class{fragment}{ = \\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}} \\\\[10pt]\n&\\class{fragment}{ = \\mathbf{y} - \\mathbf{H}\\mathbf{y}} \\\\[20pt]\n\\class{fragment}{\\color{#993399}{\\mathbf{e}}} &\\class{fragment}{\\color{#993399}{=(\\mathbf{I} - \\mathbf{H})\\mathbf{y}}} \\\\[10pt]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix.html#recap",
    "href": "slides/04-slr-matrix.html#recap",
    "title": "SLR: Matrix representation",
    "section": "Recap",
    "text": "Recap\n\nIntroduced matrix representation for simple linear regression\n\nModel form\nLeast square estimate\nPredicted (fitted) values\nResiduals"
  },
  {
    "objectID": "slides/04-slr-matrix.html#for-next-class",
    "href": "slides/04-slr-matrix.html#for-next-class",
    "title": "SLR: Matrix representation",
    "section": "For next class",
    "text": "For next class\n\nComplete Prepare for Lecture 05 - SLR: matrix representation cont’d"
  },
  {
    "objectID": "slides/project-peer-review-lab.html#goals",
    "href": "slides/project-peer-review-lab.html#goals",
    "title": "Project peer review",
    "section": "Goals",
    "text": "Goals\n\nProject milestones\nProject peer review"
  },
  {
    "objectID": "slides/project-peer-review-lab.html#upcoming-project-milestones",
    "href": "slides/project-peer-review-lab.html#upcoming-project-milestones",
    "title": "Project peer review",
    "section": "Upcoming project milestones",
    "text": "Upcoming project milestones\n\nDecember 3: Peer review due\nDecember 8: Deadline for Round 1 submission (optional)\nDecember 12: Final report + organized GitHub repo due\n\nSee project instructions for more detail."
  },
  {
    "objectID": "slides/project-peer-review-lab.html#peer-review-assignments---section-01l",
    "href": "slides/project-peer-review-lab.html#peer-review-assignments---section-01l",
    "title": "Project peer review",
    "section": "Peer review assignments - Section 01L",
    "text": "Peer review assignments - Section 01L"
  },
  {
    "objectID": "slides/project-peer-review-lab.html#peer-review-assignments---section-02l",
    "href": "slides/project-peer-review-lab.html#peer-review-assignments---section-02l",
    "title": "Project peer review",
    "section": "Peer review assignments - Section 02L",
    "text": "Peer review assignments - Section 02L"
  },
  {
    "objectID": "slides/project-peer-review-lab.html#getting-started",
    "href": "slides/project-peer-review-lab.html#getting-started",
    "title": "Project peer review",
    "section": "Getting started",
    "text": "Getting started\nFor each team you’re reviewing…\n\nOpen that team’s repo, read the project draft, and browse the rest of the repo.\nGo to the Issues tab in that repo, click on New issue, and click on Get started for the Peer Review issue.\nWrite your responses to the prompts in the issue.\n\n\n\n\n\n\n\nNote\n\n\nYou may choose to all work on both peer reviews or have some team members focus on a single peer review. Either way there will be one peer review grade assigned per team."
  },
  {
    "objectID": "slides/11-exam-01-review-notes.html",
    "href": "slides/11-exam-01-review-notes.html",
    "title": "Exam 01 review",
    "section": "",
    "text": "HW 02 due TODAY at 11:59pm\nExam 01: Tuesday, February 18 (in-class + take-home)\n\nGo directly to assigned room (emailed Wednesday evening)\n\nFriday’s lab: Exam 01 review - Graded on attendance and participation\nNo office hours February 18 - 20"
  },
  {
    "objectID": "slides/11-exam-01-review-notes.html#announcements",
    "href": "slides/11-exam-01-review-notes.html#announcements",
    "title": "Exam 01 review",
    "section": "",
    "text": "HW 02 due TODAY at 11:59pm\nExam 01: Tuesday, February 18 (in-class + take-home)\n\nGo directly to assigned room (emailed Wednesday evening)\n\nFriday’s lab: Exam 01 review - Graded on attendance and participation\nNo office hours February 18 - 20"
  },
  {
    "objectID": "slides/11-exam-01-review-notes.html#exam-01",
    "href": "slides/11-exam-01-review-notes.html#exam-01",
    "title": "Exam 01 review",
    "section": "Exam 01",
    "text": "Exam 01\n\n50 points total\n\nin-class: 35 points\ntake-home: 15 points\n\nIn-class: 75 minutes during February 18 lecture\nTake-home: due February 20 at 9pm (no lecture on Thursday)\nIf you miss any part of the exam for an excused absence (with academic dean’s note), your Exam 02 score will be counted twice"
  },
  {
    "objectID": "slides/11-exam-01-review-notes.html#outline-of-in-class-portion",
    "href": "slides/11-exam-01-review-notes.html#outline-of-in-class-portion",
    "title": "Exam 01 review",
    "section": "Outline of in-class portion",
    "text": "Outline of in-class portion\n\nClosed-book, closed-note.\nQuestion types:\n\nShort answer (show work / explain response)\nTrue/ False.\n\nIf false, write 1 - 2 sentence justification about why it is false.\n\nDerivations\n\nWill be provided all relevant R output and a page of matrix calculus and probability rules\nCan use any results from class or assignments without reproving them (e.g., \\(\\mathbf{H}\\) is symmetric and idempotent)\nJust need a pencil or pen. No calculator permitted on exam."
  },
  {
    "objectID": "slides/11-exam-01-review-notes.html#outline-of-take-home-portion",
    "href": "slides/11-exam-01-review-notes.html#outline-of-take-home-portion",
    "title": "Exam 01 review",
    "section": "Outline of take-home portion",
    "text": "Outline of take-home portion\n\nReleased: Tuesday, February 18 right after class\nDue: Thursday, February 20 at 9pm (no lecture February 20)\nSimilar in format to a lab/ HW\n\nWill receive Exam questions in README of GitHub repo\nFormatting + using a reproducible workflow will be part of grade\n\nSubmit a PDF of responses to GitHub"
  },
  {
    "objectID": "slides/11-exam-01-review-notes.html#tips-for-studying",
    "href": "slides/11-exam-01-review-notes.html#tips-for-studying",
    "title": "Exam 01 review",
    "section": "Tips for studying",
    "text": "Tips for studying\n\nRework derivations from assignments and lecture notes\nReview exercises in AEs and assignments, asking “why” as you review your process and reasoning\n\ne.g., Why do we include “holding all else constant” in interpretations?\n\nFocus on understanding not memorization\nExplain concepts / process to others\nAsk questions in office hours\nReview lecture recordings as needed"
  },
  {
    "objectID": "slides/11-exam-01-review-notes.html#content-weeks-1---6",
    "href": "slides/11-exam-01-review-notes.html#content-weeks-1---6",
    "title": "Exam 01 review",
    "section": "Content: Weeks 1 - 6",
    "text": "Content: Weeks 1 - 6\n\n\n\nExploratory data analysis\nFitting and interpreting linear regression models\nModel assessment and comparison\nANOVA\nCategorical + interaction terms\nInference for model coefficients\n\n\n\nMatrix representation of regression\nHat matrix\nFinding the least-squares estimator\nAssumptions for least-squares regression"
  },
  {
    "objectID": "slides/11-exam-01-review-notes.html#population-level-vs.-sample-level-models",
    "href": "slides/11-exam-01-review-notes.html#population-level-vs.-sample-level-models",
    "title": "Exam 01 review",
    "section": "Population-level vs. sample-level models",
    "text": "Population-level vs. sample-level models\nStatistical model (population-level model)\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}, \\quad \\epsilon \\sim N(\\mathbf{0}, \\sigma^2_{\\epsilon}\\mathbf{I})\n\\]\n\nEstimated regression model (sample-level model)\n\\[\n\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}\\quad \\quad \\mathbf{e} = \\mathbf{y} - \\hat{\\mathbf{y}}\n\\]"
  },
  {
    "objectID": "slides/11-exam-01-review-notes.html#model-in-matrix-form",
    "href": "slides/11-exam-01-review-notes.html#model-in-matrix-form",
    "title": "Exam 01 review",
    "section": "Model in matrix form",
    "text": "Model in matrix form\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n\\]\n\n\n\nWhat are the dimensions of \\(\\mathbf{y}, \\mathbf{X}, \\boldsymbol{\\beta}, \\boldsymbol{\\epsilon}\\) ?\nWhat assumption do we make about the columns of \\(\\mathbf{X}\\)? Why is that important?"
  },
  {
    "objectID": "slides/11-exam-01-review-notes.html#model-in-matrix-form-1",
    "href": "slides/11-exam-01-review-notes.html#model-in-matrix-form-1",
    "title": "Exam 01 review",
    "section": "Model in matrix form",
    "text": "Model in matrix form\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n\\]\n\n\n\nWhat assumptions do we make about \\(\\boldsymbol{\\epsilon}\\) making given this model?\nWhat does this model tell us about the distribution of \\(\\mathbf{y}\\) ?"
  },
  {
    "objectID": "slides/11-exam-01-review-notes.html#find-least-squares-estimator-hatboldsymbolbeta",
    "href": "slides/11-exam-01-review-notes.html#find-least-squares-estimator-hatboldsymbolbeta",
    "title": "Exam 01 review",
    "section": "Find least-squares estimator \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Find least-squares estimator \\(\\hat{\\boldsymbol{\\beta}}\\)"
  },
  {
    "objectID": "slides/11-exam-01-review-notes.html#expected-value-of-hatboldsymbolbeta",
    "href": "slides/11-exam-01-review-notes.html#expected-value-of-hatboldsymbolbeta",
    "title": "Exam 01 review",
    "section": "Expected value of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Expected value of \\(\\hat{\\boldsymbol{\\beta}}\\)"
  },
  {
    "objectID": "slides/11-exam-01-review-notes.html#variance-of-hatboldsymbolbeta",
    "href": "slides/11-exam-01-review-notes.html#variance-of-hatboldsymbolbeta",
    "title": "Exam 01 review",
    "section": "Variance of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Variance of \\(\\hat{\\boldsymbol{\\beta}}\\)"
  },
  {
    "objectID": "slides/11-exam-01-review-notes.html#ssr",
    "href": "slides/11-exam-01-review-notes.html#ssr",
    "title": "Exam 01 review",
    "section": "SSR",
    "text": "SSR\n\nShow\n\\[\nSSR = \\mathbf{y}^\\mathsf{T}\\mathbf{y} - \\hat{\\boldsymbol{\\beta}}\\mathbf{X}^\\mathsf{T}\\mathbf{y}\n\\]"
  },
  {
    "objectID": "slides/11-exam-01-review.html#announcements",
    "href": "slides/11-exam-01-review.html#announcements",
    "title": "Exam 01 review",
    "section": "Announcements",
    "text": "Announcements\n\nHW 02 due TODAY at 11:59pm\nExam 01: Tuesday, February 18 (in-class + take-home)\n\nGo directly to assigned room (emailed Wednesday evening)\n\nFriday’s lab: Exam 01 review - Graded on attendance and participation\nNo office hours February 18 - 20"
  },
  {
    "objectID": "slides/11-exam-01-review.html#exam-01",
    "href": "slides/11-exam-01-review.html#exam-01",
    "title": "Exam 01 review",
    "section": "Exam 01",
    "text": "Exam 01\n\n50 points total\n\nin-class: 35 points\ntake-home: 15 points\n\nIn-class: 75 minutes during February 18 lecture\nTake-home: due February 20 at 9pm (no lecture on Thursday)\nIf you miss any part of the exam for an excused absence (with academic dean’s note), your Exam 02 score will be counted twice"
  },
  {
    "objectID": "slides/11-exam-01-review.html#outline-of-in-class-portion",
    "href": "slides/11-exam-01-review.html#outline-of-in-class-portion",
    "title": "Exam 01 review",
    "section": "Outline of in-class portion",
    "text": "Outline of in-class portion\n\nClosed-book, closed-note.\nQuestion types:\n\nShort answer (show work / explain response)\nTrue/ False.\n\nIf false, write 1 - 2 sentence justification about why it is false.\n\nDerivations\n\nWill be provided all relevant R output and a page of matrix calculus and probability rules\nCan use any results from class or assignments without reproving them (e.g., \\(\\mathbf{H}\\) is symmetric and idempotent)\nJust need a pencil or pen. No calculator permitted on exam."
  },
  {
    "objectID": "slides/11-exam-01-review.html#outline-of-take-home-portion",
    "href": "slides/11-exam-01-review.html#outline-of-take-home-portion",
    "title": "Exam 01 review",
    "section": "Outline of take-home portion",
    "text": "Outline of take-home portion\n\nReleased: Tuesday, February 18 right after class\nDue: Thursday, February 20 at 9pm (no lecture February 20)\nSimilar in format to a lab/ HW\n\nWill receive Exam questions in README of GitHub repo\nFormatting + using a reproducible workflow will be part of grade\n\nSubmit a PDF of responses to GitHub"
  },
  {
    "objectID": "slides/11-exam-01-review.html#tips-for-studying",
    "href": "slides/11-exam-01-review.html#tips-for-studying",
    "title": "Exam 01 review",
    "section": "Tips for studying",
    "text": "Tips for studying\n\nRework derivations from assignments and lecture notes\nReview exercises in AEs and assignments, asking “why” as you review your process and reasoning\n\ne.g., Why do we include “holding all else constant” in interpretations?\n\nFocus on understanding not memorization\nExplain concepts / process to others\nAsk questions in office hours\nReview lecture recordings as needed"
  },
  {
    "objectID": "slides/11-exam-01-review.html#content-weeks-1---6",
    "href": "slides/11-exam-01-review.html#content-weeks-1---6",
    "title": "Exam 01 review",
    "section": "Content: Weeks 1 - 6",
    "text": "Content: Weeks 1 - 6\n\n\n\nExploratory data analysis\nFitting and interpreting linear regression models\nModel assessment and comparison\nANOVA\nCategorical + interaction terms\nInference for model coefficients\n\n\n\nMatrix representation of regression\nHat matrix\nFinding the least-squares estimator\nAssumptions for least-squares regression"
  },
  {
    "objectID": "slides/11-exam-01-review.html#population-level-vs.-sample-level-models",
    "href": "slides/11-exam-01-review.html#population-level-vs.-sample-level-models",
    "title": "Exam 01 review",
    "section": "Population-level vs. sample-level models",
    "text": "Population-level vs. sample-level models\nStatistical model (population-level model)\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}, \\quad \\epsilon \\sim N(\\mathbf{0}, \\sigma^2_{\\epsilon}\\mathbf{I})\n\\]\n\nEstimated regression model (sample-level model)\n\\[\n\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}\\quad \\quad \\mathbf{e} = \\mathbf{y} - \\hat{\\mathbf{y}}\n\\]"
  },
  {
    "objectID": "slides/11-exam-01-review.html#model-in-matrix-form",
    "href": "slides/11-exam-01-review.html#model-in-matrix-form",
    "title": "Exam 01 review",
    "section": "Model in matrix form",
    "text": "Model in matrix form\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n\\]\n\n\n\nWhat are the dimensions of \\(\\mathbf{y}, \\mathbf{X}, \\boldsymbol{\\beta}, \\boldsymbol{\\epsilon}\\) ?\nWhat assumption do we make about the columns of \\(\\mathbf{X}\\)? Why is that important?"
  },
  {
    "objectID": "slides/11-exam-01-review.html#model-in-matrix-form-1",
    "href": "slides/11-exam-01-review.html#model-in-matrix-form-1",
    "title": "Exam 01 review",
    "section": "Model in matrix form",
    "text": "Model in matrix form\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n\\]\n\n\n\nWhat assumptions do we make about \\(\\boldsymbol{\\epsilon}\\) making given this model?\nWhat does this model tell us about the distribution of \\(\\mathbf{y}\\) ?"
  },
  {
    "objectID": "slides/11-exam-01-review.html#find-least-squares-estimator-hatboldsymbolbeta",
    "href": "slides/11-exam-01-review.html#find-least-squares-estimator-hatboldsymbolbeta",
    "title": "Exam 01 review",
    "section": "Find least-squares estimator \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Find least-squares estimator \\(\\hat{\\boldsymbol{\\beta}}\\)"
  },
  {
    "objectID": "slides/11-exam-01-review.html#expected-value-of-hatboldsymbolbeta",
    "href": "slides/11-exam-01-review.html#expected-value-of-hatboldsymbolbeta",
    "title": "Exam 01 review",
    "section": "Expected value of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Expected value of \\(\\hat{\\boldsymbol{\\beta}}\\)"
  },
  {
    "objectID": "slides/11-exam-01-review.html#variance-of-hatboldsymbolbeta",
    "href": "slides/11-exam-01-review.html#variance-of-hatboldsymbolbeta",
    "title": "Exam 01 review",
    "section": "Variance of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Variance of \\(\\hat{\\boldsymbol{\\beta}}\\)"
  },
  {
    "objectID": "slides/11-exam-01-review.html#ssr",
    "href": "slides/11-exam-01-review.html#ssr",
    "title": "Exam 01 review",
    "section": "SSR",
    "text": "SSR\n\nShow\n\\[\nSSR = \\mathbf{y}^\\mathsf{T}\\mathbf{y} - \\hat{\\boldsymbol{\\beta}}\\mathbf{X}^\\mathsf{T}\\mathbf{y}\n\\]"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html",
    "href": "slides/19-logistic-regression-notes.html",
    "title": "Logistic Regression",
    "section": "",
    "text": "Project Presentations in lab on Friday, March 28\n\nCheck email for presentation order and feedback assignments\n\nStatistics experience due April 22"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#announcements",
    "href": "slides/19-logistic-regression-notes.html#announcements",
    "title": "Logistic Regression",
    "section": "",
    "text": "Project Presentations in lab on Friday, March 28\n\nCheck email for presentation order and feedback assignments\n\nStatistics experience due April 22"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#questions-from-this-weeks-content",
    "href": "slides/19-logistic-regression-notes.html#questions-from-this-weeks-content",
    "title": "Logistic Regression",
    "section": "Questions from this week’s content?",
    "text": "Questions from this week’s content?"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#topics",
    "href": "slides/19-logistic-regression-notes.html#topics",
    "title": "Logistic Regression",
    "section": "Topics",
    "text": "Topics\n\nLogistic regression for binary response variable\nUse logistic regression model to calculate predicted odds and probabilities\nInterpret the coefficients of a logistic regression model with\n\na single categorical predictor\na single quantitative predictor\nmultiple predictors"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#computational-setup",
    "href": "slides/19-logistic-regression-notes.html#computational-setup",
    "title": "Logistic Regression",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(Stat2Data) #contains data set\nlibrary(patchwork)\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#do-teenagers-get-7-hours-of-sleep",
    "href": "slides/19-logistic-regression-notes.html#do-teenagers-get-7-hours-of-sleep",
    "title": "Logistic Regression",
    "section": "Do teenagers get 7+ hours of sleep?",
    "text": "Do teenagers get 7+ hours of sleep?\n\n\nStudents in grades 9 - 12 surveyed about health risk behaviors including whether they usually get 7 or more hours of sleep.\nSleep7\n1: yes\n0: no\n\n\n\n# A tibble: 446 × 6\n     Age Sleep7 Sleep           SmokeLife SmokeDaily MarijuaEver\n   &lt;int&gt;  &lt;int&gt; &lt;fct&gt;           &lt;fct&gt;     &lt;fct&gt;            &lt;int&gt;\n 1    16      1 8 hours         Yes       Yes                  1\n 2    17      0 5 hours         Yes       Yes                  1\n 3    18      0 5 hours         Yes       Yes                  1\n 4    17      1 7 hours         Yes       No                   1\n 5    15      0 4 or less hours No        No                   0\n 6    17      0 6 hours         No        No                   0\n 7    17      1 7 hours         No        No                   0\n 8    16      1 8 hours         Yes       No                   0\n 9    16      1 8 hours         No        No                   0\n10    18      0 4 or less hours Yes       Yes                  1\n# ℹ 436 more rows"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#lets-fit-a-linear-regression-model",
    "href": "slides/19-logistic-regression-notes.html#lets-fit-a-linear-regression-model",
    "title": "Logistic Regression",
    "section": "Let’s fit a linear regression model",
    "text": "Let’s fit a linear regression model\nOutcome: \\(Y\\) = 1: yes, 0: no"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#lets-use-proportions",
    "href": "slides/19-logistic-regression-notes.html#lets-use-proportions",
    "title": "Logistic Regression",
    "section": "Let’s use proportions",
    "text": "Let’s use proportions\nOutcome: Probability of getting 7+ hours of sleep"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#what-happens-if-we-zoom-out",
    "href": "slides/19-logistic-regression-notes.html#what-happens-if-we-zoom-out",
    "title": "Logistic Regression",
    "section": "What happens if we zoom out?",
    "text": "What happens if we zoom out?\nOutcome: Probability of getting 7+ hours of sleep\n\n\n\n\n\n\n\n\n\n🛑 This model produces predictions outside of 0 and 1."
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#lets-try-another-model",
    "href": "slides/19-logistic-regression-notes.html#lets-try-another-model",
    "title": "Logistic Regression",
    "section": "Let’s try another model",
    "text": "Let’s try another model\n\n\n\n\n\n\n\n\n\n✅ This model (called a logistic regression model) only produces predictions between 0 and 1."
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#binary-response-variable",
    "href": "slides/19-logistic-regression-notes.html#binary-response-variable",
    "title": "Logistic Regression",
    "section": "Binary response variable",
    "text": "Binary response variable\n\n\n\\(Y = 1: \\text{ yes}, 0: \\text{ no}\\)\n\\(\\pi\\): probability that \\(Y=1\\), i.e., \\(P(Y = 1)\\)\n\\(\\frac{\\pi}{1-\\pi}\\): odds that \\(Y = 1\\)\n\\(\\log\\big(\\frac{\\pi}{1-\\pi}\\big)\\): log odds\nGo from \\(\\pi\\) to \\(\\log\\big(\\frac{\\pi}{1-\\pi}\\big)\\) using the logit transformation"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#from-odds-to-probabilities",
    "href": "slides/19-logistic-regression-notes.html#from-odds-to-probabilities",
    "title": "Logistic Regression",
    "section": "From odds to probabilities",
    "text": "From odds to probabilities\n\nLogistic model: log odds = \\(\\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\mathbf{X}\\boldsymbol{\\beta}\\)\nOdds = \\(\\exp\\big\\{\\log\\big(\\frac{\\pi}{1-\\pi}\\big)\\big\\} = \\frac{\\pi}{1-\\pi}\\)\nCombining (1) and (2) with what we saw earlier\n\n. . .\n\\[\\text{probability} = \\pi = \\frac{\\exp\\{\\mathbf{X}\\boldsymbol{\\beta}\\}}{1 + \\exp\\{\\mathbf{X}\\boldsymbol{\\beta}\\}}\\]"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#sigmoid-function",
    "href": "slides/19-logistic-regression-notes.html#sigmoid-function",
    "title": "Logistic Regression",
    "section": "Sigmoid Function",
    "text": "Sigmoid Function\nWe call this function relating the probability to the predictors a sigmoid function, \\[\n\\sigma(x) = \\frac{\\exp\\{x\\}}{1 + \\exp\\{x\\}}= \\frac{1}{1+\\text{exp}\\{-x\\}}.\\]"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#sigmoid-function-1",
    "href": "slides/19-logistic-regression-notes.html#sigmoid-function-1",
    "title": "Logistic Regression",
    "section": "Sigmoid Function",
    "text": "Sigmoid Function\n\n\n\n\n\n\n\n\n\n. . ."
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#logistic-regression-model",
    "href": "slides/19-logistic-regression-notes.html#logistic-regression-model",
    "title": "Logistic Regression",
    "section": "Logistic regression model",
    "text": "Logistic regression model\nLogit form: \\[\\text{logit}(\\pi) = \\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\mathbf{X}\\boldsymbol{\\beta}\\]\n. . .\nProbability form:\n\\[\n\\pi = \\frac{\\exp\\{\\mathbf{X}\\boldsymbol{\\beta}\\}}{1 + \\exp\\{\\mathbf{X}\\boldsymbol{\\beta} \\}}  \n\\]\n. . .\nLogit and sigmoid link functions are inverses of each other.\n\n\n\n\n\n\nNote\n\n\n\nMore on link functions later, if time permits"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#goal",
    "href": "slides/19-logistic-regression-notes.html#goal",
    "title": "Logistic Regression",
    "section": "Goal",
    "text": "Goal\nWe want to use our data to estimate \\(\\boldsymbol{\\beta}\\) (find \\(\\hat{\\boldsymbol{\\beta}}\\)) and obtain the model:\n\\[\n\\hat\\pi = \\frac{\\exp\\{\\mathbf{X}\\hat{\\boldsymbol\\beta}\\}}{ 1 + \\exp\\{\\mathbf{X}\\hat{\\boldsymbol\\beta}\\}}\n\\]\nIn this modeling scheme, one typically finds \\(\\hat{\\boldsymbol{\\beta}}\\) by maximizing the likelihood function."
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#linear-regression-vs.-logistic-regression",
    "href": "slides/19-logistic-regression-notes.html#linear-regression-vs.-logistic-regression",
    "title": "Logistic Regression",
    "section": "Linear Regression vs. Logistic Regression",
    "text": "Linear Regression vs. Logistic Regression\n\n\nLinear regression:\n\nQuantitative outcome\n\\(y_i = x_i^\\top \\boldsymbol{\\beta} + \\epsilon_i\\)\n\\(E[Y_i] = x_i^\\top \\boldsymbol{\\beta}\\)\nEstimate \\(\\boldsymbol\\beta\\)\nUse \\(\\hat{\\boldsymbol\\beta}\\) to predict \\(\\hat y_i\\)\n\n\nLogistic regression:\n\nBinary outcome\n\\(\\log\\left(\\frac{\\pi_i}{1-\\pi_i}\\right) = x_i^\\top \\boldsymbol{\\beta}\\)\n\\(E[Y_i] = \\pi_i\\)\nEstimate \\(\\boldsymbol\\beta\\)\nUse \\(\\hat{\\boldsymbol\\beta}\\) to predict \\(\\hat \\pi_i\\)"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#likelihood-function-for-boldsymbolbeta",
    "href": "slides/19-logistic-regression-notes.html#likelihood-function-for-boldsymbolbeta",
    "title": "Logistic Regression",
    "section": "Likelihood function for \\(\\boldsymbol{\\beta}\\)",
    "text": "Likelihood function for \\(\\boldsymbol{\\beta}\\)\n\n\\(P(Y_i = 1) = \\pi_i\\). What likelihood function should we use?\n\n. . .\n\n\\(f(y_i | x_i, \\boldsymbol{\\beta}) = \\pi_i^{y_i} (1-\\pi_i)^{1-y_i}\\)\n\n. . .\n\n\\(Y_i\\)’s are independent, so\n\n\\[f(y_1, \\dots, y_n) = \\prod_{i=1}^n \\pi_i^{y_i} (1-\\pi_i)^{1-y_i}\\]"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#likelihood",
    "href": "slides/19-logistic-regression-notes.html#likelihood",
    "title": "Logistic Regression",
    "section": "Likelihood",
    "text": "Likelihood\nThe likelihood function for \\(\\boldsymbol\\beta\\) is\n\\[\n\\begin{aligned}\nL&(\\boldsymbol\\beta| x_1, \\dots, x_n, y_1, \\dots, y_n) \\\\[5pt]\n&=  \\prod_{i=1}^n \\pi_i^{y_i} (1-\\pi_i)^{1-y_i} \\\\[10pt]\n\\end{aligned}\n\\] \n. . .\nWe will use the log-likelihood function to find the MLEs"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#log-likelihood",
    "href": "slides/19-logistic-regression-notes.html#log-likelihood",
    "title": "Logistic Regression",
    "section": "Log-likelihood",
    "text": "Log-likelihood\nThe log-likelihood function for \\(\\boldsymbol\\beta\\) is\n\\[\n\\begin{aligned}\n\\log &L(\\boldsymbol\\beta | x_1, \\dots, x_n, y_1, \\dots, y_n)\n  \\\\[8pt]\n& = \\sum_{i=1}^n\\log(\\pi_i^{y_i}(1-\\pi_i)^{1-y_i})\\\\\n&= \\sum_{i=1}^n\\left(y_i\\log (\\pi_i) + (1-y_i)\\log(1-\\pi_i)\\right)\\\\\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#log-likelihood-1",
    "href": "slides/19-logistic-regression-notes.html#log-likelihood-1",
    "title": "Logistic Regression",
    "section": "Log-likelihood",
    "text": "Log-likelihood\nPlugging in \\(\\pi_i = \\frac{\\exp\\{x_i^\\top \\boldsymbol\\beta\\}}{1+\\exp\\{x_i^\\top \\boldsymbol\\beta\\}}\\) and simplifying, we get:\n\\[\n\\begin{aligned}\\log &L(\\boldsymbol\\beta | x_1, \\dots, x_n, y_1, \\dots, y_n) \\\\\n&= \\sum_{i=1}^n y_i x_i^\\top \\boldsymbol\\beta - \\sum_{i=1}^n \\log(1+ \\exp\\{x_i^\\top \\beta\\})\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#finding-the-mle",
    "href": "slides/19-logistic-regression-notes.html#finding-the-mle",
    "title": "Logistic Regression",
    "section": "Finding the MLE",
    "text": "Finding the MLE\n\nTaking the derivative:\n\n\\[\n\\begin{aligned}\n\\frac{\\partial \\log L}{\\partial \\boldsymbol\\beta} =\\sum_{i=1}^n y_i x_i^\\top\n&- \\sum_{i=1}^n \\frac{\\exp\\{x_i^\\top \\boldsymbol\\beta\\} x_i^\\top}{1+\\exp\\{x_i^\\top \\boldsymbol\\beta\\}}\n\\end{aligned}\n\\]\n. . .\n\nIf we set this to zero, there is no closed form solution.\n\n. . .\n\nR uses numerical approximation to find the MLE."
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#risk-of-coronary-heart-disease",
    "href": "slides/19-logistic-regression-notes.html#risk-of-coronary-heart-disease",
    "title": "Logistic Regression",
    "section": "Risk of coronary heart disease",
    "text": "Risk of coronary heart disease\nThis data set is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. We want to examine the relationship between various health characteristics and the risk of having heart disease.\n\nhigh_risk: 1 = High risk of having heart disease in next 10 years, 0 = Not high risk of having heart disease in next 10 years\nage: Age at exam time (in years)\neducation: 1 = Some High School, 2 = High School or GED, 3 = Some College or Vocational School, 4 = College"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#data-heart_disease",
    "href": "slides/19-logistic-regression-notes.html#data-heart_disease",
    "title": "Logistic Regression",
    "section": "Data: heart_disease",
    "text": "Data: heart_disease\n\n\n# A tibble: 4,135 × 3\n     age education high_risk\n   &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt;    \n 1    39 4         0        \n 2    46 2         0        \n 3    48 1         0        \n 4    61 3         1        \n 5    46 3         0        \n 6    43 2         0        \n 7    63 1         1        \n 8    45 2         0        \n 9    52 1         0        \n10    43 1         0        \n# ℹ 4,125 more rows"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#univariate-eda",
    "href": "slides/19-logistic-regression-notes.html#univariate-eda",
    "title": "Logistic Regression",
    "section": "Univariate EDA",
    "text": "Univariate EDA"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#bivariate-eda",
    "href": "slides/19-logistic-regression-notes.html#bivariate-eda",
    "title": "Logistic Regression",
    "section": "Bivariate EDA",
    "text": "Bivariate EDA"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#bivariate-eda-code",
    "href": "slides/19-logistic-regression-notes.html#bivariate-eda-code",
    "title": "Logistic Regression",
    "section": "Bivariate EDA code",
    "text": "Bivariate EDA code\n\n{r}\n#| echo: false\n\np1 &lt;- ggplot(heart_disease, aes(x = high_risk, y = age)) +\n  geom_boxplot(fill = \"steelblue\") +\n  labs(x = \"High risk - 1: yes, 0: no\",\n       y = \"Age\")\n\np2 &lt;- ggplot(heart_disease, aes(x = education, fill = high_risk)) +\n  geom_bar(position = \"fill\", color = \"black\") +\n  labs(x = \"Education\",\n    fill = \"High risk\") +\n  scale_fill_viridis_d() +\n  theme(legend.position = \"bottom\")\n\np1 + p2"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#lets-fit-the-model",
    "href": "slides/19-logistic-regression-notes.html#lets-fit-the-model",
    "title": "Logistic Regression",
    "section": "Let’s fit the model",
    "text": "Let’s fit the model\n\n\nheart_edu_age_fit &lt;- glm(high_risk ~ age + education, \n                         data  = heart_disease, \n                         family = \"binomial\")\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-5.385\n0.308\n-17.507\n0.000\n\n\nage\n0.073\n0.005\n13.385\n0.000\n\n\neducation2\n-0.242\n0.112\n-2.162\n0.031\n\n\neducation3\n-0.235\n0.134\n-1.761\n0.078\n\n\neducation4\n-0.020\n0.148\n-0.136\n0.892\n\n\n\n\n\n\\[\n\\begin{aligned}\n\\log\\Big(\\frac{\\hat{\\pi}}{1-\\hat{\\pi}}\\Big) =& -5.385 + 0.073 \\times \\text{age} - 0.242\\times \\text{education}_2 \\\\\n&- 0.235\\times\\text{education}_3 - 0.020 \\times\\text{education}_4\n\\end{aligned}\n\\] where \\(\\hat{\\pi}\\) is the predicted probability of being high risk of having heart disease in the next 10 years"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#interpretation-in-terms-of-log-odds",
    "href": "slides/19-logistic-regression-notes.html#interpretation-in-terms-of-log-odds",
    "title": "Logistic Regression",
    "section": "Interpretation in terms of log-odds",
    "text": "Interpretation in terms of log-odds\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-5.385\n0.308\n-17.507\n0.000\n\n\nage\n0.073\n0.005\n13.385\n0.000\n\n\neducation2\n-0.242\n0.112\n-2.162\n0.031\n\n\neducation3\n-0.235\n0.134\n-1.761\n0.078\n\n\neducation4\n-0.020\n0.148\n-0.136\n0.892\n\n\n\n\n\n\neducation4: The log-odds of being high risk for heart disease are expected to be 0.020 less for those with a college degree compared to those with some high school, holding age constant.\n. . .\n\n\n\n\n\n\nWarning\n\n\n\nWe would not use the interpretation in terms of log-odds in practice."
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#interpretation-in-terms-of-log-odds-1",
    "href": "slides/19-logistic-regression-notes.html#interpretation-in-terms-of-log-odds-1",
    "title": "Logistic Regression",
    "section": "Interpretation in terms of log-odds",
    "text": "Interpretation in terms of log-odds\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-5.385\n0.308\n-17.507\n0.000\n\n\nage\n0.073\n0.005\n13.385\n0.000\n\n\neducation2\n-0.242\n0.112\n-2.162\n0.031\n\n\neducation3\n-0.235\n0.134\n-1.761\n0.078\n\n\neducation4\n-0.020\n0.148\n-0.136\n0.892\n\n\n\n\n\n\nage: For each additional year in age, the log-odds of being high risk for heart disease are expected to increase by 0.073, holding education level constant.\n. . .\n\n\n\n\n\n\nWarning\n\n\n\nWe would not use the interpretation in terms of log-odds in practice."
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#interpretation-in-terms-of-odds",
    "href": "slides/19-logistic-regression-notes.html#interpretation-in-terms-of-odds",
    "title": "Logistic Regression",
    "section": "Interpretation in terms of odds",
    "text": "Interpretation in terms of odds\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-5.385\n0.308\n-17.507\n0.000\n\n\nage\n0.073\n0.005\n13.385\n0.000\n\n\neducation2\n-0.242\n0.112\n-2.162\n0.031\n\n\neducation3\n-0.235\n0.134\n-1.761\n0.078\n\n\neducation4\n-0.020\n0.148\n-0.136\n0.892\n\n\n\n\n\n\neducation4: The odds of being high risk for heart disease for those with a college degree are expected to be 0.98 (exp{-0.020}) times the odds for those with some high school, holding age constant.\n\n\n\n\n\n\nNote\n\n\n\nIn logistic regression with 2+ predictors, \\(exp\\{\\hat{\\beta}_j\\}\\) is often called the adjusted odds ratio (AOR)."
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#interpretation-in-terms-of-odds-1",
    "href": "slides/19-logistic-regression-notes.html#interpretation-in-terms-of-odds-1",
    "title": "Logistic Regression",
    "section": "Interpretation in terms of odds",
    "text": "Interpretation in terms of odds\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-5.385\n0.308\n-17.507\n0.000\n\n\nage\n0.073\n0.005\n13.385\n0.000\n\n\neducation2\n-0.242\n0.112\n-2.162\n0.031\n\n\neducation3\n-0.235\n0.134\n-1.761\n0.078\n\n\neducation4\n-0.020\n0.148\n-0.136\n0.892\n\n\n\n\n\n\nage: For each additional year in age, the odds being high risk for heart disease are expected to multiply by a factor of 1.08 (exp(0.073)), holding education level constant.\nAlternate interpretation: For each additional year in age, the odds of being high risk for heart disease are expected to increase by 8%.\n\n\n\n\n\n\nNote\n\n\n\nIn logistic regression with 2+ predictors, \\(exp\\{\\hat{\\beta}_j\\}\\) is often called the adjusted odds ratio (AOR)."
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#introduction-to-glms",
    "href": "slides/19-logistic-regression-notes.html#introduction-to-glms",
    "title": "Logistic Regression",
    "section": "Introduction to GLMs",
    "text": "Introduction to GLMs\n\n\nWider class of models.\nResponse variable does not have to be continuous and/or normal.\nVariance does not have to be constant\nStill need to specify distribution of outcome variable (randomness).\nDoes not require a linear relationship between response and explanatory variable. Instead, assumes linear relationship between the transformed expected response (ex. \\(\\text{logit}(\\pi_i)\\)) and predictors."
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#generalization-of-linear-model",
    "href": "slides/19-logistic-regression-notes.html#generalization-of-linear-model",
    "title": "Logistic Regression",
    "section": "Generalization of Linear Model",
    "text": "Generalization of Linear Model\n\nLinear model\n\\(E[Y_i] = \\mu_i = x_i^\\top\\boldsymbol\\beta\\).\n\\(Y_i \\overset{ind}{\\sim} N(\\mu_i, \\sigma^2)\\).\n\n. . .\n\nGLM\n\\(g\\left(E[Y_i]\\right) = g(\\mu_i)  = x_i^\\top \\beta\\). Alternatively, \\(\\mu_i \\sim g^{-1}(x_i^\\top \\beta)\\).\n\\(Y_i \\overset{ind}{\\sim} f(\\mu_i)\\).\n\n. . .\n\n\n\n\n\n\nNote\n\n\n\nWe call \\(g\\) a link function"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#examples-of-link-functions",
    "href": "slides/19-logistic-regression-notes.html#examples-of-link-functions",
    "title": "Logistic Regression",
    "section": "Examples of link functions",
    "text": "Examples of link functions\nLinear regression\n\\(g(\\mu_i) = \\mu_i\\) and \\(Y_i\\sim N(\\mu_i,\\sigma^2)\\).\n. . .\nLogistic regression\n\\(g(\\pi_i) = \\text{logit}(\\pi_i)\\) (note, \\(E[Y_i] = \\pi_i\\)). \\(Y_i \\sim \\text{Bernoulli}(\\pi_i)\\). Alternatively, \\(\\pi_i = \\sigma(x_i^\\top\\boldsymbol\\beta)\\) where \\(\\sigma\\) is the sigmoid function.\n. . .\nProbit model\n\\(\\pi_i = \\Phi(x_i^\\top\\boldsymbol\\beta)\\), where \\(\\Phi\\) is the cdf of standard normal. \\(Y_i \\sim \\text{Bernoulli}(\\pi_i)\\). \\(g(\\pi_i) = \\Phi^{-1}(\\pi_i)\\) is called a probit link."
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#predicted-log-odds",
    "href": "slides/19-logistic-regression-notes.html#predicted-log-odds",
    "title": "Logistic Regression",
    "section": "Predicted log odds",
    "text": "Predicted log odds\n\nheart_disease_aug = \n  augment(heart_edu_age_fit) \nheart_disease_aug|&gt; select(.fitted, .resid)|&gt;\n  head(6)\n\n# A tibble: 6 × 2\n  .fitted .resid\n    &lt;dbl&gt;  &lt;dbl&gt;\n1   -2.55 -0.388\n2   -2.26 -0.446\n3   -1.87 -0.536\n4   -1.15  1.69 \n5   -2.25 -0.448\n6   -2.48 -0.402\n\n\n. . .\nFor observation 1\n\\[\\text{predicted odds} = \\hat{\\omega} = \\frac{\\hat{\\pi}}{1-\\hat{\\pi}} = \\exp\\{-2.548\\} = 0.078\\]"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#predicted-probabilities",
    "href": "slides/19-logistic-regression-notes.html#predicted-probabilities",
    "title": "Logistic Regression",
    "section": "Predicted probabilities",
    "text": "Predicted probabilities\n\nheart_disease_aug$predicted_prob &lt;- \n  predict.glm(heart_edu_age_fit, heart_disease, type = \"response\")\nheart_disease_aug|&gt;\n  select(.fitted,predicted_prob) |&gt;\n  head(6)\n\n# A tibble: 6 × 2\n  .fitted predicted_prob\n    &lt;dbl&gt;          &lt;dbl&gt;\n1   -2.55         0.0726\n2   -2.26         0.0948\n3   -1.87         0.134 \n4   -1.15         0.240 \n5   -2.25         0.0954\n6   -2.48         0.0775\n\n\n. . .\nFor observation 1\n\\[\\text{predicted probability} = \\hat{\\pi} = \\frac{\\exp\\{-2.548\\}}{1 + \\exp\\{-2.548\\}} = 0.073\\]"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#predicted-classes",
    "href": "slides/19-logistic-regression-notes.html#predicted-classes",
    "title": "Logistic Regression",
    "section": "Predicted classes",
    "text": "Predicted classes\n\n# Convert probabilities to binary predictions (0 or 1)\nheart_disease_aug &lt;- heart_disease_aug |&gt;\n  mutate(predicted_class =  ifelse(predicted_prob &gt; 0.5, 1, 0))\nheart_disease_aug |&gt;\n  select(predicted_prob, predicted_class) \n\n# A tibble: 4,135 × 2\n   predicted_prob predicted_class\n            &lt;dbl&gt;           &lt;dbl&gt;\n 1         0.0726               0\n 2         0.0948               0\n 3         0.134                0\n 4         0.240                0\n 5         0.0954               0\n 6         0.0775               0\n 7         0.317                0\n 8         0.0887               0\n 9         0.172                0\n10         0.0967               0\n# ℹ 4,125 more rows"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#observed-vs.-predicted",
    "href": "slides/19-logistic-regression-notes.html#observed-vs.-predicted",
    "title": "Logistic Regression",
    "section": "Observed vs. predicted",
    "text": "Observed vs. predicted\n\nWhat does the following table show?\n\n\nheart_disease_aug|&gt;\n  count(high_risk, predicted_class)\n\n# A tibble: 2 × 3\n  high_risk predicted_class     n\n  &lt;fct&gt;               &lt;dbl&gt; &lt;int&gt;\n1 0                       0  3507\n2 1                       0   628\n\n\n. . .\n\nThe predicted_class is the class with the probability of occurring higher than 0.5. What is a limitation to using this method to determine the predicted class?"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#recap-1",
    "href": "slides/19-logistic-regression-notes.html#recap-1",
    "title": "Logistic Regression",
    "section": "Recap",
    "text": "Recap\n\nReviewed the relationship between odds and probabilities\nIntroduced logistic regression for binary response variable\nInterpreted the coefficients of a logistic regression model with multiple predictors\nIntroduced generalized linear model"
  },
  {
    "objectID": "slides/19-logistic-regression-notes.html#questions-from-this-weeks-content-1",
    "href": "slides/19-logistic-regression-notes.html#questions-from-this-weeks-content-1",
    "title": "Logistic Regression",
    "section": "Questions from this week’s content?",
    "text": "Questions from this week’s content?"
  },
  {
    "objectID": "slides/19-logistic-regression.html#announcements",
    "href": "slides/19-logistic-regression.html#announcements",
    "title": "Logistic Regression",
    "section": "Announcements",
    "text": "Announcements\n\nProject Presentations in lab on Friday, March 28\n\nCheck email for presentation order and feedback assignments\n\nStatistics experience due April 22"
  },
  {
    "objectID": "slides/19-logistic-regression.html#questions-from-this-weeks-content",
    "href": "slides/19-logistic-regression.html#questions-from-this-weeks-content",
    "title": "Logistic Regression",
    "section": "Questions from this week’s content?",
    "text": "Questions from this week’s content?"
  },
  {
    "objectID": "slides/19-logistic-regression.html#topics",
    "href": "slides/19-logistic-regression.html#topics",
    "title": "Logistic Regression",
    "section": "Topics",
    "text": "Topics\n\nLogistic regression for binary response variable\nUse logistic regression model to calculate predicted odds and probabilities\nInterpret the coefficients of a logistic regression model with\n\na single categorical predictor\na single quantitative predictor\nmultiple predictors"
  },
  {
    "objectID": "slides/19-logistic-regression.html#computational-setup",
    "href": "slides/19-logistic-regression.html#computational-setup",
    "title": "Logistic Regression",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(Stat2Data) #contains data set\nlibrary(patchwork)\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/19-logistic-regression.html#do-teenagers-get-7-hours-of-sleep",
    "href": "slides/19-logistic-regression.html#do-teenagers-get-7-hours-of-sleep",
    "title": "Logistic Regression",
    "section": "Do teenagers get 7+ hours of sleep?",
    "text": "Do teenagers get 7+ hours of sleep?\n\n\nStudents in grades 9 - 12 surveyed about health risk behaviors including whether they usually get 7 or more hours of sleep.\nSleep7\n1: yes\n0: no\n\n\n\n# A tibble: 446 × 6\n     Age Sleep7 Sleep           SmokeLife SmokeDaily MarijuaEver\n   &lt;int&gt;  &lt;int&gt; &lt;fct&gt;           &lt;fct&gt;     &lt;fct&gt;            &lt;int&gt;\n 1    16      1 8 hours         Yes       Yes                  1\n 2    17      0 5 hours         Yes       Yes                  1\n 3    18      0 5 hours         Yes       Yes                  1\n 4    17      1 7 hours         Yes       No                   1\n 5    15      0 4 or less hours No        No                   0\n 6    17      0 6 hours         No        No                   0\n 7    17      1 7 hours         No        No                   0\n 8    16      1 8 hours         Yes       No                   0\n 9    16      1 8 hours         No        No                   0\n10    18      0 4 or less hours Yes       Yes                  1\n# ℹ 436 more rows"
  },
  {
    "objectID": "slides/19-logistic-regression.html#lets-fit-a-linear-regression-model",
    "href": "slides/19-logistic-regression.html#lets-fit-a-linear-regression-model",
    "title": "Logistic Regression",
    "section": "Let’s fit a linear regression model",
    "text": "Let’s fit a linear regression model\nOutcome: \\(Y\\) = 1: yes, 0: no"
  },
  {
    "objectID": "slides/19-logistic-regression.html#lets-use-proportions",
    "href": "slides/19-logistic-regression.html#lets-use-proportions",
    "title": "Logistic Regression",
    "section": "Let’s use proportions",
    "text": "Let’s use proportions\nOutcome: Probability of getting 7+ hours of sleep"
  },
  {
    "objectID": "slides/19-logistic-regression.html#what-happens-if-we-zoom-out",
    "href": "slides/19-logistic-regression.html#what-happens-if-we-zoom-out",
    "title": "Logistic Regression",
    "section": "What happens if we zoom out?",
    "text": "What happens if we zoom out?\nOutcome: Probability of getting 7+ hours of sleep\n\n🛑 This model produces predictions outside of 0 and 1."
  },
  {
    "objectID": "slides/19-logistic-regression.html#lets-try-another-model",
    "href": "slides/19-logistic-regression.html#lets-try-another-model",
    "title": "Logistic Regression",
    "section": "Let’s try another model",
    "text": "Let’s try another model\n\n✅ This model (called a logistic regression model) only produces predictions between 0 and 1."
  },
  {
    "objectID": "slides/19-logistic-regression.html#binary-response-variable",
    "href": "slides/19-logistic-regression.html#binary-response-variable",
    "title": "Logistic Regression",
    "section": "Binary response variable",
    "text": "Binary response variable\n\n\n\\(Y = 1: \\text{ yes}, 0: \\text{ no}\\)\n\\(\\pi\\): probability that \\(Y=1\\), i.e., \\(P(Y = 1)\\)\n\\(\\frac{\\pi}{1-\\pi}\\): odds that \\(Y = 1\\)\n\\(\\log\\big(\\frac{\\pi}{1-\\pi}\\big)\\): log odds\nGo from \\(\\pi\\) to \\(\\log\\big(\\frac{\\pi}{1-\\pi}\\big)\\) using the logit transformation"
  },
  {
    "objectID": "slides/19-logistic-regression.html#from-odds-to-probabilities",
    "href": "slides/19-logistic-regression.html#from-odds-to-probabilities",
    "title": "Logistic Regression",
    "section": "From odds to probabilities",
    "text": "From odds to probabilities\n\nLogistic model: log odds = \\(\\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\mathbf{X}\\boldsymbol{\\beta}\\)\nOdds = \\(\\exp\\big\\{\\log\\big(\\frac{\\pi}{1-\\pi}\\big)\\big\\} = \\frac{\\pi}{1-\\pi}\\)\nCombining (1) and (2) with what we saw earlier\n\n\n\\[\\text{probability} = \\pi = \\frac{\\exp\\{\\mathbf{X}\\boldsymbol{\\beta}\\}}{1 + \\exp\\{\\mathbf{X}\\boldsymbol{\\beta}\\}}\\]"
  },
  {
    "objectID": "slides/19-logistic-regression.html#sigmoid-function",
    "href": "slides/19-logistic-regression.html#sigmoid-function",
    "title": "Logistic Regression",
    "section": "Sigmoid Function",
    "text": "Sigmoid Function\nWe call this function relating the probability to the predictors a sigmoid function, \\[\n\\sigma(x) = \\frac{\\exp\\{x\\}}{1 + \\exp\\{x\\}}= \\frac{1}{1+\\text{exp}\\{-x\\}}.\\]"
  },
  {
    "objectID": "slides/19-logistic-regression.html#sigmoid-function-1",
    "href": "slides/19-logistic-regression.html#sigmoid-function-1",
    "title": "Logistic Regression",
    "section": "Sigmoid Function",
    "text": "Sigmoid Function"
  },
  {
    "objectID": "slides/19-logistic-regression.html#logistic-regression-model",
    "href": "slides/19-logistic-regression.html#logistic-regression-model",
    "title": "Logistic Regression",
    "section": "Logistic regression model",
    "text": "Logistic regression model\nLogit form: \\[\\text{logit}(\\pi) = \\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\mathbf{X}\\boldsymbol{\\beta}\\]\n\nProbability form:\n\\[\n\\pi = \\frac{\\exp\\{\\mathbf{X}\\boldsymbol{\\beta}\\}}{1 + \\exp\\{\\mathbf{X}\\boldsymbol{\\beta} \\}}  \n\\]\n\n\nLogit and sigmoid link functions are inverses of each other.\n\n\n\n\n\n\nNote\n\n\nMore on link functions later, if time permits"
  },
  {
    "objectID": "slides/19-logistic-regression.html#goal",
    "href": "slides/19-logistic-regression.html#goal",
    "title": "Logistic Regression",
    "section": "Goal",
    "text": "Goal\nWe want to use our data to estimate \\(\\boldsymbol{\\beta}\\) (find \\(\\hat{\\boldsymbol{\\beta}}\\)) and obtain the model:\n\\[\n\\hat\\pi = \\frac{\\exp\\{\\mathbf{X}\\hat{\\boldsymbol\\beta}\\}}{ 1 + \\exp\\{\\mathbf{X}\\hat{\\boldsymbol\\beta}\\}}\n\\]\nIn this modeling scheme, one typically finds \\(\\hat{\\boldsymbol{\\beta}}\\) by maximizing the likelihood function."
  },
  {
    "objectID": "slides/19-logistic-regression.html#linear-regression-vs.-logistic-regression",
    "href": "slides/19-logistic-regression.html#linear-regression-vs.-logistic-regression",
    "title": "Logistic Regression",
    "section": "Linear Regression vs. Logistic Regression",
    "text": "Linear Regression vs. Logistic Regression\n\n\nLinear regression:\n\nQuantitative outcome\n\\(y_i = x_i^\\top \\boldsymbol{\\beta} + \\epsilon_i\\)\n\\(E[Y_i] = x_i^\\top \\boldsymbol{\\beta}\\)\nEstimate \\(\\boldsymbol\\beta\\)\nUse \\(\\hat{\\boldsymbol\\beta}\\) to predict \\(\\hat y_i\\)\n\n\nLogistic regression:\n\nBinary outcome\n\\(\\log\\left(\\frac{\\pi_i}{1-\\pi_i}\\right) = x_i^\\top \\boldsymbol{\\beta}\\)\n\\(E[Y_i] = \\pi_i\\)\nEstimate \\(\\boldsymbol\\beta\\)\nUse \\(\\hat{\\boldsymbol\\beta}\\) to predict \\(\\hat \\pi_i\\)"
  },
  {
    "objectID": "slides/19-logistic-regression.html#likelihood-function-for-boldsymbolbeta",
    "href": "slides/19-logistic-regression.html#likelihood-function-for-boldsymbolbeta",
    "title": "Logistic Regression",
    "section": "Likelihood function for \\(\\boldsymbol{\\beta}\\)",
    "text": "Likelihood function for \\(\\boldsymbol{\\beta}\\)\n\n\\(P(Y_i = 1) = \\pi_i\\). What likelihood function should we use?\n\n\n\n\\(f(y_i | x_i, \\boldsymbol{\\beta}) = \\pi_i^{y_i} (1-\\pi_i)^{1-y_i}\\)\n\n\n\n\n\\(Y_i\\)’s are independent, so\n\n\\[f(y_1, \\dots, y_n) = \\prod_{i=1}^n \\pi_i^{y_i} (1-\\pi_i)^{1-y_i}\\]"
  },
  {
    "objectID": "slides/19-logistic-regression.html#likelihood",
    "href": "slides/19-logistic-regression.html#likelihood",
    "title": "Logistic Regression",
    "section": "Likelihood",
    "text": "Likelihood\nThe likelihood function for \\(\\boldsymbol\\beta\\) is\n\\[\n\\begin{aligned}\nL&(\\boldsymbol\\beta| x_1, \\dots, x_n, y_1, \\dots, y_n) \\\\[5pt]\n&=  \\prod_{i=1}^n \\pi_i^{y_i} (1-\\pi_i)^{1-y_i} \\\\[10pt]\n\\end{aligned}\n\\] \n\nWe will use the log-likelihood function to find the MLEs"
  },
  {
    "objectID": "slides/19-logistic-regression.html#log-likelihood",
    "href": "slides/19-logistic-regression.html#log-likelihood",
    "title": "Logistic Regression",
    "section": "Log-likelihood",
    "text": "Log-likelihood\nThe log-likelihood function for \\(\\boldsymbol\\beta\\) is\n\\[\n\\begin{aligned}\n\\log &L(\\boldsymbol\\beta | x_1, \\dots, x_n, y_1, \\dots, y_n)\n  \\\\[8pt]\n& = \\sum_{i=1}^n\\log(\\pi_i^{y_i}(1-\\pi_i)^{1-y_i})\\\\\n&= \\sum_{i=1}^n\\left(y_i\\log (\\pi_i) + (1-y_i)\\log(1-\\pi_i)\\right)\\\\\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/19-logistic-regression.html#log-likelihood-1",
    "href": "slides/19-logistic-regression.html#log-likelihood-1",
    "title": "Logistic Regression",
    "section": "Log-likelihood",
    "text": "Log-likelihood\nPlugging in \\(\\pi_i = \\frac{\\exp\\{x_i^\\top \\boldsymbol\\beta\\}}{1+\\exp\\{x_i^\\top \\boldsymbol\\beta\\}}\\) and simplifying, we get:\n\\[\n\\begin{aligned}\\log &L(\\boldsymbol\\beta | x_1, \\dots, x_n, y_1, \\dots, y_n) \\\\\n&= \\sum_{i=1}^n y_i x_i^\\top \\boldsymbol\\beta - \\sum_{i=1}^n \\log(1+ \\exp\\{x_i^\\top \\beta\\})\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/19-logistic-regression.html#finding-the-mle",
    "href": "slides/19-logistic-regression.html#finding-the-mle",
    "title": "Logistic Regression",
    "section": "Finding the MLE",
    "text": "Finding the MLE\n\nTaking the derivative:\n\n\\[\n\\begin{aligned}\n\\frac{\\partial \\log L}{\\partial \\boldsymbol\\beta} =\\sum_{i=1}^n y_i x_i^\\top\n&- \\sum_{i=1}^n \\frac{\\exp\\{x_i^\\top \\boldsymbol\\beta\\} x_i^\\top}{1+\\exp\\{x_i^\\top \\boldsymbol\\beta\\}}\n\\end{aligned}\n\\]\n\n\nIf we set this to zero, there is no closed form solution.\n\n\n\n\nR uses numerical approximation to find the MLE."
  },
  {
    "objectID": "slides/19-logistic-regression.html#risk-of-coronary-heart-disease",
    "href": "slides/19-logistic-regression.html#risk-of-coronary-heart-disease",
    "title": "Logistic Regression",
    "section": "Risk of coronary heart disease",
    "text": "Risk of coronary heart disease\nThis data set is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. We want to examine the relationship between various health characteristics and the risk of having heart disease.\n\nhigh_risk: 1 = High risk of having heart disease in next 10 years, 0 = Not high risk of having heart disease in next 10 years\nage: Age at exam time (in years)\neducation: 1 = Some High School, 2 = High School or GED, 3 = Some College or Vocational School, 4 = College"
  },
  {
    "objectID": "slides/19-logistic-regression.html#data-heart_disease",
    "href": "slides/19-logistic-regression.html#data-heart_disease",
    "title": "Logistic Regression",
    "section": "Data: heart_disease",
    "text": "Data: heart_disease\n\n\n# A tibble: 4,135 × 3\n     age education high_risk\n   &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt;    \n 1    39 4         0        \n 2    46 2         0        \n 3    48 1         0        \n 4    61 3         1        \n 5    46 3         0        \n 6    43 2         0        \n 7    63 1         1        \n 8    45 2         0        \n 9    52 1         0        \n10    43 1         0        \n# ℹ 4,125 more rows"
  },
  {
    "objectID": "slides/19-logistic-regression.html#univariate-eda",
    "href": "slides/19-logistic-regression.html#univariate-eda",
    "title": "Logistic Regression",
    "section": "Univariate EDA",
    "text": "Univariate EDA"
  },
  {
    "objectID": "slides/19-logistic-regression.html#bivariate-eda",
    "href": "slides/19-logistic-regression.html#bivariate-eda",
    "title": "Logistic Regression",
    "section": "Bivariate EDA",
    "text": "Bivariate EDA"
  },
  {
    "objectID": "slides/19-logistic-regression.html#bivariate-eda-code",
    "href": "slides/19-logistic-regression.html#bivariate-eda-code",
    "title": "Logistic Regression",
    "section": "Bivariate EDA code",
    "text": "Bivariate EDA code\n\n{r}\n#| echo: false\n\np1 &lt;- ggplot(heart_disease, aes(x = high_risk, y = age)) +\n  geom_boxplot(fill = \"steelblue\") +\n  labs(x = \"High risk - 1: yes, 0: no\",\n       y = \"Age\")\n\np2 &lt;- ggplot(heart_disease, aes(x = education, fill = high_risk)) +\n  geom_bar(position = \"fill\", color = \"black\") +\n  labs(x = \"Education\",\n    fill = \"High risk\") +\n  scale_fill_viridis_d() +\n  theme(legend.position = \"bottom\")\n\np1 + p2"
  },
  {
    "objectID": "slides/19-logistic-regression.html#lets-fit-the-model",
    "href": "slides/19-logistic-regression.html#lets-fit-the-model",
    "title": "Logistic Regression",
    "section": "Let’s fit the model",
    "text": "Let’s fit the model\n\n\nheart_edu_age_fit &lt;- glm(high_risk ~ age + education, \n                         data  = heart_disease, \n                         family = \"binomial\")\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-5.385\n0.308\n-17.507\n0.000\n\n\nage\n0.073\n0.005\n13.385\n0.000\n\n\neducation2\n-0.242\n0.112\n-2.162\n0.031\n\n\neducation3\n-0.235\n0.134\n-1.761\n0.078\n\n\neducation4\n-0.020\n0.148\n-0.136\n0.892\n\n\n\n\n\n\\[\n\\begin{aligned}\n\\log\\Big(\\frac{\\hat{\\pi}}{1-\\hat{\\pi}}\\Big) =& -5.385 + 0.073 \\times \\text{age} - 0.242\\times \\text{education}_2 \\\\\n&- 0.235\\times\\text{education}_3 - 0.020 \\times\\text{education}_4\n\\end{aligned}\n\\] where \\(\\hat{\\pi}\\) is the predicted probability of being high risk of having heart disease in the next 10 years"
  },
  {
    "objectID": "slides/19-logistic-regression.html#interpretation-in-terms-of-log-odds",
    "href": "slides/19-logistic-regression.html#interpretation-in-terms-of-log-odds",
    "title": "Logistic Regression",
    "section": "Interpretation in terms of log-odds",
    "text": "Interpretation in terms of log-odds\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-5.385\n0.308\n-17.507\n0.000\n\n\nage\n0.073\n0.005\n13.385\n0.000\n\n\neducation2\n-0.242\n0.112\n-2.162\n0.031\n\n\neducation3\n-0.235\n0.134\n-1.761\n0.078\n\n\neducation4\n-0.020\n0.148\n-0.136\n0.892\n\n\n\n\n\n\neducation4: The log-odds of being high risk for heart disease are expected to be 0.020 less for those with a college degree compared to those with some high school, holding age constant.\n\n\n\n\n\n\n\nWarning\n\n\nWe would not use the interpretation in terms of log-odds in practice."
  },
  {
    "objectID": "slides/19-logistic-regression.html#interpretation-in-terms-of-log-odds-1",
    "href": "slides/19-logistic-regression.html#interpretation-in-terms-of-log-odds-1",
    "title": "Logistic Regression",
    "section": "Interpretation in terms of log-odds",
    "text": "Interpretation in terms of log-odds\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-5.385\n0.308\n-17.507\n0.000\n\n\nage\n0.073\n0.005\n13.385\n0.000\n\n\neducation2\n-0.242\n0.112\n-2.162\n0.031\n\n\neducation3\n-0.235\n0.134\n-1.761\n0.078\n\n\neducation4\n-0.020\n0.148\n-0.136\n0.892\n\n\n\n\n\n\nage: For each additional year in age, the log-odds of being high risk for heart disease are expected to increase by 0.073, holding education level constant.\n\n\n\n\n\n\n\nWarning\n\n\nWe would not use the interpretation in terms of log-odds in practice."
  },
  {
    "objectID": "slides/19-logistic-regression.html#interpretation-in-terms-of-odds",
    "href": "slides/19-logistic-regression.html#interpretation-in-terms-of-odds",
    "title": "Logistic Regression",
    "section": "Interpretation in terms of odds",
    "text": "Interpretation in terms of odds\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-5.385\n0.308\n-17.507\n0.000\n\n\nage\n0.073\n0.005\n13.385\n0.000\n\n\neducation2\n-0.242\n0.112\n-2.162\n0.031\n\n\neducation3\n-0.235\n0.134\n-1.761\n0.078\n\n\neducation4\n-0.020\n0.148\n-0.136\n0.892\n\n\n\n\n\n\neducation4: The odds of being high risk for heart disease for those with a college degree are expected to be 0.98 (exp{-0.020}) times the odds for those with some high school, holding age constant.\n\n\n\n\n\n\nNote\n\n\nIn logistic regression with 2+ predictors, \\(exp\\{\\hat{\\beta}_j\\}\\) is often called the adjusted odds ratio (AOR)."
  },
  {
    "objectID": "slides/19-logistic-regression.html#interpretation-in-terms-of-odds-1",
    "href": "slides/19-logistic-regression.html#interpretation-in-terms-of-odds-1",
    "title": "Logistic Regression",
    "section": "Interpretation in terms of odds",
    "text": "Interpretation in terms of odds\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-5.385\n0.308\n-17.507\n0.000\n\n\nage\n0.073\n0.005\n13.385\n0.000\n\n\neducation2\n-0.242\n0.112\n-2.162\n0.031\n\n\neducation3\n-0.235\n0.134\n-1.761\n0.078\n\n\neducation4\n-0.020\n0.148\n-0.136\n0.892\n\n\n\n\n\n\nage: For each additional year in age, the odds being high risk for heart disease are expected to multiply by a factor of 1.08 (exp(0.073)), holding education level constant.\nAlternate interpretation: For each additional year in age, the odds of being high risk for heart disease are expected to increase by 8%.\n\n\n\n\n\n\nNote\n\n\nIn logistic regression with 2+ predictors, \\(exp\\{\\hat{\\beta}_j\\}\\) is often called the adjusted odds ratio (AOR)."
  },
  {
    "objectID": "slides/19-logistic-regression.html#introduction-to-glms",
    "href": "slides/19-logistic-regression.html#introduction-to-glms",
    "title": "Logistic Regression",
    "section": "Introduction to GLMs",
    "text": "Introduction to GLMs\n\n\nWider class of models.\nResponse variable does not have to be continuous and/or normal.\nVariance does not have to be constant\nStill need to specify distribution of outcome variable (randomness).\nDoes not require a linear relationship between response and explanatory variable. Instead, assumes linear relationship between the transformed expected response (ex. \\(\\text{logit}(\\pi_i)\\)) and predictors."
  },
  {
    "objectID": "slides/19-logistic-regression.html#generalization-of-linear-model",
    "href": "slides/19-logistic-regression.html#generalization-of-linear-model",
    "title": "Logistic Regression",
    "section": "Generalization of Linear Model",
    "text": "Generalization of Linear Model\n\nLinear model\n\\(E[Y_i] = \\mu_i = x_i^\\top\\boldsymbol\\beta\\).\n\\(Y_i \\overset{ind}{\\sim} N(\\mu_i, \\sigma^2)\\).\n\n\n\nGLM\n\\(g\\left(E[Y_i]\\right) = g(\\mu_i)  = x_i^\\top \\beta\\). Alternatively, \\(\\mu_i \\sim g^{-1}(x_i^\\top \\beta)\\).\n\\(Y_i \\overset{ind}{\\sim} f(\\mu_i)\\).\n\n\n\n\n\n\n\n\n\nNote\n\n\nWe call \\(g\\) a link function"
  },
  {
    "objectID": "slides/19-logistic-regression.html#examples-of-link-functions",
    "href": "slides/19-logistic-regression.html#examples-of-link-functions",
    "title": "Logistic Regression",
    "section": "Examples of link functions",
    "text": "Examples of link functions\nLinear regression\n\\(g(\\mu_i) = \\mu_i\\) and \\(Y_i\\sim N(\\mu_i,\\sigma^2)\\).\n\nLogistic regression\n\\(g(\\pi_i) = \\text{logit}(\\pi_i)\\) (note, \\(E[Y_i] = \\pi_i\\)). \\(Y_i \\sim \\text{Bernoulli}(\\pi_i)\\). Alternatively, \\(\\pi_i = \\sigma(x_i^\\top\\boldsymbol\\beta)\\) where \\(\\sigma\\) is the sigmoid function.\n\n\nProbit model\n\\(\\pi_i = \\Phi(x_i^\\top\\boldsymbol\\beta)\\), where \\(\\Phi\\) is the cdf of standard normal. \\(Y_i \\sim \\text{Bernoulli}(\\pi_i)\\). \\(g(\\pi_i) = \\Phi^{-1}(\\pi_i)\\) is called a probit link."
  },
  {
    "objectID": "slides/19-logistic-regression.html#predicted-log-odds",
    "href": "slides/19-logistic-regression.html#predicted-log-odds",
    "title": "Logistic Regression",
    "section": "Predicted log odds",
    "text": "Predicted log odds\n\nheart_disease_aug = \n  augment(heart_edu_age_fit) \nheart_disease_aug|&gt; select(.fitted, .resid)|&gt;\n  head(6)\n\n# A tibble: 6 × 2\n  .fitted .resid\n    &lt;dbl&gt;  &lt;dbl&gt;\n1   -2.55 -0.388\n2   -2.26 -0.446\n3   -1.87 -0.536\n4   -1.15  1.69 \n5   -2.25 -0.448\n6   -2.48 -0.402\n\n\n\nFor observation 1\n\\[\\text{predicted odds} = \\hat{\\omega} = \\frac{\\hat{\\pi}}{1-\\hat{\\pi}} = \\exp\\{-2.548\\} = 0.078\\]"
  },
  {
    "objectID": "slides/19-logistic-regression.html#predicted-probabilities",
    "href": "slides/19-logistic-regression.html#predicted-probabilities",
    "title": "Logistic Regression",
    "section": "Predicted probabilities",
    "text": "Predicted probabilities\n\nheart_disease_aug$predicted_prob &lt;- \n  predict.glm(heart_edu_age_fit, heart_disease, type = \"response\")\nheart_disease_aug|&gt;\n  select(.fitted,predicted_prob) |&gt;\n  head(6)\n\n# A tibble: 6 × 2\n  .fitted predicted_prob\n    &lt;dbl&gt;          &lt;dbl&gt;\n1   -2.55         0.0726\n2   -2.26         0.0948\n3   -1.87         0.134 \n4   -1.15         0.240 \n5   -2.25         0.0954\n6   -2.48         0.0775\n\n\n\nFor observation 1\n\\[\\text{predicted probability} = \\hat{\\pi} = \\frac{\\exp\\{-2.548\\}}{1 + \\exp\\{-2.548\\}} = 0.073\\]"
  },
  {
    "objectID": "slides/19-logistic-regression.html#predicted-classes",
    "href": "slides/19-logistic-regression.html#predicted-classes",
    "title": "Logistic Regression",
    "section": "Predicted classes",
    "text": "Predicted classes\n\n# Convert probabilities to binary predictions (0 or 1)\nheart_disease_aug &lt;- heart_disease_aug |&gt;\n  mutate(predicted_class =  ifelse(predicted_prob &gt; 0.5, 1, 0))\nheart_disease_aug |&gt;\n  select(predicted_prob, predicted_class) \n\n# A tibble: 4,135 × 2\n   predicted_prob predicted_class\n            &lt;dbl&gt;           &lt;dbl&gt;\n 1         0.0726               0\n 2         0.0948               0\n 3         0.134                0\n 4         0.240                0\n 5         0.0954               0\n 6         0.0775               0\n 7         0.317                0\n 8         0.0887               0\n 9         0.172                0\n10         0.0967               0\n# ℹ 4,125 more rows"
  },
  {
    "objectID": "slides/19-logistic-regression.html#observed-vs.-predicted",
    "href": "slides/19-logistic-regression.html#observed-vs.-predicted",
    "title": "Logistic Regression",
    "section": "Observed vs. predicted",
    "text": "Observed vs. predicted\n\nWhat does the following table show?\n\n\nheart_disease_aug|&gt;\n  count(high_risk, predicted_class)\n\n# A tibble: 2 × 3\n  high_risk predicted_class     n\n  &lt;fct&gt;               &lt;dbl&gt; &lt;int&gt;\n1 0                       0  3507\n2 1                       0   628\n\n\n\n\nThe predicted_class is the class with the probability of occurring higher than 0.5. What is a limitation to using this method to determine the predicted class?"
  },
  {
    "objectID": "slides/19-logistic-regression.html#recap-1",
    "href": "slides/19-logistic-regression.html#recap-1",
    "title": "Logistic Regression",
    "section": "Recap",
    "text": "Recap\n\nReviewed the relationship between odds and probabilities\nIntroduced logistic regression for binary response variable\nInterpreted the coefficients of a logistic regression model with multiple predictors\nIntroduced generalized linear model"
  },
  {
    "objectID": "slides/19-logistic-regression.html#questions-from-this-weeks-content-1",
    "href": "slides/19-logistic-regression.html#questions-from-this-weeks-content-1",
    "title": "Logistic Regression",
    "section": "Questions from this week’s content?",
    "text": "Questions from this week’s content?"
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html",
    "href": "slides/06-mlr-pt2-notes.html",
    "title": "Multiple linear regression",
    "section": "",
    "text": "Lab 02 due TODAY at 11:59pm\nHW 01 due Thursday, January 30 at 11:59pm"
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html#announcements",
    "href": "slides/06-mlr-pt2-notes.html#announcements",
    "title": "Multiple linear regression",
    "section": "",
    "text": "Lab 02 due TODAY at 11:59pm\nHW 01 due Thursday, January 30 at 11:59pm"
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html#topics",
    "href": "slides/06-mlr-pt2-notes.html#topics",
    "title": "Multiple linear regression",
    "section": "Topics",
    "text": "Topics\n\nCategorical predictors\nCentering quantitative predictors\nStandardizing quantitative predictors\nInteraction terms"
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html#computing-setup",
    "href": "slides/06-mlr-pt2-notes.html#computing-setup",
    "title": "Multiple linear regression",
    "section": "Computing setup",
    "text": "Computing setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(viridis) #adjust color palette\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))"
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html#data-peer-to-peer-lender",
    "href": "slides/06-mlr-pt2-notes.html#data-peer-to-peer-lender",
    "title": "Multiple linear regression",
    "section": "Data: Peer-to-peer lender",
    "text": "Data: Peer-to-peer lender\nToday’s data is a sample of 50 loans made through a peer-to-peer lending club. The data is in the loan50 data frame in the openintro R package.\n\n\n# A tibble: 50 × 4\n   annual_income_th debt_to_income verified_income interest_rate\n              &lt;dbl&gt;          &lt;dbl&gt; &lt;fct&gt;                   &lt;dbl&gt;\n 1             59           0.558  Not Verified            10.9 \n 2             60           1.31   Not Verified             9.92\n 3             75           1.06   Verified                26.3 \n 4             75           0.574  Not Verified             9.92\n 5            254           0.238  Not Verified             9.43\n 6             67           1.08   Source Verified          9.92\n 7             28.8         0.0997 Source Verified         17.1 \n 8             80           0.351  Not Verified             6.08\n 9             34           0.698  Not Verified             7.97\n10             80           0.167  Source Verified         12.6 \n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html#variables",
    "href": "slides/06-mlr-pt2-notes.html#variables",
    "title": "Multiple linear regression",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\n\nannual_income_th: Annual income (in $1000s)\ndebt_to_income: Debt-to-income ratio, i.e. the percentage of a borrower’s total debt divided by their total income\nverified_income: Whether borrower’s income source and amount have been verified (Not Verified, Source Verified, Verified)\n\n\nResponse: interest_rate: Interest rate for the loan"
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html#response-vs.-predictors",
    "href": "slides/06-mlr-pt2-notes.html#response-vs.-predictors",
    "title": "Multiple linear regression",
    "section": "Response vs. predictors",
    "text": "Response vs. predictors\n\n\n\n\n\n\n\n\n\nGoal: Use these predictors in a single model to understand variability in interest rate."
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html#model-fit-in-r",
    "href": "slides/06-mlr-pt2-notes.html#model-fit-in-r",
    "title": "Multiple linear regression",
    "section": "Model fit in R",
    "text": "Model fit in R\n\nint_fit &lt;- lm(interest_rate ~ debt_to_income + verified_income  + annual_income_th,\n              data = loan50)\n\ntidy(int_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n10.726\n1.507\n7.116\n0.000\n\n\ndebt_to_income\n0.671\n0.676\n0.993\n0.326\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n\n\nannual_income_th\n-0.021\n0.011\n-1.804\n0.078"
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html#matrix-form-of-multiple-linear-regression",
    "href": "slides/06-mlr-pt2-notes.html#matrix-form-of-multiple-linear-regression",
    "title": "Multiple linear regression",
    "section": "Matrix form of multiple linear regression",
    "text": "Matrix form of multiple linear regression\n\\[\n\\underbrace{\n\\begin{bmatrix}\ny_1 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix} }_\n{\\mathbf{y}} \\hspace{3mm}\n=\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n1 &x_{11} & \\dots & x_{1p}\\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\n1 &  x_{n1} & \\dots &x_{np}\n\\end{bmatrix}\n}_{\\mathbf{X}}\n\\hspace{2mm}\n\\underbrace{\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\vdots \\\\\n\\beta_p\n\\end{bmatrix}\n}_{\\boldsymbol{\\beta}}\n\\hspace{3mm}\n+\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n\\epsilon_1 \\\\\n\\vdots\\\\\n\\epsilon_n\n\\end{bmatrix}\n}_\\boldsymbol{\\epsilon}\n\\]\n\nHow might we include a categorical predictor with \\(k\\) levels in the design matrix, \\(\\mathbf{X}\\) ?"
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html#indicator-variables",
    "href": "slides/06-mlr-pt2-notes.html#indicator-variables",
    "title": "Multiple linear regression",
    "section": "Indicator variables",
    "text": "Indicator variables\n\nSuppose there is a categorical variable with \\(k\\) levels\nWe can make \\(k\\) indicator variables from the data - one indicator for each level\nAn indicator (dummy) variable takes values 1 or 0\n\n1 if the observation belongs to that level\n0 if the observation does not belong to that level"
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html#indicator-variables-1",
    "href": "slides/06-mlr-pt2-notes.html#indicator-variables-1",
    "title": "Multiple linear regression",
    "section": "Indicator variables",
    "text": "Indicator variables\nSuppose we want to predict the amount of sleep a Duke student gets based on whether they are in Pratt (Pratt Yes/ No are the only two options). Consider the model\n\\[\nSleep_i = \\beta_0 + \\beta_1\\mathbf{1}(Pratt_i = \\texttt{Yes}) + \\beta_2\\mathbf{1}(Pratt_i = \\texttt{No})\n\\]\n\n\nWrite out the design matrix for this hypothesized linear model.\nDemonstrate that the design matrix is not of full column rank (that is, affirmatively provide one of the columns in terms of the others).\nUse this intuition to explain why when we include categorical predictors, we cannot include both indicators for every level of the variable and an intercept."
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html#indicator-variables-for-verified_income",
    "href": "slides/06-mlr-pt2-notes.html#indicator-variables-for-verified_income",
    "title": "Multiple linear regression",
    "section": "Indicator variables for verified_income",
    "text": "Indicator variables for verified_income\n\nloan50 &lt;- loan50 |&gt;\n  mutate(\n    not_verified = factor(if_else(verified_income == \"Not Verified\", 1, 0)),\n    source_verified = factor(if_else(verified_income == \"Source Verified\", 1, 0)),\n    verified = factor(if_else(verified_income == \"Verified\", 1, 0))\n  )\n\n. . .\n\n\n# A tibble: 3 × 4\n  verified_income not_verified source_verified verified\n  &lt;fct&gt;           &lt;fct&gt;        &lt;fct&gt;           &lt;fct&gt;   \n1 Not Verified    1            0               0       \n2 Verified        0            0               1       \n3 Source Verified 0            1               0"
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html#indicator-variables-in-the-model",
    "href": "slides/06-mlr-pt2-notes.html#indicator-variables-in-the-model",
    "title": "Multiple linear regression",
    "section": "Indicator variables in the model",
    "text": "Indicator variables in the model\nGiven a categorical predictor with \\(k\\) levels…\n\nUse \\(k-1\\) indicator variables in the model\nThe baseline is the category that doesn’t have a term in the model\n\nThis is also called the reference level\n\nThe coefficients of the indicator variables in the model are interpreted as the expected change in the response compared to the baseline, holding all other variables constant."
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html#interpreting-verified_income",
    "href": "slides/06-mlr-pt2-notes.html#interpreting-verified_income",
    "title": "Multiple linear regression",
    "section": "Interpreting verified_income",
    "text": "Interpreting verified_income\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n10.726\n1.507\n7.116\n0.000\n7.690\n13.762\n\n\ndebt_to_income\n0.671\n0.676\n0.993\n0.326\n-0.690\n2.033\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n-0.606\n5.028\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n3.253\n10.508\n\n\nannual_income_th\n-0.021\n0.011\n-1.804\n0.078\n-0.043\n0.002\n\n\n\n\n\n\n\n. . .\n\n\nThe baseline level is Not verified.\nPeople with source verified income are expected to take a loan with an interest rate that is 2.211% higher, on average, than the rate on loans to those whose income is not verified, holding all else constant."
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html#centering",
    "href": "slides/06-mlr-pt2-notes.html#centering",
    "title": "Multiple linear regression",
    "section": "Centering",
    "text": "Centering\n\nCentering a quantitative predictor means shifting every value by some constant \\(C\\)\nOne common type of centering is mean-centering, in which every value of a predictor is shifted by its mean\nOnly quantitative predictors are centered\nCenter all quantitative predictors in the model for ease of interpretation\n\n\nWhat is one reason one might want to center the quantitative predictors? What is are the units of centered variables?"
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html#centering-1",
    "href": "slides/06-mlr-pt2-notes.html#centering-1",
    "title": "Multiple linear regression",
    "section": "Centering",
    "text": "Centering\nUse the scale() function with center = TRUE and scale = FALSE to mean-center variables\n\nloan50 &lt;- loan50 |&gt;\n  mutate(debt_to_inc_cent = scale(debt_to_income, center = TRUE, scale = FALSE), \n         annual_inc_cent = scale(annual_income_th, center = TRUE, scale = FALSE))\n\nlm(interest_rate ~ debt_to_inc_cent + verified_income + annual_inc_cent, data = loan50) |&gt; \n  tidy() |&gt; kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n9.444\n0.977\n9.663\n0.000\n\n\ndebt_to_inc_cent\n0.671\n0.676\n0.993\n0.326\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n\n\nannual_inc_cent\n-0.021\n0.011\n-1.804\n0.078"
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html#centering-2",
    "href": "slides/06-mlr-pt2-notes.html#centering-2",
    "title": "Multiple linear regression",
    "section": "Centering",
    "text": "Centering\n\n\n\n\n\nTerm\nOriginal Model\nCentered Model\n\n\n\n\n(Intercept)\n10.726\n9.444\n\n\ndebt_to_income\n0.671\n0.671\n\n\nverified_incomeSource Verified\n2.211\n2.211\n\n\nverified_incomeVerified\n6.880\n6.880\n\n\nannual_income_th\n-0.021\n-0.021\n\n\n\n\n\n\nHow has the model changed? How has the model remained the same?"
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html#standardizing",
    "href": "slides/06-mlr-pt2-notes.html#standardizing",
    "title": "Multiple linear regression",
    "section": "Standardizing",
    "text": "Standardizing\n\nStandardizing a quantitative predictor mean shifting every value by the mean and dividing by the standard deviation of that variable\nOnly quantitative predictors are standardized\nStandardize all quantitative predictors in the model for ease of interpretation\n\n\nWhat is one reason one might want to standardize the quantitative predictors? What is are the units of standardized variables?"
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html#standardizing-1",
    "href": "slides/06-mlr-pt2-notes.html#standardizing-1",
    "title": "Multiple linear regression",
    "section": "Standardizing",
    "text": "Standardizing\nUse the scale() function with center = TRUE and scale = TRUE to standardized variables\n\nloan50 &lt;- loan50 |&gt;\n  mutate(debt_to_inc_std = scale(debt_to_income, center = TRUE, scale = TRUE), \n         annual_inc_std = scale(annual_income_th, center = TRUE, scale = TRUE))\n\nlm(interest_rate ~ debt_to_inc_std + verified_income + annual_inc_std, data = loan50) |&gt;\n  tidy() |&gt; kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n9.444\n0.977\n9.663\n0.000\n\n\ndebt_to_inc_std\n0.643\n0.648\n0.993\n0.326\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n\n\nannual_inc_std\n-1.180\n0.654\n-1.804\n0.078"
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html#standardizing-2",
    "href": "slides/06-mlr-pt2-notes.html#standardizing-2",
    "title": "Multiple linear regression",
    "section": "Standardizing",
    "text": "Standardizing\n\n\n\n\n\nTerm\nOriginal Model\nStandardized Model\n\n\n\n\n(Intercept)\n10.726\n9.444\n\n\ndebt_to_income\n0.671\n0.643\n\n\nverified_incomeSource Verified\n2.211\n2.211\n\n\nverified_incomeVerified\n6.880\n6.880\n\n\nannual_income_th\n-0.021\n-1.180\n\n\n\n\n\n\nHow has the model changed? How has the model remained the same?"
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html#interaction-terms-1",
    "href": "slides/06-mlr-pt2-notes.html#interaction-terms-1",
    "title": "Multiple linear regression",
    "section": "Interaction terms",
    "text": "Interaction terms\n\nSometimes the relationship between a predictor variable and the response depends on the value of another predictor variable.\nThis is an interaction effect.\nTo account for this, we can include interaction terms in the model."
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html#interest-rate-vs.-annual-income",
    "href": "slides/06-mlr-pt2-notes.html#interest-rate-vs.-annual-income",
    "title": "Multiple linear regression",
    "section": "Interest rate vs. annual income",
    "text": "Interest rate vs. annual income\nThe lines are not parallel indicating there is a potential interaction effect. The slope of annual income differs based on the income verification."
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html#interaction-term-in-model",
    "href": "slides/06-mlr-pt2-notes.html#interaction-term-in-model",
    "title": "Multiple linear regression",
    "section": "Interaction term in model",
    "text": "Interaction term in model\n\nint_fit_2 &lt;- lm(interest_rate ~ debt_to_income + verified_income + annual_income_th + verified_income * annual_income_th,\n      data = loan50)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n9.560\n2.034\n4.700\n0.000\n\n\ndebt_to_income\n0.691\n0.685\n1.009\n0.319\n\n\nverified_incomeSource Verified\n3.577\n2.539\n1.409\n0.166\n\n\nverified_incomeVerified\n9.923\n3.654\n2.716\n0.009\n\n\nannual_income_th\n-0.007\n0.020\n-0.341\n0.735\n\n\nverified_incomeSource Verified:annual_income_th\n-0.016\n0.026\n-0.643\n0.523\n\n\nverified_incomeVerified:annual_income_th\n-0.032\n0.033\n-0.979\n0.333"
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html#interpreting-interaction-terms",
    "href": "slides/06-mlr-pt2-notes.html#interpreting-interaction-terms",
    "title": "Multiple linear regression",
    "section": "Interpreting interaction terms",
    "text": "Interpreting interaction terms\n\nWhat the interaction means: The effect of annual income on the interest rate differs by -0.016 when the income is source verified compared to when it is not verified, holding all else constant.\nInterpreting annual_income for source verified: If the income is source verified, we expect the interest rate to decrease by 0.023% (-0.007 + -0.016) for each additional thousand dollars in annual income, holding all else constant."
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html#recap",
    "href": "slides/06-mlr-pt2-notes.html#recap",
    "title": "Multiple linear regression",
    "section": "Recap",
    "text": "Recap\n\nInterpreted categorical predictors\nExplored by \\(k-1\\) indicators are included in a model\nFit and interpreted models with centered and standardized variables\nInterpreted interaction terms"
  },
  {
    "objectID": "slides/06-mlr-pt2-notes.html#next-class",
    "href": "slides/06-mlr-pt2-notes.html#next-class",
    "title": "Multiple linear regression",
    "section": "Next class",
    "text": "Next class\n\nModel comparison for multiple linear regression"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#announcements",
    "href": "slides/06-mlr-pt2.html#announcements",
    "title": "Multiple linear regression",
    "section": "Announcements",
    "text": "Announcements\n\nLab 02 due TODAY at 11:59pm\nHW 01 due Thursday, January 30 at 11:59pm"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#topics",
    "href": "slides/06-mlr-pt2.html#topics",
    "title": "Multiple linear regression",
    "section": "Topics",
    "text": "Topics\n\nCategorical predictors\nCentering quantitative predictors\nStandardizing quantitative predictors\nInteraction terms"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#computing-setup",
    "href": "slides/06-mlr-pt2.html#computing-setup",
    "title": "Multiple linear regression",
    "section": "Computing setup",
    "text": "Computing setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(viridis) #adjust color palette\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#data-peer-to-peer-lender",
    "href": "slides/06-mlr-pt2.html#data-peer-to-peer-lender",
    "title": "Multiple linear regression",
    "section": "Data: Peer-to-peer lender",
    "text": "Data: Peer-to-peer lender\nToday’s data is a sample of 50 loans made through a peer-to-peer lending club. The data is in the loan50 data frame in the openintro R package.\n\n\n# A tibble: 50 × 4\n   annual_income_th debt_to_income verified_income interest_rate\n              &lt;dbl&gt;          &lt;dbl&gt; &lt;fct&gt;                   &lt;dbl&gt;\n 1             59           0.558  Not Verified            10.9 \n 2             60           1.31   Not Verified             9.92\n 3             75           1.06   Verified                26.3 \n 4             75           0.574  Not Verified             9.92\n 5            254           0.238  Not Verified             9.43\n 6             67           1.08   Source Verified          9.92\n 7             28.8         0.0997 Source Verified         17.1 \n 8             80           0.351  Not Verified             6.08\n 9             34           0.698  Not Verified             7.97\n10             80           0.167  Source Verified         12.6 \n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#variables",
    "href": "slides/06-mlr-pt2.html#variables",
    "title": "Multiple linear regression",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\n\nannual_income_th: Annual income (in $1000s)\ndebt_to_income: Debt-to-income ratio, i.e. the percentage of a borrower’s total debt divided by their total income\nverified_income: Whether borrower’s income source and amount have been verified (Not Verified, Source Verified, Verified)\n\n\nResponse: interest_rate: Interest rate for the loan"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#response-vs.-predictors",
    "href": "slides/06-mlr-pt2.html#response-vs.-predictors",
    "title": "Multiple linear regression",
    "section": "Response vs. predictors",
    "text": "Response vs. predictors\n\nGoal: Use these predictors in a single model to understand variability in interest rate."
  },
  {
    "objectID": "slides/06-mlr-pt2.html#model-fit-in-r",
    "href": "slides/06-mlr-pt2.html#model-fit-in-r",
    "title": "Multiple linear regression",
    "section": "Model fit in R",
    "text": "Model fit in R\n\nint_fit &lt;- lm(interest_rate ~ debt_to_income + verified_income  + annual_income_th,\n              data = loan50)\n\ntidy(int_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n10.726\n1.507\n7.116\n0.000\n\n\ndebt_to_income\n0.671\n0.676\n0.993\n0.326\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n\n\nannual_income_th\n-0.021\n0.011\n-1.804\n0.078"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#matrix-form-of-multiple-linear-regression",
    "href": "slides/06-mlr-pt2.html#matrix-form-of-multiple-linear-regression",
    "title": "Multiple linear regression",
    "section": "Matrix form of multiple linear regression",
    "text": "Matrix form of multiple linear regression\n\\[\n\\underbrace{\n\\begin{bmatrix}\ny_1 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix} }_\n{\\mathbf{y}} \\hspace{3mm}\n=\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n1 &x_{11} & \\dots & x_{1p}\\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\n1 &  x_{n1} & \\dots &x_{np}\n\\end{bmatrix}\n}_{\\mathbf{X}}\n\\hspace{2mm}\n\\underbrace{\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\vdots \\\\\n\\beta_p\n\\end{bmatrix}\n}_{\\boldsymbol{\\beta}}\n\\hspace{3mm}\n+\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n\\epsilon_1 \\\\\n\\vdots\\\\\n\\epsilon_n\n\\end{bmatrix}\n}_\\boldsymbol{\\epsilon}\n\\]\n\nHow might we include a categorical predictor with \\(k\\) levels in the design matrix, \\(\\mathbf{X}\\) ?"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#indicator-variables",
    "href": "slides/06-mlr-pt2.html#indicator-variables",
    "title": "Multiple linear regression",
    "section": "Indicator variables",
    "text": "Indicator variables\n\nSuppose there is a categorical variable with \\(k\\) levels\nWe can make \\(k\\) indicator variables from the data - one indicator for each level\nAn indicator (dummy) variable takes values 1 or 0\n\n1 if the observation belongs to that level\n0 if the observation does not belong to that level"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#indicator-variables-1",
    "href": "slides/06-mlr-pt2.html#indicator-variables-1",
    "title": "Multiple linear regression",
    "section": "Indicator variables",
    "text": "Indicator variables\nSuppose we want to predict the amount of sleep a Duke student gets based on whether they are in Pratt (Pratt Yes/ No are the only two options). Consider the model\n\\[\nSleep_i = \\beta_0 + \\beta_1\\mathbf{1}(Pratt_i = \\texttt{Yes}) + \\beta_2\\mathbf{1}(Pratt_i = \\texttt{No})\n\\]\n\n\nWrite out the design matrix for this hypothesized linear model.\nDemonstrate that the design matrix is not of full column rank (that is, affirmatively provide one of the columns in terms of the others).\nUse this intuition to explain why when we include categorical predictors, we cannot include both indicators for every level of the variable and an intercept."
  },
  {
    "objectID": "slides/06-mlr-pt2.html#indicator-variables-for-verified_income",
    "href": "slides/06-mlr-pt2.html#indicator-variables-for-verified_income",
    "title": "Multiple linear regression",
    "section": "Indicator variables for verified_income",
    "text": "Indicator variables for verified_income\n\nloan50 &lt;- loan50 |&gt;\n  mutate(\n    not_verified = factor(if_else(verified_income == \"Not Verified\", 1, 0)),\n    source_verified = factor(if_else(verified_income == \"Source Verified\", 1, 0)),\n    verified = factor(if_else(verified_income == \"Verified\", 1, 0))\n  )\n\n\n\n\n# A tibble: 3 × 4\n  verified_income not_verified source_verified verified\n  &lt;fct&gt;           &lt;fct&gt;        &lt;fct&gt;           &lt;fct&gt;   \n1 Not Verified    1            0               0       \n2 Verified        0            0               1       \n3 Source Verified 0            1               0"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#indicator-variables-in-the-model",
    "href": "slides/06-mlr-pt2.html#indicator-variables-in-the-model",
    "title": "Multiple linear regression",
    "section": "Indicator variables in the model",
    "text": "Indicator variables in the model\nGiven a categorical predictor with \\(k\\) levels…\n\nUse \\(k-1\\) indicator variables in the model\nThe baseline is the category that doesn’t have a term in the model\n\nThis is also called the reference level\n\nThe coefficients of the indicator variables in the model are interpreted as the expected change in the response compared to the baseline, holding all other variables constant."
  },
  {
    "objectID": "slides/06-mlr-pt2.html#interpreting-verified_income",
    "href": "slides/06-mlr-pt2.html#interpreting-verified_income",
    "title": "Multiple linear regression",
    "section": "Interpreting verified_income",
    "text": "Interpreting verified_income\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n10.726\n1.507\n7.116\n0.000\n7.690\n13.762\n\n\ndebt_to_income\n0.671\n0.676\n0.993\n0.326\n-0.690\n2.033\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n-0.606\n5.028\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n3.253\n10.508\n\n\nannual_income_th\n-0.021\n0.011\n-1.804\n0.078\n-0.043\n0.002\n\n\n\n\n\n\n\n\n\n\nThe baseline level is Not verified.\nPeople with source verified income are expected to take a loan with an interest rate that is 2.211% higher, on average, than the rate on loans to those whose income is not verified, holding all else constant."
  },
  {
    "objectID": "slides/06-mlr-pt2.html#centering",
    "href": "slides/06-mlr-pt2.html#centering",
    "title": "Multiple linear regression",
    "section": "Centering",
    "text": "Centering\n\nCentering a quantitative predictor means shifting every value by some constant \\(C\\)\nOne common type of centering is mean-centering, in which every value of a predictor is shifted by its mean\nOnly quantitative predictors are centered\nCenter all quantitative predictors in the model for ease of interpretation\n\n\nWhat is one reason one might want to center the quantitative predictors? What is are the units of centered variables?"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#centering-1",
    "href": "slides/06-mlr-pt2.html#centering-1",
    "title": "Multiple linear regression",
    "section": "Centering",
    "text": "Centering\nUse the scale() function with center = TRUE and scale = FALSE to mean-center variables\n\nloan50 &lt;- loan50 |&gt;\n  mutate(debt_to_inc_cent = scale(debt_to_income, center = TRUE, scale = FALSE), \n         annual_inc_cent = scale(annual_income_th, center = TRUE, scale = FALSE))\n\nlm(interest_rate ~ debt_to_inc_cent + verified_income + annual_inc_cent, data = loan50) |&gt; \n  tidy() |&gt; kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n9.444\n0.977\n9.663\n0.000\n\n\ndebt_to_inc_cent\n0.671\n0.676\n0.993\n0.326\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n\n\nannual_inc_cent\n-0.021\n0.011\n-1.804\n0.078"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#centering-2",
    "href": "slides/06-mlr-pt2.html#centering-2",
    "title": "Multiple linear regression",
    "section": "Centering",
    "text": "Centering\n\n\n\n\n\nTerm\nOriginal Model\nCentered Model\n\n\n\n\n(Intercept)\n10.726\n9.444\n\n\ndebt_to_income\n0.671\n0.671\n\n\nverified_incomeSource Verified\n2.211\n2.211\n\n\nverified_incomeVerified\n6.880\n6.880\n\n\nannual_income_th\n-0.021\n-0.021\n\n\n\n\n\n\nHow has the model changed? How has the model remained the same?"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#standardizing",
    "href": "slides/06-mlr-pt2.html#standardizing",
    "title": "Multiple linear regression",
    "section": "Standardizing",
    "text": "Standardizing\n\nStandardizing a quantitative predictor mean shifting every value by the mean and dividing by the standard deviation of that variable\nOnly quantitative predictors are standardized\nStandardize all quantitative predictors in the model for ease of interpretation\n\n\nWhat is one reason one might want to standardize the quantitative predictors? What is are the units of standardized variables?"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#standardizing-1",
    "href": "slides/06-mlr-pt2.html#standardizing-1",
    "title": "Multiple linear regression",
    "section": "Standardizing",
    "text": "Standardizing\nUse the scale() function with center = TRUE and scale = TRUE to standardized variables\n\nloan50 &lt;- loan50 |&gt;\n  mutate(debt_to_inc_std = scale(debt_to_income, center = TRUE, scale = TRUE), \n         annual_inc_std = scale(annual_income_th, center = TRUE, scale = TRUE))\n\nlm(interest_rate ~ debt_to_inc_std + verified_income + annual_inc_std, data = loan50) |&gt;\n  tidy() |&gt; kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n9.444\n0.977\n9.663\n0.000\n\n\ndebt_to_inc_std\n0.643\n0.648\n0.993\n0.326\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n\n\nannual_inc_std\n-1.180\n0.654\n-1.804\n0.078"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#standardizing-2",
    "href": "slides/06-mlr-pt2.html#standardizing-2",
    "title": "Multiple linear regression",
    "section": "Standardizing",
    "text": "Standardizing\n\n\n\n\n\nTerm\nOriginal Model\nStandardized Model\n\n\n\n\n(Intercept)\n10.726\n9.444\n\n\ndebt_to_income\n0.671\n0.643\n\n\nverified_incomeSource Verified\n2.211\n2.211\n\n\nverified_incomeVerified\n6.880\n6.880\n\n\nannual_income_th\n-0.021\n-1.180\n\n\n\n\n\n\nHow has the model changed? How has the model remained the same?"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#interaction-terms-1",
    "href": "slides/06-mlr-pt2.html#interaction-terms-1",
    "title": "Multiple linear regression",
    "section": "Interaction terms",
    "text": "Interaction terms\n\nSometimes the relationship between a predictor variable and the response depends on the value of another predictor variable.\nThis is an interaction effect.\nTo account for this, we can include interaction terms in the model."
  },
  {
    "objectID": "slides/06-mlr-pt2.html#interest-rate-vs.-annual-income",
    "href": "slides/06-mlr-pt2.html#interest-rate-vs.-annual-income",
    "title": "Multiple linear regression",
    "section": "Interest rate vs. annual income",
    "text": "Interest rate vs. annual income\nThe lines are not parallel indicating there is a potential interaction effect. The slope of annual income differs based on the income verification."
  },
  {
    "objectID": "slides/06-mlr-pt2.html#interaction-term-in-model",
    "href": "slides/06-mlr-pt2.html#interaction-term-in-model",
    "title": "Multiple linear regression",
    "section": "Interaction term in model",
    "text": "Interaction term in model\n\nint_fit_2 &lt;- lm(interest_rate ~ debt_to_income + verified_income + annual_income_th + verified_income * annual_income_th,\n      data = loan50)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n9.560\n2.034\n4.700\n0.000\n\n\ndebt_to_income\n0.691\n0.685\n1.009\n0.319\n\n\nverified_incomeSource Verified\n3.577\n2.539\n1.409\n0.166\n\n\nverified_incomeVerified\n9.923\n3.654\n2.716\n0.009\n\n\nannual_income_th\n-0.007\n0.020\n-0.341\n0.735\n\n\nverified_incomeSource Verified:annual_income_th\n-0.016\n0.026\n-0.643\n0.523\n\n\nverified_incomeVerified:annual_income_th\n-0.032\n0.033\n-0.979\n0.333"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#interpreting-interaction-terms",
    "href": "slides/06-mlr-pt2.html#interpreting-interaction-terms",
    "title": "Multiple linear regression",
    "section": "Interpreting interaction terms",
    "text": "Interpreting interaction terms\n\nWhat the interaction means: The effect of annual income on the interest rate differs by -0.016 when the income is source verified compared to when it is not verified, holding all else constant.\nInterpreting annual_income for source verified: If the income is source verified, we expect the interest rate to decrease by 0.023% (-0.007 + -0.016) for each additional thousand dollars in annual income, holding all else constant."
  },
  {
    "objectID": "slides/06-mlr-pt2.html#recap",
    "href": "slides/06-mlr-pt2.html#recap",
    "title": "Multiple linear regression",
    "section": "Recap",
    "text": "Recap\n\nInterpreted categorical predictors\nExplored by \\(k-1\\) indicators are included in a model\nFit and interpreted models with centered and standardized variables\nInterpreted interaction terms"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#next-class",
    "href": "slides/06-mlr-pt2.html#next-class",
    "title": "Multiple linear regression",
    "section": "Next class",
    "text": "Next class\n\nModel comparison for multiple linear regression"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html",
    "href": "slides/18-prob-odds-notes.html",
    "title": "Probabilities, odds, odds ratios",
    "section": "",
    "text": "Project Presentations in lab on Friday, March 28\nLab 06 due TODAY at 11:59pm\nStatistics experience due April 22\n\n\n\nDrop-in Peer Advising will be happening Wednesday, March 26, from 6:30-8:30 PM in Bostock Lounge for students to stop by with any questions they have around STA/CS/MATH classes, major pathways, or other general advice since shopping carts just opened."
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#announcements",
    "href": "slides/18-prob-odds-notes.html#announcements",
    "title": "Probabilities, odds, odds ratios",
    "section": "",
    "text": "Project Presentations in lab on Friday, March 28\nLab 06 due TODAY at 11:59pm\nStatistics experience due April 22\n\n\n\nDrop-in Peer Advising will be happening Wednesday, March 26, from 6:30-8:30 PM in Bostock Lounge for students to stop by with any questions they have around STA/CS/MATH classes, major pathways, or other general advice since shopping carts just opened."
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#fall-2025-sta-classes",
    "href": "slides/18-prob-odds-notes.html#fall-2025-sta-classes",
    "title": "Probabilities, odds, odds ratios",
    "section": "Fall 2025 STA classes",
    "text": "Fall 2025 STA classes\n\nSTA 240: Probability for Statistical Inference, Modeling, and Data Analysis (or STA 230 or STA 231)\nSTA 322: Study Design: Design of Surveys and Causal Studies\nSTA 323: Statistical Computing\nSTA 325: Machine Learning and Data Mining (need STA 230/231/240)\nSTA 332: Statistical Inference (need STA 230/231/240)\nSTA 344: Introduction to Statistical Modeling of Spatial and Time Series data (need STA 230/231/240)\nSTA 402: Bayesian Statistical Modeling and Data Analysis (need STA 332)\nSTA 465: Introduction to High Dimensional Data Analysis"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#topics",
    "href": "slides/18-prob-odds-notes.html#topics",
    "title": "Probabilities, odds, odds ratios",
    "section": "Topics",
    "text": "Topics\n\nReview: Multicollinearity vs. interaction effects\nLogistic regression for binary response variable\nRelationship between odds and probabilities\nOdds ratios"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#computational-setup",
    "href": "slides/18-prob-odds-notes.html#computational-setup",
    "title": "Probabilities, odds, odds ratios",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(Stat2Data) #contains sleep data set\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#review-multicollinearity-vs.-interactions",
    "href": "slides/18-prob-odds-notes.html#review-multicollinearity-vs.-interactions",
    "title": "Probabilities, odds, odds ratios",
    "section": "Review: Multicollinearity vs. interactions",
    "text": "Review: Multicollinearity vs. interactions\nSuppose we fit a model using flipper length and bill length to understand variability in body mass for Palmer Penguins. We make the plots below as part of the EDA.\n\n\n\n\n\n\n\n\n\n\nWhat are we checking in Plot 1? In Plot 2?"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#types-of-outcome-variables",
    "href": "slides/18-prob-odds-notes.html#types-of-outcome-variables",
    "title": "Probabilities, odds, odds ratios",
    "section": "Types of outcome variables",
    "text": "Types of outcome variables\nQuantitative outcome variable:\n\nSales price of a house in Duke Forest\nModel: Expected sales price given the number of bedrooms, lot size, etc.\n\n. . .\nCategorical outcome variable:\n\nIndicator of being high risk of getting coronary heart disease in the next 10 years\nModel: Probability an adult is high risk of heart disease in the next 10 years given their age, total cholesterol, etc."
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#models-for-categorical-outcomes",
    "href": "slides/18-prob-odds-notes.html#models-for-categorical-outcomes",
    "title": "Probabilities, odds, odds ratios",
    "section": "Models for categorical outcomes",
    "text": "Models for categorical outcomes\n\n\nLogistic regression\n2 Outcomes\n1: Yes, 0: No\n\nMultinomial logistic regression\n3+ Outcomes\n1: Democrat, 2: Republican, 3: Independent"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#example-win-probabilities",
    "href": "slides/18-prob-odds-notes.html#example-win-probabilities",
    "title": "Probabilities, odds, odds ratios",
    "section": "Example: Win probabilities",
    "text": "Example: Win probabilities\nDuke in 2nd round of NCCA March Madness Tournaments\n\n\n\n\nMen’s Basketball\n\n\n\n\nSource: ESPN Gamecast\n\n\n\n\nWomen’s Basketball\n\n\n\n\nSource: ESPN Gamecast"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#do-teenagers-get-7-hours-of-sleep",
    "href": "slides/18-prob-odds-notes.html#do-teenagers-get-7-hours-of-sleep",
    "title": "Probabilities, odds, odds ratios",
    "section": "Do teenagers get 7+ hours of sleep?",
    "text": "Do teenagers get 7+ hours of sleep?\n\n\nStudents in grades 9 - 12 were surveyed about health risk behaviors including whether they usually get 7 or more hours of sleep.\nSleep7\n1: yes\n0: no\n\n\n\n# A tibble: 446 × 2\n     Age Sleep7\n   &lt;int&gt;  &lt;int&gt;\n 1    16      1\n 2    17      0\n 3    18      0\n 4    17      1\n 5    15      0\n 6    17      0\n 7    17      1\n 8    16      1\n 9    16      1\n10    18      0\n# ℹ 436 more rows"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#plot-the-data",
    "href": "slides/18-prob-odds-notes.html#plot-the-data",
    "title": "Probabilities, odds, odds ratios",
    "section": "Plot the data",
    "text": "Plot the data\n\nggplot(sleep, aes(x = Age, y = Sleep7)) +\n  geom_point() + \n  labs(y = \"Getting 7+ hours of sleep\")"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#lets-fit-a-linear-regression-model",
    "href": "slides/18-prob-odds-notes.html#lets-fit-a-linear-regression-model",
    "title": "Probabilities, odds, odds ratios",
    "section": "Let’s fit a linear regression model",
    "text": "Let’s fit a linear regression model\nOutcome: \\(Y\\) = 1: yes, 0: no"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#lets-use-proportions",
    "href": "slides/18-prob-odds-notes.html#lets-use-proportions",
    "title": "Probabilities, odds, odds ratios",
    "section": "Let’s use proportions",
    "text": "Let’s use proportions\nOutcome: Probability of getting 7+ hours of sleep"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#what-happens-if-we-zoom-out",
    "href": "slides/18-prob-odds-notes.html#what-happens-if-we-zoom-out",
    "title": "Probabilities, odds, odds ratios",
    "section": "What happens if we zoom out?",
    "text": "What happens if we zoom out?\nOutcome: Probability of getting 7+ hours of sleep\n\n\n\n\n\n\n\n\n\n🛑 This model produces predictions outside of 0 and 1."
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#lets-try-another-model",
    "href": "slides/18-prob-odds-notes.html#lets-try-another-model",
    "title": "Probabilities, odds, odds ratios",
    "section": "Let’s try another model",
    "text": "Let’s try another model\n\n\n\n\n\n\n\n\n\n✅ This model (called a logistic regression model) only produces predictions between 0 and 1."
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#the-code",
    "href": "slides/18-prob-odds-notes.html#the-code",
    "title": "Probabilities, odds, odds ratios",
    "section": "The code",
    "text": "The code\n\nggplot(sleep_age, aes(x = Age, y = prop)) +\n  geom_point() + \n  geom_hline(yintercept = c(0,1), lty = 2) + \n  stat_smooth(method =\"glm\", method.args = list(family = \"binomial\"), \n              fullrange = TRUE, se = FALSE) +\n  labs(y = \"P(7+ hours of sleep)\") +\n  xlim(1, 40) +\n  ylim(-0.5, 1.5)"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#different-types-of-models",
    "href": "slides/18-prob-odds-notes.html#different-types-of-models",
    "title": "Probabilities, odds, odds ratios",
    "section": "Different types of models",
    "text": "Different types of models\n\n\n\n\n\n\n\n\nMethod\nOutcome\nModel\n\n\n\n\nLinear regression\nQuantitative\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon}\n\\]\n\n\nLinear regression (transform Y)\nQuantitative\n\\[\n\\log(\\mathbf{y}) = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon}\n\\]\n\n\nLogistic regression\nBinary\n\\[\n\\log\\Big(\\frac{\\boldsymbol{\\pi}}{1 - \\boldsymbol{\\pi}}\\Big) = \\mathbf{X}\\boldsymbol{\\beta}\n\\]"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#linear-vs.-logistic-regression",
    "href": "slides/18-prob-odds-notes.html#linear-vs.-logistic-regression",
    "title": "Probabilities, odds, odds ratios",
    "section": "Linear vs. logistic regression",
    "text": "Linear vs. logistic regression\n\nState whether a linear regression model or logistic regression model is more appropriate for each scenario.\n\nUse age and political party to predict if a randomly selected person will vote in the next election.\nUse budget and run time (in minutes) to predict a movie’s total revenue.\nUse age and sex to calculate the probability a randomly selected adult will visit Duke Health in the next year."
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#data-concern-about-rising-ai",
    "href": "slides/18-prob-odds-notes.html#data-concern-about-rising-ai",
    "title": "Probabilities, odds, odds ratios",
    "section": "Data: Concern about rising AI",
    "text": "Data: Concern about rising AI\nThis data comes from the 2023 Pew Research Center’s American Trends Panel. The survey aims to capture public opinion about a variety of topics including politics, religion, and technology, among others. We will use data from 11201 respondents in Wave 132 of the survey conducted July 31 - August 6, 2023.\n\nThe goal of this analysis is to understand the relationship between age, how much someone has heard about artificial intelligence (AI), and concern about the increased use of AI in daily life.\n\nA more complete analysis on this topic can be found in the Pew Research Center article Growing public concern about the role of artificial intelligence in daily life by Alec Tyson and Emma Kikuchi."
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#variables",
    "href": "slides/18-prob-odds-notes.html#variables",
    "title": "Probabilities, odds, odds ratios",
    "section": "Variables",
    "text": "Variables\n\nai_concern: Whether a respondent said they are “more concerned than excited” about in the increased use of AI in daily life (1: yes, 0: no)\n\n\n\n\nSource: Pew Research"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#variables-1",
    "href": "slides/18-prob-odds-notes.html#variables-1",
    "title": "Probabilities, odds, odds ratios",
    "section": "Variables",
    "text": "Variables\n\nai_heard : Response to the question “How much have you heard or read about AI?”\n\nA lot\nA little\nNothing at all\nRefused\n\nage_cat: Age category\n\n18-29\n30-49\n50-64\n65+\nRefused"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#data-prep",
    "href": "slides/18-prob-odds-notes.html#data-prep",
    "title": "Probabilities, odds, odds ratios",
    "section": "Data prep",
    "text": "Data prep\n\n# change variable names and recode categories\npew_data &lt;- pew_data |&gt;\n  mutate(ai_concern = if_else(CNCEXC_W132 == 2, 1, 0),\n         age_cat = case_when(F_AGECAT == 1 ~ \"18-29\",\n                             F_AGECAT == 2 ~ \"30-49\",\n                             F_AGECAT == 3 ~ \"50-64\",\n                             F_AGECAT == 4 ~ \"65+\",\n                             TRUE ~ \"Refused\"), \n         ai_heard = case_when(AI_HEARD_W132 == 1 ~ \"A lot\",\n                              AI_HEARD_W132 == 2 ~ \"A little\",\n                              AI_HEARD_W132 == 3 ~ \"Nothing at all\",\n                              TRUE ~ \"Refused\"\n                              ))\n\n# Make factors and  relevel \npew_data &lt;- pew_data |&gt;\n  mutate(ai_concern = factor(ai_concern),\n         age_cat = factor(age_cat), \n         ai_heard = factor(ai_heard, levels = c(\"A lot\", \"A little\", \"Nothing at all\", \"Refused\"))\n  )"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#univariate-eda",
    "href": "slides/18-prob-odds-notes.html#univariate-eda",
    "title": "Probabilities, odds, odds ratios",
    "section": "Univariate EDA",
    "text": "Univariate EDA"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#binary-response-variable",
    "href": "slides/18-prob-odds-notes.html#binary-response-variable",
    "title": "Probabilities, odds, odds ratios",
    "section": "Binary response variable",
    "text": "Binary response variable\n\n\n\\(Y = 1: \\text{ yes (success), } 0: \\text{ no (failure)}\\)\n\\(\\pi\\): probability that \\(Y=1\\), i.e., \\(P(Y = 1)\\)\n\\(\\frac{\\pi}{1-\\pi}\\): odds that \\(Y = 1\\)\n\\(\\log\\big(\\frac{\\pi}{1-\\pi}\\big)\\): log odds\nGo from \\(\\pi\\) to \\(\\log\\big(\\frac{\\pi}{1-\\pi}\\big)\\) using the logit transformation"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#example",
    "href": "slides/18-prob-odds-notes.html#example",
    "title": "Probabilities, odds, odds ratios",
    "section": "Example",
    "text": "Example\n\nSuppose there is a 70% chance it will rain tomorrow\n\nProbability it will rain is \\(\\mathbf{\\pi = 0.7}\\)\nProbability it won’t rain is \\(\\mathbf{1 - \\pi = 0.3}\\)\nOdds it will rain are 7 to 3, 7:3, \\(\\mathbf{\\frac{0.7}{0.3} \\approx 2.33}\\)"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#concerned-about-ai-in-daily-life",
    "href": "slides/18-prob-odds-notes.html#concerned-about-ai-in-daily-life",
    "title": "Probabilities, odds, odds ratios",
    "section": "Concerned about AI in daily life?",
    "text": "Concerned about AI in daily life?\n\npew_data |&gt;\n  count(ai_concern) |&gt;\n  mutate(pi = round(n / sum(n), 3))\n\n# A tibble: 2 × 3\n  ai_concern     n    pi\n  &lt;fct&gt;      &lt;int&gt; &lt;dbl&gt;\n1 0           5245 0.468\n2 1           5956 0.532\n\n\n\n. . .\n\\(P(\\text{Concerned about AI}) = P(Y = 1) = \\pi = 0.532\\)\n. . .\n\\(P(\\text{Not concerned about AI}) = P(Y = 0) = 1 - \\pi = 0.468\\)\n. . .\n\\(\\text{Odds of being concerned about AI} = \\frac{0.532}{0.468} = 1.137\\)"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#from-odds-to-probabilities",
    "href": "slides/18-prob-odds-notes.html#from-odds-to-probabilities",
    "title": "Probabilities, odds, odds ratios",
    "section": "From odds to probabilities",
    "text": "From odds to probabilities\n\n\nodds\n\\[\\text{odds} =  \\frac{\\pi}{1-\\pi}\\]\n\nprobability\n\\[\\pi = \\frac{\\text{odds}}{1 + \\text{odds}}\\]"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#concern-about-ai-vs.-age",
    "href": "slides/18-prob-odds-notes.html#concern-about-ai-vs.-age",
    "title": "Probabilities, odds, odds ratios",
    "section": "Concern about AI vs. age",
    "text": "Concern about AI vs. age\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#compare-the-odds-for-two-groups",
    "href": "slides/18-prob-odds-notes.html#compare-the-odds-for-two-groups",
    "title": "Probabilities, odds, odds ratios",
    "section": "Compare the odds for two groups",
    "text": "Compare the odds for two groups\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28\n\n\n\n\n\n. . .\nWe want to compare concern about increased use of AI in daily life between individuals who are 18-29 years old to those who are 65+ years old"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#compare-the-odds-for-two-groups-1",
    "href": "slides/18-prob-odds-notes.html#compare-the-odds-for-two-groups-1",
    "title": "Probabilities, odds, odds ratios",
    "section": "Compare the odds for two groups",
    "text": "Compare the odds for two groups\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28\n\n\n\n\n\nWe’ll use the odds to compare the two groups\n\\[\n\\text{odds} = \\frac{P(\\text{success})}{P(\\text{failure})} = \\frac{\\text{# of successes}}{\\text{# of failures}}\n\\]"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#compare-the-odds-for-two-groups-2",
    "href": "slides/18-prob-odds-notes.html#compare-the-odds-for-two-groups-2",
    "title": "Probabilities, odds, odds ratios",
    "section": "Compare the odds for two groups",
    "text": "Compare the odds for two groups\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28\n\n\n\n\n\n\n\nOdds of being concerned with increased use of AI in daily life for 18-29 year olds: \\(\\frac{416}{550} = 0.756\\)\nOdds of being concerned with increased use of AI in daily life for those who are 65+ years old: \\(\\frac{2013}{1376} = 1.463\\)\nBased on this, we see that individuals 65+ years old are more likely to be concerned about the increased use of AI in daily life than 18-29 year olds."
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#odds-ratio-or",
    "href": "slides/18-prob-odds-notes.html#odds-ratio-or",
    "title": "Probabilities, odds, odds ratios",
    "section": "Odds ratio (OR)",
    "text": "Odds ratio (OR)\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28\n\n\n\n\n\nLet’s summarize the relationship between the two groups. To do so, we’ll use the odds ratio (OR).\n\\[\nOR = \\frac{\\text{odds}_1}{\\text{odds}_2}\n\\]"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#or-ai-concern-by-age",
    "href": "slides/18-prob-odds-notes.html#or-ai-concern-by-age",
    "title": "Probabilities, odds, odds ratios",
    "section": "OR: AI concern by age",
    "text": "OR: AI concern by age\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28\n\n\n\n\n\n\\[OR = \\frac{\\text{odds}_{18-29}}{\\text{odds}_{65+}} = \\frac{0.756}{1.463} = \\mathbf{0.517}\\]\n. . .\nThe odds an 18-29 year old is concerned about increased use of AI in daily life are 0.517 times the odds a 65+ year old is concerned."
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#more-natural-interpretation",
    "href": "slides/18-prob-odds-notes.html#more-natural-interpretation",
    "title": "Probabilities, odds, odds ratios",
    "section": "More natural interpretation",
    "text": "More natural interpretation\n\nIt’s more natural to interpret the odds ratio with a statement with the odds ratio greater than 1.\nThe odds a 65+ year old is concerned about increased use of AI in daily life are 1.934 (1/0.517) times the odds an 18-29 year old is concerned."
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#code-to-make-table",
    "href": "slides/18-prob-odds-notes.html#code-to-make-table",
    "title": "Probabilities, odds, odds ratios",
    "section": "Code to make table",
    "text": "Code to make table\n\npew_data |&gt;\n  count(age_cat, ai_concern)\n\n# A tibble: 10 × 3\n   age_cat ai_concern     n\n   &lt;fct&gt;   &lt;fct&gt;      &lt;int&gt;\n 1 18-29   0            550\n 2 18-29   1            416\n 3 30-49   0           1898\n 4 30-49   1           1681\n 5 50-64   0           1398\n 6 50-64   1           1818\n 7 65+     0           1376\n 8 65+     1           2013\n 9 Refused 0             23\n10 Refused 1             28"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#code-to-make-table-1",
    "href": "slides/18-prob-odds-notes.html#code-to-make-table-1",
    "title": "Probabilities, odds, odds ratios",
    "section": "Code to make table",
    "text": "Code to make table\n\npew_data |&gt;\n  count(age_cat, ai_concern) |&gt;\n  pivot_wider(names_from = ai_concern, values_from = n)\n\n# A tibble: 5 × 3\n  age_cat   `0`   `1`\n  &lt;fct&gt;   &lt;int&gt; &lt;int&gt;\n1 18-29     550   416\n2 30-49    1898  1681\n3 50-64    1398  1818\n4 65+      1376  2013\n5 Refused    23    28"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#code-to-make-table-2",
    "href": "slides/18-prob-odds-notes.html#code-to-make-table-2",
    "title": "Probabilities, odds, odds ratios",
    "section": "Code to make table",
    "text": "Code to make table\n\npew_data |&gt;\n  count(age_cat, ai_concern) |&gt;\n  pivot_wider(names_from = ai_concern, values_from = n) |&gt;\n  kable()\n\n\n\n\nage_cat\n0\n1\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#code-to-make-table-3",
    "href": "slides/18-prob-odds-notes.html#code-to-make-table-3",
    "title": "Probabilities, odds, odds ratios",
    "section": "Code to make table",
    "text": "Code to make table\n\npew_data |&gt;\n  count(age_cat, ai_concern) |&gt;\n  pivot_wider(names_from = ai_concern, values_from = n) |&gt;\n  kable(col.names = c(\"Age\", \"Not concerned\", \"Concerned\"))\n\n\n\n\nAge\nNot concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28"
  },
  {
    "objectID": "slides/18-prob-odds-notes.html#recap",
    "href": "slides/18-prob-odds-notes.html#recap",
    "title": "Probabilities, odds, odds ratios",
    "section": "Recap",
    "text": "Recap\n\nIntroduced logistic regression for binary response variable\nShowed the relationship between odds and probabilities\nIntroduced odds ratios"
  },
  {
    "objectID": "slides/18-prob-odds.html#announcements",
    "href": "slides/18-prob-odds.html#announcements",
    "title": "Probabilities, odds, odds ratios",
    "section": "Announcements",
    "text": "Announcements\n\nProject Presentations in lab on Friday, March 28\nLab 06 due TODAY at 11:59pm\nStatistics experience due April 22\n\n\n\nDrop-in Peer Advising will be happening Wednesday, March 26, from 6:30-8:30 PM in Bostock Lounge for students to stop by with any questions they have around STA/CS/MATH classes, major pathways, or other general advice since shopping carts just opened."
  },
  {
    "objectID": "slides/18-prob-odds.html#fall-2025-sta-classes",
    "href": "slides/18-prob-odds.html#fall-2025-sta-classes",
    "title": "Probabilities, odds, odds ratios",
    "section": "Fall 2025 STA classes",
    "text": "Fall 2025 STA classes\n\nSTA 240: Probability for Statistical Inference, Modeling, and Data Analysis (or STA 230 or STA 231)\nSTA 322: Study Design: Design of Surveys and Causal Studies\nSTA 323: Statistical Computing\nSTA 325: Machine Learning and Data Mining (need STA 230/231/240)\nSTA 332: Statistical Inference (need STA 230/231/240)\nSTA 344: Introduction to Statistical Modeling of Spatial and Time Series data (need STA 230/231/240)\nSTA 402: Bayesian Statistical Modeling and Data Analysis (need STA 332)\nSTA 465: Introduction to High Dimensional Data Analysis"
  },
  {
    "objectID": "slides/18-prob-odds.html#topics",
    "href": "slides/18-prob-odds.html#topics",
    "title": "Probabilities, odds, odds ratios",
    "section": "Topics",
    "text": "Topics\n\nReview: Multicollinearity vs. interaction effects\nLogistic regression for binary response variable\nRelationship between odds and probabilities\nOdds ratios"
  },
  {
    "objectID": "slides/18-prob-odds.html#computational-setup",
    "href": "slides/18-prob-odds.html#computational-setup",
    "title": "Probabilities, odds, odds ratios",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(Stat2Data) #contains sleep data set\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/18-prob-odds.html#review-multicollinearity-vs.-interactions",
    "href": "slides/18-prob-odds.html#review-multicollinearity-vs.-interactions",
    "title": "Probabilities, odds, odds ratios",
    "section": "Review: Multicollinearity vs. interactions",
    "text": "Review: Multicollinearity vs. interactions\nSuppose we fit a model using flipper length and bill length to understand variability in body mass for Palmer Penguins. We make the plots below as part of the EDA.\n\n\nWhat are we checking in Plot 1? In Plot 2?"
  },
  {
    "objectID": "slides/18-prob-odds.html#types-of-outcome-variables",
    "href": "slides/18-prob-odds.html#types-of-outcome-variables",
    "title": "Probabilities, odds, odds ratios",
    "section": "Types of outcome variables",
    "text": "Types of outcome variables\nQuantitative outcome variable:\n\nSales price of a house in Duke Forest\nModel: Expected sales price given the number of bedrooms, lot size, etc.\n\n\nCategorical outcome variable:\n\nIndicator of being high risk of getting coronary heart disease in the next 10 years\nModel: Probability an adult is high risk of heart disease in the next 10 years given their age, total cholesterol, etc."
  },
  {
    "objectID": "slides/18-prob-odds.html#models-for-categorical-outcomes",
    "href": "slides/18-prob-odds.html#models-for-categorical-outcomes",
    "title": "Probabilities, odds, odds ratios",
    "section": "Models for categorical outcomes",
    "text": "Models for categorical outcomes\n\n\nLogistic regression\n2 Outcomes\n1: Yes, 0: No\n\nMultinomial logistic regression\n3+ Outcomes\n1: Democrat, 2: Republican, 3: Independent"
  },
  {
    "objectID": "slides/18-prob-odds.html#example-win-probabilities",
    "href": "slides/18-prob-odds.html#example-win-probabilities",
    "title": "Probabilities, odds, odds ratios",
    "section": "Example: Win probabilities",
    "text": "Example: Win probabilities\nDuke in 2nd round of NCCA March Madness Tournaments\n\n\n\n\nMen’s Basketball\n\n\n\n\nSource: ESPN Gamecast\n\n\n\n\nWomen’s Basketball\n\n\n\n\nSource: ESPN Gamecast"
  },
  {
    "objectID": "slides/18-prob-odds.html#do-teenagers-get-7-hours-of-sleep",
    "href": "slides/18-prob-odds.html#do-teenagers-get-7-hours-of-sleep",
    "title": "Probabilities, odds, odds ratios",
    "section": "Do teenagers get 7+ hours of sleep?",
    "text": "Do teenagers get 7+ hours of sleep?\n\n\nStudents in grades 9 - 12 were surveyed about health risk behaviors including whether they usually get 7 or more hours of sleep.\nSleep7\n1: yes\n0: no\n\n\n\n# A tibble: 446 × 2\n     Age Sleep7\n   &lt;int&gt;  &lt;int&gt;\n 1    16      1\n 2    17      0\n 3    18      0\n 4    17      1\n 5    15      0\n 6    17      0\n 7    17      1\n 8    16      1\n 9    16      1\n10    18      0\n# ℹ 436 more rows"
  },
  {
    "objectID": "slides/18-prob-odds.html#plot-the-data",
    "href": "slides/18-prob-odds.html#plot-the-data",
    "title": "Probabilities, odds, odds ratios",
    "section": "Plot the data",
    "text": "Plot the data\n\nggplot(sleep, aes(x = Age, y = Sleep7)) +\n  geom_point() + \n  labs(y = \"Getting 7+ hours of sleep\")"
  },
  {
    "objectID": "slides/18-prob-odds.html#lets-fit-a-linear-regression-model",
    "href": "slides/18-prob-odds.html#lets-fit-a-linear-regression-model",
    "title": "Probabilities, odds, odds ratios",
    "section": "Let’s fit a linear regression model",
    "text": "Let’s fit a linear regression model\nOutcome: \\(Y\\) = 1: yes, 0: no"
  },
  {
    "objectID": "slides/18-prob-odds.html#lets-use-proportions",
    "href": "slides/18-prob-odds.html#lets-use-proportions",
    "title": "Probabilities, odds, odds ratios",
    "section": "Let’s use proportions",
    "text": "Let’s use proportions\nOutcome: Probability of getting 7+ hours of sleep"
  },
  {
    "objectID": "slides/18-prob-odds.html#what-happens-if-we-zoom-out",
    "href": "slides/18-prob-odds.html#what-happens-if-we-zoom-out",
    "title": "Probabilities, odds, odds ratios",
    "section": "What happens if we zoom out?",
    "text": "What happens if we zoom out?\nOutcome: Probability of getting 7+ hours of sleep\n\n🛑 This model produces predictions outside of 0 and 1."
  },
  {
    "objectID": "slides/18-prob-odds.html#lets-try-another-model",
    "href": "slides/18-prob-odds.html#lets-try-another-model",
    "title": "Probabilities, odds, odds ratios",
    "section": "Let’s try another model",
    "text": "Let’s try another model\n\n✅ This model (called a logistic regression model) only produces predictions between 0 and 1."
  },
  {
    "objectID": "slides/18-prob-odds.html#the-code",
    "href": "slides/18-prob-odds.html#the-code",
    "title": "Probabilities, odds, odds ratios",
    "section": "The code",
    "text": "The code\n\nggplot(sleep_age, aes(x = Age, y = prop)) +\n  geom_point() + \n  geom_hline(yintercept = c(0,1), lty = 2) + \n  stat_smooth(method =\"glm\", method.args = list(family = \"binomial\"), \n              fullrange = TRUE, se = FALSE) +\n  labs(y = \"P(7+ hours of sleep)\") +\n  xlim(1, 40) +\n  ylim(-0.5, 1.5)"
  },
  {
    "objectID": "slides/18-prob-odds.html#different-types-of-models",
    "href": "slides/18-prob-odds.html#different-types-of-models",
    "title": "Probabilities, odds, odds ratios",
    "section": "Different types of models",
    "text": "Different types of models\n\n\n\n\n\n\n\n\nMethod\nOutcome\nModel\n\n\n\n\nLinear regression\nQuantitative\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon}\n\\]\n\n\nLinear regression (transform Y)\nQuantitative\n\\[\n\\log(\\mathbf{y}) = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon}\n\\]\n\n\nLogistic regression\nBinary\n\\[\n\\log\\Big(\\frac{\\boldsymbol{\\pi}}{1 - \\boldsymbol{\\pi}}\\Big) = \\mathbf{X}\\boldsymbol{\\beta}\n\\]"
  },
  {
    "objectID": "slides/18-prob-odds.html#linear-vs.-logistic-regression",
    "href": "slides/18-prob-odds.html#linear-vs.-logistic-regression",
    "title": "Probabilities, odds, odds ratios",
    "section": "Linear vs. logistic regression",
    "text": "Linear vs. logistic regression\n\nState whether a linear regression model or logistic regression model is more appropriate for each scenario.\n\nUse age and political party to predict if a randomly selected person will vote in the next election.\nUse budget and run time (in minutes) to predict a movie’s total revenue.\nUse age and sex to calculate the probability a randomly selected adult will visit Duke Health in the next year."
  },
  {
    "objectID": "slides/18-prob-odds.html#data-concern-about-rising-ai",
    "href": "slides/18-prob-odds.html#data-concern-about-rising-ai",
    "title": "Probabilities, odds, odds ratios",
    "section": "Data: Concern about rising AI",
    "text": "Data: Concern about rising AI\nThis data comes from the 2023 Pew Research Center’s American Trends Panel. The survey aims to capture public opinion about a variety of topics including politics, religion, and technology, among others. We will use data from 11201 respondents in Wave 132 of the survey conducted July 31 - August 6, 2023.\n\nThe goal of this analysis is to understand the relationship between age, how much someone has heard about artificial intelligence (AI), and concern about the increased use of AI in daily life.\n\nA more complete analysis on this topic can be found in the Pew Research Center article Growing public concern about the role of artificial intelligence in daily life by Alec Tyson and Emma Kikuchi."
  },
  {
    "objectID": "slides/18-prob-odds.html#variables",
    "href": "slides/18-prob-odds.html#variables",
    "title": "Probabilities, odds, odds ratios",
    "section": "Variables",
    "text": "Variables\n\nai_concern: Whether a respondent said they are “more concerned than excited” about in the increased use of AI in daily life (1: yes, 0: no)\n\n\nSource: Pew Research"
  },
  {
    "objectID": "slides/18-prob-odds.html#variables-1",
    "href": "slides/18-prob-odds.html#variables-1",
    "title": "Probabilities, odds, odds ratios",
    "section": "Variables",
    "text": "Variables\n\nai_heard : Response to the question “How much have you heard or read about AI?”\n\nA lot\nA little\nNothing at all\nRefused\n\nage_cat: Age category\n\n18-29\n30-49\n50-64\n65+\nRefused"
  },
  {
    "objectID": "slides/18-prob-odds.html#data-prep",
    "href": "slides/18-prob-odds.html#data-prep",
    "title": "Probabilities, odds, odds ratios",
    "section": "Data prep",
    "text": "Data prep\n\n# change variable names and recode categories\npew_data &lt;- pew_data |&gt;\n  mutate(ai_concern = if_else(CNCEXC_W132 == 2, 1, 0),\n         age_cat = case_when(F_AGECAT == 1 ~ \"18-29\",\n                             F_AGECAT == 2 ~ \"30-49\",\n                             F_AGECAT == 3 ~ \"50-64\",\n                             F_AGECAT == 4 ~ \"65+\",\n                             TRUE ~ \"Refused\"), \n         ai_heard = case_when(AI_HEARD_W132 == 1 ~ \"A lot\",\n                              AI_HEARD_W132 == 2 ~ \"A little\",\n                              AI_HEARD_W132 == 3 ~ \"Nothing at all\",\n                              TRUE ~ \"Refused\"\n                              ))\n\n# Make factors and  relevel \npew_data &lt;- pew_data |&gt;\n  mutate(ai_concern = factor(ai_concern),\n         age_cat = factor(age_cat), \n         ai_heard = factor(ai_heard, levels = c(\"A lot\", \"A little\", \"Nothing at all\", \"Refused\"))\n  )"
  },
  {
    "objectID": "slides/18-prob-odds.html#univariate-eda",
    "href": "slides/18-prob-odds.html#univariate-eda",
    "title": "Probabilities, odds, odds ratios",
    "section": "Univariate EDA",
    "text": "Univariate EDA"
  },
  {
    "objectID": "slides/18-prob-odds.html#binary-response-variable",
    "href": "slides/18-prob-odds.html#binary-response-variable",
    "title": "Probabilities, odds, odds ratios",
    "section": "Binary response variable",
    "text": "Binary response variable\n\n\n\\(Y = 1: \\text{ yes (success), } 0: \\text{ no (failure)}\\)\n\\(\\pi\\): probability that \\(Y=1\\), i.e., \\(P(Y = 1)\\)\n\\(\\frac{\\pi}{1-\\pi}\\): odds that \\(Y = 1\\)\n\\(\\log\\big(\\frac{\\pi}{1-\\pi}\\big)\\): log odds\nGo from \\(\\pi\\) to \\(\\log\\big(\\frac{\\pi}{1-\\pi}\\big)\\) using the logit transformation"
  },
  {
    "objectID": "slides/18-prob-odds.html#example",
    "href": "slides/18-prob-odds.html#example",
    "title": "Probabilities, odds, odds ratios",
    "section": "Example",
    "text": "Example\n\nSuppose there is a 70% chance it will rain tomorrow\n\nProbability it will rain is \\(\\mathbf{\\pi = 0.7}\\)\nProbability it won’t rain is \\(\\mathbf{1 - \\pi = 0.3}\\)\nOdds it will rain are 7 to 3, 7:3, \\(\\mathbf{\\frac{0.7}{0.3} \\approx 2.33}\\)"
  },
  {
    "objectID": "slides/18-prob-odds.html#concerned-about-ai-in-daily-life",
    "href": "slides/18-prob-odds.html#concerned-about-ai-in-daily-life",
    "title": "Probabilities, odds, odds ratios",
    "section": "Concerned about AI in daily life?",
    "text": "Concerned about AI in daily life?\n\npew_data |&gt;\n  count(ai_concern) |&gt;\n  mutate(pi = round(n / sum(n), 3))\n\n# A tibble: 2 × 3\n  ai_concern     n    pi\n  &lt;fct&gt;      &lt;int&gt; &lt;dbl&gt;\n1 0           5245 0.468\n2 1           5956 0.532\n\n\n\n\n\\(P(\\text{Concerned about AI}) = P(Y = 1) = \\pi = 0.532\\)\n\n\n\\(P(\\text{Not concerned about AI}) = P(Y = 0) = 1 - \\pi = 0.468\\)\n\n\n\\(\\text{Odds of being concerned about AI} = \\frac{0.532}{0.468} = 1.137\\)"
  },
  {
    "objectID": "slides/18-prob-odds.html#from-odds-to-probabilities",
    "href": "slides/18-prob-odds.html#from-odds-to-probabilities",
    "title": "Probabilities, odds, odds ratios",
    "section": "From odds to probabilities",
    "text": "From odds to probabilities\n\n\nodds\n\\[\\text{odds} =  \\frac{\\pi}{1-\\pi}\\]\n\nprobability\n\\[\\pi = \\frac{\\text{odds}}{1 + \\text{odds}}\\]"
  },
  {
    "objectID": "slides/18-prob-odds.html#concern-about-ai-vs.-age",
    "href": "slides/18-prob-odds.html#concern-about-ai-vs.-age",
    "title": "Probabilities, odds, odds ratios",
    "section": "Concern about AI vs. age",
    "text": "Concern about AI vs. age\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28"
  },
  {
    "objectID": "slides/18-prob-odds.html#compare-the-odds-for-two-groups",
    "href": "slides/18-prob-odds.html#compare-the-odds-for-two-groups",
    "title": "Probabilities, odds, odds ratios",
    "section": "Compare the odds for two groups",
    "text": "Compare the odds for two groups\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28\n\n\n\n\n\n\nWe want to compare concern about increased use of AI in daily life between individuals who are 18-29 years old to those who are 65+ years old"
  },
  {
    "objectID": "slides/18-prob-odds.html#compare-the-odds-for-two-groups-1",
    "href": "slides/18-prob-odds.html#compare-the-odds-for-two-groups-1",
    "title": "Probabilities, odds, odds ratios",
    "section": "Compare the odds for two groups",
    "text": "Compare the odds for two groups\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28\n\n\n\n\n\nWe’ll use the odds to compare the two groups\n\\[\n\\text{odds} = \\frac{P(\\text{success})}{P(\\text{failure})} = \\frac{\\text{# of successes}}{\\text{# of failures}}\n\\]"
  },
  {
    "objectID": "slides/18-prob-odds.html#compare-the-odds-for-two-groups-2",
    "href": "slides/18-prob-odds.html#compare-the-odds-for-two-groups-2",
    "title": "Probabilities, odds, odds ratios",
    "section": "Compare the odds for two groups",
    "text": "Compare the odds for two groups\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28\n\n\n\n\n\n\n\nOdds of being concerned with increased use of AI in daily life for 18-29 year olds: \\(\\frac{416}{550} = 0.756\\)\nOdds of being concerned with increased use of AI in daily life for those who are 65+ years old: \\(\\frac{2013}{1376} = 1.463\\)\nBased on this, we see that individuals 65+ years old are more likely to be concerned about the increased use of AI in daily life than 18-29 year olds."
  },
  {
    "objectID": "slides/18-prob-odds.html#odds-ratio-or",
    "href": "slides/18-prob-odds.html#odds-ratio-or",
    "title": "Probabilities, odds, odds ratios",
    "section": "Odds ratio (OR)",
    "text": "Odds ratio (OR)\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28\n\n\n\n\n\nLet’s summarize the relationship between the two groups. To do so, we’ll use the odds ratio (OR).\n\\[\nOR = \\frac{\\text{odds}_1}{\\text{odds}_2}\n\\]"
  },
  {
    "objectID": "slides/18-prob-odds.html#or-ai-concern-by-age",
    "href": "slides/18-prob-odds.html#or-ai-concern-by-age",
    "title": "Probabilities, odds, odds ratios",
    "section": "OR: AI concern by age",
    "text": "OR: AI concern by age\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28\n\n\n\n\n\n\\[OR = \\frac{\\text{odds}_{18-29}}{\\text{odds}_{65+}} = \\frac{0.756}{1.463} = \\mathbf{0.517}\\]\n\nThe odds an 18-29 year old is concerned about increased use of AI in daily life are 0.517 times the odds a 65+ year old is concerned."
  },
  {
    "objectID": "slides/18-prob-odds.html#more-natural-interpretation",
    "href": "slides/18-prob-odds.html#more-natural-interpretation",
    "title": "Probabilities, odds, odds ratios",
    "section": "More natural interpretation",
    "text": "More natural interpretation\n\nIt’s more natural to interpret the odds ratio with a statement with the odds ratio greater than 1.\nThe odds a 65+ year old is concerned about increased use of AI in daily life are 1.934 (1/0.517) times the odds an 18-29 year old is concerned."
  },
  {
    "objectID": "slides/18-prob-odds.html#code-to-make-table",
    "href": "slides/18-prob-odds.html#code-to-make-table",
    "title": "Probabilities, odds, odds ratios",
    "section": "Code to make table",
    "text": "Code to make table\n\npew_data |&gt;\n  count(age_cat, ai_concern)\n\n# A tibble: 10 × 3\n   age_cat ai_concern     n\n   &lt;fct&gt;   &lt;fct&gt;      &lt;int&gt;\n 1 18-29   0            550\n 2 18-29   1            416\n 3 30-49   0           1898\n 4 30-49   1           1681\n 5 50-64   0           1398\n 6 50-64   1           1818\n 7 65+     0           1376\n 8 65+     1           2013\n 9 Refused 0             23\n10 Refused 1             28"
  },
  {
    "objectID": "slides/18-prob-odds.html#code-to-make-table-1",
    "href": "slides/18-prob-odds.html#code-to-make-table-1",
    "title": "Probabilities, odds, odds ratios",
    "section": "Code to make table",
    "text": "Code to make table\n\npew_data |&gt;\n  count(age_cat, ai_concern) |&gt;\n  pivot_wider(names_from = ai_concern, values_from = n)\n\n# A tibble: 5 × 3\n  age_cat   `0`   `1`\n  &lt;fct&gt;   &lt;int&gt; &lt;int&gt;\n1 18-29     550   416\n2 30-49    1898  1681\n3 50-64    1398  1818\n4 65+      1376  2013\n5 Refused    23    28"
  },
  {
    "objectID": "slides/18-prob-odds.html#code-to-make-table-2",
    "href": "slides/18-prob-odds.html#code-to-make-table-2",
    "title": "Probabilities, odds, odds ratios",
    "section": "Code to make table",
    "text": "Code to make table\n\npew_data |&gt;\n  count(age_cat, ai_concern) |&gt;\n  pivot_wider(names_from = ai_concern, values_from = n) |&gt;\n  kable()\n\n\n\n\nage_cat\n0\n1\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28"
  },
  {
    "objectID": "slides/18-prob-odds.html#code-to-make-table-3",
    "href": "slides/18-prob-odds.html#code-to-make-table-3",
    "title": "Probabilities, odds, odds ratios",
    "section": "Code to make table",
    "text": "Code to make table\n\npew_data |&gt;\n  count(age_cat, ai_concern) |&gt;\n  pivot_wider(names_from = ai_concern, values_from = n) |&gt;\n  kable(col.names = c(\"Age\", \"Not concerned\", \"Concerned\"))\n\n\n\n\nAge\nNot concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28"
  },
  {
    "objectID": "slides/18-prob-odds.html#recap",
    "href": "slides/18-prob-odds.html#recap",
    "title": "Probabilities, odds, odds ratios",
    "section": "Recap",
    "text": "Recap\n\nIntroduced logistic regression for binary response variable\nShowed the relationship between odds and probabilities\nIntroduced odds ratios"
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Useful links",
    "section": "",
    "text": "STA221 RStudio containers\n🔗 for Duke Container Manager\n\n\nCourse GitHub organization\n🔗 for GitHub\n\n\nCourse Canvas site\n🔗 for Canvas\n\n\nDiscussion forum\n🔗 to Ed Discussion\n\n\nAssignment submission\n🔗 to Gradescope",
    "crumbs": [
      "Useful links"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "STA 221 Syllabus",
    "section": "",
    "text": "Lecture\nTue & Thu 10:05 - 11:20am\nOld Chemistry 116\n\n\nLab 01\nFri 8:30 - 9:45am\nPerkins Link #5\n\n\nLab 02\nFri 10:05 - 11:20am\nPerkins Link #5\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nRole\n\n\n\n\nProf. Maria Tackett\nInstructor\n\n\nKat Husar\nHead TA\nLab 01L leader\n\n\nKelly Huang\nClassroom TA\n\n\nJanice Kim\nClassroom TA\n\n\nCathy Lee\nLab 02L leader\n\n\nAlan Wang\nLab 01 helper\n\n\n\nOffice hours times and locations on Canvas.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-info",
    "href": "syllabus.html#course-info",
    "title": "STA 221 Syllabus",
    "section": "",
    "text": "Lecture\nTue & Thu 10:05 - 11:20am\nOld Chemistry 116\n\n\nLab 01\nFri 8:30 - 9:45am\nPerkins Link #5\n\n\nLab 02\nFri 10:05 - 11:20am\nPerkins Link #5\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nRole\n\n\n\n\nProf. Maria Tackett\nInstructor\n\n\nKat Husar\nHead TA\nLab 01L leader\n\n\nKelly Huang\nClassroom TA\n\n\nJanice Kim\nClassroom TA\n\n\nCathy Lee\nLab 02L leader\n\n\nAlan Wang\nLab 01 helper\n\n\n\nOffice hours times and locations on Canvas.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "STA 221 Syllabus",
    "section": "Course description",
    "text": "Course description\nIn STA 221, students will learn how linear and logistic regression models are used to explore multivariable relationships, apply these methods to answer relevant and engaging questions using a data-driven approach, and learn the mathematical underpinnings of the models. Students will develop computing skills to implement a reproducible data analysis workflow and gain experience communicating statistical results. Throughout the semester, students will work on a team project where they will develop a research question, answer it using methods learned in the course, and share results through a written report and presentation.\nTopics include applications of linear and logistic regression, analysis of variance, model diagnostics, and model selection. Regression parameter estimation via maximum likelihood least squares will also be discussed. Students will gain experience using the computing tools R and GitHub to analyze real-world data from a variety of fields.\n\nPrerequisites\nEither any STA 100-level course or STA 230, 231, or 240L and MATH 216, 218, or 221. The recommended co-requisite is STA 230, 231, or 240L. Interested students with different backgrounds should seek instructor consent.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-learning-objectives",
    "href": "syllabus.html#course-learning-objectives",
    "title": "STA 221 Syllabus",
    "section": "Course learning objectives",
    "text": "Course learning objectives\nBy the end of the semester, you will be able to…\n\nanalyze data to explore real-world multivariable relationships.\nfit, interpret, and draw conclusions from linear and logistic regression models.\nimplement a reproducible analysis workflow using R for analysis, Quarto to write reports and GitHub for version control and collaboration.\nexplain the mathematical foundations of linear and logistic regression.\neffectively communicate statistical results to a general audience.\nassess the ethical considerations and implications of analysis decisions.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-materials",
    "href": "syllabus.html#course-materials",
    "title": "STA 221 Syllabus",
    "section": "Course materials",
    "text": "Course materials\nWhile there is no official textbook for the course; readings will be made available as they are assigned. We will use the statistical software R. Students will be able to access R through Docker containers provided by Duke Office of Information Technology. See the computing page for more information.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-community",
    "href": "syllabus.html#course-community",
    "title": "STA 221 Syllabus",
    "section": "Course community",
    "text": "Course community\n\nInclusive community\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Duke’s Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nPronouns\nPronouns are meaningful tools to communicate identities and experiences, and using pronouns supports a campus environment where all community members can thrive. Please update your gender pronouns in Duke Hub. You can find instructions to do so here. You can learn more at the Center for Sexual and Gender Diversity’s website.\n\n\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the Student Disability Access Office to request or update accommodations under these circumstances.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website, sta221-sp25.netlify.app.\nLinks to Zoom meetings may be found in Canvas. Periodic announcements will be sent via email and will also be available through Ed Discussion and Canvas Announcements. Please check your email regularly to ensure you have the latest announcements for the course.\n\n\nEmail\nIf you have questions about assignment extensions, accommodations, or any other matter not appropriate for the class discussion forum, please email me directly at maria.tackett@duke.edu. If you email me, please include “STA 221” in the subject line. Barring extenuating circumstances, I will respond to STA 221 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#five-tips-for-success",
    "href": "syllabus.html#five-tips-for-success",
    "title": "STA 221 Syllabus",
    "section": "Five tips for success",
    "text": "Five tips for success\nYour success on this course depends very much on you and the effort you put into it. Your TAs and I will help you be providing you with materials and answering questions and setting a pace, but for this to work you must do the following:\n\nComplete all the preparation work before class.\nAsk questions. As often as you can. In class, out of class. Ask me, ask the TAs, ask your friends, ask the person sitting next to you. This will help you more than anything else. If you get a question wrong on an assessment, ask us why. If you’re not sure about the homework, ask. If you hear something on the news that sounds related to what we discussed, ask. If the reading is confusing, ask.\nDo the readings and other preparation work.\nDo the homework and lab.The earlier you start, the better. It’s not enough to just mechanically plow through the exercises. You should ask yourself how these exercises relate to earlier material, and imagine how they might be changed (to make questions for an exam, for example.)\nDon’t procrastinate. The content builds upon what was taught in previous weeks, so if something is confusing to you in Week 2, Week 3 will become more confusing, Week 4 even worse, etc. Don’t let the week end with unanswered questions. But if you find yourself falling behind and not knowing where to begin asking, come to office hours and work with a member of the teaching team to help you identify a good (re)starting point.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#getting-help-in-the-course",
    "href": "syllabus.html#getting-help-in-the-course",
    "title": "STA 221 Syllabus",
    "section": "Getting help in the course",
    "text": "Getting help in the course\n\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours1 to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. You are encouraged to use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on the class discussion forum Ed Discussion. There is a chance another student has already asked a similar question, so please check the other posts in Ed Discussion before adding a new question. If you know the answer to a question posted in the discussion forum, you are encouraged to respond!\n\nCheck out the Support page for more resources.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#what-to-expect-in-the-course",
    "href": "syllabus.html#what-to-expect-in-the-course",
    "title": "STA 221 Syllabus",
    "section": "What to expect in the course",
    "text": "What to expect in the course\n\nLectures and labs\nLectures and labs are designed to be interactive, so you gain experience applying new concepts and learning from each other. My role as instructor is to introduce you to new methods, tools, and techniques, but it is up to you to take them and make use of them. A lot of what you do in this course will involve writing code, and coding is a skill that is best learned by doing. Therefore, as much as possible, you will be working on a variety of tasks and activities during the lectures and labs. You are expected to prepare for class by completing assigned readings, attend all lecture and lab sessions, and meaningfully contribute to in-class exercises and discussion. Additionally, some lectures will feature application exercises that will be graded based on completing what we do in class.\nYou are expected to bring a laptop, tablet, or any device with internet and a keyboard to each class so that you can participate in the in-class exercises. Please make sure your device is fully charged before you come to class, as the number of outlets in the classroom will not be sufficient to accommodate everyone.\n\n\nTeams\nYou will be assigned to a team at the beginning of the semester. You are encouraged to sit with your teammates in lecture and you will also work with them in the lab sessions. All team members are expected to contribute equally to the completion of the group activities, labs and the final project. You will be asked to complete teamwork evaluations and self-reflections throughout the semester. Failure to adequately contribute to an assignment can result in a penalty to your score relative to the team’s overall mark.\nYou are expected to make use of the provided GitHub repository as the central collaborative platform. Commits to this repository will be used as one of several metrics of each team member’s relative contribution for each project.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#activities-assessment",
    "href": "syllabus.html#activities-assessment",
    "title": "STA 221 Syllabus",
    "section": "Activities & Assessment",
    "text": "Activities & Assessment\nYou will be assessed based on six components: application exercises, homework, labs, exams, project, and teamwork.\n\nLabs\nIn labs, you will apply the concepts discussed in lecture to various data analysis scenarios, with a focus on the computation and communication. Most lab assignments will be completed in teams, and all team members are expected to contribute equally to the completion of each assignment. You are expected to use the team’s Git repository in the course’s GitHub organization as the central platform for collaboration. Commits to this repository will be used as a metric of each team member’s relative contribution for each lab, and there will be periodic peer evaluation on the team collaboration. Lab assignments will be completed using Quarto, correspond to an appropriate GitHub repository, and submitted for grading in Gradescope.\nThe lowest lab grade will be dropped at the end of the semester.\n\n\nHomework\nIn homework, you will apply what you’ve learned during lecture and lab to complete data analysis tasks and explain the underlying mathematics. You may discuss homework assignments with other students; however, homework should be completed and submitted individually. Similar to lab assignments, homework must be typed up using Quarto and GitHub and submitted as a PDF in Gradescope.\nOne homework assignment will be dedicated to a statistics experience. The statistics experience is an opportunity to engage with statistics and data science outside of the classroom through podcasts, books, seminars, data analysis competitions, and other activities. As you complete these experiences, the goal is to consider how the material you’re learning in the course connects with society more broadly.\nThe lowest homework grade will be dropped at the end of the semester.\n\n\nExams\nThere will be two exams in this course. Each exam will include a closed-notes in-class component and an open-note take-home component. Through these exams you have the opportunity to demonstrate what you’ve learned in the course thus far. The exams will focus on both conceptual understanding of the applied and mathematical content and application through analysis and computational tasks. The exams will be based on content in reading assignments, lectures, application exercises, homework, and lab assignments. More detail about the exams will be given during the semester.\n\n\nProject\nThe purpose of the final project is to apply what you’ve learned to analyze an interesting data-driven research question. The project will be completed with your lab teams, and each team will present their work through a written report and presentation. More information about the project will be provided during the semester. You can learn more on the final project page.\n\n\nParticipation (Application exercises + teamwork)\n\nApplication exercises\nYou will get the most out of the course if you actively participate in class and when working with your team. Parts of some lectures will be dedicated to working on Application Exercises (AEs). AEs are submitted by pushing your work to the relevant GitHub repo.\nAEs will be graded based on making a good-faith effort to attempt all questions covered in class. You are welcome to, but not required, to work on AEs beyond lecture.\nSuccessful effort on at least 80% of AEs will result in full credit for AEs in the final course grade.\n\n\nTeamwork\nGiven the collaborative nature of statistics and data science work, teamwork will be a key part of this course. You will work in teams for in-class activities, lab assignments, and the final course project. There will be periodic peer and self-evaluations to reflect on the team’s collaboration. These evaluations will be counted as part of the participation grade.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#grading",
    "href": "syllabus.html#grading",
    "title": "STA 221 Syllabus",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\n\nCategory\nPercentage\n\n\n\n\nHomework\n30%\n\n\nFinal project\n15%\n\n\nLabs\n10%\n\n\nExams (2 Midterms)\n40%\n\n\nParticipation (AEs + Teamwork)\n5%\n\n\n\n\n\nThe final letter grade will be determined based on the following thresholds:\n\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n&gt;= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n&lt; 60",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-policies",
    "href": "syllabus.html#course-policies",
    "title": "STA 221 Syllabus",
    "section": "Course policies",
    "text": "Course policies\n\nDuke Community Standard\nAll students must adhere to the Duke Community Standard(DCS): Duke University is a community dedicated to scholarship, leadership, and service and to the principles of honesty, fairness, and accountability. Citizens of this community commit to reflect upon these principles in all academic and non-academic endeavors, and to protect and promote a culture of integrity.\nTo uphold the Duke Community Standard, students agree:\n\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors;and\nI will act if the Standard is compromised.\n\n\n\n\n\n\nAcademic honesty\nTL;DR: Don’t cheat!\n\nThe homework assignments must be completed individually and you are welcomed to discuss the assignment with classmates at a high level (e.g., discuss what’s the best way for approaching a problem, what functions are useful for accomplishing a particular task, etc.). However you may not directly share answers to homework questions (including any code) with anyone other than myself and the teaching assistants.\nYou may not discuss or otherwise work with others on the exams. Unauthorized collaboration or using unauthorized materials will be considered a violation for all students involved. More details will be given closer to the exam date.\nFor the projects and team labs, collaboration within teams is not only allowed, but expected. Communication between teams at a high level is also allowed however you may not share code or components of the project or team labs across teams.\nReusing code: Unless explicitly stated otherwise, you may make use of online resources (e.g. StackOverflow) for coding examples on assignments. If you directly use code from an outside source (or use it as inspiration), you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\nUse of artificial intelligence (AI): You should treat AI tools, such as ChatGPT, the same as other online resources. There are two guiding principles that govern how you can use AI in this course:2 (1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. We will practice using AI to facilitate—rather than hinder—learning. (2) Ethical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\nAI tools for code: You may make use of the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. You may use these guidelines for citing AI-generated content.\nNo AI tools for narrative: Unless instructed otherwise, AI is not permitted for writing narrative on assignments. In general, you may use AI as a resource as you complete assignments but not to answer the exercises for you. You are ultimately responsible for the work you turn in; it should reflect your understanding of the course content.\n\n\nIf you are unsure if the use of a particular resource complies with the academic honesty policy, please ask a member of the teaching team.\nRegardless of course delivery format, it is the responsibility of all students to understand and follow all Duke policies, including academic integrity (e.g., completing one’s own work, following proper citation of sources, adhering to guidance around group work projects,and more).Ignoring these requirements is a violation of the Duke Community Standard. Any questions and/or concerns regarding academic integrity can be directed to the Office of Student Conduct and Community Standards at conduct@duke.edu.\n\n\nLate work policy\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback in a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline. Note that the lowest homework and lab assignment will be dropped to accommodate such circumstances.\n\nHomework and labs may be submitted up to 2 days late. There will be a 5% deduction for each 24-hour period the assignment is late.\nThe late work policy for exams will be provided with the exam instructions.\nThe late work policy for the project will be provided with the project instructions.\n\n\n\nWaiver for extenuating circumstances\nIf there are circumstances that prevent you from completing a lab or homework assignment by the stated due date, you may email me at maria.tackett@duke.edu before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide explanation. This waiver may only be used once in the semester, so only use it for a truly extenuating circumstance.\nIf there are circumstances that are having a longer-term impact on your academic performance, please let your academic dean know, as they can be a resource. Please let me know if you need help contacting your academic dean.\n\n\nRegrade Requests\nRegrade requests must be submitted on Gradescope within a week of when an assignment is returned. Regrade requests will be considered if there was an error in the grade calculation or if you feel a correct answer was mistakenly marked as incorrect. Requests to dispute the number of points deducted for an incorrect response will not be considered. Note that by submitting a regrade request, the entire question will be graded which could potentially result in losing points.\nNo grades will be changed after the final project presentations.\n\n\nAttendance policy\nEvery student is expected to attend and participate in lecture and labs. There may be times, however, when you cannot attend class. Lecture recordings are available upon request for students who have an excused absence. See the Lecture recording request policy for more detail. If you miss a lecture, make sure to review the material and complete the application exercise, if applicable, before the next lecture. Labs dedicated to completing the lab assignment and collaborating with your lab team. If you miss a lab session, make sure to communicate with your lab TA and teammates about how you can make up your contribution. If you know you’re going to miss a lab session and you’re feeling well enough to do so, notify your lab TA and teammates ahead of time.\nMore details on Trinity attendance policies are available here.\n\n\nLecture recording request\nLectures will be recorded on Panopto and will be made available to students with an excused absence upon request. Videos shared with such students will be available for a week after the lecture date. To request a particular lecture’s video, please fill out the form at the link below. Please submit the form within 24 hours of missing lecture to ensure you have sufficient time to watch the recording. Please also make sure that any official documentation, such as STINFs, Dean’s excuses, NOVAPs, and quarantine/removal from class notices from student health are also uploaded to the form.\n🔗 https://forms.office.com/r/rvsgNcumRy\nAbout one week before each exam, the class recordings will be available to all students. These recordings will be available until the start of the exam.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#accommodations",
    "href": "syllabus.html#accommodations",
    "title": "STA 221 Syllabus",
    "section": "Accommodations",
    "text": "Accommodations\n\nAcademic accommodations\nIf you need accommodations for this class, you will need to register with the Student Disability Access Office (SDAO) and provide them with documentation related to your needs. SDAO will work with you to determine what accommodations are appropriate for your situation. Please note that accommodations are not retroactive and disability accommodations cannot be provided until a Faculty Accommodation Letter has been given to me. Please contact SDAO for more information: sdao@duke.edu or access.duke.edu.\n\n\nReligious accommodations\nStudents are permitted by university policy to be absent from class to observe a religious holiday. Accordingly, Trinity College of Arts & Sciences and the Pratt School of Engineering have established procedures to be followed by students for notifying their instructors of an absence necessitated by the observance of a religious holiday. Please submit requests for religious accommodations at the beginning of the semester so that we can work to make suitable arrangements well ahead of time. You can find the policy and relevant notification form here: trinity.duke.edu/undergraduate/academic-policies/religious-holidays",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#academic-and-wellness-support",
    "href": "syllabus.html#academic-and-wellness-support",
    "title": "STA 221 Syllabus",
    "section": "Academic and wellness support",
    "text": "Academic and wellness support\n\nAcademic Resource Center\nThere are times may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917.\n\n\nCAPS\nDuke Counseling & Psychological Services (CAPS) helps Duke Students enhance strengths and develop abilities to successfully live, grow and learn in their personal and academic lives. CAPS recognizes that we are living in unprecedented times and that the changes, challenges and stressors brought on by the COVID-19 pandemic have impacted everyone, often in ways that are tax our well-being. CAPS offers many services to Duke undergraduate students, including brief individual and group counseling, couples counseling and more. CAPS staff also provides outreach to student groups, particularly programs supportive of at-risk populations, on a wide range of issues impacting them in various aspects of campus life. CAPS provides services to students via Telehealth. To initiate services, you can contact their front desk at 919-660-1000.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#important-dates",
    "href": "syllabus.html#important-dates",
    "title": "STA 221 Syllabus",
    "section": "Important dates",
    "text": "Important dates\n\nJanuary 8: Classes begin\nJanuary 20: Martin Luther King Jr. Day holiday.\nJanuary 22: Drop/Add ends\nMarch 10 - 14: Spring break\nMarch 26: Last day to withdraw with “W”\nNovember 27 - 29: Thanksgiving recess\nApril 23: Classes end\nApril 24 - 27: Reading period\nApril 28 - May 3: Final exam period\n\nClick here for the full Duke academic calendar.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#footnotes",
    "href": "syllabus.html#footnotes",
    "title": "STA 221 Syllabus",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOffice hours are times the teaching team set aside each week to meet with students. Click here to learn more about how to effectively use office hours.↩︎\nThese guiding principles are based on Course Policies related to ChatGPT and other AI Tools developed by Joel Gladd, Ph.D.↩︎↩︎",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "computing-troubleshooting.html",
    "href": "computing-troubleshooting.html",
    "title": "Computing troubleshooting",
    "section": "",
    "text": "If you’re having difficulty launching an RStudio session from your reserved container, go to status.oit.duke.edu and scroll down to Teaching and Learning Tools. Under this heading you’ll find an entry called Container Manager (CMGR Coursework Containers).\n\nIf the status shows something other than Operational, this means there is a known incident with the containers. Check back later to see if it’s been resolved. If there’s a deadline coming up soon, post on the course forum to let us know that there’s an issue. We can look into how quickly it might get resolved and decide on what to do about the deadline accordingly. Note: We don’t anticipate this to happen regularly, the systems are Operational a huge majority of the time!\nIf the status shows Operational, this means the system is expected to be working. Check your internet connection, if need be, restart your computer to ensure a fresh new connection. If your issue persists, post on the course forum with details on what you’ve tried and the errors you see (including verbatim errors and/or screenshots).",
    "crumbs": [
      "Computing",
      "Troubleshooting"
    ]
  }
]