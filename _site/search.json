[
  {
    "objectID": "project-old.html",
    "href": "project-old.html",
    "title": "Final project",
    "section": "",
    "text": "Project proposal\n\ndue Friday, October 27 (Tuesday labs)\ndue Sunday, October 29 (Thursday labs)\n\nDraft report + peer review\n\ndue Tuesday, November 14 (Tuesday labs)\ndue Thursday, November 16 (Thursday labs)\n\nRound 1 submission (optional) due Friday, December 1\nPresentation + Presentation comments\n\nTuesday, December 5 (Tuesday labs)\nThursday, December 7 (Thursday labs)\n\nWritten report due Wednesday, December 13\nReproducibility + organization due Wednesday, December 13"
  },
  {
    "objectID": "project-old.html#timeline",
    "href": "project-old.html#timeline",
    "title": "Final project",
    "section": "",
    "text": "Project proposal\n\ndue Friday, October 27 (Tuesday labs)\ndue Sunday, October 29 (Thursday labs)\n\nDraft report + peer review\n\ndue Tuesday, November 14 (Tuesday labs)\ndue Thursday, November 16 (Thursday labs)\n\nRound 1 submission (optional) due Friday, December 1\nPresentation + Presentation comments\n\nTuesday, December 5 (Tuesday labs)\nThursday, December 7 (Thursday labs)\n\nWritten report due Wednesday, December 13\nReproducibility + organization due Wednesday, December 13"
  },
  {
    "objectID": "project-old.html#introduction",
    "href": "project-old.html#introduction",
    "title": "Final project",
    "section": "Introduction",
    "text": "Introduction\nTL;DR: Pick a data set and do a regression analysis. That is your final project.\nThe goal of the final project is for you to use regression analysis to analyze a data set of your own choosing. The data set may already exist or you may collect your own data by scraping the web.\nChoose the data based on your group’s interests or work you all have done in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like!) and apply them to a data set to analyze it in a meaningful way.\nAll analyses must be done in RStudio using Quarto and GitHub, and your analysis and written report must be reproducible.\n\nLogistics\nYou will work on the project with your lab groups. The four primary deliverables for the final project are\n\na written, reproducible report detailing your analysis\na GitHub repository corresponding to your report\nslides and an in-person presentation\nformal peer review on another team’s work and presentation feedback"
  },
  {
    "objectID": "project-old.html#project-proposal",
    "href": "project-old.html#project-proposal",
    "title": "Final project",
    "section": "Project proposal",
    "text": "Project proposal\n\n\n\n\n\n\nDue dates\n\n\n\n\nFriday, October 27 (Tuesday labs)\nSunday, October 29 (Thursday labs)\n\n\n\nThe purpose of the project proposal is for your team to identify the data set you’re interested in analyzing for the project, do some preliminary exploratory data analysis, and begin to think about a modeling strategy . If you’re unsure where to find data, you can use the list of potential data sources on the Tips + resources page as a starting point. It may also help to think of topics you’re interested in investigating and find data sets on those topics.\nThe data set must meet the following criteria:\n\nAt least 500 observations\nAt least 10 columns, such that at least 6 of the columns are useful and unique predictor variables.\n\ne.g., identifier variables such as “name”, “ID number”, etc. are not useful predictor variables.\ne.g., if you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique predictors.\n\nAt least one variable that can be identified as a reasonable response variable.\n\nThe response variable can be quantitative or categorical.\n\nA mix of quantitative and categorical variables that can be used as predictors.\nMay not be data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\n\n\n\n\n\n\nTypes of data sets to avoid\n\n\n\n\nData that are likely violate the independence condition. Therefore, avoid data with repeated measures, data collected over time, etc.\nData sets in which there is no information about how the data were originally collected\nData sets in which there are missing or unclear definitions about the observations and/or variables\n\n\n\nAsk a member of the teaching team if you’re unsure whether your data set meets the criteria.\nThe proposal will include the following sections:\n\nSection 1: Introduction\nThe introduction section includes\n\nan introduction to the subject matter you’re investigating (citing any relevant literature)\nthe motivation for your research question (citing any relevant literature)\nthe primary research question you are interested in exploring\nyour team’s hypotheses regarding the research question\n\nThis is a narrative about what you think regarding the research question, not formal statistical hypotheses.\n\n\n\n\nSection 2: Data description\nThe data description section includes\n\nthe source of the data set\na description of when and how the data were originally collected (by the original data curator, not necessarily how you found the data)\na description of the observations and general characteristics being measured\n\n\n\nSection 3: Initial exploratory data analysis\nIn this section, you will begin to explore the data. This includes using narrative, visualizations and summary statistics to describe the following:\n\ndistribution of the response variable\ndistributions of one potential quantitative predictor variable and one potential categorical predictor variable\nthe relationships between the response variable and each of the predictors from the previous step\na potential interaction effect you’re interested in exploring (it doesn’t have to be an interaction with the two predictors from above)\n\nThese steps are to help get you started on exploratory data analysis and will not be the complete EDA for the final report. The requirements above are minimum requirements, but your group is welcome to include more at this stage.\nIn this section, you will also describe any data cleaning you need to do to prepare for modeling, such as imputing missing values, collapsing levels for categorical predictors, creating new variables, summarizing data, etc.\n\n\nSection 4: Analysis approach\nIn this section, you will provide a brief overview of your analysis approach. This includes\n\na description of the response variable and list of all potential predictors\nregression model technique (multiple linear regression or logistic regression)\n\n\n\nData dictionary (aka code book)\nSubmit a data dictionary for all the variables in your data set in the README of the data folder. You do not need to include the data dictionary in the PDF document.\n\n\nSubmission\n\n\n\n\n\n\nImportant\n\n\n\nWrite your narrative and analysis for Sections 1 - 4 in the proposal.qmd file. Put the data set and the data dictionary in the data folder.\nSubmit the PDF of the proposal to Gradescope. Mark all pages of the document.\n\n\n\n\nGrading\nThe anticipated length, including all graphs, tables, narrative, etc., is 2 -4 pages; it may not exceed 5 pages.\nThe proposal is worth 15 points and will be graded based on accurately and comprehensively addressing the criteria stated above. Points will be assigned based on a holistic review of the project proposal.\n\nExcellent (14 - 15 points) : All required elements are completed and are accurate. There is a thorough exploration of the data as descrbied above, and the team has demonstrated a careful and thoughtful approach exploring the data and preparing it for analysis. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nStrong: (11 - 13 points): Requirements are mostly met, but there are some elements that are incomplete or inaccurate. Some minor revision of the work required before team is ready for modeling.\nSatisfactory (8 - 10 points): Requirements partially met, but there are some elements that are incomplete and/or inaccurate. Major revision of the work required before team is ready for modeling.\nNeeds Improvement (7 or fewer points points): Requirements are largely unmet, and there are large elements that are incomplete and/or inaccurate. Substantial revisions of the work required before team is ready for modeling."
  },
  {
    "objectID": "project-old.html#draft-report-peer-review",
    "href": "project-old.html#draft-report-peer-review",
    "title": "Final project",
    "section": "Draft report + peer review",
    "text": "Draft report + peer review\nThe purpose of the draft and peer review is to give you an opportunity to get early feedback on your analysis. Therefore, the draft and peer review will focus primarily on the exploratory data analysis, modeling, and initial interpretations.\n\nDraft report\n\n\n\n\n\n\nDue dates\n\n\n\nDraft is due in your project GitHub repo at 9am on\n\nTuesday, November 14 (Tuesday labs)\nThursday, November 16 (Thursday labs)\n\n\n\nWrite the draft in the written-report.qmd file in your project repo. You do not need to submit the draft on Gradescope.\nBelow is a brief description of the sections to focus on in the draft:\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the body of the report, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, any variable transformations (if needed), and any other relevant considerations that were part of the model fitting process.\n\n\nResults\nIn this section, you will output the final model and include a brief discussion of the model assumptions, diagnostics, and any relevant model fit statistics.\nThis section also includes initial interpretations and conclusions drawn from the model.\n\n\nGrading\nThe draft will be graded based on whether there is demonstration of a reasonable attempt at each of the sections described below in the written-report.qmd file in our GitHub repo by the deadline.\n\n\n\nPeer review\n\n\n\n\n\n\nImportant\n\n\n\nPeer review comments are due in GitHub at 11:59pm on\n\nWednesday, November 15 (Tuesday labs)\nFriday, November 17 (Thursday labs)\n\n\n\nCritically reviewing others’ work is a crucial part of the scientific process, and STA 210 is no exception. Each lab team will be assigned two other teams’s projects to review. Each team should push their draft to their GitHub repo by the 9am on the day their lab’s draft is due. The lab that week will be dedicate to the peer review, so your team will have time to review and provide quality feedback to two other teams.\nDuring the peer review process, you will be provided read-only access to your partner teams’ GitHub repos. Provide your review in the form of GitHub issues to your partner team’s GitHub repo using the issue template provided in the repo.\n\nSteps for peer review\n\n\n\n\n\n\nPeer review assignments\n\n\n\nClick here to see which project your team is reviewing. You’ll spend about 30 minutes reviewing each project.\n\n\nWhen you get to lab, you should have access to the GitHub repos for the teams you’re reviewing. In GitHub, search the repositories for project, and you should see the repos for the projects you’re reviewing. You will be able to read the files in the repo and post issues, but you cannot push changes to the repo. You will have access to the repo until the deadline for the peer review.\nFor each team you’re reviewing:\n\nOpen that team’s repo, read the project draft, and browse the rest of the repo.\nGo to the Issues tab in that repo, click on New issue, and click on Get started for the Peer Review issue. Fill out this issue. You will answer the the following questions:\n\nDescribe the goal of the project.\nDescribe the data set used in the project. What are the observations in the data? What is the source of the data? How were the data originally collected?\nConsider the exploratory data analysis (EDA). Describe one aspect of the EDA that is effective in helping you understand the data. Provide constructive feedback on how the team might improve the EDA.\nDescribe the statistical methods and analysis approach used.\nProvide constructive feedback on how the team might improve their analysis. Make sure your feedback includes at least one comment on the statistical modeling aspect of the project, but also feel free to comment on aspects beyond the modeling.\nWhat aspect of this project are you most interested in and would like to see highlighted in the presentation?\nProvide constructive feedback on any issues with file and/or code organization.\n(Optional) Any further comments or feedback?\n\n\n\n\nGrading\nThe peer review will be graded on the extent to which it comprehensively and constructively addresses the components of the partner team’s report: the research context and motivation, exploratory data analysis, modeling, interpretations, and conclusions."
  },
  {
    "objectID": "project-old.html#written-report",
    "href": "project-old.html#written-report",
    "title": "Final project",
    "section": "Written report",
    "text": "Written report\nYour written report must be completed in the written-report.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\n\n\n\n\n\n\nNote\n\n\n\nBefore you finalize your write up, make sure the code chunks are not visible and all messages and warnings are suppressed.\n\n\nYou will submit the PDF of your final report on GitHub.\nThe PDF you submit must match the .qmd in your GitHub repository exactly. The mandatory components of the report are below. You are free to add additional sections as necessary. The report, including tables and visualizations, must be no more than 10 pages long. There is no minimum page requirement; however, you should comprehensively address all of the analysis and report.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will overwhelmingly be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\nGrading criteria\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The explanatory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\nGrading criteria\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to select the variables in the final model; the approach is clearly described in the report. The model selection process took into account potential interaction effects and addressed any violations in model conditions. If violations of model conditions are still present, there was a reasonable attempt to address the violations based on the course content.\n\n\n\nResults\nThis is where you will output the final model with any relevant model fit statistics, conditions, and diagnostics.\nDescribe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\nGrading criteria\nThe model fit is clearly assessed, and interesting findings from the model are clearly described. The model conditions and diagnostics are thoroughly and accurately assessed for their model. Interpretations of model coefficients are used to support the key findings and conclusions, rather than merely listing the interpretation of every model coefficient. If the primary modeling objective is prediction, the model’s predictive power is thoroughly assessed.\n\n\n\nDiscussion + Conclusion\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\nGrading criteria\nOverall conclusions from analysis are clearly described, and the model results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report.\n\nGrading criteria\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted and labeled. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages.\n\n\nSubmission\n\n\n\n\n\n\nImportant\n\n\n\nThe written report is due on Wednesday, December 13 at 11:59pm.\nTo submit your report, written-report.qmd and the rendered written-report.pdf to your team’s GitHub repo by the deadline. You will not submit the report on Gradescope.\nThe version of the report in the repo by Wednesday, December 13 will be the one that is graded."
  },
  {
    "objectID": "project-old.html#round1-submission",
    "href": "project-old.html#round1-submission",
    "title": "Final project",
    "section": "Round 1 submission (optional)",
    "text": "Round 1 submission (optional)\n\n\n\n\n\n\nDue date\n\n\n\nFriday, December 1 at 11:59pm on GitHub (all teams)\nReports submitted after this date will not receive preliminary feedback.\n\n\nThe Round 1 submission is an opportunity to receive detailed feedback on your analysis and written report before the final submission. Therefore, to make the feedback most useful, you must submit a complete written report to receive feedback. You will also be notified of the grade you would receive at that point. You will have the option to keep the grade (and thus you don’t need to turn in an updated report) or resubmit the written report by the final submission deadline to receive a new grade.\n\nTo submit the Round 1 submission:\n\nPush the updated written-report.qmd and written-report.pdf to your GitHub repo.\nOpen an issue with the title “Round 1 Submission”. You can use the template issue in the GitHub repo. Make sure I am tagged in the issue (@matackett), so I receive an email notification of your Round 1 submission. See Creating an issue from a repository for instructions on opening an issue. Please ask a member of the teaching team for assistance if you need help opening the issue.\n\n\n\n\n\n\n\nNote\n\n\n\nNote that this is optional, so there is nograde penalty for not turning in a Round 1 submission. Due to time constraints at the end of the semester, only high-level feedback will be given for the reports submitted at the final written report deadline on December 13."
  },
  {
    "objectID": "project-old.html#presentation",
    "href": "project-old.html#presentation",
    "title": "Final project",
    "section": "Presentation",
    "text": "Presentation\n\n\n\n\n\n\nImportant\n\n\n\nPresentations will take place in class during labs December 5 & 7.\n\nClick here for the presentation order.\n\n\nIn addition to the written report, your team will also do an in-person presentation that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. The presentation should be supported by slides that serve as a brief visual addition to the presentation. The presentation and slides will be graded for content and clarity.\nYou can create your slides with any software you like (Keynote, PowerPoint, Google Slides, etc.). We recommend choosing an option that’s easy to collaborate with, e.g., Google Slides.\n\n\n\n\n\n\nNote\n\n\n\nYou can also use Quarto to make your slides! While we won’t be covering making slides with Quarto in the class, we would be happy to help you with it in office hours. It’s no different than writing other documents with Quarto, so the learning curve will not be steep!\n\n\nThe presentation must be no longer than 6 minutes. It is fine if the presentation is shorter than 6 minutes, but it cannot exceed 6 minutes due to the limited time during lab.\nEvery team member is expected to speak in the presentation. Part of the grade will be whether every team member had a meaningful speaking role in the presentation.\n\nSlides\nThe slide deck should have no more than 6 content slides + 1 title slide. Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Introduce the data\nSlide 3: Highlights from EDA\nSlide 4: Final model\nSlide 5: Interesting findings from the model\nSlide 6: Conclusions + future work\n\n\n\nGrading criteria\nThe presentation grade will be based on the following criteira:\n\nContent: The group told a unified story using the appropriate regression analysis.\nSlides: The presentation slides were organized, included clear and informative visualizations, and were easily readable.\nProfessionalism: The group’s communication style was clear and professional.\nTime Management: Team divided the time well and stayed within the 6 minute time limit, with each team member making a meaning contribution to the presentation. (assessed by the teaching team only).\n\n80% of the presentation grade will be the average of the teaching scores and 20% will be the average of the peer scores.\n\n\n\n\n\n\nImportant\n\n\n\nYou can submit the presentation slides in two ways:\n\nPut a PDF of the slides in the presentation folder in your team’s GitHub repo.\nPut the URL to your slides in the README of the presentation folder. If you share the URL, please make sure permissions are set so Prof. Tackett can view the slides.\n\nSlides must be submitted by the start of your lab on December 5 or 7. You will not submit the slides on Gradescope."
  },
  {
    "objectID": "project-old.html#presentation-comments",
    "href": "project-old.html#presentation-comments",
    "title": "Final project",
    "section": "Presentation comments",
    "text": "Presentation comments\n\n\n\n\n\n\nImportant\n\n\n\nClick here to find the teams you’re scoring and a link to the feedback form.\nThis portion of the project will be assessed individually.\n\n\n\nYou will provide feedback on two teams’ presentations. You can find your assigned teams and the link to the feedback from here. Please provide all scores and comments by the end of the lab session. There will be a few minutes between each presentation to submit scores.\nThe grade will be based on submitting the scores and comments for both of your assigned teams by the end of the presentation day (December 5 for Tuesday labs, December 7 for Thursday labs)."
  },
  {
    "objectID": "project-old.html#reproducibility-organization",
    "href": "project-old.html#reproducibility-organization",
    "title": "Final project",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nThe GitHub repo should have the following structure:\n\nREADME: Short project description and data dictionary\nwritten-report.qmd & written-report.pdf: Final written report\nproposal.qmd & proposal.pdf: Project proposal\n/data: Folder that contains the data set for the final project.\nproject.Rproj: File specifying the RStudio project\n/presentation: Folder with the presentation slides or link to slides.\n.gitignore: File that lists all files that are in the local RStudio project but not the GitHub repo\n/.github: Folder for peer review issue template\n\nPoints for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable.\n\n\n\n\n\n\nImportant\n\n\n\nThe repo must be ready for grading by Wednesday, December 13 at 11:59pm."
  },
  {
    "objectID": "project-old.html#peer-teamwork-evaluation",
    "href": "project-old.html#peer-teamwork-evaluation",
    "title": "Final project",
    "section": "Peer teamwork evaluation",
    "text": "Peer teamwork evaluation\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member by assigning a contribution percentage for each team member. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly."
  },
  {
    "objectID": "project-old.html#overall-grading",
    "href": "project-old.html#overall-grading",
    "title": "Final project",
    "section": "Overall grading",
    "text": "Overall grading\nThe grade breakdown is as follows:\n\n\n\nTotal\n100 pts\n\n\n\n\nProject proposal\n15 pts\n\n\nDraft report + peer review\n15 pts\n\n\nPresentation\n20 pts\n\n\nPresentation comments\n5 pts\n\n\nWritten report\n40 pts\n\n\nReproducibility + organization\n5 pts\n\n\n\n\nGrading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort."
  },
  {
    "objectID": "project-old.html#late-work-policy",
    "href": "project-old.html#late-work-policy",
    "title": "Final project",
    "section": "Late work policy",
    "text": "Late work policy\nThere is no late work accepted on the draft report or presentation. Other components of the project may be accepted up to 48 hours late. A 10% late deduction will apply for each 24-hour period late.\nBe sure to turn in your work early to avoid any technological mishaps."
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Final project",
    "section": "",
    "text": "Research questions due Thursday, September 26\nProject proposal due Thursday, October 3\nExploratory data analysis due Thursday, October 31\nPresentation + Presentation comments Monday, November 11 (in lab)\nAnalysis draft + peer review Monday, November 25 (peer review in lab)\nRound 1 submission (optional) due Friday, December 6\nWritten report due Thursday, December 12 at 9pm\nReproducibility + organization due Thursday, December 12 at 9pm",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#project-milestones",
    "href": "project.html#project-milestones",
    "title": "Final project",
    "section": "",
    "text": "Research questions due Thursday, September 26\nProject proposal due Thursday, October 3\nExploratory data analysis due Thursday, October 31\nPresentation + Presentation comments Monday, November 11 (in lab)\nAnalysis draft + peer review Monday, November 25 (peer review in lab)\nRound 1 submission (optional) due Friday, December 6\nWritten report due Thursday, December 12 at 9pm\nReproducibility + organization due Thursday, December 12 at 9pm",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#introduction",
    "href": "project.html#introduction",
    "title": "Final project",
    "section": "Introduction",
    "text": "Introduction\nTL;DR: Pick a data set and do a regression analysis. That is your final project.\nThe goal of the final project is for you to use regression analysis to analyze a data set of your own choosing. The data set may already exist or you may collect your own data by scraping the web.\nChoose the data based on your group’s interests or work you all have done in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like!) and apply them to a data set to analyze it in a meaningful way.\nAll analyses must be done in RStudio using Quarto and GitHub, and your analysis and written report must be reproducible.\n\nLogistics\nYou will work on the project with your lab groups. The primary deliverables for the project are\n\nan in-person presentation about the exploratory data analysis and initial modeling\na written, reproducible final report detailing your analysis\na GitHub repository containing all work from the project\n\nThere are intermediate milestones and peer review assignments throughout the semester to help you work towards the final deliverables.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#research-questions",
    "href": "project.html#research-questions",
    "title": "Final project",
    "section": "Research questions",
    "text": "Research questions\nThe goal of this milestone is to discuss topics and develop potential research questions your team is interested in investigating for the project. You are only developing potential research questions; you do not need to have a data set identified at this point.\nDevelop three potential research questions. Include the following for each question:\n\nA statement of the research question.\nThe target population of interest for this question.\nA statement about your motivation for investigating this research question and why this question is important.\nIdeas about the type of data you might use to answer this question. Note: These are your ideas about the type of data you could use. You do not need to have a data set at this point.\n\n\nSubmission\nWrite your responses in research-questions.qmd in your team’s project GitHub repo. Push the qmd and rendered pdf documents to GitHub by the deadline, Thursday, September 26 at 11:59pm.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#project-proposal",
    "href": "project.html#project-proposal",
    "title": "Final project",
    "section": "Project proposal",
    "text": "Project proposal\nThe purpose of the project proposal is for your team to identify the data set you’re interested in analyzing to investigate one of your potential research questions. You will also do some preliminary exploration of the response variable and begin thinking about the modeling strategy. If you’re unsure where to find data, you can use the list of potential data sources on the Tips + resources page as a starting point.\n\n\n\n\n\n\nImportant\n\n\n\nYou must the data set(s) in the proposal for the final project, unless instructed otherwise when given feedback.\n\n\nThe data set must meet the following criteria:\n\nAt least 500 observations\nAt least 10 columns, such that at least 6 of the columns are useful and unique predictor variables.\n\ne.g., identifier variables such as “name”, “ID number”, etc. are not useful predictor variables.\ne.g., if you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique predictors.\n\nAt least one variable that can be identified as a reasonable response variable.\n\nThe response variable can be quantitative or categorical.\n\nA mix of quantitative and categorical variables that can be used as predictors.\nMay not be data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\n\n\n\n\n\n\nTypes of data sets to avoid\n\n\n\n\nData that are likely violate the independence condition. Therefore, avoid data with repeated measures, data collected over time, etc.\nData sets in which there is no information about how the data were originally collected\nData sets in which there are missing or unclear definitions about the observations and/or variables\n\n\n\nAsk a member of the teaching team if you’re unsure whether your data set meets the criteria.\nThe proposal will include the following sections:\n\nSection 1: Introduction\n\n\n\n\n\n\nTip\n\n\n\nReuse and iterate on the work from the Research Questions milestone.\n\n\n\nAn introduction to the subject matter you’re investigating (citing any relevant literature)\nStatement of a well-developed research question.\nThe motivation for your research question and why it is important\nYour team’s hypotheses regarding the research question\n\nThis is a narrative about what you think regarding the research question, not formal statistical hypotheses.\n\n\n\n\nSection 2: Data description\n\nThe source of the data set\nA description of when and how the data were originally collected (by the original data curator, not necessarily how you found the data)\nA description of the observations and general characteristics being measured\n\n\n\nSection 3: Initial exploratory data analysis\n\nDescription of data cleaning you need to do to prepare for analysis (can focus on the response variable for now), such as joining data sets, imputing missing values, variable transformation, creating a new variable, etc.\nVisualizations, summary statistics, and narrative to describe the distribution of the response variable.\n\n\n\nSection 4: Analysis approach\n\na description of the potential predictor variables of interest\nregression model technique (multiple linear regression for quantitative response variable or logistic regression for a categorical response variable)\n\n\n\nData dictionary (aka code book)\nSubmit a data dictionary for all the variables in your data set in the README of the data folder. You do not need to include the data dictionary in the PDF document.\n\n\nSubmission\nWrite your narrative and analysis for Sections 1 - 4 in the proposal.qmd file in your team’s GitHub repo. Put the data set and the data dictionary in the data folder in the repo. Push the qmd and rendered pdf documents to GitHub by the deadline, Thursday, October 3 at 11:59pm.\n\n\nGrading\nThe anticipated length, including all graphs, tables, narrative, etc., is 2 -4 pages.\nThe proposal is worth 10 points and will be graded based on accurately and comprehensively addressing the criteria stated above. Points will be assigned based on a holistic review of the project proposal.\n\nExcellent (9 - 10 points) : All required elements are completed and are accurate. The data set meets the requirements (or the team has otherwise discussed the data with Professor Tackett) and the data do not pose obvious violations to the modeling assumptions. There is a thoughtful and comprehensive description of the data and exploration of the response variable as descrbied above. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nStrong (7 - 8 points): Requirements are mostly met, but there are some elements that are incomplete or inaccurate. Some minor revision of the work required before team is ready for modeling.\nSatisfactory (5 - 6 points): Requirements partially met, but there are some elements that are incomplete and/or inaccurate. Major revision of the work required before team is ready for modeling.\nNeeds Improvement (4 or fewer points points): Requirements are largely unmet, and there are large elements that are incomplete and/or inaccurate. Substantial revisions of the work required before team is ready for modeling.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#eda",
    "href": "project.html#eda",
    "title": "Final project",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\n\n\n\n\n\nTip\n\n\n\nReuse and iterate on the work from the previous milestones.\n\n\nThe purpose of this milestone is begin exploring the data and get early feedback on your data and analysis. You will submit a draft of the beginning of your report that includes the introduction and exploratory data analysis, with an emphasis on the EDA. It will also help you prepare for the presentation of the exploratory data analysis results.\nBelow is a brief description of the sections to include in this step:\n\nIntroduction\nThis section includes an introduction to the project motivation, background, data, and research question.\n\n\nExploratory data analysis\nThis section includes the following:\n\nDescription of the data set and key variables.\nExploratory data analysis of the response variable and key predictor variables.\n\nUnivariate EDA of the response and key predictor variables.\nBivariate EDA of the response and key predictor variables\nPotential interaction effects.\n\n\n\n\nSubmission\nWrite your draft introduction and exploratory data analysis in the written-report.qmd file in your team’s GitHub repo. Push the qmd and rendered pdf documents to GitHub by the deadline, Thursday, October 31 at 11:59pm.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#presentation",
    "href": "project.html#presentation",
    "title": "Final project",
    "section": "Presentation",
    "text": "Presentation",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#draft-report-peer-review",
    "href": "project.html#draft-report-peer-review",
    "title": "Final project",
    "section": "Analysis + peer review",
    "text": "Analysis + peer review",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#round1-submission",
    "href": "project.html#round1-submission",
    "title": "Final project",
    "section": "Round 1 submission (optional)",
    "text": "Round 1 submission (optional)",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#written-report",
    "href": "project.html#written-report",
    "title": "Final project",
    "section": "Written report",
    "text": "Written report",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#reproducibility-organization",
    "href": "project.html#reproducibility-organization",
    "title": "Final project",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#peer-teamwork-evaluation",
    "href": "project.html#peer-teamwork-evaluation",
    "title": "Final project",
    "section": "Peer teamwork evaluation",
    "text": "Peer teamwork evaluation\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member by assigning a contribution percentage for each team member. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#overall-grading",
    "href": "project.html#overall-grading",
    "title": "Final project",
    "section": "Overall grading",
    "text": "Overall grading\nThe grade breakdown is as follows:\n\n\n\nTotal\n100 pts\n\n\n\n\nResearch question\n3 pts\n\n\nProject proposal\n10 pts\n\n\nExploratory data analysis\n15 pts\n\n\nPresentation\n10 pts\n\n\nPresentation comments\n2 pts\n\n\nDraft report + peer review\n15 pts\n\n\nWritten report\n40 pts\n\n\nReproducibility + organization\n5 pts\n\n\n\n\nGrading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#late-work-policy",
    "href": "project.html#late-work-policy",
    "title": "Final project",
    "section": "Late work policy",
    "text": "Late work policy\nThere is no late work accepted on the draft report or presentation. Other components of the project may be accepted up to 48 hours late. A 10% late deduction will apply for each 24-hour period late.\nBe sure to turn in your work early to avoid any technological mishaps.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project-tips.html",
    "href": "project-tips.html",
    "title": "Final project tips + resources",
    "section": "",
    "text": "Data sources\n\nSome resources that may be helpful as you find data:\n\nFiveThirtyEight data\nTidyTuesday\nData Is Plural\nR Data Sources for Regression Analysis\n\n\n\nOther data repositories\n\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies\n\n\n\n\nTips\n\nAsk questions if any of the expectations are unclear.\nCode: In your write up your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your Qmd file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you’re welcome to show that portion.\n\nMerge conflicts will happen, issues will arise, and that’s fine! Commit and push often, and ask questions when stuck.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nAll team members are expected to contribute equally to the completion of this assignment and group assessments will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works.\n\n\n\nFormatting + communication tips\n\nSuppress Code, Warnings, & Messages\n\nInclude the following code in a code chunk at the top of your .qmd file to suppress all code, warnings, and other messages. Use the code chunk header {r set-up, include = FALSE} to suppress this set up code.\n\nknitr::opts_chunk$set(echo = FALSE,\n                      warning = FALSE, \n                      message = FALSE)\n\nAn alternative approach is to add the following code to the YAML:\n\nexecute:\n  echo: false\n  warning: false\n  message: false\n\n\n\n\nHeaders\n\nUse headers to clearly label each section. Make sure there is a space between the last # and the title, so the header renders correctly. For example, ###Section Title will not render as header, but ### Section Title will.\n\n\n\nReferences\n\nInclude all references in a section called “References” at the end of the report.\nThis course does not have specific requirements for formatting citations and references.\n\n\n\nAppendix\n\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called “Appendix”.\nThe items in the appendix should be properly labeled.\nThe appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix.\n\n\n\nResize figures\n\nResize plots and figures, so you have more space for the narrative.\n\nResize individual figures: Use the code chunk header {r plot1, fig.height = 3, fig.width = 5}, replacing plot1 with a meaningful label and the height and width with values appropriate for your write up.\nResize all figures: Include the fig_width and fig_height options in your YAML header as shown below:\n\n\n\n---\ntitle: \"Your title\"\nauthor: \"Your names\"\nformat:\n  pdf:\n    fig-width: 7\n    fig-height: 5\n---\nReplace the height and width values with values appropriate for your write up.\n\n\nArranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\n\nIf you’re using ggplot2 functions, the patchwork package makes it easy to arrange plots in a grid. See the documentation and examples here.\nIf you’re using base R function, i.e. when using the emplogit functions, put the code par(mfrow = c(rows,columns)) before the code to make the plots. For example, par(mfrow = c(2,3)) will arrange plots in a grid with 2 rows and 3 columns.\n\n\n\nPlot titles and axis labels\nBe sure all plot titles and axis labels are visible and easy to read.\n\nUse informative titles, not variable names, for titles and axis labels.\nUse coord_flip() to flip the x and y axes on the plot. This is useful if you a bar plot with an x-axis that is difficult to read due to overlapping text.\n\n❌ NO! The x-axis is hard to read because the names overlap.\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n✅ YES! Names are readable\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\nDo a little more to make the plot look professional!\n\nInformative title and axis labels\nFlipped coordinates to make names readable\nArranged bars based on count\nCapitalized manufacturer names\nOptional: Added color - Use a coordinated color scheme throughout paper / presentation\nOptional: Applied a theme - Use same theme throughout paper / presentation\n\n\nmpg |&gt;\n  count(manufacturer) |&gt;\n  mutate(manufacturer = str_to_title(manufacturer)) |&gt;\n  ggplot(aes(x = fct_reorder(manufacturer,n), y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  coord_flip() +\n  labs(x = \"Manufacturer\", \n       y = \"Count\", \n       title = \"The most common manufacturer is Dodge\") +\n  theme_bw() \n\n\n\n\n\n\n\n\n\n\nTables and model output\n\nUse the kable function from the knitr package to neatly output all tables and model output. This will also ensure all model coefficients are displayed.\n\nUse the digits argument to display only 3 or 4 significant digits.\nUse the caption argument to add captions to your table.\n\n\n\nmodel &lt;- lm(mpg ~ hp, data = mtcars)\ntidy(model) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n30.099\n1.634\n18.421\n0\n\n\nhp\n-0.068\n0.010\n-6.742\n0\n\n\n\n\n\n\n\nGuidelines for communicating results\n\nDon’t use variable names in your narrative! Use descriptive terms, so the reader understands your narrative without relying on the data dictionary.\n\n❌ There is a negative linear relationship between mpg and hp.\n✅ There is a negative linear relationship between a car’s fuel economy (in miles per gallon) and its horsepower.\n\nKnow your audience: Your report should be written for a general audience who has an understanding of statistics at the level of STA 210.\nAvoid subject matter jargon: Don’t assume the audience knows all of the specific terminology related to your subject area. If you must use jargon, include a brief definition the first time you introduce a term.\nTell the “so what”: Your report and presentation should be more than a list of interpretations and technical definitions. Focus on what the results mean, i.e. what you want the audience to know about your topic after reading your report or viewing your presentation.\n\n❌ For every one unit increase in horsepower, we expect the miles per gallon to decrease by 0.068 units, on average.\n✅ If the priority is to have good fuel economy, then one should choose a car with lower horsepower. Based on our model, the fuel economy is expected to decrease, on average, by 0.68 miles per gallon for every 10 additional horsepower.\n\nTell a story: All visualizations, tables, model output, and narrative should tell a cohesive story!\nUse one voice: Though multiple people are writing the report, it should read as if it’s from a single author. At least one team member should read through the report before submission to ensure it reads like a cohesive document.\n\n\n\n\nAdditional resources\n\nExploring RStudio’s Visual Markdown Editor\nR for Data Science\nQuarto documentation:\n\nQuarto PDF Basics\nPresentations in Quarto\n\nData visualization\n\nggplot2 Reference\nggplot2: Elegant Graphics for Data Analysis\nData Visualization: A Practice Introduction\nPatchwork R Package",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "math-rules.html",
    "href": "math-rules.html",
    "title": "Math rules",
    "section": "",
    "text": "This page contains mathematical rules we’ll use in this course that may be beyond what is covered in a linear algebra course.\n\n\n\n\nLet \\(\\mathbf{x} = \\begin{bmatrix}x_1 \\\\ x_2 \\\\ \\vdots \\\\x_k\\end{bmatrix}\\)be a \\(k \\times 1\\) vector and \\(f(\\mathbf{x})\\) be a function of \\(\\mathbf{x}\\).\nThen \\(\\nabla_\\mathbf{x}f\\), the gradient of \\(f\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x}f = \\begin{bmatrix}\\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial x_k}\\end{bmatrix}\n\\]\n\n\n\n\nLet \\(\\mathbf{x}\\) be a \\(k \\times 1\\) vector and \\(\\mathbf{z}\\) be a \\(k \\times 1\\) vector, such that \\(\\mathbf{z}\\) is not a function of \\(\\mathbf{x}\\) .\nThe gradient of \\(\\mathbf{x}^T\\mathbf{z}\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x} \\hspace{1mm} \\mathbf{x}^T\\mathbf{z} = \\mathbf{z}\n\\]\n\n\n\n\nLet \\(\\mathbf{x}\\) be a \\(k \\times 1\\) vector and \\(\\mathbf{A}\\) be a \\(k \\times k\\) matrix, such that \\(\\mathbf{A}\\) is not a function of \\(\\mathbf{x}\\) .\nThen the gradient of \\(\\mathbf{x}^T\\mathbf{A}\\mathbf{x}\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x} \\hspace{1mm} \\mathbf{x}^T\\mathbf{A}\\mathbf{x} = (\\mathbf{A}\\mathbf{x} + \\mathbf{A}^T \\mathbf{x}) = (\\mathbf{A} + \\mathbf{A}^T)\\mathbf{x}\n\\]\nIf \\(\\mathbf{A}\\) is symmetric, then\n\\[\n(\\mathbf{A} + \\mathbf{A}^T)\\mathbf{x} = 2\\mathbf{A}\\mathbf{x}\n\\]\n\n\n\n\nThe Hessian matrix, \\(\\nabla_\\mathbf{x}^2f\\) is a \\(k \\times k\\) matrix of partial second derivatives\n\\[\n\\nabla_{\\mathbf{x}}^2f = \\begin{bmatrix} \\frac{\\partial^2f}{\\partial x_1^2} & \\frac{\\partial^2f}{\\partial x_1 \\partial x_2} & \\dots & \\frac{\\partial^2f}{\\partial x_1\\partial x_k} \\\\\n\\frac{\\partial^2f}{\\partial\\ x_2 \\partial x_1} & \\frac{\\partial^2f}{\\partial x_2^2} & \\dots & \\frac{\\partial^2f}{\\partial x_2 \\partial x_k} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial^2f}{\\partial x_k\\partial x_1} & \\frac{\\partial^2f}{\\partial x_k\\partial x_2} & \\dots & \\frac{\\partial^2f}{\\partial x_k^2} \\end{bmatrix}\n\\]\n\n\n\n\n\n\nThe expected value of a random variable \\(\\mathbf{X}\\) is a weighted average, i.e., the mean value of the possible values a random variable can take weighted by the probability of the outcomes.\nLet \\(f_X(x)\\) be the probability distribution of \\(X\\). If \\(X\\) is continuous then\n\\[\nE(X) = \\int_{-\\infty}^{\\infty}xf_X(x)dx\n\\]\nIf \\(X\\) is discrete then\n\\[\nE(X) = \\sum_{x \\in X}xf_X(x) = \\sum_{x\\in X}xP(X = x)\n\\]\n\n\n\n\nLet \\(X\\) be a random variable and \\(a\\) and \\(b\\) be constants. Then\n\\[\nE(aX + b) = E(aX) + E(b) = aE(X) + b\n\\]\n\n\n\n\nLet \\(X\\) be a random variable and \\(a\\), \\(b\\), and \\(c\\) be constants. For any functions \\(g_1(x)\\) and \\(g_2(x)\\), then\n\\[E(ag_1(X) + bg_2(X) + c) = aE(g_1(X)) + bE(g_2(X)) + c\\]\n\n\n\n\nLet \\(\\mathbf{b} = \\begin{bmatrix}b_1 \\\\ \\vdots \\\\b_p\\end{bmatrix}\\) be a \\(p \\times 1\\) vector of random variables.\nThen \\(E(\\mathbf{b}) = E\\begin{bmatrix}b_1 \\\\ \\vdots \\\\ b_p\\end{bmatrix} = \\begin{bmatrix}E(b_1) \\\\ \\vdots \\\\ E(b_p)\\end{bmatrix}\\)\n\n\n\n\nLet \\(\\mathbf{A}\\) be a \\(n \\times p\\) matrix of constants and \\(\\mathbf{b}\\) a \\(p \\times 1\\) vector of random variables. Then\n\\[\nE(\\mathbf{Ab}) = \\mathbf{A}E(\\mathbf{b})\n\\]\n\n\n\n\n\n\nThe variance of a random variable \\(X\\) is a measure of the spread of a distribution about its mean.\n\\[\nVar(X) = E[(X - E(X))^2] = E(X^2) - E(X)^2\n\\]\n\n\n\n\nLet \\(X\\) be a random variable and \\(a\\) and \\(b\\) be constants. Then\n\\[\nVar(aX + b) = a^2Var(X)\n\\]\n\n\n\n\nLet \\(\\mathbf{b} = \\begin{bmatrix}b_1 \\\\ \\vdots \\\\b_p\\end{bmatrix}\\) be a \\(p \\times 1\\) vector of random variables.\nThen\n\\[\nVar(\\mathbf{b}) = E[(\\mathbf{b} - E(\\mathbf{b}))(\\mathbf{b} - E(\\mathbf{b}))^T]\n\\]\n\n\n\n\nLet \\(\\mathbf{A}\\) be a \\(n \\times p\\) matrix of constants and \\(\\mathbf{b}\\) a \\(p \\times 1\\) vector of random variables. Then\n\\[\n\\begin{aligned}\nVar(\\mathbf{Ab}) &= E[(\\mathbf{Ab} - E(\\mathbf{Ab}))(\\mathbf{Ab} - E(\\mathbf{Ab}))^T]\\\\& = \\mathbf{A}Var(\\mathbf{b})\\mathbf{A}^T\n\\end{aligned}\n\\]\n\n\n\n\n\n\nLet \\(X\\) be a random variable, such that \\(X \\sim N(\\mu, \\sigma^2)\\). Then the probability function is\n\\[\nP(X = x | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\Big\\{-{\\frac{1}{2\\sigma^2}(x - \\mu)^2}\\Big\\}\n\\]",
    "crumbs": [
      "Math rules"
    ]
  },
  {
    "objectID": "math-rules.html#matrix-calculus",
    "href": "math-rules.html#matrix-calculus",
    "title": "Math rules",
    "section": "",
    "text": "Let \\(\\mathbf{x} = \\begin{bmatrix}x_1 \\\\ x_2 \\\\ \\vdots \\\\x_k\\end{bmatrix}\\)be a \\(k \\times 1\\) vector and \\(f(\\mathbf{x})\\) be a function of \\(\\mathbf{x}\\).\nThen \\(\\nabla_\\mathbf{x}f\\), the gradient of \\(f\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x}f = \\begin{bmatrix}\\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial x_k}\\end{bmatrix}\n\\]\n\n\n\n\nLet \\(\\mathbf{x}\\) be a \\(k \\times 1\\) vector and \\(\\mathbf{z}\\) be a \\(k \\times 1\\) vector, such that \\(\\mathbf{z}\\) is not a function of \\(\\mathbf{x}\\) .\nThe gradient of \\(\\mathbf{x}^T\\mathbf{z}\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x} \\hspace{1mm} \\mathbf{x}^T\\mathbf{z} = \\mathbf{z}\n\\]\n\n\n\n\nLet \\(\\mathbf{x}\\) be a \\(k \\times 1\\) vector and \\(\\mathbf{A}\\) be a \\(k \\times k\\) matrix, such that \\(\\mathbf{A}\\) is not a function of \\(\\mathbf{x}\\) .\nThen the gradient of \\(\\mathbf{x}^T\\mathbf{A}\\mathbf{x}\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x} \\hspace{1mm} \\mathbf{x}^T\\mathbf{A}\\mathbf{x} = (\\mathbf{A}\\mathbf{x} + \\mathbf{A}^T \\mathbf{x}) = (\\mathbf{A} + \\mathbf{A}^T)\\mathbf{x}\n\\]\nIf \\(\\mathbf{A}\\) is symmetric, then\n\\[\n(\\mathbf{A} + \\mathbf{A}^T)\\mathbf{x} = 2\\mathbf{A}\\mathbf{x}\n\\]\n\n\n\n\nThe Hessian matrix, \\(\\nabla_\\mathbf{x}^2f\\) is a \\(k \\times k\\) matrix of partial second derivatives\n\\[\n\\nabla_{\\mathbf{x}}^2f = \\begin{bmatrix} \\frac{\\partial^2f}{\\partial x_1^2} & \\frac{\\partial^2f}{\\partial x_1 \\partial x_2} & \\dots & \\frac{\\partial^2f}{\\partial x_1\\partial x_k} \\\\\n\\frac{\\partial^2f}{\\partial\\ x_2 \\partial x_1} & \\frac{\\partial^2f}{\\partial x_2^2} & \\dots & \\frac{\\partial^2f}{\\partial x_2 \\partial x_k} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial^2f}{\\partial x_k\\partial x_1} & \\frac{\\partial^2f}{\\partial x_k\\partial x_2} & \\dots & \\frac{\\partial^2f}{\\partial x_k^2} \\end{bmatrix}\n\\]",
    "crumbs": [
      "Math rules"
    ]
  },
  {
    "objectID": "math-rules.html#expected-value",
    "href": "math-rules.html#expected-value",
    "title": "Math rules",
    "section": "",
    "text": "The expected value of a random variable \\(\\mathbf{X}\\) is a weighted average, i.e., the mean value of the possible values a random variable can take weighted by the probability of the outcomes.\nLet \\(f_X(x)\\) be the probability distribution of \\(X\\). If \\(X\\) is continuous then\n\\[\nE(X) = \\int_{-\\infty}^{\\infty}xf_X(x)dx\n\\]\nIf \\(X\\) is discrete then\n\\[\nE(X) = \\sum_{x \\in X}xf_X(x) = \\sum_{x\\in X}xP(X = x)\n\\]\n\n\n\n\nLet \\(X\\) be a random variable and \\(a\\) and \\(b\\) be constants. Then\n\\[\nE(aX + b) = E(aX) + E(b) = aE(X) + b\n\\]\n\n\n\n\nLet \\(X\\) be a random variable and \\(a\\), \\(b\\), and \\(c\\) be constants. For any functions \\(g_1(x)\\) and \\(g_2(x)\\), then\n\\[E(ag_1(X) + bg_2(X) + c) = aE(g_1(X)) + bE(g_2(X)) + c\\]\n\n\n\n\nLet \\(\\mathbf{b} = \\begin{bmatrix}b_1 \\\\ \\vdots \\\\b_p\\end{bmatrix}\\) be a \\(p \\times 1\\) vector of random variables.\nThen \\(E(\\mathbf{b}) = E\\begin{bmatrix}b_1 \\\\ \\vdots \\\\ b_p\\end{bmatrix} = \\begin{bmatrix}E(b_1) \\\\ \\vdots \\\\ E(b_p)\\end{bmatrix}\\)\n\n\n\n\nLet \\(\\mathbf{A}\\) be a \\(n \\times p\\) matrix of constants and \\(\\mathbf{b}\\) a \\(p \\times 1\\) vector of random variables. Then\n\\[\nE(\\mathbf{Ab}) = \\mathbf{A}E(\\mathbf{b})\n\\]",
    "crumbs": [
      "Math rules"
    ]
  },
  {
    "objectID": "math-rules.html#variance",
    "href": "math-rules.html#variance",
    "title": "Math rules",
    "section": "",
    "text": "The variance of a random variable \\(X\\) is a measure of the spread of a distribution about its mean.\n\\[\nVar(X) = E[(X - E(X))^2] = E(X^2) - E(X)^2\n\\]\n\n\n\n\nLet \\(X\\) be a random variable and \\(a\\) and \\(b\\) be constants. Then\n\\[\nVar(aX + b) = a^2Var(X)\n\\]\n\n\n\n\nLet \\(\\mathbf{b} = \\begin{bmatrix}b_1 \\\\ \\vdots \\\\b_p\\end{bmatrix}\\) be a \\(p \\times 1\\) vector of random variables.\nThen\n\\[\nVar(\\mathbf{b}) = E[(\\mathbf{b} - E(\\mathbf{b}))(\\mathbf{b} - E(\\mathbf{b}))^T]\n\\]\n\n\n\n\nLet \\(\\mathbf{A}\\) be a \\(n \\times p\\) matrix of constants and \\(\\mathbf{b}\\) a \\(p \\times 1\\) vector of random variables. Then\n\\[\n\\begin{aligned}\nVar(\\mathbf{Ab}) &= E[(\\mathbf{Ab} - E(\\mathbf{Ab}))(\\mathbf{Ab} - E(\\mathbf{Ab}))^T]\\\\& = \\mathbf{A}Var(\\mathbf{b})\\mathbf{A}^T\n\\end{aligned}\n\\]",
    "crumbs": [
      "Math rules"
    ]
  },
  {
    "objectID": "math-rules.html#probability-distributions",
    "href": "math-rules.html#probability-distributions",
    "title": "Math rules",
    "section": "",
    "text": "Let \\(X\\) be a random variable, such that \\(X \\sim N(\\mu, \\sigma^2)\\). Then the probability function is\n\\[\nP(X = x | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\Big\\{-{\\frac{1}{2\\sigma^2}(x - \\mu)^2}\\Big\\}\n\\]",
    "crumbs": [
      "Math rules"
    ]
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#announcements",
    "href": "slides/05-slr-matrix-contd.html#announcements",
    "title": "SLR: Matrix representation",
    "section": "Announcements",
    "text": "Announcements\n\nLab 01 due on Thursday, September 12 at 11:59pm\n\nPush work to GitHub repo\nSubmit final PDF on Gradescope + mark pages for each question\n\nHW 01 will be assigned on Thursday"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#topics",
    "href": "slides/05-slr-matrix-contd.html#topics",
    "title": "SLR: Matrix representation",
    "section": "Topics",
    "text": "Topics\n\nMatrix representation of simple linear regression\n\nModel form\nLeast square estimate\nPredicted (fitted) values\nResiduals"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#slr-in-matrix-form",
    "href": "slides/05-slr-matrix-contd.html#slr-in-matrix-form",
    "title": "SLR: Matrix representation",
    "section": "SLR in matrix form",
    "text": "SLR in matrix form\nSuppose we have \\(n\\) observations, a quantitative response variable, and a single predictor\\[\n\\underbrace{\n\\begin{bmatrix}\ny_1 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix} }_\n{\\mathbf{y}} \\hspace{3mm}\n=\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n1 &x_1 \\\\\n\\vdots &  \\vdots \\\\\n1 &  x_n\n\\end{bmatrix}\n}_{\\mathbf{X}}\n\\hspace{2mm}\n\\underbrace{\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1\n\\end{bmatrix}\n}_{\\boldsymbol{\\beta}}\n\\hspace{3mm}\n+\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n\\epsilon_1 \\\\\n\\vdots\\\\\n\\epsilon_n\n\\end{bmatrix}\n}_\\boldsymbol{\\epsilon}\n\\]\n\n\n\\(\\mathbf{y}\\): \\(n\\times 1\\) vector of responses\n\\(\\mathbf{X}\\): \\(n \\times 2\\) design matrix\n\\(\\boldsymbol{\\beta}\\): \\(2 \\times 1\\) vector of coefficients\n\\(\\boldsymbol{\\epsilon}\\): \\(n \\times 1\\) vector of error terms"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#minimize-sum-of-squared-residuals",
    "href": "slides/05-slr-matrix-contd.html#minimize-sum-of-squared-residuals",
    "title": "SLR: Matrix representation",
    "section": "Minimize sum of squared residuals",
    "text": "Minimize sum of squared residuals\nGoal: Find \\(\\boldsymbol{\\beta} = \\begin{bmatrix}\\beta_0 \\\\ \\beta_1 \\end{bmatrix}\\) that minimizes the sum of squared residuals \\[\n\\begin{aligned}\nSSR = \\sum_{i=1}^n e_i^2 = \\mathbf{e}^T\\mathbf{e} &= (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) \\\\[10pt]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#minimize-sum-of-squared-residuals-1",
    "href": "slides/05-slr-matrix-contd.html#minimize-sum-of-squared-residuals-1",
    "title": "SLR: Matrix representation",
    "section": "Minimize sum of squared residuals",
    "text": "Minimize sum of squared residuals\n\\[\n\\begin{aligned}\n\\mathbf{e}^T\\mathbf{e} &= (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) \\\\[10pt]\n&\\class{fragment}{= (\\mathbf{y}^T - \\boldsymbol{\\beta}^T\\mathbf{X}^T)(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})}\\\\[10pt]\n&\\class{fragment}{=\\mathbf{y}^T\\mathbf{y} - \\mathbf{y}^T\\mathbf{X}\\boldsymbol{\\beta} - \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y} + \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}}\\\\[10pt]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#minimize-sum-of-squared-residuals-2",
    "href": "slides/05-slr-matrix-contd.html#minimize-sum-of-squared-residuals-2",
    "title": "SLR: Matrix representation",
    "section": "Minimize sum of squared residuals",
    "text": "Minimize sum of squared residuals\n\\[\n\\begin{aligned}\n\\mathbf{e}^T\\mathbf{e} &= (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) \\\\[10pt]\n&= (\\mathbf{y}^T - \\boldsymbol{\\beta}^T\\mathbf{X}^T)(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\\\[10pt]\n&=\\mathbf{y}^T\\mathbf{y} - \\mathbf{y}^T\\mathbf{X}\\boldsymbol{\\beta} - \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y} + \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}\\\\[10pt]\n&=\\mathbf{y}^T\\mathbf{y} - 2\\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y} + \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#minimize-sum-of-squared-residuals-3",
    "href": "slides/05-slr-matrix-contd.html#minimize-sum-of-squared-residuals-3",
    "title": "SLR: Matrix representation",
    "section": "Minimize sum of squared residuals",
    "text": "Minimize sum of squared residuals\nThe estimate of \\(\\boldsymbol{\\beta} = \\begin{bmatrix}\\beta_0 \\\\ \\beta_1 \\end{bmatrix}\\) that minimizes SSR is the one such that\n\\[\n\\nabla_{\\boldsymbol{\\beta}} SSR = \\nabla_{\\boldsymbol{\\beta}}( \\mathbf{y}^T\\mathbf{y} - 2\\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y} + \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}) = 0\n\\]"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#side-note-vector-operations",
    "href": "slides/05-slr-matrix-contd.html#side-note-vector-operations",
    "title": "SLR: Matrix representation",
    "section": "Side note: Vector operations",
    "text": "Side note: Vector operations\nLet \\(\\mathbf{x} = \\begin{bmatrix}x_1 \\\\ x_2 \\\\ \\vdots \\\\x_k\\end{bmatrix}\\)be a \\(k \\times 1\\) vector and \\(f(\\mathbf{x})\\) be a function of \\(\\mathbf{x}\\).\n\nThen \\(\\nabla_\\mathbf{x}f\\), the gradient of \\(f\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x}f = \\begin{bmatrix}\\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial x_k}\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#side-note-vector-operations-1",
    "href": "slides/05-slr-matrix-contd.html#side-note-vector-operations-1",
    "title": "SLR: Matrix representation",
    "section": "Side note: Vector operations",
    "text": "Side note: Vector operations\nThe Hessian matrix, \\(\\nabla_\\mathbf{x}^2f\\) is a \\(k \\times k\\) matrix of partial second derivatives\n\\[\n\\nabla_{\\mathbf{x}}^2f = \\begin{bmatrix} \\frac{\\partial^2f}{\\partial x_1^2} & \\frac{\\partial^2f}{\\partial x_1 \\partial x_2} & \\dots & \\frac{\\partial^2f}{\\partial x_1\\partial x_k} \\\\\n\\frac{\\partial^2f}{\\partial\\ x_2 \\partial x_1} & \\frac{\\partial^2f}{\\partial x_2^2} & \\dots & \\frac{\\partial^2f}{\\partial x_2 \\partial x_k} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial^2f}{\\partial x_k\\partial x_1} & \\frac{\\partial^2f}{\\partial x_k\\partial x_2} & \\dots & \\frac{\\partial^2f}{\\partial x_k^2} \\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#side-note-vector-operations-2",
    "href": "slides/05-slr-matrix-contd.html#side-note-vector-operations-2",
    "title": "SLR: Matrix representation",
    "section": "Side note: Vector operations",
    "text": "Side note: Vector operations\n\n\n\nProposition 1\n\n\nLet \\(\\mathbf{x}\\) be a \\(k \\times 1\\) vector and \\(\\mathbf{z}\\) be a \\(k \\times 1\\) vector, such that \\(\\mathbf{z}\\) is not a function of \\(\\mathbf{x}\\) .\nThe gradient of \\(\\mathbf{x}^T\\mathbf{z}\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x} \\hspace{1mm} \\mathbf{x}^T\\mathbf{z} = \\mathbf{z}\n\\]"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#side-note-proposition-1",
    "href": "slides/05-slr-matrix-contd.html#side-note-proposition-1",
    "title": "SLR: Matrix representation",
    "section": "Side note: Proposition 1",
    "text": "Side note: Proposition 1\n\\[\n\\begin{aligned}\n\\mathbf{x}^T\\mathbf{z} &= \\class{fragment}{\\begin{bmatrix}x_1 & x_2 & \\dots &x_k\\end{bmatrix}\n\\begin{bmatrix}z_1 \\\\ z_2 \\\\ \\vdots \\\\z_k\\end{bmatrix}} \\\\[10pt]\n&\\class{fragment}{= x_1z_1 + x_2z_2 + \\dots + x_kz_k} \\\\\n&\\class{fragment}{= \\sum_{i=1}^k x_iz_i}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#side-note-proposition-1-1",
    "href": "slides/05-slr-matrix-contd.html#side-note-proposition-1-1",
    "title": "SLR: Matrix representation",
    "section": "Side note: Proposition 1",
    "text": "Side note: Proposition 1\n\\[\n\\nabla_\\mathbf{x}\\hspace{1mm}\\mathbf{x}^T\\mathbf{z} = \\class{fragment}{\\begin{bmatrix}\\frac{\\partial \\mathbf{x}^T\\mathbf{z}}{\\partial x_1} \\\\ \\frac{\\partial \\mathbf{x}^T\\mathbf{z}}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial \\mathbf{x}^T\\mathbf{z}}{\\partial x_k}\\end{bmatrix}}  \n= \\class{fragment}{\\begin{bmatrix}\\frac{\\partial}{\\partial x_1} (x_1z_1 + x_2z_2 + \\dots + x_kz_k) \\\\ \\frac{\\partial}{\\partial x_2} (x_1z_1 + x_2z_2 + \\dots + x_kz_k)\\\\ \\vdots \\\\ \\frac{\\partial}{\\partial x_k} (x_1z_1 + x_2z_2 + \\dots + x_kz_k)\\end{bmatrix}}\n= \\class{fragment}{\\begin{bmatrix} z_1 \\\\ z_2 \\\\ \\vdots \\\\ z_k\\end{bmatrix} = \\mathbf{z}}\n\\]"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#side-note-vector-matrix-operations",
    "href": "slides/05-slr-matrix-contd.html#side-note-vector-matrix-operations",
    "title": "SLR: Matrix representation",
    "section": "Side note: Vector + matrix operations",
    "text": "Side note: Vector + matrix operations\n\n\n\nProposition 2\n\n\nLet \\(\\mathbf{x}\\) be a \\(k \\times 1\\) vector and \\(\\mathbf{A}\\) be a \\(k \\times k\\) matrix, such that \\(\\mathbf{A}\\) is not a function of \\(\\mathbf{x}\\) .\nThen the gradient of \\(\\mathbf{x}^T\\mathbf{A}\\mathbf{x}\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x} \\hspace{1mm} \\mathbf{x}^T\\mathbf{A}\\mathbf{x} = (\\mathbf{A}\\mathbf{x} + \\mathbf{A}^T \\mathbf{x}) = (\\mathbf{A} + \\mathbf{A}^T)\\mathbf{x}\n\\]\nIf \\(\\mathbf{A}\\) is symmetric, then\n\\[\n(\\mathbf{A} + \\mathbf{A}^T)\\mathbf{x} = 2\\mathbf{A}\\mathbf{x}\n\\]\n\n\n\n\nProof in HW 01"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#find-the-least-squares-estimators",
    "href": "slides/05-slr-matrix-contd.html#find-the-least-squares-estimators",
    "title": "SLR: Matrix representation",
    "section": "Find the least squares estimators",
    "text": "Find the least squares estimators\n\\[\n\\begin{aligned}\n\\nabla_{\\boldsymbol{\\beta}} SSR &= \\nabla_{\\boldsymbol{\\beta}}( \\mathbf{y}^T\\mathbf{y} - 2\\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y} + \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta})  \\\\[10pt]\n& \\class{fragment}{= \\nabla_\\boldsymbol{\\beta} \\hspace{1mm} \\mathbf{y}^T\\mathbf{y} - 2\\nabla_\\boldsymbol{\\beta} \\hspace{1mm} \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y} + \\nabla_\\boldsymbol{\\beta} \\hspace{1mm} \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}} \\\\[10pt]\n&\\class{fragment}{= 0 - 2\\mathbf{X}^T\\mathbf{y} + 2\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}}\\class{fragment}{=0} \\\\[10pt]\n&\\class{fragment}{\\Rightarrow \\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta} = \\mathbf{X}^T\\mathbf{y}} \\\\[10pt]\n&\\class{fragment}{\\Rightarrow   (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}} \\\\[10pt]\n&\\class{fragment}{\\color{#993399}{\\Rightarrow \\hat{\\boldsymbol{\\beta}} =  (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}}}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#did-we-find-a-minimum",
    "href": "slides/05-slr-matrix-contd.html#did-we-find-a-minimum",
    "title": "SLR: Matrix representation",
    "section": "Did we find a minimum?",
    "text": "Did we find a minimum?\n\\[\n\\begin{aligned}\n\\nabla^2_{\\boldsymbol{\\beta}} SSR &= \\nabla_{\\boldsymbol{\\beta}} (-2\\mathbf{X}^T\\mathbf{y} + 2\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}) \\\\[10pt]\n&\\class{fragment}{=-2\\nabla_{\\boldsymbol{\\beta}}\\mathbf{X}^T\\mathbf{y} + 2\\nabla_{\\boldsymbol{\\beta}}(\\mathbf{X}^T\\mathbf{X}\\mathbf{\\beta})} \\\\[10pt]\n&\\class{fragment}{\\propto \\mathbf{X}^T\\mathbf{X}}\\class{fragment}{ &gt; 0}\n\\end{aligned}\n\\]\n\nShow the details in HW 01"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#predicted-fitted-values",
    "href": "slides/05-slr-matrix-contd.html#predicted-fitted-values",
    "title": "SLR: Matrix representation",
    "section": "Predicted (fitted) values",
    "text": "Predicted (fitted) values\nNow that we have \\(\\hat{\\boldsymbol{\\beta}}\\), let’s predict values of \\(\\mathbf{y}\\) using the model\n\\[\n\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\underbrace{\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T}_{\\mathbf{H}}\\mathbf{y} = \\mathbf{H}\\mathbf{y}\n\\]\n\nHat matrix: \\(\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\)\n\n\n\n\\(\\mathbf{H}\\) is an \\(n\\times n\\) matrix\nMaps vector of observed values \\(\\mathbf{y}\\) to a vector of fitted values \\(\\hat{\\mathbf{y}}\\)\nIt is only a function of \\(\\mathbf{X}\\) not \\(\\mathbf{y}\\)"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#residuals",
    "href": "slides/05-slr-matrix-contd.html#residuals",
    "title": "SLR: Matrix representation",
    "section": "Residuals",
    "text": "Residuals\nRecall that the residuals are the difference between the observed and predicted values\n\\[\n\\begin{aligned}\n\\mathbf{e} &= \\mathbf{y} - \\hat{\\mathbf{y}}\\\\[10pt]\n&\\class{fragment}{ = \\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}} \\\\[10pt]\n&\\class{fragment}{ = \\mathbf{y} - \\mathbf{H}\\mathbf{y}} \\\\[20pt]\n\\class{fragment}{\\color{#993399}{\\mathbf{e}}} &\\class{fragment}{\\color{#993399}{=(\\mathbf{I} - \\mathbf{H})\\mathbf{y}}} \\\\[10pt]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#recap",
    "href": "slides/05-slr-matrix-contd.html#recap",
    "title": "SLR: Matrix representation",
    "section": "Recap",
    "text": "Recap\n\nIntroduced matrix representation for simple linear regression\n\nModel from\nLeast square estimate\nPredicted (fitted) values\nResiduals\n\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#announcements",
    "href": "slides/06-mlr-pt2.html#announcements",
    "title": "Multiple linear regression (MLR)",
    "section": "Announcements",
    "text": "Announcements\n\nLab 01 due on TODAY at 11:59pm\n\nPush work to GitHub repo\nSubmit final PDF on Gradescope + mark pages for each question\n\nHW 01 due Thursday, September 19 at 11:59pm\n\nWill be released after class\n\nTeam labs start on Monday"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#homework",
    "href": "slides/06-mlr-pt2.html#homework",
    "title": "Multiple linear regression (MLR)",
    "section": "Homework",
    "text": "Homework\nHomework will generally be split into two sections:\n\n1️⃣ Conceptual exercises\nThe conceptual exercises are focused on explaining concepts and showing results mathematically. Show your work for each question.\n\nYou may write the answers and associated work for conceptual exercises by hand or type them in your Quarto document."
  },
  {
    "objectID": "slides/06-mlr-pt2.html#homework-1",
    "href": "slides/06-mlr-pt2.html#homework-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Homework",
    "text": "Homework\n2️⃣ Applied exercises\nThe applied exercises are focused on applying the concepts to analyze data.\nAll work for the applied exercises must be typed in your Quarto document following a reproducible workflow.\nWrite all narrative using complete sentences and include informative axis labels / titles on visualizations."
  },
  {
    "objectID": "slides/06-mlr-pt2.html#topics",
    "href": "slides/06-mlr-pt2.html#topics",
    "title": "Multiple linear regression (MLR)",
    "section": "Topics",
    "text": "Topics\n\nCategorical predictors and interaction terms\nAssess model fit using RSME and \\(R^2\\)\nCompare models using \\(Adj. R^2\\)\nIntroduce LaTex"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#computing-setup",
    "href": "slides/06-mlr-pt2.html#computing-setup",
    "title": "Multiple linear regression (MLR)",
    "section": "Computing setup",
    "text": "Computing setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(viridis) #adjust color palette\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#data-peer-to-peer-lender",
    "href": "slides/06-mlr-pt2.html#data-peer-to-peer-lender",
    "title": "Multiple linear regression (MLR)",
    "section": "Data: Peer-to-peer lender",
    "text": "Data: Peer-to-peer lender\nToday’s data is a sample of 50 loans made through a peer-to-peer lending club. The data is in the loan50 data frame in the openintro R package.\n\n\n# A tibble: 50 × 4\n   annual_income_th debt_to_income verified_income interest_rate\n              &lt;dbl&gt;          &lt;dbl&gt; &lt;fct&gt;                   &lt;dbl&gt;\n 1             59           0.558  Not Verified            10.9 \n 2             60           1.31   Not Verified             9.92\n 3             75           1.06   Verified                26.3 \n 4             75           0.574  Not Verified             9.92\n 5            254           0.238  Not Verified             9.43\n 6             67           1.08   Source Verified          9.92\n 7             28.8         0.0997 Source Verified         17.1 \n 8             80           0.351  Not Verified             6.08\n 9             34           0.698  Not Verified             7.97\n10             80           0.167  Source Verified         12.6 \n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#variables",
    "href": "slides/06-mlr-pt2.html#variables",
    "title": "Multiple linear regression (MLR)",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\n\nannual_income_th: Annual income (in $1000s)\ndebt_to_income: Debt-to-income ratio, i.e. the percentage of a borrower’s total debt divided by their total income\nverified_income: Whether borrower’s income source and amount have been verified (Not Verified, Source Verified, Verified)\n\n\nResponse: interest_rate: Interest rate for the loan"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#response-vs.-predictors",
    "href": "slides/06-mlr-pt2.html#response-vs.-predictors",
    "title": "Multiple linear regression (MLR)",
    "section": "Response vs. predictors",
    "text": "Response vs. predictors\n\nGoal: Use these predictors in a single model to understand variability in interest rate."
  },
  {
    "objectID": "slides/06-mlr-pt2.html#model-fit-in-r",
    "href": "slides/06-mlr-pt2.html#model-fit-in-r",
    "title": "Multiple linear regression (MLR)",
    "section": "Model fit in R",
    "text": "Model fit in R\n\nint_fit &lt;- lm(interest_rate ~ debt_to_income + verified_income  + annual_income_th,\n              data = loan50)\n\ntidy(int_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n10.726\n1.507\n7.116\n0.000\n\n\ndebt_to_income\n0.671\n0.676\n0.993\n0.326\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n\n\nannual_income_th\n-0.021\n0.011\n-1.804\n0.078"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#matrix-form-of-multiple-linear-regression",
    "href": "slides/06-mlr-pt2.html#matrix-form-of-multiple-linear-regression",
    "title": "Multiple linear regression (MLR)",
    "section": "Matrix form of multiple linear regression",
    "text": "Matrix form of multiple linear regression\n\\[\n\\underbrace{\n\\begin{bmatrix}\ny_1 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix} }_\n{\\mathbf{y}} \\hspace{3mm}\n=\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n1 &x_{11} & \\dots & x_{1p}\\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\n1 &  x_{n1} & \\dots &x_{np}\n\\end{bmatrix}\n}_{\\mathbf{X}}\n\\hspace{2mm}\n\\underbrace{\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\vdots \\\\\n\\beta_p\n\\end{bmatrix}\n}_{\\boldsymbol{\\beta}}\n\\hspace{3mm}\n+\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n\\epsilon_1 \\\\\n\\vdots\\\\\n\\epsilon_n\n\\end{bmatrix}\n}_\\boldsymbol{\\epsilon}\n\\]\n\nHow might we include a categorical predictor with \\(k\\) levels in the design matrix, \\(\\mathbf{X}\\) ?"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#indicator-variables",
    "href": "slides/06-mlr-pt2.html#indicator-variables",
    "title": "Multiple linear regression (MLR)",
    "section": "Indicator variables",
    "text": "Indicator variables\nSuppose we want to predict the amount of sleep a Duke student gets based on whether they are in Pratt (Pratt Yes/ No are the only two options). Consider the model\n\\[\nSleep_i = \\beta_0 + \\beta_1\\mathbf{1}(Pratt_i = \\texttt{Yes}) + \\beta_2\\mathbf{1}(Pratt_i = \\texttt{No})\n\\]\n\n\nWrite out the design matrix for this hypothesized linear model.\nDemonstrate that the design matrix is not of full column rank (that is, affirmatively provide one of the columns in terms of the others).\nUse this intuition to explain why when we include categorical predictors, we cannot include both indicators for every level of the variable and an intercept."
  },
  {
    "objectID": "slides/06-mlr-pt2.html#indicator-variables-1",
    "href": "slides/06-mlr-pt2.html#indicator-variables-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Indicator variables",
    "text": "Indicator variables\n\nSuppose there is a categorical variable with \\(k\\) levels\nWe can make \\(k\\) indicator variables from the data - one indicator for each level\nAn indicator (dummy) variable takes values 1 or 0\n\n1 if the observation belongs to that level\n0 if the observation does not belong to that level"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#indicator-variables-for-verified_income",
    "href": "slides/06-mlr-pt2.html#indicator-variables-for-verified_income",
    "title": "Multiple linear regression (MLR)",
    "section": "Indicator variables for verified_income",
    "text": "Indicator variables for verified_income\n\nloan50 &lt;- loan50 |&gt;\n  mutate(\n    not_verified = if_else(verified_income == \"Not Verified\", 1, 0),\n    source_verified = if_else(verified_income == \"Source Verified\", 1, 0),\n    verified = if_else(verified_income == \"Verified\", 1, 0)\n  )\n\n\n\n\n# A tibble: 3 × 4\n  verified_income not_verified source_verified verified\n  &lt;fct&gt;                  &lt;dbl&gt;           &lt;dbl&gt;    &lt;dbl&gt;\n1 Not Verified               1               0        0\n2 Verified                   0               0        1\n3 Source Verified            0               1        0"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#indicator-variables-in-the-model",
    "href": "slides/06-mlr-pt2.html#indicator-variables-in-the-model",
    "title": "Multiple linear regression (MLR)",
    "section": "Indicator variables in the model",
    "text": "Indicator variables in the model\n\nWe will use \\(k-1\\) of the indicator variables in the model.\nThe baseline is the category that doesn’t have a term in the model.\nThe coefficients of the indicator variables in the model are interpreted as the expected change in the response compared to the baseline, holding all other variables constant.\n\n\n\nloan50 |&gt;\n  select(verified_income, source_verified, verified) |&gt;\n  slice(1, 3, 6)\n\n# A tibble: 3 × 3\n  verified_income source_verified verified\n  &lt;fct&gt;                     &lt;dbl&gt;    &lt;dbl&gt;\n1 Not Verified                  0        0\n2 Verified                      0        1\n3 Source Verified               1        0\n\n\n\nTake a look at the design matrix in AE 02"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#interpreting-verified_income",
    "href": "slides/06-mlr-pt2.html#interpreting-verified_income",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting verified_income",
    "text": "Interpreting verified_income\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n10.726\n1.507\n7.116\n0.000\n7.690\n13.762\n\n\ndebt_to_income\n0.671\n0.676\n0.993\n0.326\n-0.690\n2.033\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n-0.606\n5.028\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n3.253\n10.508\n\n\nannual_income_th\n-0.021\n0.011\n-1.804\n0.078\n-0.043\n0.002\n\n\n\n\n\n\n\n\n\n\nThe baseline level is Not verified.\nPeople with source verified income are expected to take a loan with an interest rate that is 2.211% higher, on average, than the rate on loans to those whose income is not verified, holding all else constant.\n\n\n\n\n\nWhat is the expected interest rate for someone whose income is Verified, who has a debt-to-income ratio of 0 and annual income of $0?"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#interaction-terms-1",
    "href": "slides/06-mlr-pt2.html#interaction-terms-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Interaction terms",
    "text": "Interaction terms\n\nSometimes the relationship between a predictor variable and the response depends on the value of another predictor variable.\nThis is an interaction effect.\nTo account for this, we can include interaction terms in the model."
  },
  {
    "objectID": "slides/06-mlr-pt2.html#interest-rate-vs.-annual-income",
    "href": "slides/06-mlr-pt2.html#interest-rate-vs.-annual-income",
    "title": "Multiple linear regression (MLR)",
    "section": "Interest rate vs. annual income",
    "text": "Interest rate vs. annual income\nThe lines are not parallel indicating there is a potential interaction effect. The slope of annual income differs based on the income verification."
  },
  {
    "objectID": "slides/06-mlr-pt2.html#interaction-term-in-model",
    "href": "slides/06-mlr-pt2.html#interaction-term-in-model",
    "title": "Multiple linear regression (MLR)",
    "section": "Interaction term in model",
    "text": "Interaction term in model\n\nint_fit_2 &lt;- lm(interest_rate ~ debt_to_income + verified_income + annual_income_th + verified_income * annual_income_th,\n      data = loan50)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n9.560\n2.034\n4.700\n0.000\n\n\ndebt_to_income\n0.691\n0.685\n1.009\n0.319\n\n\nverified_incomeSource Verified\n3.577\n2.539\n1.409\n0.166\n\n\nverified_incomeVerified\n9.923\n3.654\n2.716\n0.009\n\n\nannual_income_th\n-0.007\n0.020\n-0.341\n0.735\n\n\nverified_incomeSource Verified:annual_income_th\n-0.016\n0.026\n-0.643\n0.523\n\n\nverified_incomeVerified:annual_income_th\n-0.032\n0.033\n-0.979\n0.333"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#interpreting-interaction-terms",
    "href": "slides/06-mlr-pt2.html#interpreting-interaction-terms",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting interaction terms",
    "text": "Interpreting interaction terms\n\nWhat the interaction means: The effect of annual income on the interest rate differs by -0.016 when the income is source verified compared to when it is not verified, holding all else constant.\nInterpreting annual_income for source verified: If the income is source verified, we expect the interest rate to decrease by 0.023% (-0.007 + -0.016) for each additional thousand dollars in annual income, holding all else constant."
  },
  {
    "objectID": "slides/06-mlr-pt2.html#rmse-r2",
    "href": "slides/06-mlr-pt2.html#rmse-r2",
    "title": "Multiple linear regression (MLR)",
    "section": "RMSE & \\(R^2\\)",
    "text": "RMSE & \\(R^2\\)\n\nRoot mean square error, RMSE: A measure of the average error (average difference between observed and predicted values of the outcome)\nR-squared, \\(R^2\\) : Percentage of variability in the outcome explained by the regression model"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#comparing-models",
    "href": "slides/06-mlr-pt2.html#comparing-models",
    "title": "Multiple linear regression (MLR)",
    "section": "Comparing models",
    "text": "Comparing models\n\n\nWhen comparing models, do we prefer the model with the lower or higher RMSE?\nThough we use \\(R^2\\) to assess the model fit, it is generally unreliable for comparing models with different number of predictors. Why?\n\n\\(R^2\\) will stay the same or increase as we add more variables to the model . Let’s show why this is true.\nIf we only use \\(R^2\\) to choose a best fit model, we will be prone to choose the model with the most predictor variables."
  },
  {
    "objectID": "slides/06-mlr-pt2.html#adjusted-r2",
    "href": "slides/06-mlr-pt2.html#adjusted-r2",
    "title": "Multiple linear regression (MLR)",
    "section": "Adjusted \\(R^2\\)",
    "text": "Adjusted \\(R^2\\)\n\nAdjusted \\(R^2\\): measure that includes a penalty for unnecessary predictor variables\nSimilar to \\(R^2\\), it is a measure of the amount of variation in the response that is explained by the regression model"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#r2-and-adjusted-r2",
    "href": "slides/06-mlr-pt2.html#r2-and-adjusted-r2",
    "title": "Multiple linear regression (MLR)",
    "section": "\\(R^2\\) and Adjusted \\(R^2\\)",
    "text": "\\(R^2\\) and Adjusted \\(R^2\\)\n\\[R^2 = \\frac{SSM}{SST} = 1 - \\frac{SSR}{SST}\\]\n\n\n\\[R^2_{adj} = 1 - \\frac{SSR/(n-p-1)}{SST/(n-1)}\\]\nwhere\n\n\\(n\\) is the number of observations used to fit the model\n\\(p\\) is the number of terms (not including the intercept) in the model"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#using-r2-and-adjusted-r2",
    "href": "slides/06-mlr-pt2.html#using-r2-and-adjusted-r2",
    "title": "Multiple linear regression (MLR)",
    "section": "Using \\(R^2\\) and Adjusted \\(R^2\\)",
    "text": "Using \\(R^2\\) and Adjusted \\(R^2\\)\n\nAdjusted \\(R^2\\) can be used as a quick assessment to compare the fit of multiple models; however, it should not be the only assessment!\nUse \\(R^2\\) when describing the relationship between the response and predictor variables\n\n\n\n📋 https://sta221-fa24.netlify.app/ae/ae-02-mlr"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#latex-in-this-class",
    "href": "slides/06-mlr-pt2.html#latex-in-this-class",
    "title": "Multiple linear regression (MLR)",
    "section": "Latex in this class",
    "text": "Latex in this class\nFor this class you will need to be able to…\n\nProperly write mathematical symbols, e.g., \\(\\beta_1\\) not B1, \\(R^2\\) not R2\nWrite basic regression equations, e.g., \\(\\hat{y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2\\)\nWrite matrix equations: \\(\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\\)\nWrite hypotheses (we’ll start this next week), e.g., \\(H_0: \\beta = 0\\)\n\nYou are welcome to but not required to write math proofs using LaTex."
  },
  {
    "objectID": "slides/06-mlr-pt2.html#recap",
    "href": "slides/06-mlr-pt2.html#recap",
    "title": "Multiple linear regression (MLR)",
    "section": "Recap",
    "text": "Recap\n\nInterpreted categorical predictors and interaction terms\nAssessed model fit using RSME and \\(R^2\\)\nCompared models using \\(Adj. R^2\\)\nIntroduced LaTex"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#next-class",
    "href": "slides/06-mlr-pt2.html#next-class",
    "title": "Multiple linear regression (MLR)",
    "section": "Next class",
    "text": "Next class\n\nGeometric interpretation\nInference for regression\nSee Sep 17 prepare\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#announcements",
    "href": "slides/03-slr-model-assessment.html#announcements",
    "title": "SLR: Model Assessment",
    "section": "Announcements",
    "text": "Announcements\n\nOffice hours start this week. See schedule on Overview page of the course website or on Canvas."
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#topics",
    "href": "slides/03-slr-model-assessment.html#topics",
    "title": "SLR: Model Assessment",
    "section": "Topics",
    "text": "Topics\n\nUse R to conduct exploratory data analysis and fit a model\nEvaluate models using RMSE and \\(R^2\\)\nUse analysis of variance to partition variability in the response variable"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#computing-set-up",
    "href": "slides/03-slr-model-assessment.html#computing-set-up",
    "title": "SLR: Model Assessment",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling (includes broom, yardstick, and other packages)\nlibrary(openintro)   # for the duke_forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(knitr)       # for pretty tables\nlibrary(patchwork)   # arrange plots\n\n# set default theme for ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#data-houses-in-duke-forest",
    "href": "slides/03-slr-model-assessment.html#data-houses-in-duke-forest",
    "title": "SLR: Model Assessment",
    "section": "Data: Houses in Duke Forest",
    "text": "Data: Houses in Duke Forest\n\n\n\nData on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020\nScraped from Zillow\nSource: openintro::duke_forest\n\n\n\n\nGoal: Use the area (in square feet) to understand variability in the price of houses in Duke Forest."
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#clone-repo-start-new-rstudio-project",
    "href": "slides/03-slr-model-assessment.html#clone-repo-start-new-rstudio-project",
    "title": "SLR: Model Assessment",
    "section": "Clone repo + Start new RStudio project",
    "text": "Clone repo + Start new RStudio project\n\nGo to the course organization. Click on the repo with the prefix ae-01. It contains the starter documents you need to complete the AE.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File → New Project → Version Control → Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick ae-01.qmd to open the template Quarto file. This is where you will write up your code and narrative for the AE."
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#two-statistics",
    "href": "slides/03-slr-model-assessment.html#two-statistics",
    "title": "SLR: Model Assessment",
    "section": "Two statistics",
    "text": "Two statistics\n\nRoot mean square error, RMSE: A measure of the average error (average difference between observed and predicted values of the outcome)\nR-squared, \\(R^2\\) : Percentage of variability in the outcome explained by the regression model (in the context of SLR, the predictor)\n\n\n\nWhat indicates a good model fit? Higher or lower RMSE? Higher or lower \\(R^2\\)?"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#rmse",
    "href": "slides/03-slr-model-assessment.html#rmse",
    "title": "SLR: Model Assessment",
    "section": "RMSE",
    "text": "RMSE\n\\[\nRMSE = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n}} = \\sqrt{\\frac{\\sum_{i=1}^ne_i^2}{n}}\n\\]\n\n\n\nRanges between 0 (perfect predictor) and infinity (terrible predictor)\nSame units as the response variable\nThe value of RMSE is more useful for comparing across models than evaluating a single model (more on this when we get to regression with multiple predictors)"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#analysis-of-variance-anova",
    "href": "slides/03-slr-model-assessment.html#analysis-of-variance-anova",
    "title": "SLR: Model Assessment",
    "section": "ANOVA",
    "text": "ANOVA\nAnalysis of Variance (ANOVA): Technique to partition variability in \\(Y\\) by the sources of variability"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#total-variability-response",
    "href": "slides/03-slr-model-assessment.html#total-variability-response",
    "title": "SLR: Model Assessment",
    "section": "Total variability (Response)",
    "text": "Total variability (Response)\n\n\n\n\n\n\nMin\nMedian\nMax\nMean\nStd.Dev\n\n\n\n\n95000\n540000\n1520000\n559898.7\n225448.1"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#partition-sources-of-variability-in-price",
    "href": "slides/03-slr-model-assessment.html#partition-sources-of-variability-in-price",
    "title": "SLR: Model Assessment",
    "section": "Partition sources of variability in price",
    "text": "Partition sources of variability in price"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#total-variability-response-1",
    "href": "slides/03-slr-model-assessment.html#total-variability-response-1",
    "title": "SLR: Model Assessment",
    "section": "Total variability (Response)",
    "text": "Total variability (Response)\n\n\\[\\text{Sum of Squares Total (SST)} = \\sum_{i=1}^n(y_i - \\bar{y})^2 = (n-1)s_y^2\\]"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#explained-variability-model",
    "href": "slides/03-slr-model-assessment.html#explained-variability-model",
    "title": "SLR: Model Assessment",
    "section": "Explained variability (Model)",
    "text": "Explained variability (Model)\n\n\\[\\text{Sum of Squares Model (SSM)} = \\sum_{i = 1}^{n}(\\hat{y}_i - \\bar{y})^2\\]"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#unexplained-variability-residuals",
    "href": "slides/03-slr-model-assessment.html#unexplained-variability-residuals",
    "title": "SLR: Model Assessment",
    "section": "Unexplained variability (Residuals)",
    "text": "Unexplained variability (Residuals)\n\n\\[\\text{Sum of Squares Residuals (SSR)} = \\sum_{i = 1}^{n}(y_i - \\hat{y}_i)^2\\]"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#sum-of-squares",
    "href": "slides/03-slr-model-assessment.html#sum-of-squares",
    "title": "SLR: Model Assessment",
    "section": "Sum of Squares",
    "text": "Sum of Squares\n\n\\[\n\\begin{aligned}\n\\color{#407E99}{SST} \\hspace{5mm}&= &\\color{#993399}{SSM} &\\hspace{5mm} +  &\\color{#8BB174}{SSR} \\\\[10pt]\n\\color{#407E99}{\\sum_{i=1}^n(y_i - \\bar{y})^2} \\hspace{5mm}&= &\\color{#993399}{\\sum_{i = 1}^{n}(\\hat{y}_i - \\bar{y})^2} &\\hspace{5mm}+ &\\color{#8BB174}{\\sum_{i = 1}^{n}(y_i - \\hat{y}_i)^2}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#r2",
    "href": "slides/03-slr-model-assessment.html#r2",
    "title": "SLR: Model Assessment",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\nThe coefficient of determination \\(R^2\\) is the proportion of variation in the response, \\(Y\\), that is explained by the regression model\n\n\\[\\large{R^2 = \\frac{SSM}{SST} = 1 - \\frac{SSR}{SST}}\\]\n\n\nWhat is the range of \\(R^2\\)? Does \\(R^2\\) have units?"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#interpreting-r2",
    "href": "slides/03-slr-model-assessment.html#interpreting-r2",
    "title": "SLR: Model Assessment",
    "section": "Interpreting $R^2$",
    "text": "Interpreting $R^2$\n\nQuestionSubmit\n\n\n\nSubmit your response to the following question on Ed Discussion.\n\nThe \\(R^2\\) of the model for price from area of houses in Duke Forest is 44.5%. Which of the following is the correct interpretation of this value?\n\nArea correctly predicts 44.5% of price for houses in Duke Forest.\n44.5% of the variability in price for houses in Duke Forest can be explained by area.\n44.5% of the variability in area for houses in Duke Forest can be explained by price.\n44.5% of the time price for houses in Duke Forest can be predicted by area.\n\nDo you think this model is useful for explaining variability in the price of Duke Forest houses?\n\n\n\n\n\n\n\n\n🔗 https://edstem.org/us/courses/62513/discussion/629888"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#augmented-data-frame",
    "href": "slides/03-slr-model-assessment.html#augmented-data-frame",
    "title": "SLR: Model Assessment",
    "section": "Augmented data frame",
    "text": "Augmented data frame\nUse the augment() function from the broom package to add columns for predicted values, residuals, and other observation-level model statistics\n\n\nduke_forest_aug &lt;- augment(duke_forest_fit)\nduke_forest_aug\n\n# A tibble: 98 × 8\n     price  area  .fitted  .resid   .hat  .sigma   .cooksd .std.resid\n     &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 1520000  6040 1079931. 440069. 0.133  162605. 0.604         2.80  \n 2 1030000  4475  830340. 199660. 0.0435 168386. 0.0333        1.21  \n 3  420000  1745  394951.  25049. 0.0226 169664. 0.000260      0.150 \n 4  680000  2091  450132. 229868. 0.0157 168011. 0.0150        1.37  \n 5  428500  1772  399257.  29243. 0.0220 169657. 0.000345      0.175 \n 6  456000  1950  427645.  28355. 0.0182 169659. 0.000266      0.170 \n 7 1270000  3909  740072. 529928. 0.0250 160502. 0.130         3.18  \n 8  557450  2841  569744. -12294. 0.0102 169679. 0.0000277    -0.0732\n 9  697500  3924  742465. -44965. 0.0254 169620. 0.000948     -0.270 \n10  650000  2173  463209. 186791. 0.0145 168582. 0.00912       1.11  \n# ℹ 88 more rows"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#finding-rmse-in-r",
    "href": "slides/03-slr-model-assessment.html#finding-rmse-in-r",
    "title": "SLR: Model Assessment",
    "section": "Finding RMSE in R",
    "text": "Finding RMSE in R\nUse the rmse() function from the yardstick package (part of tidymodels)\n\nrmse(duke_forest_aug, truth = price, estimate = .fitted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard     167067.\n\n\n\n\nDo you think this model is useful for predicting the price of Duke Forest houses?"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#finding-r2-in-r",
    "href": "slides/03-slr-model-assessment.html#finding-r2-in-r",
    "title": "SLR: Model Assessment",
    "section": "Finding \\(R^2\\) in R",
    "text": "Finding \\(R^2\\) in R\nUse the rsq() function from the yardstick package (part of tidymodels)\n\nrsq(duke_forest_aug, truth = price, estimate = .fitted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rsq     standard       0.445\n\n\n\n\nAlternatively, use glance() to construct a single row summary of the model fit, including \\(R^2\\):\n\nglance(duke_forest_fit)$r.squared\n\n[1] 0.4451945"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#recap",
    "href": "slides/03-slr-model-assessment.html#recap",
    "title": "SLR: Model Assessment",
    "section": "Recap",
    "text": "Recap\n\nUsed R to conduct exploratory data analysis and fit a model\nEvaluated models using RMSE and \\(R^2\\)\nUsed analysis of variance to partition variability in the response variable"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#next-class",
    "href": "slides/03-slr-model-assessment.html#next-class",
    "title": "SLR: Model Assessment",
    "section": "Next class",
    "text": "Next class\n\nMatrix representation of simple linear regression\n\nSee Sep 5 prepare\n\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/04-slr-matrix.html#topics",
    "href": "slides/04-slr-matrix.html#topics",
    "title": "SLR: Matrix representation",
    "section": "Topics",
    "text": "Topics\n\nMatrix representation for simple linear regression\n\nModel form\nLeast square estimate\nPredicted (fitted) values\nResiduals\n\nMatrix representation in R"
  },
  {
    "objectID": "slides/04-slr-matrix.html#slr-statistical-model-population",
    "href": "slides/04-slr-matrix.html#slr-statistical-model-population",
    "title": "SLR: Matrix representation",
    "section": "SLR: Statistical model (population)",
    "text": "SLR: Statistical model (population)\nWhen we have a quantitative response, \\(Y\\), and a single quantitative predictor, \\(X\\), we can use a simple linear regression model to describe the relationship between \\(Y\\) and \\(X\\). \\[\\large{Y = \\mathbf{\\beta_0 + \\beta_1 X} + \\epsilon}, \\hspace{8mm} \\epsilon \\sim N(0, \\sigma_{\\epsilon}^2)\\]\n\n\n\\(\\beta_1\\): Population (true) slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\beta_0\\): Population (true) intercept of the relationship between \\(X\\) and \\(Y\\)\n\\(\\epsilon\\): Error"
  },
  {
    "objectID": "slides/04-slr-matrix.html#slr-in-matrix-form",
    "href": "slides/04-slr-matrix.html#slr-in-matrix-form",
    "title": "SLR: Matrix representation",
    "section": "SLR in matrix form",
    "text": "SLR in matrix form\nSuppose we have \\(n\\) observations.\n\\[\n\\underbrace{\n\\begin{bmatrix}\ny_1 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix} }_\n{\\mathbf{y}} \\hspace{3mm}\n=\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n1 &x_1 \\\\\n\\vdots &  \\vdots \\\\\n1 &  x_n\n\\end{bmatrix}\n}_{\\mathbf{X}}\n\\hspace{2mm}\n\\underbrace{\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1\n\\end{bmatrix}\n}_{\\boldsymbol{\\beta}}\n\\hspace{3mm}\n+\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n\\epsilon_1 \\\\\n\\vdots\\\\\n\\epsilon_n\n\\end{bmatrix}\n}_\\boldsymbol{\\epsilon}\n\\]\n\n\nWhat are the dimensions of \\(\\mathbf{y}\\), \\(\\mathbf{X}\\), \\(\\boldsymbol{\\beta}\\), and \\(\\boldsymbol{\\epsilon}\\)?"
  },
  {
    "objectID": "slides/04-slr-matrix.html#sum-of-squared-residuals",
    "href": "slides/04-slr-matrix.html#sum-of-squared-residuals",
    "title": "SLR: Matrix representation",
    "section": "Sum of squared residuals",
    "text": "Sum of squared residuals\nWe use the sum of squared residuals (also called “sum of squared error”) to find the least squares line:\n\\[\nSSR = \\sum_{i=1}^ne_i^2 = \\mathbf{e}^T\\mathbf{e} = (\\mathbf{y} - \\hat{\\mathbf{y}})^T(\\mathbf{y} - \\hat{\\mathbf{y}})\n\\]\n\n\n\nWhat is the dimension of SSR?\nWhat is \\(\\hat{\\mathbf{y}}\\) in terms of \\(\\mathbf{y}\\), \\(\\mathbf{X}\\), and/or \\(\\boldsymbol{\\beta}\\) ?"
  },
  {
    "objectID": "slides/04-slr-matrix.html#minimize-sum-of-squared-residuals",
    "href": "slides/04-slr-matrix.html#minimize-sum-of-squared-residuals",
    "title": "SLR: Matrix representation",
    "section": "Minimize sum of squared residuals",
    "text": "Minimize sum of squared residuals\nWe want to find values of \\(\\boldsymbol{\\beta} = \\begin{bmatrix}\\beta_0 \\\\ \\beta_1 \\end{bmatrix}\\) that minimize the sum of squared residuals \\[\n\\begin{aligned}\n\\mathbf{e}^T\\mathbf{e} &= (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) \\\\[10pt]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix.html#minimize-sum-of-squared-residuals-1",
    "href": "slides/04-slr-matrix.html#minimize-sum-of-squared-residuals-1",
    "title": "SLR: Matrix representation",
    "section": "Minimize sum of squared residuals",
    "text": "Minimize sum of squared residuals\nWe want to find values of \\(\\boldsymbol{\\beta} = \\begin{bmatrix}\\beta_0 \\\\ \\beta_1 \\end{bmatrix}\\) that minimize the sum of squared residuals \\[\n\\begin{aligned}\n\\mathbf{e}^T\\mathbf{e} &= (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) \\\\[10pt]\n&= (\\mathbf{y}^T - \\boldsymbol{\\beta}^T\\mathbf{X}^T)(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\\\[10pt]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix.html#minimize-sum-of-squared-residuals-2",
    "href": "slides/04-slr-matrix.html#minimize-sum-of-squared-residuals-2",
    "title": "SLR: Matrix representation",
    "section": "Minimize sum of squared residuals",
    "text": "Minimize sum of squared residuals\nWe want to find values of \\(\\boldsymbol{\\beta} = \\begin{bmatrix}\\beta_0 \\\\ \\beta_1 \\end{bmatrix}\\) that minimize the sum of squared residuals \\[\n\\begin{aligned}\n\\mathbf{e}^T\\mathbf{e} &= (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) \\\\[10pt]\n&= (\\mathbf{y}^T - \\boldsymbol{\\beta}^T\\mathbf{X}^T)(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\\\[10pt]\n&=\\mathbf{y}^T\\mathbf{y} - \\mathbf{y}^T\\mathbf{X}\\boldsymbol{\\beta} - \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y} + \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}\\\\[10pt]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix.html#minimize-sum-of-squared-residuals-3",
    "href": "slides/04-slr-matrix.html#minimize-sum-of-squared-residuals-3",
    "title": "SLR: Matrix representation",
    "section": "Minimize sum of squared residuals",
    "text": "Minimize sum of squared residuals\nWe want to find values of \\(\\boldsymbol{\\beta} = \\begin{bmatrix}\\beta_0 \\\\ \\beta_1 \\end{bmatrix}\\) that minimize the sum of squared residuals \\[\n\\begin{aligned}\n\\mathbf{e}^T\\mathbf{e} &= (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) \\\\[10pt]\n&= (\\mathbf{y}^T - \\boldsymbol{\\beta}^T\\mathbf{X}^T)(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\\\[10pt]\n&=\\mathbf{y}^T\\mathbf{y} - \\mathbf{y}^T\\mathbf{X}\\boldsymbol{\\beta} - \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y} + \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}\\\\[10pt]\n&=\\mathbf{y}^T\\mathbf{y} - 2\\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y} + \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix.html#least-squares-estimators",
    "href": "slides/04-slr-matrix.html#least-squares-estimators",
    "title": "SLR: Matrix representation",
    "section": "Least squares estimators",
    "text": "Least squares estimators\n\\[\nSSR = \\mathbf{e}^T\\mathbf{e} =\\mathbf{y}^T\\mathbf{y} - 2\\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y} + \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}\n\\]\n\n\nThe least squares estimators must satisfy\n\\[\n\\nabla_{\\boldsymbol{\\beta}} SSR = -2\\mathbf{X}^T\\mathbf{y} + 2\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta} = 0\n\\]\n\n\n\n\\[\n\\color{#993399}{\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix.html#did-we-find-a-minimum",
    "href": "slides/04-slr-matrix.html#did-we-find-a-minimum",
    "title": "SLR: Matrix representation",
    "section": "Did we find a minimum?",
    "text": "Did we find a minimum?\n\\[\n\\nabla^2_{\\beta} SSR \\propto  2\\mathbf{X}^T\\mathbf{X} = 0\n\\]\n\n\n\\(\\mathbf{X}\\) is full rank \\(\\Rightarrow\\) \\(\\mathbf{X}^T\\mathbf{X}\\) is positive definite\nTherefore we have found the minimizing point"
  },
  {
    "objectID": "slides/04-slr-matrix.html#obtain-mathbfy-vector",
    "href": "slides/04-slr-matrix.html#obtain-mathbfy-vector",
    "title": "SLR: Matrix representation",
    "section": "Obtain \\(\\mathbf{y}\\) vector",
    "text": "Obtain \\(\\mathbf{y}\\) vector\nLet’s go back to the Duke Forest data. We want to use the matrix representation to fit a model of the form:\n\\[\nprice = \\beta_0 + \\beta_1 ~ area + \\epsilon, \\hspace{5mm} \\epsilon \\sim N(0, \\sigma^2_\\epsilon)\n\\]\n\nGet \\(\\mathbf{y}\\), the vector of responses\n\ny &lt;- duke_forest$price\n\n\n\n\nLet’s look at the first 10 observations of \\(y\\)\n\ny[1:10]\n\n [1] 1520000 1030000  420000  680000  428500  456000 1270000  557450  697500\n[10]  650000"
  },
  {
    "objectID": "slides/04-slr-matrix.html#obtain-mathbfx-matrix",
    "href": "slides/04-slr-matrix.html#obtain-mathbfx-matrix",
    "title": "SLR: Matrix representation",
    "section": "Obtain \\(\\mathbf{X}\\) matrix",
    "text": "Obtain \\(\\mathbf{X}\\) matrix\nUse the model.matrix() function to get \\(\\mathbf{X}\\)\n\nX &lt;- model.matrix(price ~ area, data = duke_forest)\n\n\n\nLet’s look at the first 10 rows of \\(\\mathbf{X}\\)\n\nX[1:10,]\n\n   (Intercept) area\n1            1 6040\n2            1 4475\n3            1 1745\n4            1 2091\n5            1 1772\n6            1 1950\n7            1 3909\n8            1 2841\n9            1 3924\n10           1 2173"
  },
  {
    "objectID": "slides/04-slr-matrix.html#calculate-hatboldsymbolbeta",
    "href": "slides/04-slr-matrix.html#calculate-hatboldsymbolbeta",
    "title": "SLR: Matrix representation",
    "section": "Calculate \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Calculate \\(\\hat{\\boldsymbol{\\beta}}\\)\nMatrix functions in R. Let \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\) be matrices\n\nt(A): transpose \\(\\mathbf{A}\\)\nsolve(A): inverse of \\(\\mathbf{A}\\)\nA %*% B: multiply \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\)\n\n\nNow let’s calculate \\(\\hat{\\boldsymbol{\\beta}}\\)\n\nbeta_hat &lt;- solve(t(X)%*%X)%*%t(X)%*%y\nbeta_hat\n\n                   [,1]\n(Intercept) 116652.3251\narea           159.4833"
  },
  {
    "objectID": "slides/04-slr-matrix.html#compare-to-result-from-lm",
    "href": "slides/04-slr-matrix.html#compare-to-result-from-lm",
    "title": "SLR: Matrix representation",
    "section": "Compare to result from lm",
    "text": "Compare to result from lm\n\nduke_forest_model &lt;- lm(price ~ area, data = duke_forest)\ntidy(duke_forest_model) |&gt; kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.325\n53302.463\n2.188\n0.031\n\n\narea\n159.483\n18.171\n8.777\n0.000\n\n\n\n\n\n\n\n\nbeta_hat \n\n                   [,1]\n(Intercept) 116652.3251\narea           159.4833"
  },
  {
    "objectID": "slides/04-slr-matrix.html#predicted-fitted-values",
    "href": "slides/04-slr-matrix.html#predicted-fitted-values",
    "title": "SLR: Matrix representation",
    "section": "Predicted (fitted) values",
    "text": "Predicted (fitted) values\nNow that we have \\(\\hat{\\boldsymbol{\\beta}}\\), let’s predict values of \\(\\mathbf{y}\\) using the model\n\\[\n\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\underbrace{\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T}_{\\mathbf{H}}\\mathbf{y} = \\mathbf{H}\\mathbf{y}\n\\]\n\nHat matrix: \\(\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\)\n\n\\(\\mathbf{H}\\) is an \\(n\\times n\\) matrix\nMaps vector of observed values \\(\\mathbf{y}\\) to a vector of fitted values \\(\\hat{\\mathbf{y}}\\)"
  },
  {
    "objectID": "slides/04-slr-matrix.html#residuals",
    "href": "slides/04-slr-matrix.html#residuals",
    "title": "SLR: Matrix representation",
    "section": "Residuals",
    "text": "Residuals\nRecall that the residuals are the difference between the observed and predicted values\n\\[\n\\begin{aligned}\n\\mathbf{e} &= \\mathbf{y} - \\hat{\\mathbf{y}}\\\\[10pt]\n& = \\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\\\[10pt]\n& = \\mathbf{y} - \\mathbf{H}\\mathbf{y} \\\\[10pt]\n& = (\\mathbf{I} - \\mathbf{H})\\mathbf{y}\n\\end{aligned}\n\\]\n\n\\[\n\\color{#993399}{\\mathbf{e} = (\\mathbf{I} - \\mathbf{H})\\mathbf{y}}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix.html#recap",
    "href": "slides/04-slr-matrix.html#recap",
    "title": "SLR: Matrix representation",
    "section": "Recap",
    "text": "Recap\n\nIntroduced matrix representation for simple linear regression\n\nModel from\nLeast square estimate\nPredicted (fitted) values\nResiduals\n\nUsed R for matrix calculations"
  },
  {
    "objectID": "slides/04-slr-matrix.html#next-class",
    "href": "slides/04-slr-matrix.html#next-class",
    "title": "SLR: Matrix representation",
    "section": "Next class",
    "text": "Next class\n\nMultiple linear regression\nSee Sep 10 prepare\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/15-multicollinearity.html#announcements",
    "href": "slides/15-multicollinearity.html#announcements",
    "title": "Multicollinearity + Variable transformations",
    "section": "Announcements",
    "text": "Announcements\n\nExam corrections (optional) due Thursday at 11:59pm on Canvas\nLab 04 due Thursday at 11:59pm\nTeam Feedback (from TEAMMATES) due Thursday at 11:59pm\nMid semester survey (strongly encouraged!) by Thursday at 11:59pm\nLooking ahead\n\nProject: Exploratory data analysis due October 31\nStatistics experience due Tuesday, November 26"
  },
  {
    "objectID": "slides/15-multicollinearity.html#spring-2025-statistics-classes",
    "href": "slides/15-multicollinearity.html#spring-2025-statistics-classes",
    "title": "Multicollinearity + Variable transformations",
    "section": "Spring 2025 statistics classes",
    "text": "Spring 2025 statistics classes\n\nSTA 230, STA 231 or STA 240: Probability\nSTA 310: Generalized Linear Models\nSTA 323: Statistical Computing\nSTA 360: Bayesian Inference and Modern Statistical Methods\nSTA 432: Theory and Methods of Statistical Learning and Inference"
  },
  {
    "objectID": "slides/15-multicollinearity.html#computing-set-up",
    "href": "slides/15-multicollinearity.html#computing-set-up",
    "title": "Multicollinearity + Variable transformations",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)\nlibrary(GGally) #for pairwise plot matrix\n\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/15-multicollinearity.html#topics",
    "href": "slides/15-multicollinearity.html#topics",
    "title": "Multicollinearity + Variable transformations",
    "section": "Topics",
    "text": "Topics\n\nMulticollinearity\n\nDefinition\nHow it impacts the model\nHow to detect it\nWhat to do about it\n\nVariable transformations"
  },
  {
    "objectID": "slides/15-multicollinearity.html#data-trail-users",
    "href": "slides/15-multicollinearity.html#data-trail-users",
    "title": "Multicollinearity + Variable transformations",
    "section": "Data: Trail users",
    "text": "Data: Trail users\n\nThe Pioneer Valley Planning Commission (PVPC) collected data at the beginning a trail in Florence, MA for ninety days from April 5, 2005 to November 15, 2005 to\nData collectors set up a laser sensor, with breaks in the laser beam recording when a rail-trail user passed the data collection station.\n\n\n\n# A tibble: 5 × 7\n  volume hightemp avgtemp season cloudcover precip day_type\n   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   \n1    501       83    66.5 Summer       7.60  0     Weekday \n2    419       73    61   Summer       6.30  0.290 Weekday \n3    397       74    63   Spring       7.5   0.320 Weekday \n4    385       95    78   Summer       2.60  0     Weekend \n5    200       44    48   Spring      10     0.140 Weekday \n\n\nSource: Pioneer Valley Planning Commission via the mosaicData package."
  },
  {
    "objectID": "slides/15-multicollinearity.html#variables",
    "href": "slides/15-multicollinearity.html#variables",
    "title": "Multicollinearity + Variable transformations",
    "section": "Variables",
    "text": "Variables\nOutcome:\n\nvolume estimated number of trail users that day (number of breaks recorded)\n\nPredictors\n\nhightemp daily high temperature (in degrees Fahrenheit)\navgtemp average of daily low and daily high temperature (in degrees Fahrenheit)\nseason one of “Fall”, “Spring”, or “Summer”\nprecip measure of precipitation (in inches)"
  },
  {
    "objectID": "slides/15-multicollinearity.html#eda-relationship-between-predictors",
    "href": "slides/15-multicollinearity.html#eda-relationship-between-predictors",
    "title": "Multicollinearity + Variable transformations",
    "section": "EDA: Relationship between predictors",
    "text": "EDA: Relationship between predictors\nWe can create a pairwise plot matrix using the ggpairs function from the GGally R package\n\nrail_trail |&gt;\n  select(hightemp, avgtemp, season, precip) |&gt;\n  ggpairs()"
  },
  {
    "objectID": "slides/15-multicollinearity.html#eda-relationship-between-predictors-1",
    "href": "slides/15-multicollinearity.html#eda-relationship-between-predictors-1",
    "title": "Multicollinearity + Variable transformations",
    "section": "EDA: Relationship between predictors",
    "text": "EDA: Relationship between predictors\n\n\nWhat might be a potential concern with a model that uses high temperature, average temperature, season, and precipitation to predict volume?"
  },
  {
    "objectID": "slides/15-multicollinearity.html#multicollinearity-1",
    "href": "slides/15-multicollinearity.html#multicollinearity-1",
    "title": "Multicollinearity + Variable transformations",
    "section": "Multicollinearity",
    "text": "Multicollinearity\n\nIdeally there is no linear relationship (dependence) between the predictors\n\nThis is generally not the case in practice but is often not a major issue\n\nMulticollinearity: there are near-linear dependencies between predictors"
  },
  {
    "objectID": "slides/15-multicollinearity.html#common-sources-of-multicollinearity",
    "href": "slides/15-multicollinearity.html#common-sources-of-multicollinearity",
    "title": "Multicollinearity + Variable transformations",
    "section": "Common sources of multicollinearity",
    "text": "Common sources of multicollinearity\n\n\nDependencies that generally occur in the population\nHow the model is defined and the variables that are included\nSample comes from only a subspace of the region of predictors\nThere are more predictor variables than observations"
  },
  {
    "objectID": "slides/15-multicollinearity.html#detecting-multicollinearity",
    "href": "slides/15-multicollinearity.html#detecting-multicollinearity",
    "title": "Multicollinearity + Variable transformations",
    "section": "Detecting multicollinearity",
    "text": "Detecting multicollinearity\n\nVariance Inflation Factor (VIF): measure of multicollinearity in the regression model\n\n\\[\nVIF_j = \\frac{1}{1 - R^2_j}\n\\]\nwhere \\(R^2_j\\) is the proportion of variation in \\(x_j\\) that is explained by a linear combination of all the other predictors"
  },
  {
    "objectID": "slides/15-multicollinearity.html#detecting-multicollinearity-1",
    "href": "slides/15-multicollinearity.html#detecting-multicollinearity-1",
    "title": "Multicollinearity + Variable transformations",
    "section": "Detecting multicollinearity",
    "text": "Detecting multicollinearity\n\nCommon practice uses threshold \\(VIF &gt; 10\\) as indication of concerning multicollinearity\nVariables with similar values of VIF are typically the ones correlated with each other\nUse the vif() function in the rms R package to calculate VIF"
  },
  {
    "objectID": "slides/15-multicollinearity.html#effects-of-multicollinearity",
    "href": "slides/15-multicollinearity.html#effects-of-multicollinearity",
    "title": "Multicollinearity + Variable transformations",
    "section": "Effects of multicollinearity",
    "text": "Effects of multicollinearity\n\n\nLarge variance \\((\\hat{\\sigma}^2_{\\epsilon}(\\mathbf{X}^T\\mathbf{X})^{-1})\\) in the model coefficients\n\nDifferent combinations of coefficient estimates produce equally good model fits\n\nUnreliable statistical inference results\n\nMay conclude coefficients are not statistically significant when there is, in fact, a relationship between the predictors and response\n\nInterpretation of coefficient is no longer “holding all other variables constant”, since this would be impossible for correlated predictors"
  },
  {
    "objectID": "slides/15-multicollinearity.html#dealing-with-multicollinearity",
    "href": "slides/15-multicollinearity.html#dealing-with-multicollinearity",
    "title": "Multicollinearity + Variable transformations",
    "section": "Dealing with multicollinearity",
    "text": "Dealing with multicollinearity\n\n\nCollect more data (often not feasible given practical constraints)\nRedefine the correlated predictors to keep the information from predictors but eliminate collinearity\n\ne.g., if \\(x_1, x_2, x_3\\) are correlated, use a new variable \\((x_1 + x_2) / x_3\\) in the model\n\nFor categorical predictors, avoid using levels with very few observations as the baseline\nRemove one of the correlated variables\n\nBe careful about substantially reducing predictive power of the model"
  },
  {
    "objectID": "slides/15-multicollinearity.html#data-respiratory-rate-vs.-age",
    "href": "slides/15-multicollinearity.html#data-respiratory-rate-vs.-age",
    "title": "Multicollinearity + Variable transformations",
    "section": "Data: Respiratory Rate vs. Age",
    "text": "Data: Respiratory Rate vs. Age\n\nA high respiratory rate can potentially indicate a respiratory infection in children. In order to determine what indicates a “high” rate, we first want to understand the relationship between a child’s age and their respiratory rate.\nThe data contain the respiratory rate for 618 children ages 15 days to 3 years. It was obtained from the Sleuth3 R package and is originally form a 1994 publication “Reference Values for Respiratory Rate in the First 3 Years of Life”.\nVariables:\n\nAge: age in months\nRate: respiratory rate (breaths per minute)"
  },
  {
    "objectID": "slides/15-multicollinearity.html#rate-vs.-age",
    "href": "slides/15-multicollinearity.html#rate-vs.-age",
    "title": "Multicollinearity + Variable transformations",
    "section": "Rate vs. Age",
    "text": "Rate vs. Age"
  },
  {
    "objectID": "slides/15-multicollinearity.html#model-1-rate-vs.-age",
    "href": "slides/15-multicollinearity.html#model-1-rate-vs.-age",
    "title": "Multicollinearity + Variable transformations",
    "section": "Model 1: Rate vs. Age",
    "text": "Model 1: Rate vs. Age\n\nresp_fit &lt;- lm(Rate ~ Age, data = respiratory)\n\ntidy(resp_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n47.052\n0.504\n93.317\n0\n\n\nAge\n-0.696\n0.029\n-23.684\n0"
  },
  {
    "objectID": "slides/15-multicollinearity.html#model-1-residuals",
    "href": "slides/15-multicollinearity.html#model-1-residuals",
    "title": "Multicollinearity + Variable transformations",
    "section": "Model 1: Residuals",
    "text": "Model 1: Residuals"
  },
  {
    "objectID": "slides/15-multicollinearity.html#consider-different-transformations",
    "href": "slides/15-multicollinearity.html#consider-different-transformations",
    "title": "Multicollinearity + Variable transformations",
    "section": "Consider different transformations…",
    "text": "Consider different transformations…"
  },
  {
    "objectID": "slides/15-multicollinearity.html#identifying-a-need-to-transform-y",
    "href": "slides/15-multicollinearity.html#identifying-a-need-to-transform-y",
    "title": "Multicollinearity + Variable transformations",
    "section": "Identifying a need to transform Y",
    "text": "Identifying a need to transform Y\n\n\nTypically, a “fan-shaped” residual plot indicates the need for a transformation of the response variable Y\n\nThere are multiple ways to transform a variable, e.g., Y, 1/Y, log⁡(Y)\nlog⁡(Y) the most straightforward to interpret, so we use that transformation when possible\n\n\n\n\nWhen building a model:\n\nChoose a transformation and build the model on the transformed data\nReassess the residual plots\nIf the residuals plots did not sufficiently improve, try a new transformation!"
  },
  {
    "objectID": "slides/15-multicollinearity.html#log-transformation-on-y",
    "href": "slides/15-multicollinearity.html#log-transformation-on-y",
    "title": "Multicollinearity + Variable transformations",
    "section": "Log transformation on \\(Y\\)",
    "text": "Log transformation on \\(Y\\)\n\nIf we apply a log transformation to the response variable, we want to estimate the parameters for the statistical model\n\n\\[\n\\log(y_i) = \\beta_0+ \\beta_1 x_{i1} + \\dots +\\beta_px_{ip} + \\epsilon_i, \\hspace{10mm} \\epsilon \\sim N(0,\\sigma^2_\\epsilon)\n\\]\n\nThe regression equation is\n\n\\[\\widehat{\\log(y_i)} = \\hat{\\beta}_0+ \\hat{\\beta}_1 x_{i1} + \\dots + \\hat{\\beta}_px_{ip}\\]"
  },
  {
    "objectID": "slides/15-multicollinearity.html#log-transformation-on-y-1",
    "href": "slides/15-multicollinearity.html#log-transformation-on-y-1",
    "title": "Multicollinearity + Variable transformations",
    "section": "Log transformation on \\(Y\\)",
    "text": "Log transformation on \\(Y\\)\nWe want to interpret the model in terms of the original variable \\(Y\\), not \\(\\log(Y)\\), so we need to write the regression equation in terms of \\(Y\\)\n\\[\\begin{align}\\hat{y_i} &= \\exp\\{\\hat{\\beta}_0 + \\hat{\\beta}_1 x_{i1} + \\dots + \\hat{\\beta}_Px_{ip}\\}\\\\ &= \\exp\\{\\hat{\\beta}_0\\}\\exp\\{\\hat{\\beta}_1x_{i1}\\}\\dots\\exp\\{\\hat{\\beta}_px_{ip}\\}\\end{align}\\]\n\n\n\n\n\n\nNote\n\n\nThe predicted value \\(\\hat{y_i}\\) is the predicted median of \\(Y\\). Note, when the distribution of \\(y_i|x_1, \\ldots, x_p\\) is symmetric, then the median equals the mean. (See notes at the end for more details)"
  },
  {
    "objectID": "slides/15-multicollinearity.html#model-interpretation",
    "href": "slides/15-multicollinearity.html#model-interpretation",
    "title": "Multicollinearity + Variable transformations",
    "section": "Model interpretation",
    "text": "Model interpretation\n\\[\\begin{align}\\hat{y_i} &= \\exp\\{\\hat{\\beta}_0 + \\hat{\\beta}_1 x_{1p} + \\dots + \\hat{\\beta}_Px_{ip}\\}\\\\ &= \\exp\\{\\hat{\\beta}_0\\}\\exp\\{\\hat{\\beta}_1x_{i1}\\}\\dots\\exp\\{\\hat{\\beta}_px_{ip}\\}\\end{align}\\]\n\n\nIntercept: When \\(x_{i1} = \\dots = x_{ip} =0\\), \\(y_i\\) is expected to be \\(\\exp\\{\\hat{\\beta}_0\\}\\)\nSlope: For every one unit increase in \\(x_{ij}\\), \\(y_{i}\\) is expected to multiply by a factor of \\(\\exp\\{\\hat{\\beta}_j\\}\\), holding all else constant\n\n\nWhy is the interpretation in terms of a multiplicative change?"
  },
  {
    "objectID": "slides/15-multicollinearity.html#model-2-lograte-vs.-age",
    "href": "slides/15-multicollinearity.html#model-2-lograte-vs.-age",
    "title": "Multicollinearity + Variable transformations",
    "section": "Model 2: log(Rate) vs. Age",
    "text": "Model 2: log(Rate) vs. Age\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n3.845\n0.013\n304.500\n0\n\n\nAge\n-0.019\n0.001\n-25.839\n0\n\n\n\n\n\n\n\n\nInterpret the intercept in terms of (1) log(Rate) and (2) Rate.\nInterpret the effect of Age in terms of (1) log(Rate) and (2) Rate."
  },
  {
    "objectID": "slides/15-multicollinearity.html#model-2-residuals",
    "href": "slides/15-multicollinearity.html#model-2-residuals",
    "title": "Multicollinearity + Variable transformations",
    "section": "Model 2: Residuals",
    "text": "Model 2: Residuals"
  },
  {
    "objectID": "slides/15-multicollinearity.html#compare-residual-plots",
    "href": "slides/15-multicollinearity.html#compare-residual-plots",
    "title": "Multicollinearity + Variable transformations",
    "section": "Compare residual plots",
    "text": "Compare residual plots"
  },
  {
    "objectID": "slides/15-multicollinearity.html#log-transformation-on-x",
    "href": "slides/15-multicollinearity.html#log-transformation-on-x",
    "title": "Multicollinearity + Variable transformations",
    "section": "Log Transformation on \\(X\\)",
    "text": "Log Transformation on \\(X\\)\n\nTry a transformation on \\(X\\) if the scatterplot shows some curvature but the variance is constant for all values of \\(X\\)"
  },
  {
    "objectID": "slides/15-multicollinearity.html#rate-vs.-logage",
    "href": "slides/15-multicollinearity.html#rate-vs.-logage",
    "title": "Multicollinearity + Variable transformations",
    "section": "Rate vs. log(Age)",
    "text": "Rate vs. log(Age)"
  },
  {
    "objectID": "slides/15-multicollinearity.html#model-with-transformation-on-x",
    "href": "slides/15-multicollinearity.html#model-with-transformation-on-x",
    "title": "Multicollinearity + Variable transformations",
    "section": "Model with Transformation on \\(X\\)",
    "text": "Model with Transformation on \\(X\\)\nSuppose we have the following regression equation:\n\\[\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\log(x_i)\\]\n\n\n\nIntercept: When \\(x_i = 1\\) \\((\\log(x_i) = 0)\\), \\(y_i\\) is expected to be \\(\\hat{\\beta}_0\\) (i.e. the mean of \\(y_i\\) is \\(\\hat{\\beta}_0\\))\nSlope: When \\(x_i\\) is multiplied by a factor of \\(\\mathbf{C}\\), the mean of \\(y_i\\) is expected to increase by \\(\\hat{\\beta}_1\\log(C)\\) units\n\nExample: when \\(x_i\\) is multiplied by a factor of 2, \\(y_i\\) is expected to increase by \\(\\hat{\\beta}_1}\\mathbf{\\log(2)\\) units"
  },
  {
    "objectID": "slides/15-multicollinearity.html#model-3-rate-vs.-logage",
    "href": "slides/15-multicollinearity.html#model-3-rate-vs.-logage",
    "title": "Multicollinearity + Variable transformations",
    "section": "Model 3: Rate vs. log(Age)",
    "text": "Model 3: Rate vs. log(Age)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n50.135\n0.632\n79.330\n0\n\n\nlog_age\n-5.982\n0.263\n-22.781\n0\n\n\n\n\n\n\n\nInterpret the slope and intercept in the context of the data."
  },
  {
    "objectID": "slides/15-multicollinearity.html#model-3-residuals",
    "href": "slides/15-multicollinearity.html#model-3-residuals",
    "title": "Multicollinearity + Variable transformations",
    "section": "Model 3: Residuals",
    "text": "Model 3: Residuals"
  },
  {
    "objectID": "slides/15-multicollinearity.html#choose-a-model",
    "href": "slides/15-multicollinearity.html#choose-a-model",
    "title": "Multicollinearity + Variable transformations",
    "section": "Choose a model",
    "text": "Choose a model\nRecall the goal of the analysis:\nIn order to determine what indicates a “high” rate, we first want to understand the relationship between a child’s age and their respiratory rate.\n\n\nWhich is the preferred metric to compare the models - \\(R^2\\) or RMSE?"
  },
  {
    "objectID": "slides/15-multicollinearity.html#compare-models",
    "href": "slides/15-multicollinearity.html#compare-models",
    "title": "Multicollinearity + Variable transformations",
    "section": "Compare models",
    "text": "Compare models\n\n\n\n\n\n\n\n\nRate vs. Age\nlog(Rate) vs. Age\nRate vs. log(Age)\n\n\n\n\n0.477\n0.52\n0.457\n\n\n\n\n\nWhich model would you choose?"
  },
  {
    "objectID": "slides/15-multicollinearity.html#learn-more",
    "href": "slides/15-multicollinearity.html#learn-more",
    "title": "Multicollinearity + Variable transformations",
    "section": "Learn more",
    "text": "Learn more\nSee Log Transformations in Linear Regression for more details about interpreting regression models with log-transformed variables."
  },
  {
    "objectID": "slides/15-multicollinearity.html#recap",
    "href": "slides/15-multicollinearity.html#recap",
    "title": "Multicollinearity + Variable transformations",
    "section": "Recap",
    "text": "Recap\n\nIntroduced multicollinearity\n\nDefinition\nHow it impacts the model\nHow to detect it\nWhat to do about it\n\nIntroduced variable transformations\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#announcements",
    "href": "slides/14-model-diagnostics.html#announcements",
    "title": "Model diagnostics",
    "section": "Announcements",
    "text": "Announcements\n\nExam corrections (optional) due Thursday, October 24 at 11:59pm on Canvas\nLabs resume on Monday\nProject: Exploratory data analysis due October 31\nStatistics experience due Tuesday, November 26"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#computing-set-up",
    "href": "slides/14-model-diagnostics.html#computing-set-up",
    "title": "Model diagnostics",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)   \nlibrary(viridis)\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#topics",
    "href": "slides/14-model-diagnostics.html#topics",
    "title": "Model diagnostics",
    "section": "Topics",
    "text": "Topics\n\nReview: Maximum likelihood estimation\nInfluential points\nModel diagnostics\n\nLeverage\nStudentized residuals\nCook’s Distance"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#likelihood",
    "href": "slides/14-model-diagnostics.html#likelihood",
    "title": "Model diagnostics",
    "section": "Likelihood",
    "text": "Likelihood\n\n\nA likelihood is a function that tells us how likely we are to observe our data for a given parameter value (or values). \nNote that this is not the same as the probability function.\n\nProbability function: Fixed parameter value(s) + input possible outcomes \\(\\Rightarrow\\) probability of seeing the different outcomes given the parameter value(s)\nLikelihood function: Fixed data + input possible parameter values \\(\\Rightarrow\\) probability of seeing the fixed data for each parameter value"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#maximum-likelihood-estimation-1",
    "href": "slides/14-model-diagnostics.html#maximum-likelihood-estimation-1",
    "title": "Model diagnostics",
    "section": "Maximum likelihood estimation",
    "text": "Maximum likelihood estimation\n\nMaximum likelihood estimation is the process of finding the values of the parameters that maximize the likelihood function , i.e., the values that are most likely given the observed data.\nThere are three primary ways to find the maximum likelihood estimator\n\nApproximate using a graph\nUsing calculus\nNumerical approximation"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#simple-linear-regression-model",
    "href": "slides/14-model-diagnostics.html#simple-linear-regression-model",
    "title": "Model diagnostics",
    "section": "Simple linear regression model",
    "text": "Simple linear regression model\nSuppose we have the simple linear regression (SLR) model\n\\[\ny_i = \\beta_0 + \\beta_1x_i + \\epsilon_i, \\hspace{10mm} \\epsilon_i \\sim N(0, \\sigma^2_{\\epsilon})\n\\]\nsuch that \\(\\epsilon_i\\) are independently and identically distributed.\n\n\nWe can write this model in the form below and use this to find the MLE\n\\[\ny_i | x_i \\sim N(\\beta_0 + \\beta_1 x_i, \\sigma^2_{\\epsilon})\n\\]"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#likelihood-for-slr",
    "href": "slides/14-model-diagnostics.html#likelihood-for-slr",
    "title": "Model diagnostics",
    "section": "Likelihood for SLR",
    "text": "Likelihood for SLR\nThe likelihood function for \\(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon}\\) is\n\\[\n\\begin{aligned}\nL&(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon} | x_i, \\dots, x_n, y_i, \\dots, y_n) \\\\[5pt]\n&= \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma_\n\\epsilon^2}}\\exp\\Big\\{{-\\frac{1}{2\\sigma_\\epsilon^2}(y_i - [\\beta_0 + \\beta_1x_i])^2}\\Big\\} \\\\[10pt]\n& = (2\\pi\\sigma^2_{\\epsilon})^{-\\frac{n}{2}}\\exp\\Big\\{-\\frac{1}{2\\sigma^2_{\\epsilon}}\\sum_{i=1}^n(y_i - \\beta_0 - \\beta_1x_i)^2\\Big\\}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#log-likelihood-for-slr",
    "href": "slides/14-model-diagnostics.html#log-likelihood-for-slr",
    "title": "Model diagnostics",
    "section": "Log-likelihood for SLR",
    "text": "Log-likelihood for SLR\nThe log-likelihood function for \\(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon}\\) is\n\\[\n\\begin{aligned}\n\\log &L(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon} | x_i, \\dots, x_n, y_i, \\dots, y_n)\n  \\\\[8pt]\n& = -\\frac{n}{2}\\log(2\\pi\\sigma^2_{\\epsilon}) -\\frac{1}{2\\sigma^2_{\\epsilon}}\\sum_{i=1}^n(y_i - \\beta_0 - \\beta_1x_i)^2\n\\end{aligned}\n\\]\n\n\nWe will use the log-likelihood function to find the MLEs"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#mle-for-beta_0beta_1-sigma2_epsilon",
    "href": "slides/14-model-diagnostics.html#mle-for-beta_0beta_1-sigma2_epsilon",
    "title": "Model diagnostics",
    "section": "MLE for \\(\\beta_0,\\beta_1, \\sigma^2_{\\epsilon}\\)",
    "text": "MLE for \\(\\beta_0,\\beta_1, \\sigma^2_{\\epsilon}\\)\n\\[\n\\tilde{\\beta}_0 = \\frac{1}{n}\\sum_{i=1}^ny_i  - \\frac{1}{n}\\tilde{\\beta}_1\\sum_{i=1}^n x_i\n\\]\n\n\\[\n\\tilde{\\beta}_1 = \\frac{\\sum_{i=1}^n y_i(x_i - \\bar{x})}{\\sum_{i=1}^n(x_i - \\bar{x})^2}\n\\]\n\n\\[\n\\tilde{\\sigma}^2_{\\epsilon} = \\frac{\\sum_{i=1}^n(y_i - \\tilde{\\beta}_0 - \\tilde{\\beta}_1x_i)^2}{n} = \\frac{\\sum_{i=1}^ne_i^2}{n}\n\\]"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#mle-for-linear-regression-in-matrix-form",
    "href": "slides/14-model-diagnostics.html#mle-for-linear-regression-in-matrix-form",
    "title": "Model diagnostics",
    "section": "MLE for linear regression in matrix form",
    "text": "MLE for linear regression in matrix form\n\\[\nL(\\boldsymbol{\\beta}, \\sigma^2_{\\epsilon} | \\mathbf{X}, \\mathbf{y}) = \\frac{1}{(2\\pi)^{n/2}\\sigma^n_{\\epsilon}}\\exp\\Big\\{-\\frac{1}{2\\sigma^2_{\\epsilon}}(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\Big\\}\n\\]\n\n\\[\n\\log L(\\boldsymbol{\\beta}, \\sigma^2_\\epsilon | \\mathbf{X}, \\mathbf{y}) = -\\frac{n}{2}\\log(2\\pi) - n \\log(\\sigma_{\\epsilon}) - \\frac{1}{2\\sigma^2_{\\epsilon}}(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\mathbf{\\beta})\n\\]\n\n\n\n\nFor a fixed value of \\(\\sigma_\\epsilon\\) , we know that \\(\\log L\\) is maximized when what is true about \\((\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\) ?\nWhat does this tell us about the relationship between the MLE and least-squares estimator for \\(\\boldsymbol{\\beta}\\)?"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#why-maximum-likelihood-estimation",
    "href": "slides/14-model-diagnostics.html#why-maximum-likelihood-estimation",
    "title": "Model diagnostics",
    "section": "Why maximum likelihood estimation?",
    "text": "Why maximum likelihood estimation?\n\n“Maximum likelihood estimation is, by far, the most popular technique for deriving estimators.” (Casella and Berger 2024, 315)\nMLEs have nice statistical properties. They are\n\nConsistent\nEfficient - Have the smallest MSE among all consistent estimators\nAsymptotically normal"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#putting-it-all-together",
    "href": "slides/14-model-diagnostics.html#putting-it-all-together",
    "title": "Model diagnostics",
    "section": "Putting it all together",
    "text": "Putting it all together\n\n\nThe MLE \\(\\tilde{\\boldsymbol{\\beta}}\\) is equivalent to the least-squares estimator \\(\\hat{\\boldsymbol{\\beta}}\\) , when the errors follow independent and identical normal distributions\nThis means the least-squares estimator \\(\\hat{\\mathbf{\\boldsymbol{\\beta}}}\\) inherits all the nice properties of MLEs\n\nConsistency\nEfficiency - minimum variance among all consistent estimators\nAsymptotically normal"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#putting-it-all-together-1",
    "href": "slides/14-model-diagnostics.html#putting-it-all-together-1",
    "title": "Model diagnostics",
    "section": "Putting it all together",
    "text": "Putting it all together\n\nFrom previous work, we also know \\(\\hat{\\boldsymbol{\\beta}}\\) is unbiased and thus the MLE \\(\\tilde{\\boldsymbol{\\beta}}\\) is unbiased\nNote that the MLE \\(\\tilde{\\sigma}^2_{\\epsilon}\\) is asymptotically unbiased\n\nThe estimate from least-squares \\(\\hat{\\sigma}_{\\epsilon}^2\\) is unbiased"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#data-duke-lemurs",
    "href": "slides/14-model-diagnostics.html#data-duke-lemurs",
    "title": "Model diagnostics",
    "section": "Data: Duke lemurs",
    "text": "Data: Duke lemurs\nToday’s data contains a subset of the original Duke Lemur data set available in the TidyTuesday GitHub repo. This data includes information on “young adult” lemurs from the Coquerel’s sifaka species (PCOQ), the largest species at the Duke Lemur Center. The analysis will focus on the following variables:\n\nage_at_wt_mo: Age in months: Age of the animal when the weight was taken, in months (((Weight_Date-DOB)/365)*12)\nweight_g: Weight: Animal weight, in grams. Weights under 500g generally to nearest 0.1-1g; Weights &gt;500g generally to the nearest 1-20g.\n\nThe goal of the analysis is to use the age of the lemurs to understand variability in the weight."
  },
  {
    "objectID": "slides/14-model-diagnostics.html#eda",
    "href": "slides/14-model-diagnostics.html#eda",
    "title": "Model diagnostics",
    "section": "EDA",
    "text": "EDA"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#fit-model",
    "href": "slides/14-model-diagnostics.html#fit-model",
    "title": "Model diagnostics",
    "section": "Fit model",
    "text": "Fit model\n\nlemurs_fit &lt;- lm(weight_g ~ age_at_wt_mo, data = lemurs)\n\ntidy(lemurs_fit) |&gt; \n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n3133.284\n353.499\n8.864\n0.000\n\n\nage_at_wt_mo\n19.558\n10.083\n1.940\n0.056"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#model-conditions",
    "href": "slides/14-model-diagnostics.html#model-conditions",
    "title": "Model diagnostics",
    "section": "Model conditions",
    "text": "Model conditions\n\n\nLinearity\nConstant variance"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#model-conditions-1",
    "href": "slides/14-model-diagnostics.html#model-conditions-1",
    "title": "Model diagnostics",
    "section": "Model conditions",
    "text": "Model conditions\n\n\nNormality\nIndependence"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#model-diagnostics-1",
    "href": "slides/14-model-diagnostics.html#model-diagnostics-1",
    "title": "Model diagnostics",
    "section": "Model diagnostics",
    "text": "Model diagnostics\n\nlemurs_aug &lt;- augment(lemurs_fit)\n\nlemurs_aug |&gt; slice(1:10)\n\n# A tibble: 10 × 8\n   weight_g age_at_wt_mo .fitted .resid   .hat .sigma    .cooksd .std.resid\n      &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1     3400         32.0   3758. -358.  0.0158   516. 0.00396       -0.703 \n 2     4143         46.2   4037.  106.  0.0655   517. 0.00159        0.213 \n 3     3581         43.1   3977. -396.  0.0414   515. 0.0134        -0.787 \n 4     3620         33.0   3778. -158.  0.0141   517. 0.000690      -0.310 \n 5     3720         32.4   3768.  -47.9 0.0149   517. 0.0000668     -0.0940\n 6     3540         35.4   3825. -285.  0.0134   516. 0.00212       -0.559 \n 7     4440         37.3   3863.  577.  0.0161   513. 0.0105         1.13  \n 8     4440         32.6   3770.  670.  0.0147   511. 0.0129         1.31  \n 9     3770         31.8   3754.   15.6 0.0162   517. 0.00000767     0.0305\n10     3920         31.9   3757.  163.  0.0159   517. 0.000828       0.320"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#model-diagnostics-in-r",
    "href": "slides/14-model-diagnostics.html#model-diagnostics-in-r",
    "title": "Model diagnostics",
    "section": "Model diagnostics in R",
    "text": "Model diagnostics in R\nUse the augment() function in the broom package to output the model diagnostics (along with the predicted values and residuals)\n\nresponse and predictor variables in the model\n.fitted: predicted values\n.se.fit: standard errors of predicted values\n.resid: residuals\n.hat: leverage\n.sigma: estimate of residual standard deviation when the corresponding observation is dropped from model\n.cooksd: Cook’s distance\n.std.resid: standardized residuals"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#influential-point",
    "href": "slides/14-model-diagnostics.html#influential-point",
    "title": "Model diagnostics",
    "section": "Influential Point",
    "text": "Influential Point\nAn observation is influential if removing has a noticeable impact on the regression coefficients"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#influential-points",
    "href": "slides/14-model-diagnostics.html#influential-points",
    "title": "Model diagnostics",
    "section": "Influential points",
    "text": "Influential points\n\n\nInfluential points have a noticeable impact on the coefficients and standard errors used for inference\nThese points can sometimes be identified in a scatterplot if there is only one predictor variable\n\nThis is often not the case when there are multiple predictors\n\nWe will use measures to quantify an individual observation’s influence on the regression model\n\nleverage, standardized & studentized residuals, and Cook’s distance"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#hat-matrix",
    "href": "slides/14-model-diagnostics.html#hat-matrix",
    "title": "Model diagnostics",
    "section": "Hat matrix",
    "text": "Hat matrix\n\n\nRecall the hat matrix \\(\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\)\nWe’ve seen that \\(\\mathbf{H}\\) is used to compute \\(Var(\\hat{\\mathbf{y}}) = \\sigma^2_{\\epsilon}\\mathbf{H}\\) and \\(Var(\\mathbf{e}) = \\sigma^2_{\\epsilon}(\\mathbf{I} - \\mathbf{H})\\)\nAn element of \\(\\mathbf{H}\\), \\(h_{ij}\\), is the leverage of the observation \\(y_i\\) on the fitted values \\(\\hat{y}_{j}\\)"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#leverage-1",
    "href": "slides/14-model-diagnostics.html#leverage-1",
    "title": "Model diagnostics",
    "section": "Leverage",
    "text": "Leverage\n\n\nWe focus on the diagonal elements\n\\[\nh_{ii} = \\mathbf{x}_i^T(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{x}_i\n\\]such that \\(\\mathbf{x}^T_i\\) is the \\(i^{th}\\) row of \\(\\mathbf{X}\\)\n\\(h_{ii}\\) is the leverage: a measure of the distance of the \\(i^{th}\\) observation from the center (or centroid) of the \\(x\\) space\nObservations with large values of \\(h_{ii}\\) are far away from the typical value (or combination of values) of the predictors in the data"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#large-leverage",
    "href": "slides/14-model-diagnostics.html#large-leverage",
    "title": "Model diagnostics",
    "section": "Large leverage",
    "text": "Large leverage\n\n\nThe sum of the leverages for all points is \\(p + 1\\), where \\(p\\) is the number of predictors in the model . More specifically\n\\[\n\\sum_{i=1}^n h_{ii} = \\text{rank}(\\mathbf{H}) = \\text{rank}(\\mathbf{X}) = p+1\n\\]\nThe average value of leverage, \\(h_{ii}\\), is \\(\\bar{h} =  \\frac{(p+1)}{n}\\)\nAn observation has large leverage if \\[h_{ii} &gt; \\frac{2(p+1)}{n}\\]"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#lemurs-leverage",
    "href": "slides/14-model-diagnostics.html#lemurs-leverage",
    "title": "Model diagnostics",
    "section": "Lemurs: Leverage",
    "text": "Lemurs: Leverage\n\nh_threshold &lt;- 2 * 2 / nrow(lemurs)\nh_threshold\n\n[1] 0.05263158\n\n\n\n\nlemurs_aug |&gt;\n  filter(.hat &gt; h_threshold)\n\n# A tibble: 7 × 8\n  weight_g age_at_wt_mo .fitted .resid   .hat .sigma .cooksd .std.resid\n     &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n1     4143         46.2   4037.  106.  0.0655   517. 0.00159     0.213 \n2     4313         58.2   4272.   41.1 0.229    517. 0.00123     0.0910\n3     4640         54.9   4208.  432.  0.173    514. 0.0895      0.925 \n4     3677         47.4   4061. -384.  0.0770   515. 0.0253     -0.778 \n5     4319         58.2   4272.   47.1 0.229    517. 0.00161     0.104 \n6     3610         47.4   4061. -451.  0.0770   514. 0.0348     -0.914 \n7     3597         48.6   4084. -487.  0.0889   514. 0.0480     -0.992 \n\n\n\n\n\nWhy do you think these points have large leverage?"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#lets-look-at-the-data",
    "href": "slides/14-model-diagnostics.html#lets-look-at-the-data",
    "title": "Model diagnostics",
    "section": "Let’s look at the data",
    "text": "Let’s look at the data"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#large-leverage-1",
    "href": "slides/14-model-diagnostics.html#large-leverage-1",
    "title": "Model diagnostics",
    "section": "Large leverage",
    "text": "Large leverage\nIf there is point with high leverage, ask\n\n❓ Is there a data entry error?\n❓ Is this observation within the scope of individuals for which you want to make predictions and draw conclusions?\n❓ Is this observation impacting the estimates of the model coefficients? (Need more information!)\n\n\nJust because a point has high leverage does not necessarily mean it will have a substantial impact on the regression. Therefore we need to check other measures."
  },
  {
    "objectID": "slides/14-model-diagnostics.html#scaled-residuals-1",
    "href": "slides/14-model-diagnostics.html#scaled-residuals-1",
    "title": "Model diagnostics",
    "section": "Scaled residuals",
    "text": "Scaled residuals\n\n\nWhat is the best way to identify outlier points that don’t fit the pattern from the regression line?\n\nLook for points that have large residuals\n\nWe can rescale residuals and put them on a common scale to more easily identify “large” residuals\nWe will consider two types of scaled residuals: standardized residuals and studentized residuals"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#standardized-residuals",
    "href": "slides/14-model-diagnostics.html#standardized-residuals",
    "title": "Model diagnostics",
    "section": "Standardized residuals",
    "text": "Standardized residuals\n\n\nThe variance of the residuals can be estimated by the mean squared residuals (MSR) \\(= \\frac{SSR}{n - p - 1} = \\hat{\\sigma}^2_{\\epsilon}\\)\nWe can use MSR to compute standardized residuals\n\\[\nstd.res_i = \\frac{e_i}{\\sqrt{MSR}}\n\\]\nStandardized residuals are produced by augment() in the column .std.resid"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#studentized-residuals",
    "href": "slides/14-model-diagnostics.html#studentized-residuals",
    "title": "Model diagnostics",
    "section": "Studentized residuals",
    "text": "Studentized residuals\n\n\nMSR is an approximation of the variance of the residuals.\nThe variance of the residuals is \\(Var(\\mathbf{e}) = \\sigma^2_{\\epsilon}(\\mathbf{I} - \\mathbf{H})\\)\n\nThe variance of the \\(i^{th}\\) residual is \\(Var(e_i) = \\sigma^2_{\\epsilon}(1 - h_{ii})\\)\n\nThe studentized residual is the residual rescaled by the more exact calculation for variance\n\n\n\\[\nr_i = \\frac{e_{i}}{\\sqrt{\\hat{\\sigma}^2_{\\epsilon}(1 - h_{ii})}}\n\\]\n\nStandardized and studentized residuals provide similar information about which points are outliers in the response."
  },
  {
    "objectID": "slides/14-model-diagnostics.html#using-standardized-residuals",
    "href": "slides/14-model-diagnostics.html#using-standardized-residuals",
    "title": "Model diagnostics",
    "section": "Using standardized residuals",
    "text": "Using standardized residuals\nWe can examine the standardized residuals directly from the output from the augment() function\n\n\nAn observation is a potential outlier if its standardized residual is beyond \\(\\pm 3\\)"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#digging-in-to-the-data",
    "href": "slides/14-model-diagnostics.html#digging-in-to-the-data",
    "title": "Model diagnostics",
    "section": "Digging in to the data",
    "text": "Digging in to the data\nLet’s look at the value of the response variable to better understand potential outliers"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#motivating-cooks-distance",
    "href": "slides/14-model-diagnostics.html#motivating-cooks-distance",
    "title": "Model diagnostics",
    "section": "Motivating Cook’s Distance",
    "text": "Motivating Cook’s Distance\n\nAn observation’s influence on the regression line depends on\n\nHow close it lies to the general trend of the data\nIts leverage\n\nCook’s Distance is a statistic that includes both of these components to measure an observation’s overall impact on the model"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#cooks-distance-1",
    "href": "slides/14-model-diagnostics.html#cooks-distance-1",
    "title": "Model diagnostics",
    "section": "Cook’s Distance",
    "text": "Cook’s Distance\nCook’s distance for the \\(i^{th}\\) observation is\n\\[\nD_i = \\frac{r^2_i}{p + 1}\\Big(\\frac{h_{ii}}{1 - h_{ii}}\\Big)\n\\]\n\nThis measure is a combination of\n\nHow well the model fits the \\(i^{th}\\) observation (magnitude of residuals)\nHow far the \\(i^{th}\\) observation is from the rest of the data (where the point is in the \\(x\\) space)"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#using-cooks-distance",
    "href": "slides/14-model-diagnostics.html#using-cooks-distance",
    "title": "Model diagnostics",
    "section": "Using Cook’s Distance",
    "text": "Using Cook’s Distance\n\nAn observation with large value of \\(D_i\\) is said to have a strong influence on the predicted values\nGeneral thresholds .An observation with\n\n\\(D_i &gt; 0.5\\) is moderately influential\n\\(D_i &gt; 1\\) is very influential"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#cooks-distance-2",
    "href": "slides/14-model-diagnostics.html#cooks-distance-2",
    "title": "Model diagnostics",
    "section": "Cook’s Distance",
    "text": "Cook’s Distance\nCook’s Distance is in the column .cooksd in the output from the augment() function"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#using-these-measures",
    "href": "slides/14-model-diagnostics.html#using-these-measures",
    "title": "Model diagnostics",
    "section": "Using these measures",
    "text": "Using these measures\n\nStandardized residuals, leverage, and Cook’s Distance should all be examined together\nExamine plots of the measures to identify observations that are outliers, high leverage, and may potentially impact the model."
  },
  {
    "objectID": "slides/14-model-diagnostics.html#what-to-do-with-outliersinfluential-points",
    "href": "slides/14-model-diagnostics.html#what-to-do-with-outliersinfluential-points",
    "title": "Model diagnostics",
    "section": "What to do with outliers/influential points?",
    "text": "What to do with outliers/influential points?\n\n\nFirst consider if the outlier is a result of a data entry error.\nIf not, you may consider dropping an observation if it’s an outlier in the predictor variables if…\n\nIt is meaningful to drop the observation given the context of the problem\nYou intended to build a model on a smaller range of the predictor variables. Mention this in the write up of the results and be careful to avoid extrapolation when making predictions"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#what-to-do-with-outliersinfluential-points-1",
    "href": "slides/14-model-diagnostics.html#what-to-do-with-outliersinfluential-points-1",
    "title": "Model diagnostics",
    "section": "What to do with outliers/influential points?",
    "text": "What to do with outliers/influential points?\n\n\nIt is generally not good practice to drop observations that ar outliers in the value of the response variable\n\nThese are legitimate observations and should be in the model\nYou can try transformations or increasing the sample size by collecting more data\n\nA general strategy when there are influential points is to fit the model with and without the influential points and compare the outcomes"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#recap",
    "href": "slides/14-model-diagnostics.html#recap",
    "title": "Model diagnostics",
    "section": "Recap",
    "text": "Recap\n\nReviewed Maximum likelihood estimation\nInfluential points\nModel diagnostics\n\nLeverage\nStudentized residuals\nCook’s Distance"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#references",
    "href": "slides/14-model-diagnostics.html#references",
    "title": "Model diagnostics",
    "section": "References",
    "text": "References\n\n\n\n\n🔗 STA 221 - Fall 2024\n\n\n\n\nCasella, George, and Roger Berger. 2024. Statistical Inference. CRC Press."
  },
  {
    "objectID": "slides/08-inference.html#announcements",
    "href": "slides/08-inference.html#announcements",
    "title": "Inference for regression",
    "section": "Announcements",
    "text": "Announcements\n\nLab 02 due on TODAY at 11:59pm\nHW 01 due TODAY at 11:59pm\nStatistics experience due Tue, Nov 26 at 11:59pm"
  },
  {
    "objectID": "slides/08-inference.html#statistics-experience",
    "href": "slides/08-inference.html#statistics-experience",
    "title": "Inference for regression",
    "section": "Statistics experience",
    "text": "Statistics experience\nGoal: Engage with statistics / data science outside the classroom and connect your experience with what you’re learning in the course.\nWhat: Have a statistics experience + create a slide reflecting on the experience. Counts as a homework grade.\nWhen: Must do the activity this semester. Reflection due Tuesday, November 26 at 11:59pm\nFor more info: sta221-fa24.netlify.app/hw/stats-experience"
  },
  {
    "objectID": "slides/08-inference.html#reminder-course-policies-about-assignments",
    "href": "slides/08-inference.html#reminder-course-policies-about-assignments",
    "title": "Inference for regression",
    "section": "Reminder: course policies about assignments",
    "text": "Reminder: course policies about assignments\n\nLate work\n\nHW and labs accepted up to 2 days late.\n5% deduction for each 24-hour period the assignment is late.\n\nOne time late waiver\n\nCan use on HW and individual labs\n\nLowest HW and lowest lab grade dropped at the end of the semester."
  },
  {
    "objectID": "slides/08-inference.html#reminder-course-policies-about-assignments-1",
    "href": "slides/08-inference.html#reminder-course-policies-about-assignments-1",
    "title": "Inference for regression",
    "section": "Reminder: course policies about assignments",
    "text": "Reminder: course policies about assignments\n\nRead the feedback on Gradescope carefully! If you have questions about the comments, ask a member of the teaching team during office hours or before/after class.\nRegrade requests\n\nOpened 1 day after assignment is returned and due within 1 week\nOnly submit regrade request if there is an error in the grading not to dispute points or ask questions about grading.\nProf. Tackett or Kat (Head TA) will regrade the entire exercise being disputed, which could potentially result in a lower grade."
  },
  {
    "objectID": "slides/08-inference.html#poll-office-hours-availability",
    "href": "slides/08-inference.html#poll-office-hours-availability",
    "title": "Inference for regression",
    "section": "Poll: Office hours availability",
    "text": "Poll: Office hours availability"
  },
  {
    "objectID": "slides/08-inference.html#topics",
    "href": "slides/08-inference.html#topics",
    "title": "Inference for regression",
    "section": "Topics",
    "text": "Topics\n\nUnderstand statistical inference in the context of regression\nDescribe the assumptions for regression\nUnderstand connection between distribution of residuals and inferential procedures\nConduct inference on a single coefficient"
  },
  {
    "objectID": "slides/08-inference.html#computing-setup",
    "href": "slides/08-inference.html#computing-setup",
    "title": "Inference for regression",
    "section": "Computing setup",
    "text": "Computing setup\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(kableExtra)  \nlibrary(patchwork)   \n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/08-inference.html#data-ncaa-football-expenditures",
    "href": "slides/08-inference.html#data-ncaa-football-expenditures",
    "title": "Inference for regression",
    "section": "Data: NCAA Football expenditures",
    "text": "Data: NCAA Football expenditures\nToday’s data come from Equity in Athletics Data Analysis and includes information about sports expenditures and revenues for colleges and universities in the United States. This data set was featured in a March 2022 Tidy Tuesday.\nWe will focus on the 2019 - 2020 season expenditures on football for institutions in the NCAA - Division 1 FBS. The variables are :\n\ntotal_exp_m: Total expenditures on football in the 2019 - 2020 academic year (in millions USD)\nenrollment_th: Total student enrollment in the 2019 - 2020 academic year (in thousands)\ntype: institution type (Public or Private)\n\n\nfootball &lt;- read_csv(\"data/ncaa-football-exp.csv\")"
  },
  {
    "objectID": "slides/08-inference.html#univariate-eda",
    "href": "slides/08-inference.html#univariate-eda",
    "title": "Inference for regression",
    "section": "Univariate EDA",
    "text": "Univariate EDA"
  },
  {
    "objectID": "slides/08-inference.html#bivariate-eda",
    "href": "slides/08-inference.html#bivariate-eda",
    "title": "Inference for regression",
    "section": "Bivariate EDA",
    "text": "Bivariate EDA"
  },
  {
    "objectID": "slides/08-inference.html#regression-model",
    "href": "slides/08-inference.html#regression-model",
    "title": "Inference for regression",
    "section": "Regression model",
    "text": "Regression model\n\nexp_fit &lt;- lm(total_exp_m ~ enrollment_th + type, data = football)\ntidy(exp_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0\n\n\n\n\n\n\nFor every additional 1,000 students, we expect the institution’s total expenditures on football to increase by $780,000, on average, holding institution type constant."
  },
  {
    "objectID": "slides/08-inference.html#from-sample-to-population",
    "href": "slides/08-inference.html#from-sample-to-population",
    "title": "Inference for regression",
    "section": "From sample to population",
    "text": "From sample to population\n\nFor every additional 1,000 students, we expect the institution’s total expenditures on football to increase by $780,000, on average, holding institution type constant.\n\n\n\n\nThis estimate is valid for the single sample of 127 higher education institutions in the 2019 - 2020 academic year.\nBut what if we’re not interested quantifying the relationship between student enrollment, institution type, and football expenditures for this single sample?\nWhat if we want to say something about the relationship between these variables for all colleges and universities with football programs and across different years?"
  },
  {
    "objectID": "slides/08-inference.html#statistical-inference",
    "href": "slides/08-inference.html#statistical-inference",
    "title": "Inference for regression",
    "section": "Statistical inference",
    "text": "Statistical inference\n\n\n\nStatistical inference provides methods and tools so we can use the single observed sample to make valid statements (inferences) about the population it comes from\nFor our inferences to be valid, the sample should be representative (ideally random) of the population we’re interested in\n\n\n\n\n\nImage source: Eugene Morgan © Penn State"
  },
  {
    "objectID": "slides/08-inference.html#inference-for-linear-regression",
    "href": "slides/08-inference.html#inference-for-linear-regression",
    "title": "Inference for regression",
    "section": "Inference for linear regression",
    "text": "Inference for linear regression\n\nInference based on ANOVA\n\nHypothesis test for the statistical significance of the overall regression model\nHypothesis test for a subset of coefficients\n\nInference for a single coefficient \\(\\beta_j\\)\n\nHypothesis test for a coefficient \\(\\beta_j\\)\nConfidence interval for a coefficient \\(\\beta_j\\)"
  },
  {
    "objectID": "slides/08-inference.html#linear-regression-model",
    "href": "slides/08-inference.html#linear-regression-model",
    "title": "Inference for regression",
    "section": "Linear regression model",
    "text": "Linear regression model\n\\[\n\\begin{aligned}\n\\mathbf{y} &= Model + Error \\\\[5pt]\n&= f(\\mathbf{X}) + \\boldsymbol{\\epsilon} \\\\[5pt]\n&= E(\\mathbf{y}|\\mathbf{X}) + \\mathbf{\\epsilon} \\\\[5pt]\n&= \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon}\n\\end{aligned}\n\\]\n\n\n\nWe have discussed multiple ways to find the least squares estimates of \\(\\boldsymbol{\\beta} = \\begin{bmatrix}\\beta_0 \\\\\\beta_1\\end{bmatrix}\\)\n\nNone of these approaches depend on the distribution of \\(\\boldsymbol{\\epsilon}\\)\n\nNow we will use statistical inference to draw conclusions about \\(\\boldsymbol{\\beta}\\) that depend on particular assumptions about the distribution of \\(\\boldsymbol{\\epsilon}\\)"
  },
  {
    "objectID": "slides/08-inference.html#linear-regression-model-1",
    "href": "slides/08-inference.html#linear-regression-model-1",
    "title": "Inference for regression",
    "section": "Linear regression model",
    "text": "Linear regression model\n\\[\\begin{aligned}\n\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}, \\hspace{8mm} \\boldsymbol{\\epsilon} \\sim N(0, \\sigma^2_{\\epsilon}\\mathbf{I})\n\\end{aligned}\n\\]\nsuch that the errors are independent and normally distributed.\n\n\nIndependent: Knowing the error term for one observation doesn’t tell you anything about the error term for another observation\nNormally distributed: Tell us the shape of the distribution of residuals\n\n\nWhat else do we know about the distribution of the residuals based on this equation?"
  },
  {
    "objectID": "slides/08-inference.html#describing-random-phenomena",
    "href": "slides/08-inference.html#describing-random-phenomena",
    "title": "Inference for regression",
    "section": "Describing random phenomena",
    "text": "Describing random phenomena\n\n\nThere is some uncertainty in the residuals (and the predicted responses), so we use mathematical models to describe that uncertainty.\nSome terminology:\n\nSample space: Set of all possible outcomes\nRandom variable: Function (mapping) from the sample space onto real numbers\nEvent: Subset of the sample space, i.e., a set of possible outcomes (possible values the random variable can take)\nProbability distribution function: Mathematical function that produces probability of occurrences for events in the sample space"
  },
  {
    "objectID": "slides/08-inference.html#example",
    "href": "slides/08-inference.html#example",
    "title": "Inference for regression",
    "section": "Example",
    "text": "Example\nSuppose we are tossing 2 fair coins with sides heads (H) and tails (T)\n\n\nSample space: {HH, HT, TH, TT}\nRandom variable: \\(X\\) : The number of heads in two coin tosses\nEvent: We flip two coins and get 1 head\nProbability distribution function: \\[P(X = x_i) = {2 \\choose x_i}0.5^{x_i}{0.5}^{2-x_i}\\]\nNow we can find \\[P(X = 1) = {2 \\choose 1}0.5^1{0.5}^{2-1} = 0.5\\]"
  },
  {
    "objectID": "slides/08-inference.html#mathematical-representation",
    "href": "slides/08-inference.html#mathematical-representation",
    "title": "Inference for regression",
    "section": "Mathematical representation",
    "text": "Mathematical representation\n\\[\n\\mathbf{y}|\\mathbf{X} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma_\\epsilon^2\\mathbf{I})\n\\]\n\nImage source: Introduction to the Practice of Statistics (5th ed)"
  },
  {
    "objectID": "slides/08-inference.html#expected-value-of-mathbfy",
    "href": "slides/08-inference.html#expected-value-of-mathbfy",
    "title": "Inference for regression",
    "section": "Expected value of \\(\\mathbf{y}\\)",
    "text": "Expected value of \\(\\mathbf{y}\\)\nLet \\(\\mathbf{b} = \\begin{bmatrix}b_1 \\\\ \\vdots \\\\b_p\\end{bmatrix}\\) be a \\(p \\times 1\\) vector of random variables.\n\n\nThen \\(E(\\mathbf{b}) = E\\begin{bmatrix}b_1 \\\\ \\vdots \\\\ b_p\\end{bmatrix} = \\begin{bmatrix}E(b_1) \\\\ \\vdots \\\\ E(b_p)\\end{bmatrix}\\)\n\n\n\n\nUse this to find \\(E(\\mathbf{y}|\\mathbf{X})\\)."
  },
  {
    "objectID": "slides/08-inference.html#variance",
    "href": "slides/08-inference.html#variance",
    "title": "Inference for regression",
    "section": "Variance",
    "text": "Variance\nLet \\(\\mathbf{b} = \\begin{bmatrix}b_1 \\\\ \\vdots \\\\b_p\\end{bmatrix}\\) be a \\(p \\times 1\\) vector of independent random variables.\n\n\nThen \\(Var(\\mathbf{b}) = \\begin{bmatrix}Var(b_1) & 0 & \\dots & 0 \\\\ 0 & Var(b_2) & \\dots & 0 \\\\ \\vdots & \\vdots & \\dots & \\cdot \\\\ 0 & 0 & \\dots & Var(b_p)\\end{bmatrix}\\)\n\n\n\n\nUse this to find \\(Var(\\mathbf{y}|\\mathbf{X})\\)."
  },
  {
    "objectID": "slides/08-inference.html#assumptions-of-regression",
    "href": "slides/08-inference.html#assumptions-of-regression",
    "title": "Inference for regression",
    "section": "Assumptions of regression",
    "text": "Assumptions of regression\n\n\n\\[\n\\mathbf{y}|\\mathbf{X} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma_\\epsilon^2\\mathbf{I})\n\\]\n\n\n\nImage source: Introduction to the Practice of Statistics (5th ed)\n\n\n\n\nLinearity: There is a linear relationship between the response and predictor variables.\nConstant Variance: The variability about the least squares line is generally constant.\nNormality: The distribution of the residuals is approximately normal.\nIndependence: The residuals are independent from one another."
  },
  {
    "objectID": "slides/08-inference.html#estimating-sigma2_epsilon",
    "href": "slides/08-inference.html#estimating-sigma2_epsilon",
    "title": "Inference for regression",
    "section": "Estimating \\(\\sigma^2_{\\epsilon}\\)",
    "text": "Estimating \\(\\sigma^2_{\\epsilon}\\)\n\nOnce we fit the model, we can use the residuals to estimate \\(\\sigma_{\\epsilon}^2\\)\n\\(\\hat{\\sigma}^2_{\\epsilon}\\) is needed for hypothesis testing and constructing confidence intervals for regression\n\n\\[\n\\hat{\\sigma}^2_\\epsilon = \\frac{\\sum_\\limits{i=1}^n(y_i - \\hat{y}_i)^2}{n-p-1} = \\frac{\\sum_\\limits{i=1}^ne_i^2}{n - p - 1} = \\frac{SSR}{n - p - 1}\n\\]\n\n\nThe regression standard error \\(\\hat{\\sigma}_{\\epsilon}\\) is a measure of the average distance between the observations and regression line\n\n\\[\n\\hat{\\sigma}_\\epsilon = \\sqrt{\\frac{SSR}{n - p - 1}}\n\\]"
  },
  {
    "objectID": "slides/08-inference.html#inference-for-beta_j",
    "href": "slides/08-inference.html#inference-for-beta_j",
    "title": "Inference for regression",
    "section": "Inference for \\(\\beta_j\\)",
    "text": "Inference for \\(\\beta_j\\)\nWe often want to conduct inference on individual model coefficients\n\nHypothesis test: Is there a linear relationship between the response and \\(x_j\\)?\nConfidence interval: What is a plausible range of values \\(\\beta_j\\) can take?\n\n\nBut first we need to understand the distribution of \\(\\hat{\\beta}_j\\)"
  },
  {
    "objectID": "slides/08-inference.html#sampling-distribution-of-hatbeta",
    "href": "slides/08-inference.html#sampling-distribution-of-hatbeta",
    "title": "Inference for regression",
    "section": "Sampling distribution of \\(\\hat{\\beta}\\)",
    "text": "Sampling distribution of \\(\\hat{\\beta}\\)\n\nA sampling distribution is the probability distribution of a statistic based on a large number of random samples of size \\(n\\) from a population\nThe sampling distribution of \\(\\hat{\\boldsymbol{\\beta}}\\) is the probability distribution of the estimated coefficients if we repeatedly took samples of size \\(n\\) and fit the regression model\n\n\\[\n\\hat{\\boldsymbol{\\beta}} \\sim N(\\boldsymbol{\\beta}, \\sigma^2_\\epsilon(\\mathbf{X}^T\\mathbf{X})^{-1})\n\\]\n\nThe estimated coefficients \\(\\hat{\\boldsymbol{\\beta}}\\) are normally distributed with\n\\[\nE(\\hat{\\boldsymbol{\\beta}}) = \\boldsymbol{\\beta} \\hspace{10mm} Var(\\hat{\\boldsymbol{\\beta}}) = \\sigma^2_{\\epsilon}(\\boldsymbol{X}^T\\boldsymbol{X})^{-1}\n\\]"
  },
  {
    "objectID": "slides/08-inference.html#sampling-distribution-of-hatbeta_j",
    "href": "slides/08-inference.html#sampling-distribution-of-hatbeta_j",
    "title": "Inference for regression",
    "section": "Sampling distribution of \\(\\hat{\\beta}_j\\)",
    "text": "Sampling distribution of \\(\\hat{\\beta}_j\\)\n\\[\n\\hat{\\boldsymbol{\\beta}} \\sim N(\\boldsymbol{\\beta}, \\sigma^2_\\epsilon(\\mathbf{X}^T\\mathbf{X})^{-1})\n\\]\nLet \\(\\mathbf{C} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\). Then, for each coefficient \\(\\hat{\\beta}_j\\),\n\n\n\\(E(\\hat{\\beta}_j) = \\boldsymbol{\\beta}_j\\), the \\(j^{th}\\) element of \\(\\boldsymbol{\\beta}\\)\n\\(Var(\\hat{\\beta}_j) = \\sigma^2_{\\epsilon}C_{jj}\\)\n\\(Cov(\\hat{\\beta}_i, \\hat{\\beta}_j) = \\sigma^2_{\\epsilon}C_{ij}\\)"
  },
  {
    "objectID": "slides/08-inference.html#steps-for-a-hypothesis-test",
    "href": "slides/08-inference.html#steps-for-a-hypothesis-test",
    "title": "Inference for regression",
    "section": "Steps for a hypothesis test",
    "text": "Steps for a hypothesis test\n\nState the null and alternative hypotheses.\nCalculate a test statistic.\nCalculate the p-value.\nState the conclusion."
  },
  {
    "objectID": "slides/08-inference.html#hypothesis-test-for-beta_j-hypotheses",
    "href": "slides/08-inference.html#hypothesis-test-for-beta_j-hypotheses",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Hypotheses",
    "text": "Hypothesis test for \\(\\beta_j\\): Hypotheses\nWe will generally test the hypotheses:\n\\[\n\\begin{aligned}\n&H_0: \\beta_j = 0 \\\\\n&H_a: \\beta_j \\neq 0\n\\end{aligned}\n\\]\n\nState these hypotheses in words."
  },
  {
    "objectID": "slides/08-inference.html#hypothesis-test-for-beta_j-test-statistic",
    "href": "slides/08-inference.html#hypothesis-test-for-beta_j-test-statistic",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Test statistic",
    "text": "Hypothesis test for \\(\\beta_j\\): Test statistic\nTest statistic: Number of standard errors the estimate is away from the null\n\\[\n\\text{Test Statstic} = \\frac{\\text{Estimate - Null}}{\\text{Standard error}} \\\\\n\\]\n\nIf \\(\\sigma^2_{\\epsilon}\\) was known, the test statistic would be\n\\[Z = \\frac{\\hat{\\beta}_j - 0}{SE(\\hat{\\beta}_j)} ~ = ~\\frac{\\hat{\\beta}_j - 0}{\\sqrt{\\sigma^2_\\epsilon C_{jj}}} ~\\sim ~ N(0, 1)\n\\]\n\n\nIn general, \\(\\sigma^2_{\\epsilon}\\) is not known, so we use \\(\\hat{\\sigma}_{\\epsilon}^2\\) to calculate \\(SE(\\hat{\\beta}_j)\\)\n\\[T = \\frac{\\hat{\\beta}_j - 0}{SE(\\hat{\\beta}_j)} ~ = ~\\frac{\\hat{\\beta}_j - 0}{\\sqrt{\\hat{\\sigma}^2_\\epsilon C_{jj}}} ~\\sim ~ t_{n-p-1}\n\\]"
  },
  {
    "objectID": "slides/08-inference.html#hypothesis-test-for-beta_j-test-statistic-1",
    "href": "slides/08-inference.html#hypothesis-test-for-beta_j-test-statistic-1",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Test statistic",
    "text": "Hypothesis test for \\(\\beta_j\\): Test statistic\n\nThe test statistic \\(T\\) follows a \\(t\\) distribution with \\(n - p -1\\) degrees of freedom.\nWe need to account for the additional variability introduced by calculating \\(SE(\\hat{\\beta}_j)\\) using an estimated value instead of a constant"
  },
  {
    "objectID": "slides/08-inference.html#t-vs.-n01",
    "href": "slides/08-inference.html#t-vs.-n01",
    "title": "Inference for regression",
    "section": "t vs. N(0,1)",
    "text": "t vs. N(0,1)\n\n\nFigure 1: Standard normal vs. t distributions"
  },
  {
    "objectID": "slides/08-inference.html#hypothesis-test-for-beta_j-p-value",
    "href": "slides/08-inference.html#hypothesis-test-for-beta_j-p-value",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): P-value",
    "text": "Hypothesis test for \\(\\beta_j\\): P-value\nThe p-value is the probability of observing a test statistic at least as extreme (in the direction of the alternative hypothesis) from the null value as the one observed\n\\[\np-value = P(|t| &gt; |\\text{test statistic}|),\n\\]\ncalculated from a \\(t\\) distribution with \\(n- p - 1\\) degrees of freedom\n\n\nWhy do we take into account “extreme” on both the high and low ends?"
  },
  {
    "objectID": "slides/08-inference.html#understanding-the-p-value",
    "href": "slides/08-inference.html#understanding-the-p-value",
    "title": "Inference for regression",
    "section": "Understanding the p-value",
    "text": "Understanding the p-value\n\n\n\nMagnitude of p-value\nInterpretation\n\n\n\n\np-value &lt; 0.01\nstrong evidence against \\(H_0\\)\n\n\n0.01 &lt; p-value &lt; 0.05\nmoderate evidence against \\(H_0\\)\n\n\n0.05 &lt; p-value &lt; 0.1\nweak evidence against \\(H_0\\)\n\n\np-value &gt; 0.1\neffectively no evidence against \\(H_0\\)\n\n\n\nThese are general guidelines. The strength of evidence depends on the context of the problem."
  },
  {
    "objectID": "slides/08-inference.html#hypothesis-test-for-beta_j-conclusion",
    "href": "slides/08-inference.html#hypothesis-test-for-beta_j-conclusion",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Conclusion",
    "text": "Hypothesis test for \\(\\beta_j\\): Conclusion\nThere are two parts to the conclusion\n\nMake a conclusion by comparing the p-value to a predetermined decision-making threshold called the significance level ( \\(\\alpha\\) level)\n\nIf \\(\\text{P-value} &lt; \\alpha\\): Reject \\(H_0\\)\nIf \\(\\text{P-value} \\geq \\alpha\\): Fail to reject \\(H_0\\)\n\nState the conclusion in the context of the data"
  },
  {
    "objectID": "slides/08-inference.html#recap",
    "href": "slides/08-inference.html#recap",
    "title": "Inference for regression",
    "section": "Recap",
    "text": "Recap\n\nIntroduced statistical inference in the context of regression\nDescribed the assumptions for regression\nConnected the distribution of residuals and inferential procedures\nConducted inference on a single coefficient\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/lab-04.html#goals",
    "href": "slides/lab-04.html#goals",
    "title": "Lab 04",
    "section": "Goals",
    "text": "Goals\n\nTeam feedback\nMid-semester survey\nLab 04: Maximum likelihood estimation (with Palmer penguins)"
  },
  {
    "objectID": "slides/lab-04.html#team-feedback",
    "href": "slides/lab-04.html#team-feedback",
    "title": "Lab 04",
    "section": "Team feedback",
    "text": "Team feedback\n\nPurpose: To reflect on the team’s collaboration and your contribution thus far\nYou should have received an email from Teammates with a link to the feedback from on October 21 around 11am\n\nPlease let your TA know if you do not see the email (check your spam folder first!)\n\nTeam feedback is due Thursday, October 24 at 11:59pm\nThis feedback will be graded for completion only (go towards the Participation grade)"
  },
  {
    "objectID": "slides/lab-04.html#mid-semester-feedback",
    "href": "slides/lab-04.html#mid-semester-feedback",
    "title": "Lab 04",
    "section": "Mid-semester feedback",
    "text": "Mid-semester feedback\n\nPurpose: To give the teaching team feedback on what is working well (or not as well) in helping you learn the course content\nThe feedback is anonymous and will not be graded\nIt will be available until Thursday, October 24 at 11:59pm.\n\nWe (the teaching team) appreciate you taking a few minutes to fill it out!\n🔗 duke.qualtrics.com/jfe/form/SV_244HYi8U8X85pgW"
  },
  {
    "objectID": "slides/lab-04.html#lab-04-maximum-likelihood-estimation",
    "href": "slides/lab-04.html#lab-04-maximum-likelihood-estimation",
    "title": "Lab 04",
    "section": "Lab 04: Maximum likelihood estimation",
    "text": "Lab 04: Maximum likelihood estimation\nThis lab focuses on\n\nusing linear regression and statistical inference to draw conclusions about penguins living in Palmer Archipelago in Antarctica.\nexploring maximum likelihood estimators and their connection to least-squares estimators\n\n🔗 https://sta221-fa24.netlify.app/labs/lab-04"
  },
  {
    "objectID": "slides/lab-04.html#reminder-tips-for-working-on-a-team",
    "href": "slides/lab-04.html#reminder-tips-for-working-on-a-team",
    "title": "Lab 04",
    "section": "Reminder: Tips for working on a team",
    "text": "Reminder: Tips for working on a team\n\nDo not pressure each other to finish early; use the time wisely to really learn the material and produce a quality report.\nThe labs are structured to help you learn the steps of a data analysis. Do not split up the lab among the team members; work on it together in its entirety.\nEveryone has something to contribute! Use the lab groups as an opportunity to share ideas and learn from each other.\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/lab-00.html#meet-your-tas",
    "href": "slides/lab-00.html#meet-your-tas",
    "title": "Welcome to STA 221 labs!",
    "section": "Meet your TAs!",
    "text": "Meet your TAs!"
  },
  {
    "objectID": "slides/lab-00.html#meet-each-other",
    "href": "slides/lab-00.html#meet-each-other",
    "title": "Welcome to STA 221 labs!",
    "section": "Meet each other!",
    "text": "Meet each other!\n\n\nGet into groups of 2 or 3\nIntroduce yourself: Name, year, major (or academic interest), a highlight from the summer\nIntroduce your partner to the class\n\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/lab-00.html#what-to-expect-in-lab",
    "href": "slides/lab-00.html#what-to-expect-in-lab",
    "title": "Welcome to STA 221 labs!",
    "section": "What to expect in lab",
    "text": "What to expect in lab\n\nIntroduction to the lab assignment (~ 5 - 10 minutes)\nReview lecture content, as needed (~ 10 minutes)\nWork on the lab assignment (individual for Lab 01 and in teams for the remainder of the semester)\nStarting with Lab 01, you will find the starter materials for lab in your repo in the course GitHub organization."
  },
  {
    "objectID": "slides/lab-00.html#todays-lab",
    "href": "slides/lab-00.html#todays-lab",
    "title": "Welcome to STA 221 labs!",
    "section": "Today’s lab",
    "text": "Today’s lab\nThe rest of the today’s lab is focused on setting up the computing for the course and completing the class survey. Click the link below for the Lab 00 instructions. The instructions are available on the course website.\n\n🔗 sta221-fa24.netlify.app/labs/lab-00.html\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#announcements",
    "href": "slides/04-slr-model-assessment-contd.html#announcements",
    "title": "SLR: Model assessment cont’d",
    "section": "Announcements",
    "text": "Announcements\n\nOffice hours start this week. See schedule on Overview page of the course website or on Canvas.\nLabs resume Monday, September 09"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#topics",
    "href": "slides/04-slr-model-assessment-contd.html#topics",
    "title": "SLR: Model assessment cont’d",
    "section": "Topics",
    "text": "Topics\n\nEvaluate models using RMSE and \\(R^2\\)\nUse analysis of variance to partition variability in the response variable"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#computing-set-up",
    "href": "slides/04-slr-model-assessment-contd.html#computing-set-up",
    "title": "SLR: Model assessment cont’d",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling (includes broom, yardstick, and other packages)\nlibrary(openintro)   # for the duke_forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(knitr)       # for pretty tables\nlibrary(patchwork)   # arrange plots\n\n# set default theme for ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#data-houses-in-duke-forest",
    "href": "slides/04-slr-model-assessment-contd.html#data-houses-in-duke-forest",
    "title": "SLR: Model assessment cont’d",
    "section": "Data: Houses in Duke Forest",
    "text": "Data: Houses in Duke Forest\n\n\n\nData on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020\nScraped from Zillow\nSource: openintro::duke_forest\n\n\n\n\nGoal: Use the area (in square feet) to understand variability in the price of houses in Duke Forest."
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#regression-model",
    "href": "slides/04-slr-model-assessment-contd.html#regression-model",
    "title": "SLR: Model assessment cont’d",
    "section": "Regression model",
    "text": "Regression model\n\nduke_forest_fit &lt;- lm(price ~ area, data = duke_forest)\n\ntidy(duke_forest_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.325\n53302.463\n2.188\n0.031\n\n\narea\n159.483\n18.171\n8.777\n0.000\n\n\n\n\n\n\n\nWe fit a model but is it any good?"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#two-statistics",
    "href": "slides/04-slr-model-assessment-contd.html#two-statistics",
    "title": "SLR: Model assessment cont’d",
    "section": "Two statistics",
    "text": "Two statistics\n\nRoot mean square error, RMSE: A measure of the average error (average difference between observed and predicted values of the outcome)\nR-squared, \\(R^2\\) : Percentage of variability in the outcome explained by the regression model (in the context of SLR, the predictor)"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#rmse",
    "href": "slides/04-slr-model-assessment-contd.html#rmse",
    "title": "SLR: Model assessment cont’d",
    "section": "RMSE",
    "text": "RMSE\n\\[\nRMSE = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n}} = \\sqrt{\\frac{\\sum_{i=1}^ne_i^2}{n}}\n\\]\n\n\nRanges between 0 (perfect predictor) and infinity (terrible predictor)\nSame units as the response variable\nThe value of RMSE is more useful for comparing across models than evaluating a single model (more on this when we get to regression with multiple predictors)"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#analysis-of-variance-anova",
    "href": "slides/04-slr-model-assessment-contd.html#analysis-of-variance-anova",
    "title": "SLR: Model assessment cont’d",
    "section": "ANOVA",
    "text": "ANOVA\nAnalysis of Variance (ANOVA): Technique to partition variability in \\(Y\\) by the sources of variability"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#total-variability-response",
    "href": "slides/04-slr-model-assessment-contd.html#total-variability-response",
    "title": "SLR: Model assessment cont’d",
    "section": "Total variability (Response)",
    "text": "Total variability (Response)\n\n\nGoal: Quantify how much variability in price is accounted for by the model (area) and how much accounted for by factors not included in the model."
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#partition-variability-in-price",
    "href": "slides/04-slr-model-assessment-contd.html#partition-variability-in-price",
    "title": "SLR: Model assessment cont’d",
    "section": "Partition variability in price",
    "text": "Partition variability in price\nFor now, let’s focus on two observations"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#total-variability-response-1",
    "href": "slides/04-slr-model-assessment-contd.html#total-variability-response-1",
    "title": "SLR: Model assessment cont’d",
    "section": "Total variability (Response)",
    "text": "Total variability (Response)\n\n\\[\\text{Sum of Squares Total (SST)} = \\sum_{i=1}^n(y_i - \\bar{y})^2 = (n-1)s_y^2\\]"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#explained-variability-model",
    "href": "slides/04-slr-model-assessment-contd.html#explained-variability-model",
    "title": "SLR: Model assessment cont’d",
    "section": "Explained variability (Model)",
    "text": "Explained variability (Model)\n\n\\[\\text{Sum of Squares Model (SSM)} = \\sum_{i = 1}^{n}(\\hat{y}_i - \\bar{y})^2\\]"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#unexplained-variability-residuals",
    "href": "slides/04-slr-model-assessment-contd.html#unexplained-variability-residuals",
    "title": "SLR: Model assessment cont’d",
    "section": "Unexplained variability (Residuals)",
    "text": "Unexplained variability (Residuals)\n\n\\[\\text{Sum of Squares Residuals (SSR)} = \\sum_{i = 1}^{n}(y_i - \\hat{y}_i)^2\\]"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#sum-of-squares",
    "href": "slides/04-slr-model-assessment-contd.html#sum-of-squares",
    "title": "SLR: Model assessment cont’d",
    "section": "Sum of Squares",
    "text": "Sum of Squares\n\n\\[\n\\begin{aligned}\n\\color{#407E99}{SST} \\hspace{5mm}&= &\\color{#993399}{SSM} &\\hspace{5mm} +  &\\color{#8BB174}{SSR} \\\\[10pt]\n\\color{#407E99}{\\sum_{i=1}^n(y_i - \\bar{y})^2} \\hspace{5mm}&= &\\color{#993399}{\\sum_{i = 1}^{n}(\\hat{y}_i - \\bar{y})^2} &\\hspace{5mm}+ &\\color{#8BB174}{\\sum_{i = 1}^{n}(y_i - \\hat{y}_i)^2}\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\nNote\n\n\nSee Sum of Squares for mathematical details showing \\(SST = SSM + SSR\\)."
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#r2",
    "href": "slides/04-slr-model-assessment-contd.html#r2",
    "title": "SLR: Model assessment cont’d",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\nThe coefficient of determination \\(R^2\\) is the proportion of variation in the response, \\(Y\\), that is explained by the regression model\n\n\\[\\large{R^2 = \\frac{SSM}{SST} = 1 - \\frac{SSR}{SST}}\\]\n\n\nWhat is the range of \\(R^2\\)? Does \\(R^2\\) have units?"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#interpreting-r2",
    "href": "slides/04-slr-model-assessment-contd.html#interpreting-r2",
    "title": "SLR: Model assessment cont’d",
    "section": "Interpreting $R^2$",
    "text": "Interpreting $R^2$\n\nQuestionSubmit\n\n\n\nSubmit your response to the following question on Ed Discussion.\n\nThe \\(R^2\\) of the model for price from area of houses in Duke Forest is 44.5%. Which of the following is the correct interpretation of this value?\n\nArea correctly predicts 44.5% of price for houses in Duke Forest.\n44.5% of the variability in price for houses in Duke Forest can be explained by area.\n44.5% of the variability in area for houses in Duke Forest can be explained by price.\n44.5% of the time price for houses in Duke Forest can be predicted by area.\n\nDo you think this model is useful for explaining variability in the price of Duke Forest houses?\n\n\n\n\n\n\n\n\n🔗 https://edstem.org/us/courses/62513/discussion/629888"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#augmented-data-frame",
    "href": "slides/04-slr-model-assessment-contd.html#augmented-data-frame",
    "title": "SLR: Model assessment cont’d",
    "section": "Augmented data frame",
    "text": "Augmented data frame\nUse the augment() function from the broom package (part of tidymodels) to add columns for predicted values, residuals, and other observation-level model statistics\n\n\nduke_forest_aug &lt;- augment(duke_forest_fit)\nduke_forest_aug\n\n# A tibble: 98 × 8\n     price  area  .fitted  .resid   .hat  .sigma   .cooksd .std.resid\n     &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 1520000  6040 1079931. 440069. 0.133  162605. 0.604         2.80  \n 2 1030000  4475  830340. 199660. 0.0435 168386. 0.0333        1.21  \n 3  420000  1745  394951.  25049. 0.0226 169664. 0.000260      0.150 \n 4  680000  2091  450132. 229868. 0.0157 168011. 0.0150        1.37  \n 5  428500  1772  399257.  29243. 0.0220 169657. 0.000345      0.175 \n 6  456000  1950  427645.  28355. 0.0182 169659. 0.000266      0.170 \n 7 1270000  3909  740072. 529928. 0.0250 160502. 0.130         3.18  \n 8  557450  2841  569744. -12294. 0.0102 169679. 0.0000277    -0.0732\n 9  697500  3924  742465. -44965. 0.0254 169620. 0.000948     -0.270 \n10  650000  2173  463209. 186791. 0.0145 168582. 0.00912       1.11  \n# ℹ 88 more rows"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#finding-rmse-in-r",
    "href": "slides/04-slr-model-assessment-contd.html#finding-rmse-in-r",
    "title": "SLR: Model assessment cont’d",
    "section": "Finding RMSE in R",
    "text": "Finding RMSE in R\nUse the rmse() function from the yardstick package (part of tidymodels)\n\nrmse(duke_forest_aug, truth = price, estimate = .fitted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard     167067.\n\n\n\n\nWhat does this value mean?"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#finding-r2-in-r",
    "href": "slides/04-slr-model-assessment-contd.html#finding-r2-in-r",
    "title": "SLR: Model assessment cont’d",
    "section": "Finding \\(R^2\\) in R",
    "text": "Finding \\(R^2\\) in R\nUse the rsq() function from the yardstick package (part of tidymodels)\n\nrsq(duke_forest_aug, truth = price, estimate = .fitted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rsq     standard       0.445\n\n\n\n\nAlternatively, use glance() to construct a single row summary of the model fit, including \\(R^2\\)\n\nglance(duke_forest_fit)$r.squared\n\n[1] 0.4451945"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#recap",
    "href": "slides/04-slr-model-assessment-contd.html#recap",
    "title": "SLR: Model assessment cont’d",
    "section": "Recap",
    "text": "Recap\n\nEvaluated models using RMSE and \\(R^2\\)\nUsed analysis of variance to partition variability in the response variable\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/lab-02.html#goals",
    "href": "slides/lab-02.html#goals",
    "title": "Lab 02",
    "section": "Goals",
    "text": "Goals\n\nLaTex in this course\nMeet your team!\nTeam agreement\nLab 02: Childcare costs"
  },
  {
    "objectID": "slides/lab-02.html#latex-in-this-class",
    "href": "slides/lab-02.html#latex-in-this-class",
    "title": "Lab 02",
    "section": "LaTex in this class",
    "text": "LaTex in this class\nFor this class you will need to be able to…\n\nProperly write mathematical symbols, e.g., \\(\\beta_1\\) not B1, \\(R^2\\) not R2\nWrite basic regression equations, e.g., \\(\\hat{y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2\\)\nWrite matrix equations: \\(\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\\)\nWrite hypotheses (we’ll start this next week), e.g., \\(H_0: \\beta = 0\\)\n\nYou are welcome to but not required to write math proofs using LaTex."
  },
  {
    "objectID": "slides/lab-02.html#writing-latex-from-ae-02",
    "href": "slides/lab-02.html#writing-latex-from-ae-02",
    "title": "Lab 02",
    "section": "Writing LaTex (from AE 02)",
    "text": "Writing LaTex (from AE 02)\nInline: Your mathematics will display within the line of text.\n\nUse $ to start and end your LaTex syntax. You can also use the menu: Insert -&gt; LaTex Math -&gt; Inline Math.\nExample: The text The simple linear regression model is $\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}$ produces\nThe simple linear regression model is \\(\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\\)"
  },
  {
    "objectID": "slides/lab-02.html#writing-latex-from-ae-02-1",
    "href": "slides/lab-02.html#writing-latex-from-ae-02-1",
    "title": "Lab 02",
    "section": "Writing LaTex (from AE 02)",
    "text": "Writing LaTex (from AE 02)\nDisplay: Your mathematics will display outside the line of text\n\nUse a $$ to start and end your LaTex syntax. You can also use the menu: Insert -&gt; LaTex Math -&gt; Display Math.\nExample: The text The estimated regression equation is $$\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}$$ produces\nThe estimated regression equation is\n\n\\[\n\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}\n\\]\n\n\n\n\n\n\nTip\n\n\nClick here for a quick reference of LaTex code."
  },
  {
    "objectID": "slides/lab-02.html#meet-your-team",
    "href": "slides/lab-02.html#meet-your-team",
    "title": "Lab 02",
    "section": "Meet your team!",
    "text": "Meet your team!\n\nClick here to find your team.\nSit with your team."
  },
  {
    "objectID": "slides/lab-02.html#team-name-agreement",
    "href": "slides/lab-02.html#team-name-agreement",
    "title": "Lab 02",
    "section": "Team name + agreement",
    "text": "Team name + agreement\n\nCome up with a team name. You can’t have the same name as another group in the class, so be creative!\n\nYour TA will get your team name by the end of lab.\n\nFill out the team agreement. The goals of the agreement are to…\n\nGain a common understanding of the team’s goals and expectations for collaboration\nMake a plan for team communication\nMake a plan for working outside of lab"
  },
  {
    "objectID": "slides/lab-02.html#team-workflow",
    "href": "slides/lab-02.html#team-workflow",
    "title": "Lab 02",
    "section": "Team workflow",
    "text": "Team workflow\n\nOnly one team member should type at a time. There are markers in today’s lab to help you determine whose turn it is to type.\n\nEvery team member should still be engaged in discussion for all questions, even if it’s not your turn type.\n\nDon’t forget to pull to get your teammates’ updates before making changes to the .qmd file.\n\n\n\n\n\n\nImportant\n\n\nOnly one submission per team on Gradescope. Read the submission instructions carefully!"
  },
  {
    "objectID": "slides/lab-02.html#team-workflow-in-action",
    "href": "slides/lab-02.html#team-workflow-in-action",
    "title": "Lab 02",
    "section": "Team workflow, in action",
    "text": "Team workflow, in action\n\nComplete the “Workflow: Using Git and GitHub as a team” section of the lab in your teams.\nRaise your hand if you have any questions about the workflow.\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/lab-02.html#tips-for-working-on-a-team",
    "href": "slides/lab-02.html#tips-for-working-on-a-team",
    "title": "Lab 02",
    "section": "Tips for working on a team",
    "text": "Tips for working on a team\n\nDo not pressure each other to finish early; use the time wisely to really learn the material and produce a quality report.\nThe labs are structured to help you learn the steps of a data analysis. Do not split up the lab among the team members; work on it together in its entirety.\nEveryone has something to contribute! Use the lab groups as an opportunity to share ideas and learn from each other."
  },
  {
    "objectID": "slides/lab-02.html#lab-02-childcare-costs",
    "href": "slides/lab-02.html#lab-02-childcare-costs",
    "title": "Lab 02",
    "section": "Lab 02: Childcare costs",
    "text": "Lab 02: Childcare costs\nToday’s lab focuses on using multiple linear regression (Week 03 content) to predict childcare costs for school-aged children in North Carolina.\n🔗 sta221-fa24.netlify.app/labs/lab-02.html\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "To access computing resources for the introductory data science courses offered by the Duke University Department of Statistical Science, go to the Duke Container Manager website, cmgr.oit.duke.edu/containers.\nIf this is your first time accessing the containers, click on reserve STA210 on the Reservations available menu on the right. You only need to do this once, and when you do, you’ll see this container moved to the My reservations menu on the left.\nNext, click on STA210 under My reservations to access the RStudio instance you’ll use for the course.",
    "crumbs": [
      "Computing",
      "Access"
    ]
  },
  {
    "objectID": "support.html",
    "href": "support.html",
    "title": "Course support",
    "section": "",
    "text": "We expect everyone will have questions at some point in the semester, so we want to make sure you can identify when that is and feel comfortable seeking help.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#lectures-and-labs",
    "href": "support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#office-hours",
    "href": "support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage you to take advantage of them!\nMake a pledge to stop by office hours at least once during the first three weeks of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of everyone’s office hours here.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#ed-discussion",
    "href": "support.html#ed-discussion",
    "title": "Course support",
    "section": "Ed Discussion",
    "text": "Ed Discussion\nOutside of class and office hours, any general questions about course content or assignments should be posted on Ed Discussion. There is a chance another student has already asked a similar question, so please check the other posts on Ed Discussion before adding a new question. If you know the answer to a question that is posted, I encourage you to respond!",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#email",
    "href": "support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nIf you have questions about personal matters that are not appropriate for the class discussion forum (e.g. illness, accommodations, etc.), you may me at maria.tackett@duke.edu. If you email me, please include “STA 221” in the subject line. Barring extenuating circumstances, I will respond to STA 221 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#academic-support",
    "href": "support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThere are times may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#mental-health-and-wellness",
    "href": "support.html#mental-health-and-wellness",
    "title": "Course support",
    "section": "Mental health and wellness",
    "text": "Mental health and wellness\n\nDukeReach: Provides comprehensive outreach services to identify and support students in managing all aspects of well being. If you have concerns about a student’s behavior or health visit the website for resources and assistance. Go to studentaffairs.duke.edu/dukereach\nCounseling and Psychological Services (CAPS): CAPS services include individual, group, and couples counseling services, health coaching, psychiatric services, and workshops and discussions. (919) 660-1000 or students.duke.edu/wellness/caps\nTimelyCare (formerly known as Blue Devils Care): An online platform that is a convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling. bluedevilscare.duke.edu",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#technology-accommodations",
    "href": "support.html#technology-accommodations",
    "title": "Course support",
    "section": "Technology accommodations",
    "text": "Technology accommodations\nHighly aided students who have limited access to computers may request loaner laptops through the DukeLIFE Technology Assistance Program. Please note that supplies are limited.\nNote that we will be using Duke’s computational resources in this course. These resources are freely available to you. As long as your computer can connect to the internet and open a browser window, you can perform the necessary computing for this course. All software we use is open-source and/or freely available.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#course-materials-costs",
    "href": "support.html#course-materials-costs",
    "title": "Course support",
    "section": "Course materials costs",
    "text": "Course materials costs\nThere are no costs associated with this course. All readings will come from freely available, open resources (open-source textbooks, journal articles, etc.).",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#assistance-with-zoom-or-canvas",
    "href": "support.html#assistance-with-zoom-or-canvas",
    "title": "Course support",
    "section": "Assistance with Zoom or Canvas",
    "text": "Assistance with Zoom or Canvas\nFor technical help with Canvas or Zoom, contact the Duke OIT Service Desk at oit.duke.edu/help. You can also access the self-service help documentation for Zoom here and for Canvas here.\nZoom will be used for online office hours as well as as a backup option should we need to hold the course online instead of in person.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "ae/ae-01-slr.html",
    "href": "ae/ae-01-slr.html",
    "title": "AE 01: Simple linear regression",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-01 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE.\n\nThis AE will not count towards your participation grade.\nlibrary(tidyverse)    # data wrangling and visualization\nlibrary(tidymodels)   # broom and yardstick package\nlibrary(openintro)    # duke_forest dataset\nlibrary(knitr)        # format output\nlibrary(scales)       # format plot axes\nlibrary(skimr)        # quickly calculate summary statistics"
  },
  {
    "objectID": "ae/ae-01-slr.html#exercise-1",
    "href": "ae/ae-01-slr.html#exercise-1",
    "title": "AE 01: Simple linear regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nWhat are 1 - 2 observations about the distribution of price?"
  },
  {
    "objectID": "ae/ae-01-slr.html#exercise-2",
    "href": "ae/ae-01-slr.html#exercise-2",
    "title": "AE 01: Simple linear regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nVisualize the distribution of area and calculate summary statistics.\n\n# add code here\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-01-slr.html#exercise-3",
    "href": "ae/ae-01-slr.html#exercise-3",
    "title": "AE 01: Simple linear regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nWhat are 1 - 2 observations about the distribution of area?"
  },
  {
    "objectID": "ae/ae-01-slr.html#exercise-4",
    "href": "ae/ae-01-slr.html#exercise-4",
    "title": "AE 01: Simple linear regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nFill in the code to visualize the relationship between price and area. What are 1 - 2 observations about the relationship between these two variables?\n\n\n\n\n\n\nImportant\n\n\n\nRemove #|eval: false after you have filled in the code!\n\n\n\nggplot(duke_forest, aes(x = ____, y = ____)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    x = \"_______\",\n    y = \"_________\",\n    title = \"Price and area of houses in Duke Forest\"\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "ae/ae-01-slr.html#exercise-5",
    "href": "ae/ae-01-slr.html#exercise-5",
    "title": "AE 01: Simple linear regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nYou want to fit a model of the form\n\\[\nprice = \\beta_0 + \\beta_1 ~ area + \\epsilon, \\hspace{5mm} \\epsilon \\sim N(0, \\sigma^2_\\epsilon)\n\\]\nWould a model of this form be a reasonable fit for the data? Why or why not?"
  },
  {
    "objectID": "ae/ae-01-slr.html#exercise-6",
    "href": "ae/ae-01-slr.html#exercise-6",
    "title": "AE 01: Simple linear regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nFit the linear model described in the previous exercise and neatly display the output.\nSee notes for example code.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-01-slr.html#exercise-7",
    "href": "ae/ae-01-slr.html#exercise-7",
    "title": "AE 01: Simple linear regression",
    "section": "Exercise 7",
    "text": "Exercise 7\n\nInterpret the slope in the context of the data.\nInterpret the slope in terms of area increasing by 100 sqft.\nWhich interpretation do you think is more meaningful in practice?"
  },
  {
    "objectID": "ae/ae-01-slr.html#exercise-8",
    "href": "ae/ae-01-slr.html#exercise-8",
    "title": "AE 01: Simple linear regression",
    "section": "Exercise 8",
    "text": "Exercise 8\nDoes it make sense to interpret the intercept? If so, interpret it in the context of the data. Otherwise, explain why not."
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html",
    "href": "ae/ae-04-exam-01-review.html",
    "title": "AE 04: Exam 01 Review",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-04 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE."
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#packages",
    "href": "ae/ae-04-exam-01-review.html#packages",
    "title": "AE 04: Exam 01 Review",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(patchwork)"
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#restaurant-tips",
    "href": "ae/ae-04-exam-01-review.html#restaurant-tips",
    "title": "AE 04: Exam 01 Review",
    "section": "Restaurant tips",
    "text": "Restaurant tips\nWhat factors are associated with the amount customers tip at a restaurant? To answer this question, we will use data collected in 2011 by a student at St. Olaf who worked at a local restaurant.1\nThe variables we’ll focus on for this analysis are\n\nTip: amount of the tip\nParty: number of people in the party\nAge: Age of the payer\n\nView the data set to see the remaining variables.\n\ntips &lt;- read_csv(\"data/tip-data.csv\")"
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#exploratory-data-analysis",
    "href": "ae/ae-04-exam-01-review.html#exploratory-data-analysis",
    "title": "AE 04: Exam 01 Review",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\np1 &lt;- ggplot(data = tips, aes(x = Tip)) + \n  geom_histogram(color = \"white\", binwidth = 2) +\n  labs(x = \"Tips ($)\",\n       title = \"Tips at local restaurant\")\n\np2 &lt;- ggplot(data = tips, aes(x = Party)) + \n  geom_histogram(color = \"white\") +\n  labs(x = \"Party\",\n       title = \"Number of diners in party\") +\n  xlim(c(0, 7))\n\np3 &lt;- ggplot(data = tips, aes(x = Age)) + \n  geom_bar(color = \"white\") +\n  labs(x = \"\",\n       title = \"Age of Payer\") \n\np1 / (p2 + p3)\n\n\n\n\n\n\n\n\n\np4 &lt;- ggplot(data = tips, aes(x = Party, y = Tip)) + \n  geom_jitter() + \n  labs(x = \"Number of diners in party\", \n       y = \"Tips ($)\",\n       title = \"Tips vs. Party\")\n\np5 &lt;- ggplot(data = tips, aes(x = Age, y = Tip)) + \n  geom_boxplot() + \n  labs(x = \"Age of payer\", \n       y = \"Tips ($)\",\n       title = \"Tips vs. Age\")\n\np4 + p5\n\n\n\n\n\n\n\n\nWe will use the number of diners in the party and age of the payer to understand variability in the tips."
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#exercise-1",
    "href": "ae/ae-04-exam-01-review.html#exercise-1",
    "title": "AE 04: Exam 01 Review",
    "section": "Exercise 1",
    "text": "Exercise 1\nWe will start with the main effects model.\n\nHow many indicator variables for Age can we create from the data?\nHow many indicator variables for Age will be in the regression model?\nAre the responses to parts a and b equal? If not, explain why not.\nWhich of the following is true for this model? Select all that apply.\n\nThe intercepts are the same for every level of Age.\nThe intercepts differ by Age.\nThe effect of Party is the same for every level of Age.\nThe effect of Party differs by Age."
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#exercise-2",
    "href": "ae/ae-04-exam-01-review.html#exercise-2",
    "title": "AE 04: Exam 01 Review",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nWhat is the dimension of the design matrix \\(\\mathbf{X}\\) for the main effects model?\nCalculate the coefficient estimates \\(\\hat{\\boldsymbol{\\beta}}\\) directly from the data.\nWrite the equation of the estimated regression model.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#exercise-3",
    "href": "ae/ae-04-exam-01-review.html#exercise-3",
    "title": "AE 04: Exam 01 Review",
    "section": "Exercise 3",
    "text": "Exercise 3\nCompute the following directly from the data:\n\nThe regression standard error \\(\\hat{\\sigma}_{\\epsilon}\\) . Interpret this value in the context of the data.\n\\(R^2\\). Interpret this value in the context of the data.\n\\(RMSE\\). Interpret this value in the context of the data.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#exercise-4",
    "href": "ae/ae-04-exam-01-review.html#exercise-4",
    "title": "AE 04: Exam 01 Review",
    "section": "Exercise 4",
    "text": "Exercise 4\nYou decide to add an interaction effect between Age and Party to the model and fit a model of the following form:\n\\[\n\\hat{Tip}_i = \\beta_0 + \\beta_1Party_i + \\beta_2SenCit_i + \\beta_3Yadult_i + \\beta_4Party_i \\times SenCit_i + \\beta_5 Party_i \\times Yadult_i\n\\]\n\nWhich of the following is true for this model? Select all that apply.\n\nThe intercepts are the same for every level of Age.\nThe intercepts differ by Age.\nThe effect of Party is the same for every level of Age.\nThe effect of Party differs by Age.\n\nBy how much does the intercept for tables with young adult payers differ from tables with middle age payers?\nWrite the equation of the model for tables in which the payer is a senior citizen.\nSuppose you wish to test the hypotheses: \\(H_0: \\beta_5 = 0 \\text{ vs. }H_a: \\beta_5 \\neq 0\\) . State what is being tested in terms of the effect of Party."
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#exercise-5",
    "href": "ae/ae-04-exam-01-review.html#exercise-5",
    "title": "AE 04: Exam 01 Review",
    "section": "Exercise 5",
    "text": "Exercise 5\nThe output for the model with the interaction term and 90% confidence intervals for the coefficients is shown below.\n\ntip_int_fit &lt;- lm(Tip ~ Party + Age + Party * Age, data = tips)\ntidy(tip_int_fit, conf.int = TRUE, conf.level = 0.9) |&gt;\n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.604\n0.504\n1.199\n0.232\n-0.229\n1.438\n\n\nParty\n1.924\n0.169\n11.359\n0.000\n1.644\n2.204\n\n\nAgeSenCit\n1.033\n0.784\n1.317\n0.190\n-0.265\n2.330\n\n\nAgeYadult\n-1.203\n0.928\n-1.297\n0.197\n-2.739\n0.332\n\n\nParty:AgeSenCit\n-0.259\n0.262\n-0.986\n0.325\n-0.692\n0.175\n\n\nParty:AgeYadult\n0.199\n0.504\n0.395\n0.693\n-0.635\n1.034\n\n\n\n\n\n\nWhat does 0.784, the standard error of AgeSenCit mean in the context of the data?\nWhat does 1.317, the test statistic for AgeSenCit mean in the context of the data?\nWhat does the p-value 0.190 mean in the context of the data?\nThe 90% confidence interval corresponds to what \\(\\alpha\\)-level?\nWhat is your conclusion about the effect of AgeSenCit?"
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#exercise-6",
    "href": "ae/ae-04-exam-01-review.html#exercise-6",
    "title": "AE 04: Exam 01 Review",
    "section": "Exercise 6",
    "text": "Exercise 6\nThe following are general questions about regression. They are not specific to the tips data set.\n\nWhat does it mean for an estimator to be the “least-squares” estimator?\nConsider the following derivation of \\(Var(\\hat{\\boldsymbol{\\beta}})\\) , the variance of the least-squares estimator:\n\\[\n\\begin{aligned}\nVar(\\hat{\\boldsymbol{\\beta}}) & = E[(\\hat{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta})(\\hat{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta})^T] \\\\\n& = E[((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\boldsymbol{\\epsilon})((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\boldsymbol{\\epsilon})^T] \\\\\n& = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^TE(\\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}^T)\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1} \\\\\n& = \\sigma^2(\\mathbf{X}^T\\mathbf{X})^{-1}\n\\end{aligned}\n\\]\n\nExplain how to go from Line 1 to Line 2.\n\nWhat assumptions are used to go from Line 3 to Line 4?\n\n\n\n\n\n\n\nSubmission\n\n\n\nTo submit the AE:\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your AE repo on GitHub. You’re done! 🎉"
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#footnotes",
    "href": "ae/ae-04-exam-01-review.html#footnotes",
    "title": "AE 04: Exam 01 Review",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDahlquist, Samantha, and Jin Dong. 2011. “The Effects of Credit Cards on Tipping.” Project for Statistics 212-Statistics for the Sciences, St. Olaf College.↩︎"
  },
  {
    "objectID": "prepare/prepare-sep19.html",
    "href": "prepare/prepare-sep19.html",
    "title": "Prepare for September 19 lecture",
    "section": "",
    "text": "📖 Read Inference for Simple Linear Regression:\n\nSections 5.1 - 5.3\nSection 5.6\nSection 5.8\nSection 5.9"
  },
  {
    "objectID": "prepare/prepare-aug29.html",
    "href": "prepare/prepare-aug29.html",
    "title": "Prepare for August 29 lecture",
    "section": "",
    "text": "📖 Read Simple Linear Regression\n✅ Complete Lab 00 tasks"
  },
  {
    "objectID": "prepare/prepare-sep3.html",
    "href": "prepare/prepare-sep3.html",
    "title": "Prepare for September 3 lecture",
    "section": "",
    "text": "📖 Read Section 4.7: Model Assessment\n✅ Go through R resource (optional)"
  },
  {
    "objectID": "hw/stats-experience.html",
    "href": "hw/stats-experience.html",
    "title": "Statistics Experience",
    "section": "",
    "text": "Important\n\n\n\nThis assignment is due on Tuesday, November 26 at 11:59pm on Gradescope.\nThe world of statistics and data science is vast and continually growing! The goal of the statistics experience assignments is to help you engage with the statistics and data science communities outside of the classroom.\nYou may submit the statistics experience assignment anytime between now and the deadline.\nEach experience has two parts:\n1️⃣ Have a statistics experience.\n2️⃣ Make a slide reflecting on your experience.\nYou must complete both parts to receive credit. The statistics experience will count as a homework grade.",
    "crumbs": [
      "Homework",
      "Statistics experience"
    ]
  },
  {
    "objectID": "hw/stats-experience.html#part-1-experience-statistics-outside-of-the-classroom",
    "href": "hw/stats-experience.html#part-1-experience-statistics-outside-of-the-classroom",
    "title": "Statistics Experience",
    "section": "Part 1: Experience statistics outside of the classroom",
    "text": "Part 1: Experience statistics outside of the classroom\nComplete an activity in one of the categories below. Under each category are suggested activities. You do not have to do one these suggested activities. You are welcome to find other activities as long as they are related to statistics/data science and they fit in one of the six categories. If there is an activity you’d like to do but you’re not sure if it qualifies for the statistics experience, just ask!\n\nCategory 1: Attend a talk or conference\nAttend an talk, panel, or conference related to statistics or data science. If you are attending a single talk or panel, it must be at least 30 minutes to count towards the statistics experience. The event can be in-person or online.\n\n\nCategory 2: Talk with a statistician/ data scientist\nTalk with someone who uses statistics in their daily work. This could include a professor, professional in industry, graduate student, etc.\n\n\nCategory 3: Listen to a podcast / watch video\nListen to a podcast or watch a video about statistics and data science. The podcast or video must be at least 30 minutes to count towards the statistics experience. A few suggestions are below:\n\nStats + Stories Podcast\nCausal Inference Podcast\nFiveThirtyEight Model Talk\nrstudio::conf talks\n\n2022 conference\n2021 conference\n2020 conference\n\n\nThis list is not exhaustive. You may listen to other podcasts or watch other statistics/data science videos not included on this list. Ask Professor Tackett if you are unsure whether a particular podcast or video will count towards the statistics experience.\n\n\nCategory 4: Participate in a data science competition or challenge\nParticipate in a statistics or data science competition. You can participate individually or with a team.\n\n\nCategory 5: Read a book on statistics/data science\nThere are a lot of books about statistics, data science, and related topics. A few suggestions are below. If you decide to read a book that isn’t on this list, ask Professor Tackett to make sure it counts toward the experience. Many of these books are available through Duke library.\n\nWeapons of Math Destruction by Cathy O’Neil\nHow Charts Lie: Getting Smarter about Visual Information by Alberto Cairo\nThe Theory that Would Not Die by Sharon Bertsch McGrayne\nThe Art of Statistics: How to learn from data by David Spiegelhalter\nThe Signal and the Noise: Why so many predictions fail - but some don’t by Nate Silver\nList of books about data science ethics\n\nThis list is not exhaustive.\n\n\nCategory 6: TidyTuesday\nYou may also participate in a TidyTuesday challenge. New data sets are announced on Monday afternoons.You can find more information about TidyTuesday and see the data in the TidyTuesday GitHub repo.\nA few guidelines:\n✅ Create a GitHub repo for your TidyTuesday submission. Your repo should include\n\nThe R Markdown file with all the code needed to reproduce your visualization.\nA README that includes an image of your final visualization and a short summary (~ 1 paragraph) about your visualization.\n\n✅ The visualization should include features or customization that are beyond what we’ve done in class .\n✅ Include the link to your GitHub repo in the slide summarizing your experience.\n\n\nCategory 7: CURV - connecting, uplifting, and recognizing voices\nCURV is a project by Dr. Jo Hardin at Pomona College to highlight statisticians and data scientists from groups who have been historically marginalized in the discipline. \n\n\n\n\n\n\nFor this statistics experience, you can contribute to the CURV data base. If there is a scholar you would like to suggest for the data base, submit your suggestion as an issue or pull request on the CURV GitHub repo and create a sample CURV page.\nA few guidelines:\n✅ Create a draft of the CURV page for your suggested scholar. For reference, click here for the CURV page for W.E.B. Du Bois. The page must be created in a Quarto document.\n\n\n\n\n\n\nTip\n\n\n\nYou can find the Quarto documents for current scholars in the data base in the CURV GitHub repo. You can use one of these as a template to format your page.\n\n\n✅ Make a pull request to the CURV GitHub repo to add the .qmd file for your suggested scholar, OR open an issue with a link to the .qmd file for your suggested scholar. You can ask a member of the teaching team if you have questions about how to do this.\n✅ Include the URL to your pull request or issue in your one-slide reflection.",
    "crumbs": [
      "Homework",
      "Statistics experience"
    ]
  },
  {
    "objectID": "hw/stats-experience.html#part-2-reflect-on-your-experience",
    "href": "hw/stats-experience.html#part-2-reflect-on-your-experience",
    "title": "Statistics Experience",
    "section": "Part 2: Reflect on your experience",
    "text": "Part 2: Reflect on your experience\nMake one slide summarizing and reflecting on your experience. Submit the slide as a PDF on Gradescope.\nInclude the following on your slide:\n\nDescription of the experience\n\nName and brief description of the event/podcast/competition/etc.\n\nSomething you learned\n\nWrite 2 - 4 sentences about something you learned or found particularly interesting or unexpected.\n\nConnection to STA 221\n\nWrite 2 - 4 sentences about how the experience connects to what we’ve done in the course.\n\nCitation or link to web page for event/competition/etc.\n\nNo citation needed if you do an interview.\n\n\nMake sure the slide includes the information mentioned above and is easily readable (i.e. use a reasonable font size!). Creativity on the experience and slide design is encouraged!",
    "crumbs": [
      "Homework",
      "Statistics experience"
    ]
  },
  {
    "objectID": "hw/stats-experience.html#submission",
    "href": "hw/stats-experience.html#submission",
    "title": "Statistics Experience",
    "section": "Submission",
    "text": "Submission\nSubmit the reflection as a PDF under the Statistics Experience assignment on Gradescope by Tuesday, November 26 at 11:59pm. Standard homework late policy applies.",
    "crumbs": [
      "Homework",
      "Statistics experience"
    ]
  },
  {
    "objectID": "hw/hw-03.html",
    "href": "hw/hw-03.html",
    "title": "HW 03",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-04.html",
    "href": "hw/hw-04.html",
    "title": "HW 04",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "labs/lab-06.html",
    "href": "labs/lab-06.html",
    "title": "Lab 06",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Labs",
      "Lab 06"
    ]
  },
  {
    "objectID": "labs/lab-05.html",
    "href": "labs/lab-05.html",
    "title": "Lab 05",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "labs/lab-00.html",
    "href": "labs/lab-00.html",
    "title": "Lab 00: Welcome + Getting Started",
    "section": "",
    "text": "Important\n\n\n\nPlease complete all today’s lab tasks before leaving lab today."
  },
  {
    "objectID": "labs/lab-00.html#rstudio",
    "href": "labs/lab-00.html#rstudio",
    "title": "Lab 00: Welcome + Getting Started",
    "section": "RStudio",
    "text": "RStudio\n\n\n\n\n\n\nNote\n\n\n\nR is the name of the programming language itself and RStudio is a convenient interface.\n\n\n\nReserve RStudio container\n\nGo to https://cmgr.oit.duke.edu/containers. You will log in using your NetID credentials.\nClick “Reserve STA 210” to reserve an RStudio container. Be sure you reserve the container labeled STA 210 to ensure you have the computing set up you need for the class.\n\nYou only need to reserve a container once per semester.\n\n\nOpen RStudio container\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA210 to log into the Docker container. You should now see the RStudio environment."
  },
  {
    "objectID": "labs/lab-00.html#git-and-github",
    "href": "labs/lab-00.html#git-and-github",
    "title": "Lab 00: Welcome + Getting Started",
    "section": "Git and GitHub",
    "text": "Git and GitHub\nIn addition to R and RStudio, we will use git and GitHub for version control and collaboration.\n\n\n\n\n\n\nNote\n\n\n\nGit is a version control system (like “Track Changes” features from Microsoft Word but more powerful) and GitHub is the home for your Git-based projects on the internet (like DropBox but much better).\n\n\n\nSign up for GitHub account\nYou will need a GitHub account to access the assignments, project, and in-class exercises for the course.\n\nIf you do not have a GitHub account, go to https://github.com and sign up for an account.\n\n\n\n\n\n\n\nTip\n\n\n\nClick here for advice on choosing a username.\n\n\n\nIf you already have a GitHub account, you can move on to the next step."
  },
  {
    "objectID": "labs/lab-00.html#connect-rstudio-and-github",
    "href": "labs/lab-00.html#connect-rstudio-and-github",
    "title": "Lab 00: Welcome + Getting Started",
    "section": "Connect RStudio and GitHub",
    "text": "Connect RStudio and GitHub\nNow that you have RStudio and a GitHub account, we will configure git so that RStudio and GitHub communicate with one another.\n\nSet up your SSH Key\nYou will authenticate GitHub using SSH. Below are an outline of the authentication steps; you are encouraged to follow along as your TA demonstrates the steps.\n\n\n\n\n\n\nNote\n\n\n\nYou only need to do this authentication process one time on a single system.\n\n\n\nStep 0: Open your STA 210 RStudio container.\nStep 1: Type credentials::ssh_setup_github() into the console on the bottom left of the RStudio environment.\nStep 2: R will ask “No SSH key found. Generate one now?” Click 1 for yes.\nStep 3: You will generate a key. It will begin with “ssh-rsa….” R will then ask “Would you like to open a browser now?” Click 1 for yes.\nStep 4: You may be asked to provide your username and password to log into GitHub. This would be the ones associated with your account that you set up. After entering this information, paste the key in and give it a name. You might name it in a way that indicates where the key will be used, e.g., sta221)\n\n\n\nConfigure git\nThe last thing we need to do is configure your git so that RStudio can communicate with GitHub. This requires two pieces of information: your name and email address.\nTo do so, you will use the use_git_config() function from the usethis package.\nType the following lines of code in the console in RStudio filling in your name and the email address associated with your GitHub account.\n\nusethis::use_git_config(\n  user.name = \"Your name\", \n  user.email = \"Email associated with your GitHub account\")\n\nFor example, mine would be\n\nusethis::use_git_config(\n  user.name = \"Maria Tackett\",\n  user.email = \"maria.tackett@duke.edu\")\n\nIt may look like nothing happened but you are now ready interact between GitHub and RStudio! We will begin working with RStudio and GitHub in lecture this week."
  },
  {
    "objectID": "labs/lab-03.html",
    "href": "labs/lab-03.html",
    "title": "Lab 03: Inference for regression",
    "section": "",
    "text": "Due date\n\n\n\nThis lab is due on Thursday, October 3 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your team’s GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-0",
    "href": "labs/lab-03.html#exercise-0",
    "title": "Lab 03: Inference for regression",
    "section": "Exercise 0",
    "text": "Exercise 0\nThere are two penguins in the data frame that do not have reported values for flipper length or body mass and thus will not be included in any analysis. Remove these observations from the data frame, so that we have an accurate count of the number of observations used for the analysis.\n\n\n\n\n\n\nNote\n\n\n\nExericse 0 is not graded.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-1",
    "href": "labs/lab-03.html#exercise-1",
    "title": "Lab 03: Inference for regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nLet’s begin by exploring the relationship between between flipper length and body mass, while accounting for species.\n\nVisualize the relationship between flipper length and body mass. Then describe the relationship.\nFit the main effects linear regression model (no interaction terms) between these three variables. Neatly display the results using three digits.\nInterpret the coefficient of flipper length in the context of the data.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-2",
    "href": "labs/lab-03.html#exercise-2",
    "title": "Lab 03: Inference for regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nNow let’s look at the assumptions underlying the regression model. Consider the linear regression model\n\\[ \\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}, \\quad \\boldsymbol{\\epsilon} \\sim \\mathcal{N}(0, \\sigma^2 \\mathbf{I}_n)  \\tag{1}\\]\nand let \\(\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}\\) be the least squares estimator. This model relies on four assumptions:\n\nLinearity: There is a linear relationship between the response and predictor variables.\nConstant Variance: The variability about the least squares line is generally constant.\nNormality: The distribution of the residuals is approximately normal.\nIndependence: The residuals are independent from one another.\n\nFor each condition, state the components of Equation 1 that are used to represent it.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-3",
    "href": "labs/lab-03.html#exercise-3",
    "title": "Lab 03: Inference for regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nWe can visually assess the linearity and constant variance assumptions by examining a scatterplot of the residuals versus fitted (predicted) values.\n\nCreate a scatterplot of the residuals (y-axis) versus fitted values (x-axis) for the model fit in Exercise 1.\nIf there is a linear relationship between the response and predictor variables, no discernible pattern should be present between fitted values and residuals. Does the linearity assumption appear to be satisfied?\nBriefly explain why no discernible pattern in the plot of residuals versus fitted values would indicate the linearity condition is satisfied.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-4",
    "href": "labs/lab-03.html#exercise-4",
    "title": "Lab 03: Inference for regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nIf errors have constant variance, we would expect the variability the of residuals about their mean to be approximately equal as the fitted value increases. Does the constant variance assumption appear to be satisfied? Briefly explain.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-5",
    "href": "labs/lab-03.html#exercise-5",
    "title": "Lab 03: Inference for regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nNext, let’s assess the assumptions about the distribution fo the residuals. Under the normality assumption, the residuals are expected to be normally distributed. Visualize the distribution of the residuals. Does the normality assumption appear to be satisfied? Briefly explain.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-6",
    "href": "labs/lab-03.html#exercise-6",
    "title": "Lab 03: Inference for regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nThe last assumption is that the residuals are independent of one another. Do you think it’s reasonable to assume the independence of residuals in this analysis? Briefly explain.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-7",
    "href": "labs/lab-03.html#exercise-7",
    "title": "Lab 03: Inference for regression",
    "section": "Exercise 7",
    "text": "Exercise 7\nNow let’s set up the test of whether the flipper length has a statistically significant effect on body mass in this model.\n\nWrite the null and alternative hypotheses in words and in mathematical notation.\nShow how the test statistic is computed specifically for this problem. In your response, show the code to obtain each relevant quantity in the formula for the test statistic using the matrix form of the model. Do not merely refer to the values in the lm output. You must show how each value is computed using the matrix / vector calculations.\nState the distribution of the test statistic under the null hypothesis for this problem.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-8",
    "href": "labs/lab-03.html#exercise-8",
    "title": "Lab 03: Inference for regression",
    "section": "Exercise 8",
    "text": "Exercise 8\nIn the regression output from Exercise 1, you are provided the \\(p\\)-value for the test of significance of each individual coefficient.\n\nInterpret the p-value for the coefficient of flipper length in the context of the data.\nThen, use the p-value and a decision-making threshold of \\(\\alpha = 0.05\\) to draw a conclusion about the relationship between flipper length and body mass in this model. State your conclusion in the context of the data.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-9",
    "href": "labs/lab-03.html#exercise-9",
    "title": "Lab 03: Inference for regression",
    "section": "Exercise 9",
    "text": "Exercise 9\nNow let’s construct the 95% confidence interval for the coefficient of flipper length.\n\nWrite the general formula for the 95% confidence interval.\nUse R functions to compute all the quantities you need for the interval, then compute the interval.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-10",
    "href": "labs/lab-03.html#exercise-10",
    "title": "Lab 03: Inference for regression",
    "section": "Exercise 10",
    "text": "Exercise 10\nInterpret the interval from the previous exercise in the context of the data.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-02.html",
    "href": "labs/lab-02.html",
    "title": "Lab 02: Multiple Linear Regression",
    "section": "",
    "text": "Due date\n\n\n\nThis lab is due on Thursday, September 19 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your team’s GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-1",
    "href": "labs/lab-02.html#exercise-1",
    "title": "Lab 02: Multiple Linear Regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nLet’s start with some exploratory data analysis. Visualize the distribution of the response variable mcsa and calculate summary statistics. Describe the distribution of this variable, including the shape, center, spread, and presence of potential outliers.\n\n\n\n\n\n\nImportant\n\n\n\nYou will use the childcare_train for all analysis in Exercises 1 - 7.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-2",
    "href": "labs/lab-02.html#exercise-2",
    "title": "Lab 02: Multiple Linear Regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nAs you can see from the data dictionary in the README of the data folder, there are many interesting potential variables that could be included in the model to predict median childcare cost for school-age children. Therefore, we will do some feature selection and feature design to choose potential predictors and construct new ones.\nAs a team, select four variables you want to use as predictors for the model. For each variable, state the variable name, definition, and a brief explanation about why your team hypothesizes this will be a relevant predictor of median childcare costs. The explanation may (but is not required to) include some short exploratory analysis.\n\nTeam Member 1: Knit, commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.\n\n\nAll other team members: Pull to get the updated documents from GitHub. Click on the .qmd file, and you should see the responses to exercises 1- 2.\nTeam Member 2: It’s your turn! Type the team’s response to exercises 3 - 4.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-3",
    "href": "labs/lab-02.html#exercise-3",
    "title": "Lab 02: Multiple Linear Regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nOnce we’ve identified potential predictor variables, we often need to transform some variables (e.g., change raw counts into proportions) or create new ones (e.g., create a categorical variable out of quantitative data) before fitting the regression model. This process is particularly useful when putting a variable in the model “as-is” may result in interpretation issues.\nChoose one of the variables selected in the previous exercise. For this variable,\n\nTransform the variable or use it to create a new variable. Be sure to save the variable to the childcare_train data frame.\nBriefly explain your reasoning for the transformation or new variable.\nUse visualizations and/or summary statistics to display the distribution of the original variable and the transformed / newly created variable. Note: This is to help ensure the transformation / new variable is what you expect.\n\nAn example using h_6to17_both_work is below. Note you cannot use this variable for your transformation / new variable.\n\n\n\n\n\n\nExample\n\n\n\nSay we believe that the amount of households with two working parents increases demand for childcare services, and hence their price. We have the column h_6to17_both_work encoding the number of such households per county. The raw population count differs across county, so having a larger value of h_6to17_both_work may reflect population size and not necessarily imply the type of such household is more prevalent in the county.\nA reasonable thing would be creating a variable encoding the proportion of households with both parents working. We could do this by creating a variable p_6to17_both_work:\n\np_6to17_both_work = h_6to17_both_work / households\n\nIn this case, we would then use p_6to17_both_work not h_6to17_both_work as a predictor in the model.\n\n\nYou may decide to transform and/or create multiple new variables; however, you will only be graded on the one of them.\n\n\n\n\n\n\nImportant\n\n\n\nYou will use the transformed / new variable (not the original variable) in the model!",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-4",
    "href": "labs/lab-02.html#exercise-4",
    "title": "Lab 02: Multiple Linear Regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nNow let’s conduct some bivariate exploratory data analysis. Visualize the relationship between the response variable and one of your predictor variables.\nWrite two distinct observations from the visualization.\n\nTeam Member 2: Knit, commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.\n\n\nAll other team members: Pull to get the updated documents from GitHub. Click on the .qmd file, and you should see the responses to exercises 3 - 4.\nTeam Member 3: It’s your turn! Type the team’s response to exercises 5 - 6.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-5",
    "href": "labs/lab-02.html#exercise-5",
    "title": "Lab 02: Multiple Linear Regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nUse the matrix form of the model to represent the regression model with the variables you selected and transformed/created in exercises 2 and 3 as the predictors. For each symbol in the model\n\ndescribe what it represents, and\nstate the dimensions.\n\nThe description and dimensions should be in the context of these data, not in general.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-6",
    "href": "labs/lab-02.html#exercise-6",
    "title": "Lab 02: Multiple Linear Regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nUse lm to fit the regression model you described in the previous exercise.\n\nNeatly display the model using a reasonable number of digits.\n\n\n\nInterpret the coefficient for one predictor in the model.\n\n\nTeam Member 3: Knit, commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.\n\n\nAll other team members: Pull to get the updated documents from GitHub. Click on the .qmd file, and you should see the responses to exercises 5 - 6.\nTeam Member 4: It’s your turn! Type the team’s response to exercises 7 - 9.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-7",
    "href": "labs/lab-02.html#exercise-7",
    "title": "Lab 02: Multiple Linear Regression",
    "section": "Exercise 7",
    "text": "Exercise 7\nNow let’s assess the fit of the model.\n\nHow much of the variability in the childcare costs is explained by your chosen predictor variables?\n\n\n\nBased on this, do you think the model explains a significant portion of the variability in childcare costs for school-age children in North Carolina? Briefly explain.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-8",
    "href": "labs/lab-02.html#exercise-8",
    "title": "Lab 02: Multiple Linear Regression",
    "section": "Exercise 8",
    "text": "Exercise 8\nNow let’s use the testing data to explore the predictive power of the model.\n\nAdd the variable you created in Exercise 3 to the testing data.\nThen, use the code below to compute the predicted childcare costs for the observations in the testing data using the predict function.\n\n\n# compute predictions\npred &lt;- predict(childcare_fit, childcare_test)\n\n# add predictions to testing data set\nchildcare_test &lt;- childcare_test |&gt;\n  mutate(pred = pred)",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-9",
    "href": "labs/lab-02.html#exercise-9",
    "title": "Lab 02: Multiple Linear Regression",
    "section": "Exercise 9",
    "text": "Exercise 9\n\nCompute the RMSE for the test set, and compare it to the standard deviation of the response variable mcsa.\n\n\n\nHow do these values compare?\nBased on this, how would assess the predictive power of the model?\n\n\nTeam Member 4: Render, commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and the rest of the team can see the completed lab.\n\n\nAll other team members: Pull to get the updated documents from GitHub. Click on the .qmd file, and you should see the team’s completed lab!",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-10",
    "href": "labs/lab-02.html#exercise-10",
    "title": "Lab 02: Multiple Linear Regression",
    "section": "Exercise 10",
    "text": "Exercise 10\nIf you haven’t already, make sure you have completed the team agreement (see the instructions in [Meet your team!]).",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#footnotes",
    "href": "labs/lab-02.html#footnotes",
    "title": "Lab 02: Multiple Linear Regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDon’t trust yourself to keep your hands off the keyboard? Put them in your pocket or cross your arms. No matter how silly it might feel, resist the urge to touch your keyboard until otherwise instructed!↩︎",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-01.html",
    "href": "labs/lab-01.html",
    "title": "Lab 01: Simple linear regression",
    "section": "",
    "text": "Due date\n\n\n\nThis lab is due on Thursday, September 12 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#learning-goals",
    "href": "labs/lab-01.html#learning-goals",
    "title": "Lab 01: Simple linear regression",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of the lab, you will…\n\nBe familiar with the workflow using RStudio and GitHub\nGain practice writing a reproducible report using Quarto\nPractice version control using GitHub\nBe able to produce visualizations and summary statistics to describe distributions\nBe able to fit, interpret, and evaluate simple linear regression models",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#clone-the-repo-start-new-rstudio-project",
    "href": "labs/lab-01.html#clone-the-repo-start-new-rstudio-project",
    "title": "Lab 01: Simple linear regression",
    "section": "Clone the repo & start new RStudio project",
    "text": "Clone the repo & start new RStudio project\n\nGo to the course organization at github.com/sta221-fa24 organization on GitHub.\nClick on the repo with the prefix lab-01-. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\n\nSee the Lab 00 instructions if you have not set up the SSH key or configured git.\n\nIn RStudio, go to File \\(\\rightarrow\\) New Project \\(\\rightarrow\\) Version Control \\(\\rightarrow\\) Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-01.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#r-and-r-studio",
    "href": "labs/lab-01.html#r-and-r-studio",
    "title": "Lab 01: Simple linear regression",
    "section": "R and R Studio",
    "text": "R and R Studio\nBelow are the components of the RStudio IDE.\n\n\n\n\n\nBelow are the components of an Quarto (.qmd) file.\n\n\n\n\n\n\nYAML\nThe top portion of your Quarto file (between the three dashed lines) is called YAML. It stands for “YAML Ain’t Markup Language”. It is a human friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\n\n\n\n\n\n\nImportant\n\n\n\nOpen the Quarto (.qmd) file in your project, change the author name to your name, and render the document. Examine the rendered document.\n\n\n\n\nCommitting changes\nNow, go to the Git pane in your RStudio instance. This will be in the top right hand corner in a separate tab.\nIf you have made changes to your Quarto (.qmd) file, you should see it listed here. Click on it to select it in this list and then click on Diff. This shows you the difference between the last committed state of the document and its current state including changes. You should see deletions in red and additions in green.\nIf you’re happy with these changes, we’ll prepare the changes to be pushed to your remote repository. First, stage your changes by checking the appropriate box on the files you want to prepare. Next, write a meaningful commit message (for instance, “updated author name”) in the Commit message box. Finally, click Commit. Note that every commit needs to have a commit message associated with it.\nYou don’t have to commit after every change, as this would get quite tedious. You should commit states that are meaningful to you for inspection, comparison, or restoration.\nIn the first few assignments we will tell you exactly when to commit and in some cases, what commit message to use. As the semester progresses we will let you make these decisions.\nNow let’s make sure all the changes went to GitHub. Go to your GitHub repo and refresh the page. You should see your commit message next to the updated files. If you see this, all your changes are on GitHub and you’re good to go!\n\n\nPush changes\nNow that you have made an update and committed this change, it’s time to push these changes to your repo on GitHub.\nIn order to push your changes to GitHub, you must have staged your commit to be pushed. click on Push.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-1",
    "href": "labs/lab-01.html#exercise-1",
    "title": "Lab 01: Simple linear regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nWe begin with some exploratory data analysis (EDA). As a first step, let’s get a quick summary look at the data using the glimpse function.\nViewing a summary of the data is a useful starting point for analysis, especially if there are a large number of observations or variables.\n\nglimpse(parks)\n\n\nHow many observations are in the parks data frame?\nWhat information is provided in the data about the time and location of the measurements?",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-2",
    "href": "labs/lab-01.html#exercise-2",
    "title": "Lab 01: Simple linear regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nThe predictor variable for this analysis, spend_per_resident_data, is quantitative; however, from the glimpse of the data in Exercise 1, we see its data type is chr (character) in R. We would expect it to be dbl (double), the data type for numeric data.\nWhy did spend_per_resident_data get read by R as a character data type instead of a double? Be specific.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-3",
    "href": "labs/lab-01.html#exercise-3",
    "title": "Lab 01: Simple linear regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nUse the code below to transform spend_per_resident_data , so that it is correctly treated as quantitative data in R. Write a brief explanation of what each numbered line of code does.\n\n1parks &lt;-\n  parks |&gt;  \n  mutate(spend_per_resident_data = \n2           str_replace(spend_per_resident_data,\"\\\\$\", \"\")) |&gt;\n  mutate(spend_per_resident_data = \n3           as.numeric(spend_per_resident_data))\n\n\n1\n\n______\n\n2\n\n______\n\n3\n\n______\n\n\n\n\n\nThis is a good place to render, commit, and push changes to your lab-01 repo on GitHub. Write an informative commit message (e.g., “Completed exercises 1 - 3”), and push every file to GitHub by clicking the checkbox next to each file in the Git pane. After you push the changes, the Git pane in RStudio should be empty.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-4",
    "href": "labs/lab-01.html#exercise-4",
    "title": "Lab 01: Simple linear regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nNow we’ll examine the distributions of the variables of interest.\n\nMake a histogram of spend_per_resident_data and calculate summary statistics for this variable.\nComment on the features of the distribution of this variable by describing the shape, center, spread, and presence of potential outliers.\n\n\n\n\n\n\n\nTip\n\n\n\nWhen performing data visualization, make sure that all your plots have clear and informative titles and axis labels. When investigating more complex relationships with many variables, this simple tip will save you and your readers a lot of time and confusion.\n\nSee AE 01 for example code.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-5",
    "href": "labs/lab-01.html#exercise-5",
    "title": "Lab 01: Simple linear regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nNext let’s explore the response variable, pct_near_park_points. Visualize the distribution of the variable and calculate summary statistics. Describe the distribution pct_near_park_points.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-6",
    "href": "labs/lab-01.html#exercise-6",
    "title": "Lab 01: Simple linear regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nNow let’s use bivariate exploratory data analysis to look at the relationship between spend_per_resident_data and pct_near_park_points.\n\nMake a scatterplot to visualize the relationship between the two variables.\nDoes there seem to be a relationship between spending and park access? If so, what is the shape and direction of the relationship?\n\n\nThis is a another good place to render, commit, and push changes to your lab-01 repo on GitHub. Write an informative commit message (e.g. “Completed exercises 4 - 6”), and push every file to GitHub by clicking the checkbox next to each file in the Git pane. After you push the changes, the Git pane in RStudio should be empty.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-7",
    "href": "labs/lab-01.html#exercise-7",
    "title": "Lab 01: Simple linear regression",
    "section": "Exercise 7",
    "text": "Exercise 7\nWe have seen the mathematical formulation for simple linear regression. In particular, given a response variable \\(Y\\) and predictor variable \\(X\\), the simple linear regression model is \\[Y = \\beta_0 + \\beta_1 X + \\epsilon, \\quad \\epsilon \\sim N(0, \\sigma_\\epsilon^2)\\]\nfor some unknown regression coefficients for slope and intercept\\((\\beta_0, \\beta_1)\\). This means that the expected value of each observation lies on the regression line\n\\[ E(Y|X) = \\beta_0 + \\beta_1 X\\]\nAnswer the following questions about simple linear regression. Your response should be in general terms about simple linear, not be specific to the parks data.\n\nWhat does \\(E(Y|X) = \\beta_0 + \\beta_1X\\) mean in terms of a given value of \\(X\\)?\nWhat is the interpretation of the coefficients \\(\\beta_0\\) and \\(\\beta_1\\) in terms of the expected value of \\(Y\\)?",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-8",
    "href": "labs/lab-01.html#exercise-8",
    "title": "Lab 01: Simple linear regression",
    "section": "Exercise 8",
    "text": "Exercise 8\nIn class we’ve seen how matrices can be used to represent the simple linear model from the previous exercise. In particular\n\\[\n\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon}\n\\]\nRecall that the goal is to fit a model that uses spend_per_resident_data to explain variability in park_near_pct_points.Estimate regression coefficients \\(\\hat{\\boldsymbol{\\beta}}\\) for the model using the matrix representation. Show any work and/or code used to get the answer.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-9",
    "href": "labs/lab-01.html#exercise-9",
    "title": "Lab 01: Simple linear regression",
    "section": "Exercise 9",
    "text": "Exercise 9\nNow let’s fit the model using the lm() function in R.\n\nFit the model and neatly display the output using 4 digits.\nInterpret the slope in the context of the data.\nDoes it make sense of the interpret the intercept? If so, interpret the intercept in the context of the data. Otherwise, explain why not.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-10",
    "href": "labs/lab-01.html#exercise-10",
    "title": "Lab 01: Simple linear regression",
    "section": "Exercise 10",
    "text": "Exercise 10\nDo you think that city expenditure on residents is a useful predictor of park access? Briefly explain your response, reporting any statistics used to make your assessment.\n\nYou’re done and ready to submit your work! render, commit, and push all remaining changes. You can use the commit message “Done with Lab 1!”, and make sure you have pushed all the files to GitHub (your Git pane in RStudio should be empty) and that all documents are updated in your repo on GitHub. The PDF document you submit to Gradescope should be identical to the one in your GitHub repo.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-04.html",
    "href": "labs/lab-04.html",
    "title": "Lab 04: Maximum likelihood estimation",
    "section": "",
    "text": "Due date\n\n\n\nThis lab is due on Thursday, October 24 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your team’s GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-1",
    "href": "labs/lab-04.html#exercise-1",
    "title": "Lab 04: Maximum likelihood estimation",
    "section": "Exercise 1",
    "text": "Exercise 1\nWe’ll start with exploratory data analysis focused on the relationship between the response and predictor variables.\n\nVisualize the relationship between the response variable bill_depth_mm and predictor bill_length_mm .\nNow, visualize the relationship between bill_depth_mm and bill_length_mm by species. Use geom_smooth(method = \"lm\", se = FALSE) to add lines and more clearly visualize the relationship for each species.\nBased on these visualizations, why is it important to include species when in the model of the relationship between bill depth and length? Briefly explain.\nBased on these visualizations, would you include an interaction term between the two predictors? Briefly explain?",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-2",
    "href": "labs/lab-04.html#exercise-2",
    "title": "Lab 04: Maximum likelihood estimation",
    "section": "Exercise 2",
    "text": "Exercise 2\nWe will fit the main effects model using bill length and species to understand variability in the bill depth.\n\nWrite the form of the statistical (population-level) model in matrix form.\nWrite the dimensions for \\(\\mathbf{y}, \\mathbf{X}, \\boldsymbol{\\beta}, \\boldsymbol{\\epsilon}\\) specific for this problem.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-3",
    "href": "labs/lab-04.html#exercise-3",
    "title": "Lab 04: Maximum likelihood estimation",
    "section": "Exercise 3",
    "text": "Exercise 3\nConsider the regression model described in Exercise 2.\n\nWrite the likelihood function \\(L(\\boldsymbol{\\beta}, \\sigma^2_{\\epsilon} | \\mathbf{y}, \\mathbf{X})\\) in matrix form.\nDescribe how each of the four model assumptions is necessary for the form of the likelihood function.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-4",
    "href": "labs/lab-04.html#exercise-4",
    "title": "Lab 04: Maximum likelihood estimation",
    "section": "Exercise 4",
    "text": "Exercise 4\nBriefly explain how the process of finding the maximum likelihood estimators for the likelihood function in Exercise 3 is related to the process of finding the least-squares estimators for the model in Exercise 2.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-5",
    "href": "labs/lab-04.html#exercise-5",
    "title": "Lab 04: Maximum likelihood estimation",
    "section": "Exercise 5",
    "text": "Exercise 5\nFor the next few exercises, we will compare the results of the maximum likelihood and least-squares procedures.\n\nFit the least-squares regression model described in Exercise 2. Neatly display the results using three digits.\nDescribe the estimated effect of bill length on bill depth in the context of the data.\nDescribe the estimated effect of species on bill depth in the context of the data. Include discussion about whether there is statistical evidence of a difference between species.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-6",
    "href": "labs/lab-04.html#exercise-6",
    "title": "Lab 04: Maximum likelihood estimation",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nUse matrix/vector operations to compute the maximum likelihood estimators \\(\\tilde{\\beta}\\) for the model in Exercise 2.\nHow do these estimators compare to the least-squares estimators in the previous exercise?",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-7",
    "href": "labs/lab-04.html#exercise-7",
    "title": "Lab 04: Maximum likelihood estimation",
    "section": "Exercise 7",
    "text": "Exercise 7\nThe maximum likelihood estimation procedure also produces an estimator for the variance about the regression line, \\(\\sigma^2_\\epsilon\\), which we can write as\n\\[\n\\tilde{\\sigma}^2_{\\epsilon} = \\frac{1}{n} \\mathbf{e}^T\\mathbf{e}\n\\]\nWe know that the maximum likelihood estimator and least-squares estimator for \\(\\sigma^2_{\\epsilon}\\) are not equal. Additionally, the least-squares estimator \\(\\hat{\\sigma}^2_{\\epsilon}\\) is unbiased. We want to find a scaling factor \\(c\\) such that the maximum likelihood estimator is unbiased.\nUsing the data and regression estimates for this analysis, compute both the maximum likelihood and least-squares estimators for \\(\\sigma_{\\epsilon}^2\\), and then find \\(c\\) by solving the equation \\[ \\hat\\sigma^2_{\\epsilon} = c \\cdot \\tilde\\sigma^2_{\\epsilon} \\]You can do this last step either computationally or algebraically.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-8",
    "href": "labs/lab-04.html#exercise-8",
    "title": "Lab 04: Maximum likelihood estimation",
    "section": "Exercise 8",
    "text": "Exercise 8\nNow we will look into the last property of the maximum likelihood estimator for \\(\\boldsymbol{\\beta}\\), and thus of least-squares estimator - asymptotic normality.\nIn words, this property says that, when the number of samples \\(n\\) is large compared to the number of predictors \\(p\\), the maximum likelihood estimator \\(\\tilde{\\boldsymbol\\beta}\\) follows a (multivariate) normal distribution \\(N\\big(\\boldsymbol\\beta, \\sigma_\\epsilon^2 (\\mathbf{X}^T\\mathbf{X})^{-1}\\big)\\). Let’s use this to construct an approximate confidence interval for \\(\\beta_j\\), the coefficient for speciesChinstrap.\n\nUse \\(\\tilde{\\sigma}^2_{\\epsilon}\\), the maximum likelihood estimator, to compute the approximate confidence interval for \\(\\beta_j\\) . The approximate 95% confidence interval may be computed as\n\n\\[\n\\tilde{\\beta}_j\\pm 2 \\times SE(\\tilde{\\beta}_j)\n\\]\n\nThen interpret this interval in the context of the data.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-9",
    "href": "labs/lab-04.html#exercise-9",
    "title": "Lab 04: Maximum likelihood estimation",
    "section": "Exercise 9",
    "text": "Exercise 9\n\nCompute the exact (based on the \\(t\\)-distribution) confidence interval for \\(\\beta_j\\), the coefficient of speciesChinstrap.\nCompare the center and width of the this exact interval with the one you computed in Exercise 8. Do they differ? By how much? Which one is wider, indicating more uncertainty?",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-10",
    "href": "labs/lab-04.html#exercise-10",
    "title": "Lab 04: Maximum likelihood estimation",
    "section": "Exercise 10",
    "text": "Exercise 10\nTo wrap up, we have seen that both the OLS and the maximum likelihood procedures for linear regression produce the same coefficient estimates, but lead to different estimators for the variance \\(\\sigma_\\epsilon^2\\) and allow for different types of uncertainty quantification.\nBased on the work in this lab, do you think performing inference based on either method would have changed your conclusions about the difference (or lack thereof) in the relationship between bill depth and species? Briefly explain.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-07.html",
    "href": "labs/lab-07.html",
    "title": "Lab 07",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Labs",
      "Lab 07"
    ]
  },
  {
    "objectID": "overview.html",
    "href": "overview.html",
    "title": "STA 221 - Regression Analysis: Theory and Applications",
    "section": "",
    "text": "In STA 221, students will learn how linear and logistic regression models are used to explore multivariable relationships, apply these methods to answer relevant and engaging questions using a data-driven approach, and learn the mathematical underpinnings of the models. Students will develop computing skills to implement a reproducible data analysis workflow and gain experience communicating statistical results. Throughout the semester, students will work on a team project where they will develop a research question, answer it using methods learned in the course, and share results through a written report and presentation.\nTopics include applications of linear and logistic regression, analysis of variance, model diagnostics, and model selection. Regression parameter estimation via maximum likelihood least squares will also be discussed. Students will gain experience using the computing tools R and GitHub to analyze real-world data from a variety of fields.\n\n\nEither any STA 100-level course or STA 230, 231, or 240L and MATH 216, 218, or 221. The recommended co-requisite is STA 230, 231, or 240L. Interested students with different backgrounds should seek instructor consent.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "overview.html#pre-requisites",
    "href": "overview.html#pre-requisites",
    "title": "STA 221 - Regression Analysis: Theory and Applications",
    "section": "",
    "text": "Either any STA 100-level course or STA 230, 231, or 240L and MATH 216, 218, or 221. The recommended co-requisite is STA 230, 231, or 240L. Interested students with different backgrounds should seek instructor consent.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "overview.html#teaching-assistants",
    "href": "overview.html#teaching-assistants",
    "title": "STA 221 - Regression Analysis: Theory and Applications",
    "section": "Teaching assistants",
    "text": "Teaching assistants\n\n\n\n\n\n\n\n\n\nName\nRole\nOffice Hours\n\n\n\nKat Husar\nHead TA\nLab 02L leader\nTue 1:30 - 3:30pm, Old Chem 220\n\n\n\nJon Campbell\nLab 01L leader\nTue & Thu 9 - 10am, Old Chem 025\n\n\n\nIshrit Gupta\nLab 01L helper\nFri 1- 3pm, Old Chem 203B\n\n\n\nAlan Wang\nLab 02L helper\nMon & Wed 10 - 11am, Old Chem 203B",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "hw/hw-01.html",
    "href": "hw/hw-01.html",
    "title": "HW 01: Simple linear regression",
    "section": "",
    "text": "Due date\n\n\n\nThis assignment is due on Thursday, September 19 at 11:59pm.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#instructions",
    "href": "hw/hw-01.html#instructions",
    "title": "HW 01: Simple linear regression",
    "section": "Instructions",
    "text": "Instructions\nThe conceptual exercises are focused on explaining concepts and showing results mathematically. Show your work for each question.\n\nYou may write the answers and associated work for conceptual exercises by hand or type them in your Quarto document.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-1",
    "href": "hw/hw-01.html#exercise-1",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 1",
    "text": "Exercise 1\na. Show that the hat matrix \\(\\mathbf{H}\\) is symmetric \\((\\mathbf{H}^T = \\mathbf{H})\\) and idempotent \\((\\mathbf{H}^2 = \\mathbf{H})\\).\nb. Show that \\((\\mathbf{I} - \\mathbf{H})\\) is symmetric and idempotent.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-2",
    "href": "hw/hw-01.html#exercise-2",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nLet \\(\\mathbf{x}\\) be a \\(k \\times 1\\) vector and \\(\\mathbf{A}\\) be a symmetric \\(k \\times k\\) matrix, such that \\(\\mathbf{A}\\) is not a function of \\(\\mathbf{x}\\).\nShow that the gradient of \\(\\boldsymbol{x}^T\\mathbf{A}\\mathbf{x}\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x} \\hspace{1mm} \\mathbf{x}^T\\mathbf{A}\\mathbf{x} = 2\\mathbf{A}\\mathbf{x}\n\\]\n(Proposition 2 from class)",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-3",
    "href": "hw/hw-01.html#exercise-3",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nIn class we used the sum of squared residuals (SSR) to estimate the regression coefficients, \\(\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y}\\) . To show this is the least squares estimate, we now need to show that we have, in fact, found the estimate of \\(\\boldsymbol{\\beta}\\) that minimizes the SSR (rather than maximize).\nIf the Hessian matrix \\(\\nabla_{\\boldsymbol{\\beta}}^2 SSR\\) is positive definite, then we know we have found the \\(\\hat{\\boldsymbol{\\beta}}\\) that minimizes SSR, i.e., the least squares estimator. Additionally, we have the following proposition:",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#proposition",
    "href": "hw/hw-01.html#proposition",
    "title": "HW 01: Simple linear regression",
    "section": "Proposition",
    "text": "Proposition\nA matrix \\(\\mathbf{A}\\) is positive definite if \\(\\mathbf{z}^T\\mathbf{A}\\mathbf{z} &gt; 0\\) , given \\(\\mathbf{z}\\) is a non-zero vector.\nShow that \\(\\nabla_{\\boldsymbol{\\beta}}^2 SSR\\) is positive definite.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-4",
    "href": "hw/hw-01.html#exercise-4",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nProve that the maximum value of \\(R^2\\) must be less than 1 if the data set contains observations such that there are different observed values of the response for the same value of the predictor (e.g., the dataset contains observations \\((x_i, y_i)\\) and \\((x_j, y_j)\\) such that \\(x_i = x_j\\) and \\(y_i \\neq y_j\\) ).",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#instructions-1",
    "href": "hw/hw-01.html#instructions-1",
    "title": "HW 01: Simple linear regression",
    "section": "Instructions",
    "text": "Instructions\nThe applied exercises are focused on applying the concepts to analyze data.\nAll work for the applied exercises must be typed in your Quarto document following a reproducible workflow.\nWrite all narrative using complete sentences and include informative axis labels / titles on visualizations.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#data",
    "href": "hw/hw-01.html#data",
    "title": "HW 01: Simple linear regression",
    "section": "Data",
    "text": "Data\nThe datasets wi-icecover.csv and wi-air-temperature.csv contain information about ice cover and air temperature, respectively, at Lake Monona and Lake Mendota (both in Madison, Wisonsin) for days in 1886 through 2019. The data were obtained from the ntl_icecover and ntl_airtemp data frames in the lterdatasampler R package. They were originally collected by the US Long Term Ecological Research program (LTER) Network.\n\nicecover &lt;- read_csv(\"data/wi-icecover.csv\")\nairtemp &lt;- read_csv(\"data/wi-air-temperature.csv\")\n\nThe analysis will focus on the following variables:\n\nyear: year of observation\nlakeid: lake name\nice_duration: number of days between the freeze and ice breakup dates of each lake\nair_temp_avg: yearly average air temperature in Madison, WI (degrees Celsius)",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#analysis-goal",
    "href": "hw/hw-01.html#analysis-goal",
    "title": "HW 01: Simple linear regression",
    "section": "Analysis goal",
    "text": "Analysis goal\nThe goal of this analysis is to use linear regression explain variability in ice duration for lakes in Madison, WI based on air temperature. Because ice cover is impacted by various environmental factors, researchers are interested in examining the association between these two factors to better understand the changing climate.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-5",
    "href": "hw/hw-01.html#exercise-5",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nLet’s start by looking at the response variable ice_duration.\n\nCreate side-by-side boxplots to visualize the distribution of ice_duration for each lake.\nVisualize the distribution of ice duration over time for each lake.\nThere are separate measurements for each lake in the icecover data frame. In this analysis, we will combine the data from both lakes and use the average ice duration each year.\nEvaluate the analysis choice to use the average per year rather than the individual lake measurements. Some things to consider in your evaluation: Does the average accurately reflects the ice duration for lakes in Madison, WI for that year? Will there be information loss? How might that impact (or not) the analysis conclusions? Etc.\n\n\n\n\n\n\n\nTip\n\n\n\nSee the ggplot2 reference for example code and plots.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-6",
    "href": "hw/hw-01.html#exercise-6",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nNext, let’s combine the ice duration and air temperature data into a single analysis data frame.\n\nFill in the code below to create a new data frame, icecover_avg, of the average ice duration by year.\nThen join icecover_avg and airtemp to create a new data frame. The new data frame should have 134 observations.\n\nicecover_avg &lt;- icecover |&gt;\n  group_by(_____) |&gt;\n  summarise(_____) |&gt;\n  ungroup()\n\n\n\n\n\n\n\n\nImportant\n\n\n\nYou will use the new data frame with average ice duration and average air temperature for the remainder of the assignment.\n\n\n\nVisualize the relationship between the air temperature and average ice duration. Do you think a linear model would be a good fit to capture the relationship between the two variables? \n\n\nNow is a good time to render your document again if you haven’t done so recently and commit (with a meaningful commit message) and push all updates.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-7",
    "href": "hw/hw-01.html#exercise-7",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 7",
    "text": "Exercise 7\nWe will fit a model using the average air temperature to explain variability in ice duration that takes the form\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n\\]\n\nState the dimensions of \\(\\mathbf{y}\\), \\(\\mathbf{X}\\), \\(\\boldsymbol{\\beta}\\), \\(\\boldsymbol{\\epsilon}\\) for this analysis. Your answer should have exact values given this data set.\nFind the estimated regression coefficients \\(\\hat{\\boldsymbol{\\beta}}\\) using the matrix representation of the model. Show the code used to get the answer.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-8",
    "href": "hw/hw-01.html#exercise-8",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 8",
    "text": "Exercise 8\n\nFit the model from the previous exercise using the lm function. Neatly display the results using 3 digits.\nInterpret the slope in the context of the data.\n\n\nNow is a good time to render your document again if you haven’t done so recently and commit (with a meaningful commit message) and push all updates.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-9",
    "href": "hw/hw-01.html#exercise-9",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 9",
    "text": "Exercise 9\n\nCalculate \\(R^2\\) for the model in the previous exercise and interpret it in the context of the data.\nBriefly comment on the model fit based on \\(R^2\\).",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-10",
    "href": "hw/hw-01.html#exercise-10",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 10",
    "text": "Exercise 10\nYou are asked to use a reproducible workflow for all of your work in the class, and the goal of this question to is better understand potential real-world implications of doing (or not) so. Below are some real-life examples in which having a non-reproducible workflow resulted in errors that impacted research or public records.\n\nSource: Ostblom and Timbers (2022)\n\n\nReproducibility error\nConsequence\nSource(s)\n\n\n\n\nLimitations in Excel data formats\nLoss of 16,000 COVID case records in the UK\n(Kelion 2020)\n\n\nAutomatic formatting in Excel\nImportant genes disregarded in scientific studies\n(Ziemann, Eren, and El-Osta 2016)\n\n\nDeletion of a cell caused rows to shift\nMix-up of which patient group received the treatment\n(Wallensteen et al. 2018)\n\n\nUsing binary instead of explanatory labels\nMix-up of the intervention with the control group\n(Aboumatar and Wise 2019)\n\n\nUsing the same notation for missing data and zero values\nPaper retraction\n(Whitehouse et al. 2021)\n\n\nIncorrectly copying data in a spreadsheet\nDelay in the opening of a hospital\n(Picken 2020)\n\n\n\nChoose one of the scenarios from the table and read the linked article discussing what went wrong. Then,\n\nBriefly describe what went wrong, i.e., what part of the process of was not reproducible and what error or impact that had.\nDescribe one way the researchers could have made the process reproducible.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-02.html",
    "href": "hw/hw-02.html",
    "title": "HW 02: Multiple linear regression",
    "section": "",
    "text": "Due date\n\n\n\nThis assignment is due on Thursday, October 3 at 11:59pm.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#instructions",
    "href": "hw/hw-02.html#instructions",
    "title": "HW 02: Multiple linear regression",
    "section": "Instructions",
    "text": "Instructions\nThe conceptual exercises are focused on explaining concepts and showing results mathematically. Show your work for each question.\n\nYou may write the answers and associated work for conceptual exercises by hand or type them in your Quarto document.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-1",
    "href": "hw/hw-02.html#exercise-1",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nLet \\(Var(\\hat{\\mathbf{y}})\\) be the variance of the fitted (predicted) values of the response variable. Show that \\(Var(\\hat{\\mathbf{y}}) = \\sigma^2_\\epsilon \\mathbf{H}\\).",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-2",
    "href": "hw/hw-02.html#exercise-2",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nSuppose we fit the model \\(\\mathbf{y} = \\mathbf{X}_1\\boldsymbol{\\beta}_1 + \\boldsymbol{\\epsilon}\\) when the true model is actually given by \\(\\mathbf{y} = \\mathbf{X}_1\\boldsymbol{\\beta}_1 + \\mathbf{X}_2\\boldsymbol{\\beta}_2 + \\boldsymbol{\\epsilon}\\). Assume \\(E(\\boldsymbol{\\epsilon}) = \\mathbf{0}\\) for both models.\n\nFind the expected value of the least-squares estimate \\(\\hat{\\boldsymbol{\\beta}}_1\\).\nUnder what conditions is the estimate \\(\\hat{\\boldsymbol{\\beta}}_1\\) unbiased?",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#instructions-1",
    "href": "hw/hw-02.html#instructions-1",
    "title": "HW 02: Multiple linear regression",
    "section": "Instructions",
    "text": "Instructions\nThe applied exercises are focused on applying the concepts to analyze data.\nAll work for the applied exercises must be typed in your Quarto document following a reproducible workflow.\nWrite all narrative using complete sentences and include informative axis labels / titles on visualizations.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#data-lego-sets",
    "href": "hw/hw-02.html#data-lego-sets",
    "title": "HW 02: Multiple linear regression",
    "section": "Data: LEGO® sets",
    "text": "Data: LEGO® sets\nThe data for Exercises 3 - 5 includes information about LEGO® sets from themes produced January 1, 2018 and September 11, 2020. The data were originally scraped from Brickset.com, an online LEGO set guide and were obtained for this assignment from Peterson and Ziegler (2021).\nYou will work with data on about 400 randomly selected LEGO sets produced during this time period. The primary variables are interest in this analysis are\n\nPieces: Number of pieces in the set from brickset.com.\nMinifigures: Number of minifigures (LEGO® people) in the set scraped from brickset.com.\nAmazon_Price: Price of the set on Amazon.com (in U.S. dollars)\nSize: General size of the interlocking bricks (Large = LEGO Duplo® sets - which include large brick pieces safe for children ages 1 to 5, Small = LEGO® sets which- include the traditional smaller brick pieces created for age groups 5 and - older, e.g., City, Friends)\n\nThe data are contained in lego-sample.csv. Use the code below to read in the data and remove any observations that have missing values for the relevant variables.\n\nlegos &lt;- read_csv(\"data/lego-sample.csv\")|&gt;\n  drop_na(Pieces, Amazon_Price, Size, Minifigures)\n\n\n\n\n\n\n\nAnalysis goal\n\n\n\nWe want to fit a multiple linear regression model to predict the price of LEGO® sets on Amazon.com based on Pieces, Size, and Minifigures.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-3",
    "href": "hw/hw-02.html#exercise-3",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nIn this analysis, we dropped observations that have missing values for some of the relevant variables.\n\nWhat is a disadvantage of dropping observations that have missing values, instead of using a method to impute (fill in) the missing data?\nHow might dropping these observations impact the generalizability of conclusions?\n\nFit the regression model and neatly display the results using three digits.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-4",
    "href": "hw/hw-02.html#exercise-4",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nWe want to understand the relationship between Pieces and Amazon_Price based on this model that also takes into the size of the blocks and number of minifigures.\nYou are convinced from the model output that there is evidence of a linear relationship between the two variables. Now you want to be more specific and test whether the slope is actually different from 0.1 ($10 increase in the price for every 100 additional pieces).\n\nWrite the null and alternative hypotheses for this test in using words and mathematical notation.\nCalculate the test statistic for this test. You may use any relevant output from the model in the previous exercise.\nWhat is the distribution of the test statistic under the null hypothesis for this problem?\nCalculate the p-value and state your conclusion in the context of the data using a threshold of \\(\\alpha = 0.05\\).\nCalculate the 95% confidence interval. Is the confidence interval consistent with your conclusion from the hypothesis test? Briefly explain.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-5",
    "href": "hw/hw-02.html#exercise-5",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nInstead of using the number of minifigures in the model, you decide to create an indicator variable for whether or not there are any minifigures in the set.\n\nCreate an indicator variable that takes the value “No” if there are zero minifigures in the LEGO® set, and “Yes” if there is at least one minifigure.\nYou hypothesize that the relationship between the price and number of pieces may differ based on whether or not there are minifigures in the set.\nMake a plot to visualize this potential effect. Does the relationship between price and number of pieces seem to differ based on the inclusion of minifigures? Briefly explain.\nFit a model using the number pieces, size of the blocks, the indicator for minifigures, and the interaction between pieces and the presence of minifigures to predict the price on Amazon.com.\nBased on this model, is there evidence that the effect of pieces on the price differs based on the inclusion of minifigures? Briefly explain your response, referencing any statistics used to make your determination.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#data-world-bank",
    "href": "hw/hw-02.html#data-world-bank",
    "title": "HW 02: Multiple linear regression",
    "section": "Data: World Bank",
    "text": "Data: World Bank\nThe World Bank collects “world development indicators” about the past and current development of countries. These data are made available on the World Bank’s website. It can be used to understand the relationships between these various factors and trends over time.\n\nThis analysis focuses on indicators from 2011 on 165 countries. The variables of interest are:\n\ngdp.per.capita: gross domestic product divided by midyear population. GDP is the sum of gross value added by all resident producers in the economy plus any product taxes and minus any subsidies not included in the value of the products. It is calculated without making deductions for depreciation of fabricated assets or for depletion and degradation of natural resources. Data are in current U.S. dollars.\nsanit.access.factor: Population access to sanitation facilities (Low, High)\nedu.expend: Government expenditure on education, total (% of government expenditure)\nlife.expect: Life expectancy at birth (in years)",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-6",
    "href": "hw/hw-02.html#exercise-6",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nYou fit a model using sanitation access, education expenditures, and life expectancy to understand variability in GDP. The model takes the form\n\\[\n\\begin{aligned}\\widehat{\\log(GDP)} = \\hat{\\beta}_0 &+ \\hat{\\beta}_1 ~ sanit.access.factor + \\hat{\\beta}_2 ~ edu.expend + \\hat{\\beta}_3 ~life.expect \\\\ &+ \\hat{\\beta}_4 ~ sanit.access.factor \\times life.expect\\end{aligned}\n\\]\nwhere \\(\\log(GDP)\\) is the natural log of gdp.per.capita.\nThe F output for this model is shown below.\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n4.491\n1.638\n2.742\n0.007\n\n\nsanit.access.factorhigh\n-6.993\n1.971\n-3.548\n0.001\n\n\nedu.expend\n0.097\n0.038\n2.550\n0.012\n\n\nlife.expect\n0.030\n0.029\n1.061\n0.291\n\n\nsanit.access.factorhigh:life.expect\n0.122\n0.032\n3.853\n0.000\n\n\n\n\n\n\nInterpret the coefficient of edu.expend in the context of the data. You can interpret the coefficient in terms of \\(log(GDP)\\) .\nInterpret the coefficient of sanit.access.factorhigh in the context of the data.You can interpret the coefficient in terms of \\(log(GDP)\\) .",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-7",
    "href": "hw/hw-02.html#exercise-7",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 7",
    "text": "Exercise 7\n\nWrite the estimated regression equation for countries with high sanitation access.\nInterpret the effect of life.expect for countries with high sanitation access in the context of the data. You can interpret the coefficient in terms of \\(log(GDP)\\) .",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-8",
    "href": "hw/hw-02.html#exercise-8",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 8",
    "text": "Exercise 8\nBelow are plots from the exploratory data analysis of the relationships between the predictor variables. Based on these plots, what appears to be a potential issue with the model from Exercise 6? Briefly explain your response.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#bonus-optional",
    "href": "hw/hw-02.html#bonus-optional",
    "title": "HW 02: Multiple linear regression",
    "section": "Bonus (optional)",
    "text": "Bonus (optional)\nUse the model from Exercise 6 to interpret the coefficients of edu.expend and sanit.access.factorhigh in term of GDP (not log(GDP)). Write your interpretations in the context of the data.\nEach interpretation is worth 1 point out of 50. The interpretation must be exactly correct to receive credit.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "prepare/prepare-sep10.html",
    "href": "prepare/prepare-sep10.html",
    "title": "Prepare for September 10 lecture",
    "section": "",
    "text": "Review class notes and readings on simple linear regression.\nWe will extend what we’ve done thus far to multiple linear regression, with 2 or more predictors."
  },
  {
    "objectID": "prepare/prepare-sep12.html",
    "href": "prepare/prepare-sep12.html",
    "title": "Prepare for September 12 lecture",
    "section": "",
    "text": "📖 Read Multiple Linear Regression\n✅ Review Vector Geometry [slides][video]1\n🎥: Watch Geometric interpretation of least squares"
  },
  {
    "objectID": "prepare/prepare-sep12.html#footnotes",
    "href": "prepare/prepare-sep12.html#footnotes",
    "title": "Prepare for September 12 lecture",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFrom Math 218: Matrices and Vectors (Summer 2024) taught by Dr. Brian Fitzpatrick at Duke University↩︎"
  },
  {
    "objectID": "prepare/prepare-sep5.html",
    "href": "prepare/prepare-sep5.html",
    "title": "Prepare for September 5 lecture",
    "section": "",
    "text": "Review linear algebra concepts (as needed)\n\nMatrices and vectors: [slides][video]\nMatrix-Vector products: [slides][video]\nVector geometry: [slides][video]\nMatrix multiplication: [slides][video]\n\n\n\n\n\n\n\nNote\n\n\n\nAll linear algebra review materials from Math 218: Matrices and Vectors (Summer 2024) taught by Dr. Brian Fitzpatrick at Duke University"
  },
  {
    "objectID": "ae/ae-03-inference.html",
    "href": "ae/ae-03-inference.html",
    "title": "AE 03: Inference",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-03 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE.\n\n\n\nSet up\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\n\nfootball &lt;- read_csv(\"data/ncaa-football-exp.csv\")\n\n\n\nData\n\n\nRegression model\n\nexp_fit &lt;- lm(total_exp_m ~ enrollment_th + type, data = football)\n\ntidy(exp_fit)|&gt; \n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0\n\n\n\n\n\n\n\nHypothesis test\nWe want to conduct a hypothesis test to determine if there is a linear relationship between enrollment and football expenditures after accounting for institution type.\nWe’ll start by getting estimates for statistics we’ll need for inference.\n\n\n\n\n\n\nExercise 1\n\n\n\nWe will use the vector of responses \\(\\mathbf{y}\\) and the design matrix \\(\\mathbf{X}\\) to calculate the values needed for inference.\nGet \\(\\mathbf{y}\\) and \\(\\mathbf{X}\\) from the football data frame. What are their dimensions?\n\n\n\n# add code here\n\n\n\n\n\n\n\nExercise 2\n\n\n\nNext, let’s calculate \\(\\hat{\\sigma}_\\epsilon^2\\) the estimate. Use \\(\\mathbf{y}\\) and \\(\\mathbf{X}\\) from the previous exercise to calculate this value.\n\n\n\n## add code here\n\n\n\n\n\n\n\nExercise 3\n\n\n\nNow we’re ready to conduct the hypothesis test. State the null and alternative hypotheses in words and using mathematical notation.\n\n\n. . .\n\n\n\n\n\n\nExercise 4\n\n\n\nCalculate \\(SE(\\beta_j)\\), then use this value to calculate the test statistic for the hypothesis test.\n\n\n\n## add code here\n\n\n\n\n\n\n\nExercise 5\n\n\n\nNow we need to calculate p-value to help make our final conclusion.\n\nState the distribution used to calculate the p-value.\nFill in the code below to calculate the p-value. Remove #| eval: false once you’ve filled in the code.\n\n\n\n\npt([test-statistic], [df], lower.tail = FALSE)\n\n\n\n\n\n\n\nExercise 6\n\n\n\nState your conclusion in the context of the data. Use a threshold of \\(\\alpha = 0.05\\).\n\n\n. . .\n\n\n\n\n\n\nSubmission\n\n\n\nTo submit the AE:\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your AE repo on GitHub. You’re done! 🎉"
  },
  {
    "objectID": "ae/ae-05-multicollinearity.html",
    "href": "ae/ae-05-multicollinearity.html",
    "title": "AE 05: Multicollinearity",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-05 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE.\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(tidymodels)\nlibrary(rms) #calculate VIF"
  },
  {
    "objectID": "ae/ae-05-multicollinearity.html#exercise-1",
    "href": "ae/ae-05-multicollinearity.html#exercise-1",
    "title": "AE 05: Multicollinearity",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nFit the regression model using high temperature, average temperature, season, and precipitation to predict volume.\nAre there any coefficients that may be not what you expected?\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-05-multicollinearity.html#exercise-2",
    "href": "ae/ae-05-multicollinearity.html#exercise-2",
    "title": "AE 05: Multicollinearity",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nUse the formula\n\n\\[\nVIF_j = \\frac{1}{1 - R^2_j}\n\\]\nto calculate the VIF for avgtemp.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-05-multicollinearity.html#exercise-3",
    "href": "ae/ae-05-multicollinearity.html#exercise-3",
    "title": "AE 05: Multicollinearity",
    "section": "Exercise 3",
    "text": "Exercise 3\nBased on the VIF from the previous exercise, does avgtemp have a linear dependency with one or more other predictors? Explain."
  },
  {
    "objectID": "ae/ae-05-multicollinearity.html#exercise-4",
    "href": "ae/ae-05-multicollinearity.html#exercise-4",
    "title": "AE 05: Multicollinearity",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nFill in the name of the model from Exercise 1 to calculate VIF for all predictors. (Remove #| eval: false after you’ve filled in the code.)\nAre there predictors with linear dependencies? If so, which ones?\n\n\nvif(____)"
  },
  {
    "objectID": "ae/ae-05-multicollinearity.html#exercise-5",
    "href": "ae/ae-05-multicollinearity.html#exercise-5",
    "title": "AE 05: Multicollinearity",
    "section": "Exercise 5",
    "text": "Exercise 5\nLet’s try to deal with the mulitcollinearity by removing one of the predictors that are linearly dependent. Choose a final model using this strategy.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-02-mlr.html",
    "href": "ae/ae-02-mlr.html",
    "title": "AE 02: Multiple linear regression",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-02 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE.\n\n\n\nPackages\n\nlibrary(tidyverse)   \nlibrary(tidymodels)   \nlibrary(openintro)    \nlibrary(knitr)       \n\n\n\nData\nToday’s data is a sample of 50 loans made through a peer-to-peer lending club. The data is in the loan50 data frame in the openintro R package.\nWe will focus on the following variables:\n\nannual_income_th: Annual income (in $1000s)\ndebt_to_income: Debt-to-income ratio, i.e. the percentage of a borrower’s total debt divided by their total income\nverified_income: Whether borrower’s income source and amount have been verified (Not Verified, Source Verified, Verified)\ninterest_rate: Interest rate for the loan\n\nThe goal of this analysis is to use the annual income, debt-to-income ratio, and income verification to understand variability in the interest rate on the loan.\nWe’ll start with data prep to rescale annual income to $1000’s and recode verified_income to fix an issue with the underlying data.\n\nloan50 &lt;- loan50 |&gt;\n   mutate(annual_income_th = annual_income / 1000, \n          verified_income = \n            case_when(verified_income == \"Not Verified\" ~ \"Not Verified\",\n                      verified_income == \"Source Verified\" ~ \"Source Verified\",\n                      verified_income == \"Verified\" ~ \"Verified\"),\n          verified_income = as_factor(verified_income)\n   )                    \n\n\nglimpse(loan50)\n\nRows: 50\nColumns: 19\n$ state                   &lt;fct&gt; NJ, CA, SC, CA, OH, IN, NY, MO, FL, FL, MD, HI…\n$ emp_length              &lt;dbl&gt; 3, 10, NA, 0, 4, 6, 2, 10, 6, 3, 8, 10, 10, 2,…\n$ term                    &lt;dbl&gt; 60, 36, 36, 36, 60, 36, 36, 36, 60, 60, 36, 36…\n$ homeownership           &lt;fct&gt; rent, rent, mortgage, rent, mortgage, mortgage…\n$ annual_income           &lt;dbl&gt; 59000, 60000, 75000, 75000, 254000, 67000, 288…\n$ verified_income         &lt;fct&gt; Not Verified, Not Verified, Verified, Not Veri…\n$ debt_to_income          &lt;dbl&gt; 0.55752542, 1.30568333, 1.05628000, 0.57434667…\n$ total_credit_limit      &lt;int&gt; 95131, 51929, 301373, 59890, 422619, 349825, 1…\n$ total_credit_utilized   &lt;int&gt; 32894, 78341, 79221, 43076, 60490, 72162, 2872…\n$ num_cc_carrying_balance &lt;int&gt; 8, 2, 14, 10, 2, 4, 1, 3, 10, 4, 3, 4, 3, 2, 3…\n$ loan_purpose            &lt;fct&gt; debt_consolidation, credit_card, debt_consolid…\n$ loan_amount             &lt;int&gt; 22000, 6000, 25000, 6000, 25000, 6400, 3000, 1…\n$ grade                   &lt;fct&gt; B, B, E, B, B, B, D, A, A, C, D, A, A, A, A, E…\n$ interest_rate           &lt;dbl&gt; 10.90, 9.92, 26.30, 9.92, 9.43, 9.92, 17.09, 6…\n$ public_record_bankrupt  &lt;int&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0…\n$ loan_status             &lt;fct&gt; Current, Current, Current, Current, Current, C…\n$ has_second_income       &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n$ total_income            &lt;dbl&gt; 59000, 60000, 75000, 75000, 254000, 67000, 288…\n$ annual_income_th        &lt;dbl&gt; 59.0, 60.0, 75.0, 75.0, 254.0, 67.0, 28.8, 80.…\n\n\n\n\nCategorical predictors\n\n\n\n\n\n\nExercise 1\n\n\n\nLet’s take a look at the design matrix for the model with predictors debt_to_income, annual_income_th, and verified_income.\nHow does R choose the baseline level by default?\n\n\n\n## add code here\n\n[Add response here]\n\n\n\n\n\n\nExercise 2\n\n\n\nFit the model with the predictors debt_to_income, annual_income_th, verified_income , and the interaction between annual_income_th and verified_income.\nNeatly display the model results using 3 digits.\n\n\n\n# add code here\n\n\n\n\n\n\n\nExercise 3\n\n\n\n\nWrite the estimated regression equation for the people with Not Verified income.\nWrite the estimated regression equation for people with Verified income.\n\n\n\n[add response here]\n\n\n\n\n\n\nExercise 4\n\n\n\nIn general, how do\n\nindicators for categorical predictors impact the model equation?\ninteraction terms impact the model equation?\n\n\n\n[Add response here]\n\n\nModel assessment\n\n\n\n\n\n\nExercise 5\n\n\n\nLet’s compare the original model without interaction effects to the model you fit in Exercise 2.\nCalculate \\(R^2\\) and \\(Adj. R^2\\) for each model. You can find \\(Adj. R^2\\) from the glance function:\nglance(model_name)$adj.r.squared\n\n\n\nint_fit &lt;- lm(interest_rate ~ debt_to_income + annual_income_th +\n                verified_income, data = loan50)\n\n\n# add code here\n\n\n\n\n\n\n\nExercise 6\n\n\n\nWhich model would you choose based on\n\n\\(R^2\\)?\n\\(Adj. R^2\\)?\n\n\n\n[add response here]\n\n\nLaTex\nSometimes, you will need to include mathematical notation in your document. There are two ways you can display mathematics in your document:\nInline: Your mathematics will display within the line of text.\n\nUse $ to start and end your LaTex syntax. You can also use the menu: Insert -&gt; LaTex Math -&gt; Inline Math.\nExample: The text The simple linear regression model is $\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}$ produces\n\nThe simple linear regression model is \\(\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\\)\n\n\nDisplayed: Your mathematics will display outside the line of text\n\nUse a $$ to start and end your LaTex syntax. You can also use the menu: Insert -&gt; LaTex Math -&gt; Display Math.\nExample: The text The estimated regression equation is $$\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}$$produces\n\nThe estimated regression equation is\n\n\\[\n\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}\n\\]\n\n\n\n\n\n\nTip\n\n\n\nClick here for a quick reference of LaTex code.\n\n\n\n\nSubmission\n\n\n\n\n\n\nImportant\n\n\n\nTo submit the AE:\n\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your AE repo on GitHub. You’re done! 🎉"
  },
  {
    "objectID": "computing-r-resources.html",
    "href": "computing-r-resources.html",
    "title": "Resources for learning R",
    "section": "",
    "text": "Below are freely available resources to learn or review the following in R: data wrangling, data visualization, Quarto basics.",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#in-depth-introduction",
    "href": "computing-r-resources.html#in-depth-introduction",
    "title": "Resources for learning R",
    "section": "In-depth introduction",
    "text": "In-depth introduction\nCoursera: Data Visualization and Transformation with R by Mine Çetinkaya-Rundel and Elijah Meyer\n\nIncludes videos, readings, practice exercise, quizzes, and other resources\nYou can select content within the modules you want to complete.\nFocus on Modules 2 and 3. Review the content in Module 1 as needed.s\nClick here for instructions to register for Coursera for free as a Duke student",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#in-depth-review",
    "href": "computing-r-resources.html#in-depth-review",
    "title": "Resources for learning R",
    "section": "In-depth review",
    "text": "In-depth review\nData Science with R videos by Mine Çetinkaya-Rundel and Elijah Meyer\n\nVideos from the data science Coursera course\nFocus on videos on visualizing and summarizing data\nYou need to join the Coursera course to access the files from the code along videos.\n\nLearn R: An interactive introduction to data analysis with R\n\nHands-on tutorial that can be completed within the site (no RStudio required)\nFocus on Chapters 4 - 6",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#shorter-review",
    "href": "computing-r-resources.html#shorter-review",
    "title": "Resources for learning R",
    "section": "Shorter review",
    "text": "Shorter review\nR for Data Science (2nd ed) by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund\n\nFocus on Chapters 1 - 3, 10",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#additional-resources",
    "href": "computing-r-resources.html#additional-resources",
    "title": "Resources for learning R",
    "section": "Additional resources",
    "text": "Additional resources\n\nTidy Modeling with R by Max Kuhn & Julia Silge\nPosit Cheatsheets\nR workshops by Duke Center for Data and Visualization Sciences",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 221 - Regression Analysis: Theory and Applications",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the semester. Note that this schedule will be updated as the semester progresses, with all changes documented here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nweek\ndow\ndate\ntopic\nprepare\nslides\nae\nhw\nlab\nproject\nnotes\n\n\n\n\n1\nM\nAug 26\nLab 00: Welcome + Getting Started\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nAug 27\nWelcome to STA 221!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nAug 29\nSimple linear regression (SLR)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2\nM\nSep 2\nNO LAB: Labor Day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nSep 3\nSLR: Model assessment\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nSep 5\nSLR: Model assessment cont'd\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSLR: Matrix representation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3\nM\nSep 9\nLab 01: Simple linear regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nSep 10\nSLR: Matrix representation cont'd\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultiple linear regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nSep 12\nMLR: Categorical predictors + Model assessment\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 01 assigned, Lab 01 due\n\n\n4\nM\nSep 16\nLab 02: Multiple linear regression + Meet your team!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nSep 17\nANOVA + Geometric interpretation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nSep 19\nInference for regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 01 due, Lab 02 due\n\n\n5\nM\nSep 23\nLab 03: Inference for regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject: Develop Research question\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nSep 24\nInference for regression cont'd\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nSep 26\nProperties of estimators\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 02 assigned, Project research questions due\n\n\n6\nM\nSep 30\nLab 03 + Project proposal\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nOct 1\nProperties of estimators\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nOct 3\nExam 01 Review\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 02 due, Lab 03 due, Project proposal due\n\n\n7\nM\nOct 7\nLab :Exam office hours\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nOct 8\nExam 01\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nOct 10\nMaximum Likelihood Estimation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8\nM\nOct 14\nNO LAB: Fall Break\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nOct 15\nNO LECTURE: Fall Break\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nOct 17\nMLR: Model diagnostics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExam 01 corrections assigned\n\n\n9\nM\nOct 21\nLab 04: Maximum likelihood estimation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nOct 22\nMLR: Multicollinearity + Variable transformations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nOct 24\nMLR: Variable transformations + Prediction\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExam 01 corrections due, Lab 04 due, HW 03 assigned\n\n\n10\nM\nOct 28\nLab: Expanding multiple linear regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nOct 29\nMLR: Model comparison\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nOct 31\nOdds + Odds ratios\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 03 due\n\n\n11\nM\nNov 4\nLab: Model comparison + diagnostics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nNov 5\nWellness Day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nNov 7\nLogistic regression (LR)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12\nM\nNov 11\nLab: Project presentations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nNov 12\nLR: Prediction + assessment\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nNov 14\nLR: Inference\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 04 assigned\n\n\n13\nM\nNov 18\nLab: Logistic regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nNov 19\nLR estimation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nNov 21\nTBD / Catch up day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 04 due\n\n\n14\nM\nNov 25\nProject: Draft analysis + report\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nNov 26\nProject day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nNov 28\nNO LECTURE: Thanksgiving\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n15\nM\nDec 2\nProject: Peer review\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nDec 3\nExam 02 review\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nDec 5\nExam 02\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExam period",
    "crumbs": [
      "Schedule"
    ]
  },
  {
    "objectID": "slides/lab-03.html#goals",
    "href": "slides/lab-03.html#goals",
    "title": "Lab 03",
    "section": "Goals",
    "text": "Goals\n\nTeam project\nLab 03: Palmer penguins"
  },
  {
    "objectID": "slides/lab-03.html#lab-03-palmer-penguins",
    "href": "slides/lab-03.html#lab-03-palmer-penguins",
    "title": "Lab 03",
    "section": "Lab 03: Palmer penguins",
    "text": "Lab 03: Palmer penguins\nLab 03 focuses on\n\nusing linear regression and statistical inference to draw conclusions about penguins living in Palmer Archipelago in Antarctica.\nuse the data to check conditions about the distribution of the model residuals.\n\nUse this week to get started on the lab. We will continue discussing statistical inference in this week’s lectures, so this lab will be due on Thursday, October 3, 2024.\n🔗 https://sta221-fa24.netlify.app/labs/lab-03"
  },
  {
    "objectID": "slides/lab-03.html#final-team-project",
    "href": "slides/lab-03.html#final-team-project",
    "title": "Lab 03",
    "section": "Final Team Project",
    "text": "Final Team Project\nGoal: Use the methods from STA 221 to analyze data and answer a research question developed by your team\nPrimary deliverables:\n\nan in-person presentation about the exploratory data analysis and initial modeling\na written, reproducible final report detailing your analysis\na GitHub repository containing all work from the project\n\nSubmission: All work for the project will be submitted in your team’s GitHub repo. You will receive feedback via an Issue on GitHub to model a workflow often used in practice."
  },
  {
    "objectID": "slides/lab-03.html#final-team-project-1",
    "href": "slides/lab-03.html#final-team-project-1",
    "title": "Lab 03",
    "section": "Final team project",
    "text": "Final team project\nMilestones: There are periodic project milestones throughout the semester to help you work towards the final deliverables:\n\nResearch questions (today’s lab)\nProject proposal (next week’s lab)\nExploratory data analysis draft\nPresentation + Presentation comments\nAnalysis draft + peer review\nRound 1 submission (optional)\nWritten report\nReproducibility + organization\n\nSee the Final Project Instructions for a timeline and details for each milestone."
  },
  {
    "objectID": "slides/lab-03.html#today-research-questions",
    "href": "slides/lab-03.html#today-research-questions",
    "title": "Lab 03",
    "section": "Today: Research questions",
    "text": "Today: Research questions\nGoal: Develop three potential research questions your team may be interested in investigating.\nYou do not need to have a data set at this point\nFull instructions here: sta221-fa24.netlify.app/project#research-questions"
  },
  {
    "objectID": "slides/lab-03.html#reminder-team-workflow",
    "href": "slides/lab-03.html#reminder-team-workflow",
    "title": "Lab 03",
    "section": "Reminder: Team workflow",
    "text": "Reminder: Team workflow\n\nOnly one team member should type at a time. There are markers in today’s lab to help you determine whose turn it is to type.\n\nEvery team member should still be engaged in discussion for all questions, even if it’s not your turn type.\n\nDon’t forget to pull to get your teammates’ updates before making changes to the .qmd file.\n\n\n\n\n\n\nImportant\n\n\nOnly one submission per team on Gradescope. Read the submission instructions carefully!"
  },
  {
    "objectID": "slides/lab-03.html#reminder-tips-for-working-on-a-team",
    "href": "slides/lab-03.html#reminder-tips-for-working-on-a-team",
    "title": "Lab 03",
    "section": "Reminder: Tips for working on a team",
    "text": "Reminder: Tips for working on a team\n\nDo not pressure each other to finish early; use the time wisely to really learn the material and produce a quality report.\nThe labs are structured to help you learn the steps of a data analysis. Do not split up the lab among the team members; work on it together in its entirety.\nEveryone has something to contribute! Use the lab groups as an opportunity to share ideas and learn from each other.\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/lab-01.html#getting-started",
    "href": "slides/lab-01.html#getting-started",
    "title": "Lab 01",
    "section": "Getting started",
    "text": "Getting started\nAsk your TA if\n\nYou do not have a lab-01 repo in the GitHub course organization: github.com/sta221-fa24\nYou need help cloning the repo and starting a new RStudio project"
  },
  {
    "objectID": "slides/lab-01.html#tips-for-working-on-lab",
    "href": "slides/lab-01.html#tips-for-working-on-lab",
    "title": "Lab 01",
    "section": "Tips for working on lab",
    "text": "Tips for working on lab\n\nYou do not have to finish the lab in class, they will always be due Thursdays at 11:59pm. One work strategy is to get through portions that you think will be most challenging (which initially might be the coding component) during lab when a TA can help you on the spot and leave the narrative writing until later.\nDo not pressure each other to finish early (particularly once you start working on teams); use the time wisely to really learn the material and produce a quality report."
  },
  {
    "objectID": "slides/lab-01.html#workflow-and-formatting",
    "href": "slides/lab-01.html#workflow-and-formatting",
    "title": "Lab 01",
    "section": "Workflow and formatting",
    "text": "Workflow and formatting\nPart of the lab grade is for “workflow and formatting” assessing the reproducible workflow and document format. This includes\n\nHaving at least 3 informative commit messages (practicing version control)\n\nThere are markers in Lab 01 to help you incorporate version control in your workflow\n\nThe PDF is neatly organized document with clear exercise headings and readable code and narrative\nThe name (first and last) and date are updated at the top of the document."
  },
  {
    "objectID": "slides/lab-01.html#when-youre-done-with-lab",
    "href": "slides/lab-01.html#when-youre-done-with-lab",
    "title": "Lab 01",
    "section": "When you’re done with lab",
    "text": "When you’re done with lab\n\nMake sure all your final changes have been pushed to your GitHub repo\nSubmit your final PDF to Gradescope\n\nAccess Gradescope through the course Canvas site\nMark the pages associated with each exercise."
  },
  {
    "objectID": "slides/lab-01.html#lab-01-park-access",
    "href": "slides/lab-01.html#lab-01-park-access",
    "title": "Lab 01",
    "section": "Lab 01: Park access",
    "text": "Lab 01: Park access\nToday’s lab focuses on exploratory data analysis and simple linear regression, content from Weeks 01 and 02 in the course.\n🔗 sta221-fa24.netlify.app/labs/lab-01.html\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/02-slr.html#announcements",
    "href": "slides/02-slr.html#announcements",
    "title": "Simple linear regression",
    "section": "Announcements",
    "text": "Announcements\n\nNo labs on Mon, Sep 2 (Labor Day)\nApplication exercises start Tue, Sep 3\n\nBring fully-charged laptop or device with keyboard\nMake sure you have accepted invite to GitHub course organization\n\nSee website for resources to learn / review R\nOffice hours start Tue, Sep 3"
  },
  {
    "objectID": "slides/02-slr.html#topics",
    "href": "slides/02-slr.html#topics",
    "title": "Simple linear regression",
    "section": "Topics",
    "text": "Topics\n\nHow regression is used to understand the relationship between multiple variables\nLeast squares estimation for the slope and intercept\nInterpret the slope and intercept\nPredict the response given a value of the predictor"
  },
  {
    "objectID": "slides/02-slr.html#computing-set-up",
    "href": "slides/02-slr.html#computing-set-up",
    "title": "Simple linear regression",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)        # for data wrangling\nlibrary(broom)            # for formatting regression output\nlibrary(fivethirtyeight)  # for the fandango dataset\nlibrary(knitr)            # for formatting tables\nlibrary(patchwork)        # for arranging graphs\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))\n\n# set default figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 8,\n  fig.asp = 0.618,\n  fig.retina = 3,\n  dpi = 300,\n  out.width = \"80%\"\n)"
  },
  {
    "objectID": "slides/02-slr.html#movie-scores",
    "href": "slides/02-slr.html#movie-scores",
    "title": "Simple linear regression",
    "section": "Movie scores",
    "text": "Movie scores\n\n\n\nData behind the FiveThirtyEight story Be Suspicious Of Online Movie Ratings, Especially Fandango’s\nIn the fivethirtyeight package: fandango\nContains every film released in 2014 and 2015 that has at least 30 fan reviews on Fandango, an IMDb score, Rotten Tomatoes critic and user ratings, and Metacritic critic and user scores"
  },
  {
    "objectID": "slides/02-slr.html#data-prep",
    "href": "slides/02-slr.html#data-prep",
    "title": "Simple linear regression",
    "section": "Data prep",
    "text": "Data prep\n\nRename Rotten Tomatoes columns as critics and audience\nRename the dataset as movie_scores\n\n\nmovie_scores &lt;- fandango |&gt;\n  rename(critics = rottentomatoes, \n         audience = rottentomatoes_user)"
  },
  {
    "objectID": "slides/02-slr.html#data-overview",
    "href": "slides/02-slr.html#data-overview",
    "title": "Simple linear regression",
    "section": "Data overview",
    "text": "Data overview\n\nglimpse(movie_scores)\n\nRows: 146\nColumns: 23\n$ film                       &lt;chr&gt; \"Avengers: Age of Ultron\", \"Cinderella\", \"A…\n$ year                       &lt;dbl&gt; 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2…\n$ critics                    &lt;int&gt; 74, 85, 80, 18, 14, 63, 42, 86, 99, 89, 84,…\n$ audience                   &lt;int&gt; 86, 80, 90, 84, 28, 62, 53, 64, 82, 87, 77,…\n$ metacritic                 &lt;int&gt; 66, 67, 64, 22, 29, 50, 53, 81, 81, 80, 71,…\n$ metacritic_user            &lt;dbl&gt; 7.1, 7.5, 8.1, 4.7, 3.4, 6.8, 7.6, 6.8, 8.8…\n$ imdb                       &lt;dbl&gt; 7.8, 7.1, 7.8, 5.4, 5.1, 7.2, 6.9, 6.5, 7.4…\n$ fandango_stars             &lt;dbl&gt; 5.0, 5.0, 5.0, 5.0, 3.5, 4.5, 4.0, 4.0, 4.5…\n$ fandango_ratingvalue       &lt;dbl&gt; 4.5, 4.5, 4.5, 4.5, 3.0, 4.0, 3.5, 3.5, 4.0…\n$ rt_norm                    &lt;dbl&gt; 3.70, 4.25, 4.00, 0.90, 0.70, 3.15, 2.10, 4…\n$ rt_user_norm               &lt;dbl&gt; 4.30, 4.00, 4.50, 4.20, 1.40, 3.10, 2.65, 3…\n$ metacritic_norm            &lt;dbl&gt; 3.30, 3.35, 3.20, 1.10, 1.45, 2.50, 2.65, 4…\n$ metacritic_user_nom        &lt;dbl&gt; 3.55, 3.75, 4.05, 2.35, 1.70, 3.40, 3.80, 3…\n$ imdb_norm                  &lt;dbl&gt; 3.90, 3.55, 3.90, 2.70, 2.55, 3.60, 3.45, 3…\n$ rt_norm_round              &lt;dbl&gt; 3.5, 4.5, 4.0, 1.0, 0.5, 3.0, 2.0, 4.5, 5.0…\n$ rt_user_norm_round         &lt;dbl&gt; 4.5, 4.0, 4.5, 4.0, 1.5, 3.0, 2.5, 3.0, 4.0…\n$ metacritic_norm_round      &lt;dbl&gt; 3.5, 3.5, 3.0, 1.0, 1.5, 2.5, 2.5, 4.0, 4.0…\n$ metacritic_user_norm_round &lt;dbl&gt; 3.5, 4.0, 4.0, 2.5, 1.5, 3.5, 4.0, 3.5, 4.5…\n$ imdb_norm_round            &lt;dbl&gt; 4.0, 3.5, 4.0, 2.5, 2.5, 3.5, 3.5, 3.5, 3.5…\n$ metacritic_user_vote_count &lt;int&gt; 1330, 249, 627, 31, 88, 34, 17, 124, 62, 54…\n$ imdb_user_vote_count       &lt;int&gt; 271107, 65709, 103660, 3136, 19560, 39373, …\n$ fandango_votes             &lt;int&gt; 14846, 12640, 12055, 1793, 1021, 397, 252, …\n$ fandango_difference        &lt;dbl&gt; 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5…"
  },
  {
    "objectID": "slides/02-slr.html#univariate-exploratory-data-analysis-eda",
    "href": "slides/02-slr.html#univariate-exploratory-data-analysis-eda",
    "title": "Simple linear regression",
    "section": "Univariate exploratory data analysis (EDA)",
    "text": "Univariate exploratory data analysis (EDA)\nThe data set contains the “Tomatometer” score (critics) and audience score (audience) for 146 movies rated on rottentomatoes.com."
  },
  {
    "objectID": "slides/02-slr.html#bivariate-eda",
    "href": "slides/02-slr.html#bivariate-eda",
    "title": "Simple linear regression",
    "section": "Bivariate EDA",
    "text": "Bivariate EDA"
  },
  {
    "objectID": "slides/02-slr.html#bivariate-eda-1",
    "href": "slides/02-slr.html#bivariate-eda-1",
    "title": "Simple linear regression",
    "section": "Bivariate EDA",
    "text": "Bivariate EDA\nGoal: Fit a line to describe the relationship between the critics score and audience score."
  },
  {
    "objectID": "slides/02-slr.html#why-fit-a-line",
    "href": "slides/02-slr.html#why-fit-a-line",
    "title": "Simple linear regression",
    "section": "Why fit a line?",
    "text": "Why fit a line?\nWe fit a line to accomplish one or both of the following:\n\n\n\nPrediction\n\n\nWhat is an example of a prediction question for this data set?\n\n\n\n\n\nInference\n\n\nWhat is an example of an inference question for this data set?"
  },
  {
    "objectID": "slides/02-slr.html#terminology",
    "href": "slides/02-slr.html#terminology",
    "title": "Simple linear regression",
    "section": "Terminology",
    "text": "Terminology\n\n\n\nResponse, \\(Y\\): variable describing the outcome of interest\nPredictor, \\(X\\): variable we use to help understand the variability in the response"
  },
  {
    "objectID": "slides/02-slr.html#regression-model",
    "href": "slides/02-slr.html#regression-model",
    "title": "Simple linear regression",
    "section": "Regression model",
    "text": "Regression model\nA regression model is a function that describes the relationship between the response, \\(Y\\), and the predictor, \\(X\\).\n\\[\\begin{aligned} Y &= \\color{black}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{black}{f(X)} + \\epsilon \\\\[8pt]\n& = \\color{black}{E(Y|X)} + \\epsilon \\\\[8pt]\n&= \\color{black}{\\mu_{Y|X}} + \\epsilon \\end{aligned}\\]"
  },
  {
    "objectID": "slides/02-slr.html#regression-model-1",
    "href": "slides/02-slr.html#regression-model-1",
    "title": "Simple linear regression",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\\begin{aligned} Y &= \\color{purple}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{purple}{f(X)} + \\epsilon \\\\[8pt]\n&= \\color{purple}{E(Y|X)} + \\epsilon \\\\[8pt]\n&= \\color{purple}{\\mu_{Y|X}} + \\epsilon \\end{aligned}\\]\n\n\n\n\n\n\n\n\n\n\n\n\\(E(Y|X) = \\mu_{Y|X}\\), the mean value of \\(Y\\) given a particular value of \\(X\\)."
  },
  {
    "objectID": "slides/02-slr.html#regression-model-2",
    "href": "slides/02-slr.html#regression-model-2",
    "title": "Simple linear regression",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\n\\begin{aligned} Y &= \\color{purple}{\\textbf{Model}} + \\color{blue}{\\textbf{Error}} \\\\[8pt]\n&= \\color{purple}{f(X)} + \\color{blue}{\\epsilon}\\\\[8pt]\n&= \\color{purple}{E(Y|X)} + \\color{blue}{\\epsilon}\\\\[8pt]\n&= \\color{purple}{\\mu_{Y|X}} + \\color{blue}{\\epsilon} \\\\\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/02-slr.html#determine-fx",
    "href": "slides/02-slr.html#determine-fx",
    "title": "Simple linear regression",
    "section": "Determine \\(f(X)\\)",
    "text": "Determine \\(f(X)\\)\n\nGoal: Determine \\(f(X)\\)\nHow do we determine \\(f(X)\\)\n\nMake an assumption about the functional form \\(f(X)\\) (parametric model)\nUse the data to fit a model based on that form"
  },
  {
    "objectID": "slides/02-slr.html#slr-statistical-model-population",
    "href": "slides/02-slr.html#slr-statistical-model-population",
    "title": "Simple linear regression",
    "section": "SLR: Statistical model (population)",
    "text": "SLR: Statistical model (population)\nWhen we have a quantitative response, \\(Y\\), and a single quantitative predictor, \\(X\\), we can use a simple linear regression model to describe the relationship between \\(Y\\) and \\(X\\). \\[\\large{Y = \\mathbf{\\beta_0 + \\beta_1 X} + \\epsilon}, \\hspace{8mm} \\epsilon \\sim N(0, \\sigma_{\\epsilon}^2)\\]\n\n\n\\(\\beta_1\\): Population (true) slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\beta_0\\): Population (true) intercept of the relationship between \\(X\\) and \\(Y\\)\n\\(\\epsilon\\): Error"
  },
  {
    "objectID": "slides/02-slr.html#slr-regression-equation-sample",
    "href": "slides/02-slr.html#slr-regression-equation-sample",
    "title": "Simple linear regression",
    "section": "SLR: Regression equation (sample)",
    "text": "SLR: Regression equation (sample)\n\\[\\Large{\\hat{Y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 X}\\]\n\n\\(\\hat{\\beta}_1\\): Estimated (sample) slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\hat{\\beta}_0\\): Estimated (sample) intercept of the relationship between \\(X\\) and \\(Y\\)\nNo error term!"
  },
  {
    "objectID": "slides/02-slr.html#choosing-values-for-hatbeta_1-and-hatbeta_0",
    "href": "slides/02-slr.html#choosing-values-for-hatbeta_1-and-hatbeta_0",
    "title": "Simple linear regression",
    "section": "Choosing values for \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\)",
    "text": "Choosing values for \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\)"
  },
  {
    "objectID": "slides/02-slr.html#residuals",
    "href": "slides/02-slr.html#residuals",
    "title": "Simple linear regression",
    "section": "Residuals",
    "text": "Residuals\n\n\\[\\text{residual} = \\text{observed} - \\text{predicted} = y_i - \\hat{y}_i\\]"
  },
  {
    "objectID": "slides/02-slr.html#least-squares-line",
    "href": "slides/02-slr.html#least-squares-line",
    "title": "Simple linear regression",
    "section": "Least squares line",
    "text": "Least squares line\n\nThe residual for the \\(i^{th}\\) observation is\n\n\\[e_i = \\text{observed} - \\text{predicted}\n= y_i - \\hat{y}_i\\]\n\nThe sum of squared residuals is\n\n\\[e^2_1 + e^2_2 + \\dots + e^2_n\\]\n\nThe least squares line is the one that minimizes the sum of squared residuals\n\nClick here for full calculations."
  },
  {
    "objectID": "slides/02-slr.html#properties-of-least-squares-regression",
    "href": "slides/02-slr.html#properties-of-least-squares-regression",
    "title": "Simple linear regression",
    "section": "Properties of least squares regression",
    "text": "Properties of least squares regression\n\n\nThe regression line goes through the center of mass point, the coordinates corresponding to average \\(X\\) and average \\(Y\\): \\(\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1\\bar{X}\\)\nThe slope has the same sign as the correlation coefficient: \\(\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}\\)\nThe sum of the residuals is approximately zero: \\(\\sum_{i = 1}^n e_i \\approx 0\\)\nThe residuals and \\(X\\) values are uncorrelated"
  },
  {
    "objectID": "slides/02-slr.html#estimating-the-slope",
    "href": "slides/02-slr.html#estimating-the-slope",
    "title": "Simple linear regression",
    "section": "Estimating the slope",
    "text": "Estimating the slope\n\\[\\large{\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}}\\]\n\n\n\\[\n\\begin{aligned} s_X = 30.1688  \\hspace{15mm} &s_Y =  20.0244 \\hspace{15mm} r  = 0.7814 \\\\[10pt]\\hat{\\beta}_1  &= 0.7814 \\times \\frac{20.0244}{30.1688} \\\\&= \\mathbf{0.5187}\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/02-slr.html#estimating-the-intercept",
    "href": "slides/02-slr.html#estimating-the-intercept",
    "title": "Simple linear regression",
    "section": "Estimating the intercept",
    "text": "Estimating the intercept\n\\[\\large{\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1\\bar{X}}\\]\n\n\n\\[\n\\begin{aligned}\\bar{x} = 60.8493 & \\hspace{15mm} \\bar{y} = 63.8767 \\hspace{15mm} \\hat{\\beta}_1 = 0.5187 \\\\[10pt]\n\\hat{\\beta}_0 &= 63.8767 - 0.5187 \\times 60.8493 \\\\\n&= \\mathbf{32.3142}\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/02-slr.html#interpretation",
    "href": "slides/02-slr.html#interpretation",
    "title": "Simple linear regression",
    "section": "Interpretation",
    "text": "Interpretation\n\nQuestionSubmit\n\n\n\n\nSubmit your answers to the following questions on Ed Discussion:\n\nThe slope of the model for predicting audience score from critics score is 0.5187 . Which of the following is the best interpretation of this value?\n32.3142 is the predicted mean audience score for what type of movies?\n\n\n\n\n\n\n\n\n\n🔗 https://edstem.org/us/courses/62513/discussion/5181157"
  },
  {
    "objectID": "slides/02-slr.html#does-it-make-sense-to-interpret-the-intercept",
    "href": "slides/02-slr.html#does-it-make-sense-to-interpret-the-intercept",
    "title": "Simple linear regression",
    "section": "Does it make sense to interpret the intercept?",
    "text": "Does it make sense to interpret the intercept?\n\n✅ The intercept is meaningful in the context of the data if\n\nthe predictor can feasibly take values equal to or near zero, or\nthere are values near zero in the observed data.\n\n\n\n🛑 Otherwise, the intercept may not be meaningful!"
  },
  {
    "objectID": "slides/02-slr.html#making-a-prediction",
    "href": "slides/02-slr.html#making-a-prediction",
    "title": "Simple linear regression",
    "section": "Making a prediction",
    "text": "Making a prediction\nSuppose that a movie has a critics score of 70. According to this model, what is the movie’s predicted audience score?\n\\[\\begin{aligned}\n\\widehat{\\text{audience}} &= 32.3142 + 0.5187 \\times \\text{critics} \\\\\n&= 32.3142 + 0.5187 \\times 70 \\\\\n&= \\mathbf{68.6232}\n\\end{aligned}\\]"
  },
  {
    "objectID": "slides/02-slr.html#fit-the-model",
    "href": "slides/02-slr.html#fit-the-model",
    "title": "Simple linear regression",
    "section": "Fit the model",
    "text": "Fit the model\nUse the lm() function to fit a linear regression model\n\n\nmovie_fit &lt;- lm(audience ~ critics, data = movie_scores)\nmovie_fit\n\n\nCall:\nlm(formula = audience ~ critics, data = movie_scores)\n\nCoefficients:\n(Intercept)      critics  \n    32.3155       0.5187"
  },
  {
    "objectID": "slides/02-slr.html#tidy-results",
    "href": "slides/02-slr.html#tidy-results",
    "title": "Simple linear regression",
    "section": "Tidy results",
    "text": "Tidy results\nUse the tidy() function from the broom R package to “tidy” the data\n\n\nmovie_fit &lt;- lm(audience ~ critics, data = movie_scores)\ntidy(movie_fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   32.3      2.34        13.8 4.03e-28\n2 critics        0.519    0.0345      15.0 2.70e-31"
  },
  {
    "objectID": "slides/02-slr.html#format-results",
    "href": "slides/02-slr.html#format-results",
    "title": "Simple linear regression",
    "section": "Format results",
    "text": "Format results\nUse the kable() function from the knitr package to neatly format the results\n\n\n\nmovie_fit &lt;- lm(audience ~ critics, data = movie_scores)\ntidy(movie_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n32.316\n2.343\n13.795\n0\n\n\ncritics\n0.519\n0.035\n15.028\n0"
  },
  {
    "objectID": "slides/02-slr.html#prediction-1",
    "href": "slides/02-slr.html#prediction-1",
    "title": "Simple linear regression",
    "section": "Prediction",
    "text": "Prediction\nUse the predict() function to calculate predictions for new observations\n\nSingle observation\n\nnew_movie &lt;- tibble(critics = 70)\npredict(movie_fit, new_movie)\n\n       1 \n68.62297 \n\n\n\n\nMultiple observations\n\nmore_new_movies &lt;- tibble(critics = c(24,70, 85))\npredict(movie_fit, more_new_movies)\n\n       1        2        3 \n44.76379 68.62297 76.40313"
  },
  {
    "objectID": "slides/02-slr.html#recap",
    "href": "slides/02-slr.html#recap",
    "title": "Simple linear regression",
    "section": "Recap",
    "text": "Recap\n\nDescribed how regression is used to understand the relationship between multiple variables\nUsed least squares to estimate the slope and intercept\nInterpreted the slope and intercept for simple linear regression\nPredicted the response given a value of the predictor"
  },
  {
    "objectID": "slides/02-slr.html#next-time",
    "href": "slides/02-slr.html#next-time",
    "title": "Simple linear regression",
    "section": "Next time",
    "text": "Next time\n\nModel assessment for simple linear regression\n\nSee Sep 3 prepare\n\nBring fully-charged laptop or device with keyboard for in-class application exercise (AE)\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/01-welcome.html#meet-prof.-tackett",
    "href": "slides/01-welcome.html#meet-prof.-tackett",
    "title": "Welcome to STA 221!",
    "section": "Meet Prof. Tackett!",
    "text": "Meet Prof. Tackett!\n\n\nEducation and career journey\n\nBS in Math and MS in Statistics from University of Tennessee\nStatistician at Capital One\nPhD in Statistics from University of Virginia\nAssistant Professor of the Practice, Department of Statistical Science at Duke\n\nWork focuses on statistics education and sense of belonging in introductory math and statistics classes\nCo-leader of the Bass Connections team Mental Health and the Justice System in Durham County\nMom of 19-month-old twins 🙂"
  },
  {
    "objectID": "slides/01-welcome.html#teaching-assistants-tas",
    "href": "slides/01-welcome.html#teaching-assistants-tas",
    "title": "Welcome to STA 221!",
    "section": "Teaching Assistants (TAs)",
    "text": "Teaching Assistants (TAs)\n\nKat Husar (PhD): Head TA + Lab 02 leader\nJon Campbell (MS): Lab 01 leader\nIshrit Gupta (UG): Lab 01 helper\nAlan Wang (UG): Lab 02 helper"
  },
  {
    "objectID": "slides/01-welcome.html#check-in-on-ed-discussion",
    "href": "slides/01-welcome.html#check-in-on-ed-discussion",
    "title": "Welcome to STA 221!",
    "section": "Check-in on Ed Discussion!",
    "text": "Check-in on Ed Discussion!\n\nClick on the link or scan the QR code to answer the Ed Discussion poll\nhttps://edstem.org/us/courses/62513/discussion/625046"
  },
  {
    "objectID": "slides/01-welcome.html#topics",
    "href": "slides/01-welcome.html#topics",
    "title": "Welcome to STA 221!",
    "section": "Topics",
    "text": "Topics\n\nIntroduction to the course\nSyllabus activity\nReproducibility"
  },
  {
    "objectID": "slides/01-welcome.html#what-is-regression-analysis",
    "href": "slides/01-welcome.html#what-is-regression-analysis",
    "title": "Welcome to STA 221!",
    "section": "What is regression analysis?",
    "text": "What is regression analysis?\n\n\nRegression analysis is a statistical method used to examine the relationship between a response variable and one or more predictor variables. It is used for predicting future values, understanding relationships between variables, and identifying key predictors. It also helps in modeling trends, assessing the impact of changes, and detecting outliers in data.\n\nSource: ChatGPT (with modification)"
  },
  {
    "objectID": "slides/01-welcome.html#example-rent-vs.-commute-time",
    "href": "slides/01-welcome.html#example-rent-vs.-commute-time",
    "title": "Welcome to STA 221!",
    "section": "Example: Rent vs. commute time",
    "text": "Example: Rent vs. commute time\nNew Yorkers Will Pay $56 A Month To Trim A Minute Off Their Commute\n\n\\[\n\\text{rent} = \\beta_0 + \\beta_1 ~ \\text{commute_time} + \\epsilon\n\\]\n\n\n\n\\[\n\\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix} =\n\\begin{bmatrix}\n1 & x_1 \\\\\n1 & x_2 \\\\\n\\vdots & \\vdots \\\\\n1 & x_n\n\\end{bmatrix}\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\end{bmatrix} +  \\begin{bmatrix}\n\\epsilon_1 \\\\\n\\epsilon_2 \\\\\n\\vdots \\\\\n\\epsilon_n\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/01-welcome.html#what-is-sta-221",
    "href": "slides/01-welcome.html#what-is-sta-221",
    "title": "Welcome to STA 221!",
    "section": "What is STA 221?",
    "text": "What is STA 221?\n\n\n\n\n\n STA 210 \n\nApplication\n\n\n\n\n+\n\n\n\n\n\nSTA 211\n\nTheory\n\n\n\nPrerequisites: Introductory statistics or probability course and linear algebra\nRecommended corequisite: Probability course at Duke"
  },
  {
    "objectID": "slides/01-welcome.html#course-learning-objectives",
    "href": "slides/01-welcome.html#course-learning-objectives",
    "title": "Welcome to STA 221!",
    "section": "Course learning objectives",
    "text": "Course learning objectives\nBy the end of the semester, you will be able to…\n\nanalyze data to explore real-world multivariable relationships.\nfit, interpret, and draw conclusions from linear and logistic regression models.\nimplement a reproducible analysis workflow using R for analysis, Quarto to write reports and GitHub for version control and collaboration.\nexplain the mathematical foundations of linear and logistic regression.\neffectively communicate statistical results to a general audience.\nassess the ethical considerations and implications of analysis decisions."
  },
  {
    "objectID": "slides/01-welcome.html#course-topics",
    "href": "slides/01-welcome.html#course-topics",
    "title": "Welcome to STA 221!",
    "section": "Course topics",
    "text": "Course topics\n\n\n\n\nLinear regression\n\nCoefficient estimation and interpretation\nPrediction\nModel assessment\nMatrix representation of regression\nEstimators\nModel conditions and diagnostics\nDifferent types of predictor variables\n\n\n\n\n\nLogistic regression\n\nCoefficient estimation and interpretation\nPrediction\nModel assessment\nInference\n\n\n\n\nGeneral topics\n\nComputing using R and GitHub\nPresenting statistical results\nCollaboration and teamwork"
  },
  {
    "objectID": "slides/01-welcome.html#course-toolkit",
    "href": "slides/01-welcome.html#course-toolkit",
    "title": "Welcome to STA 221!",
    "section": "Course toolkit",
    "text": "Course toolkit\n\nWebsite: https://sta221-fa24.netlify.app\n\nCentral hub for the course!\nTour of the website\n\nCanvas: https://canvas.duke.edu/courses/38867\n\nGradebook\nAnnouncements\nGradescope\nEd Discussion\n\nGitHub: https://github.com/sta221-fa24\n\nDistribute assignments\nPlatform for version control and collaboration"
  },
  {
    "objectID": "slides/01-welcome.html#computing-toolkit",
    "href": "slides/01-welcome.html#computing-toolkit",
    "title": "Welcome to STA 221!",
    "section": "Computing toolkit",
    "text": "Computing toolkit\n\n\n\n\n\n\n\n\n\n\n\nAll analyses using R, a statistical programming language\nWrite reproducible reports in Quarto\nAccess RStudio through STA 210 Docker Containers\n\n\n\n\n\n\n\n\n\n\n\n\nAccess assignments\nFacilitates version control and collaboration\nAll work in STA 221 course organization"
  },
  {
    "objectID": "slides/01-welcome.html#classroom-community",
    "href": "slides/01-welcome.html#classroom-community",
    "title": "Welcome to STA 221!",
    "section": "Classroom community",
    "text": "Classroom community\n\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\nIf you have a name that differs from those that appear in your official Duke records, please let me know.\nPlease let me know your preferred pronouns, if you are comfortable sharing.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your advisers and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said or done in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "slides/01-welcome.html#accessibility",
    "href": "slides/01-welcome.html#accessibility",
    "title": "Welcome to STA 221!",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nIf you have documented accommodations from SDAO, please send the documentation as soon as possible.\nI am committed to making all course activities and materials accessible. If any course component is not accessible to you in any way, please don’t hesitate to let me know."
  },
  {
    "objectID": "slides/01-welcome.html#syllabus-activity",
    "href": "slides/01-welcome.html#syllabus-activity",
    "title": "Welcome to STA 221!",
    "section": "Syllabus activity",
    "text": "Syllabus activity\n\n\nIntroduce yourself to your group members.\nChoose a reporter. This person will share the group’s summary with the class.\nRead the portion of the syllabus assigned to your group.\nDiscuss the key points and questions you my have.\nThe reporter will share a summary with the class."
  },
  {
    "objectID": "slides/01-welcome.html#syllabus-activity-assignments",
    "href": "slides/01-welcome.html#syllabus-activity-assignments",
    "title": "Welcome to STA 221!",
    "section": "Syllabus activity assignments",
    "text": "Syllabus activity assignments\n\nGroup 1: What to expect in lectures and labs\nGroup 2: Homework and lab assignments\nGroup 3: Exams and project\nGroup 4: Participation (Application exercises + teamwork)\nGroup 5: Academic honesty (except AI policy)\nGroup 6: Artificial intelligence policy\nGroup 7: Late work policy and waiver for extenuating circumstances\nGroup 8: Attendance and lecture recording request\nGroup 9: Getting help in the course"
  },
  {
    "objectID": "slides/01-welcome.html#syllabus-activity-report-out",
    "href": "slides/01-welcome.html#syllabus-activity-report-out",
    "title": "Welcome to STA 221!",
    "section": "Syllabus activity report out",
    "text": "Syllabus activity report out\n\n\nGroup 1: What to expect in lectures and labs\nGroup 2: Homework and lab assignments\nGroup 3: Exams and project\nGroup 4: Participation (Application exercises + teamwork)\nGroup 5: Academic honesty (except AI policy)\nGroup 6: Artificial intelligence policy\nGroup 7: Late work policy and waiver for extenuating circumstances\nGroup 8: Attendance and lecture recording request\nGroup 9: Getting help in the course"
  },
  {
    "objectID": "slides/01-welcome.html#grading",
    "href": "slides/01-welcome.html#grading",
    "title": "Welcome to STA 221!",
    "section": "Grading",
    "text": "Grading\n\n\n\nCategory\nPercentage\n\n\n\n\nHomework\n25%\n\n\nFinal project\n15%\n\n\nLab\n15%\n\n\nExam 01\n20%\n\n\nExam 02\n20%\n\n\nParticipation (AEs and teamwork)\n5%\n\n\nTotal\n100%"
  },
  {
    "objectID": "slides/01-welcome.html#five-tips-for-success-in-sta-221",
    "href": "slides/01-welcome.html#five-tips-for-success-in-sta-221",
    "title": "Welcome to STA 221!",
    "section": "Five tips for success in STA 221",
    "text": "Five tips for success in STA 221\n\nComplete all the preparation work before class.\nAsk questions in class, office hours, and on Ed Discussion.\nDo the homework and labs; get started on homework early when possible.\nDon’t procrastinate and don’t let a week pass by with lingering questions.\nStay up-to-date on announcements on Ed Discussion and sent via email."
  },
  {
    "objectID": "slides/01-welcome.html#reproducibility-checklist",
    "href": "slides/01-welcome.html#reproducibility-checklist",
    "title": "Welcome to STA 221!",
    "section": "Reproducibility checklist",
    "text": "Reproducibility checklist\n\nWhat does it mean for an analysis to be reproducible?\n\n\nNear term goals:\n✔️ Can the tables and figures be exactly reproduced from the code and data?\n✔️ Does the code actually do what you think it does?\n✔️ In addition to what was done, is it clear why it was done?\n\n\nLong term goals:\n✔️ Can the code be used for other data?\n✔️ Can you extend the code to do other things?"
  },
  {
    "objectID": "slides/01-welcome.html#why-is-reproducibility-important",
    "href": "slides/01-welcome.html#why-is-reproducibility-important",
    "title": "Welcome to STA 221!",
    "section": "Why is reproducibility important?",
    "text": "Why is reproducibility important?\n\nResults produced are more reliable and trustworthy (Ostblom and Timbers 2022)\nFacilitates more effective collaboration (Ostblom and Timbers 2022)\nContributing to science, which builds and organizes knowledge in terms of testable hypotheses (Alexander 2023)\nPossible to identify and correct errors or biases in the analysis process (Alexander 2023)"
  },
  {
    "objectID": "slides/01-welcome.html#toolkit",
    "href": "slides/01-welcome.html#toolkit",
    "title": "Welcome to STA 221!",
    "section": "Toolkit",
    "text": "Toolkit\n\nScriptability \\(\\rightarrow\\) R\nLiterate programming (code, narrative, output in one place) \\(\\rightarrow\\) Quarto\nVersion control \\(\\rightarrow\\) Git / GitHub"
  },
  {
    "objectID": "slides/01-welcome.html#r-and-rstudio",
    "href": "slides/01-welcome.html#r-and-rstudio",
    "title": "Welcome to STA 221!",
    "section": "R and RStudio",
    "text": "R and RStudio\n\nR is a statistical programming language\nRStudio is a convenient interface for R (an integrated development environment, IDE)\n\n\nSource: Statistical Inference via Data Science"
  },
  {
    "objectID": "slides/01-welcome.html#rstudio-ide",
    "href": "slides/01-welcome.html#rstudio-ide",
    "title": "Welcome to STA 221!",
    "section": "RStudio IDE",
    "text": "RStudio IDE"
  },
  {
    "objectID": "slides/01-welcome.html#quarto",
    "href": "slides/01-welcome.html#quarto",
    "title": "Welcome to STA 221!",
    "section": "Quarto",
    "text": "Quarto\n\nFully reproducible reports – the analysis is run from the beginning each time you render\nCode goes in chunks and narrative goes outside of chunks\nVisual editor to make document editing experience similar to a word processor (Google docs, Word, Pages, etc.)"
  },
  {
    "objectID": "slides/01-welcome.html#quarto-1",
    "href": "slides/01-welcome.html#quarto-1",
    "title": "Welcome to STA 221!",
    "section": "Quarto",
    "text": "Quarto"
  },
  {
    "objectID": "slides/01-welcome.html#how-will-we-use-quarto",
    "href": "slides/01-welcome.html#how-will-we-use-quarto",
    "title": "Welcome to STA 221!",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n\nEvery application exercise and assignment is written in a Quarto document\nYou’ll have a template Quarto document to start with\nThe amount of scaffolding in the template will decrease over the semester"
  },
  {
    "objectID": "slides/01-welcome.html#what-is-versioning",
    "href": "slides/01-welcome.html#what-is-versioning",
    "title": "Welcome to STA 221!",
    "section": "What is versioning?",
    "text": "What is versioning?"
  },
  {
    "objectID": "slides/01-welcome.html#what-is-versioning-1",
    "href": "slides/01-welcome.html#what-is-versioning-1",
    "title": "Welcome to STA 221!",
    "section": "What is versioning?",
    "text": "What is versioning?\nwith human readable messages"
  },
  {
    "objectID": "slides/01-welcome.html#why-do-we-need-version-control",
    "href": "slides/01-welcome.html#why-do-we-need-version-control",
    "title": "Welcome to STA 221!",
    "section": "Why do we need version control?",
    "text": "Why do we need version control?\n\n\n\n\n\n\n\n\nProvides a clear record of how the analysis methods evolved. This makes analysis auditable and thus more trustworthy and reliable. (Ostblom and Timbers 2022)"
  },
  {
    "objectID": "slides/01-welcome.html#git-and-github",
    "href": "slides/01-welcome.html#git-and-github",
    "title": "Welcome to STA 221!",
    "section": "git and GitHub",
    "text": "git and GitHub\n\n\ngit is a version control system – like “Track Changes” features from Microsoft Word.\nGitHub is the home for your git-based projects on the internet (like DropBox but much better).\nThere are a lot of git commands and very few people know them all. 99% of the time you will use git to add, commit, push, and pull."
  },
  {
    "objectID": "slides/01-welcome.html#this-week",
    "href": "slides/01-welcome.html#this-week",
    "title": "Welcome to STA 221!",
    "section": "This week",
    "text": "This week\n\nComplete Lab 00 tasks\nReview syllabus\nComplete reading to prepare for Thursday’s lecture\nThursday’s lecture: Simple linear regression"
  },
  {
    "objectID": "slides/01-welcome.html#references",
    "href": "slides/01-welcome.html#references",
    "title": "Welcome to STA 221!",
    "section": "References",
    "text": "References\n\n\n\n\n🔗 STA 221 - Fall 2024\n\n\n\n\nAlexander, Rohan. 2023. “Telling Stories with Data,” June. https://doi.org/10.1201/9781003229407.\n\n\nOstblom, Joel, and Tiffany Timbers. 2022. “Opinionated Practices for Teaching Reproducibility: Motivation, Guided Instruction and Practice.” Journal of Statistics and Data Science Education 30 (3): 241–50. https://doi.org/10.1080/26939169.2022.2074922."
  },
  {
    "objectID": "slides/09-inference-pt2.html#announcements",
    "href": "slides/09-inference-pt2.html#announcements",
    "title": "Inference for regression",
    "section": "Announcements",
    "text": "Announcements\n\nProject\n\nResearch questions due Thursday at 11:59pm\nProposal due Thursday, October 3 at 11:59pm\n\nLab 03 due Thursday, October 3 at 11:59pm\nStatistics experience due Tue, Nov 26 at 11:59pm"
  },
  {
    "objectID": "slides/09-inference-pt2.html#topics",
    "href": "slides/09-inference-pt2.html#topics",
    "title": "Inference for regression",
    "section": "Topics",
    "text": "Topics\n\nUnderstand statistical inference in the context of regression\nDescribe the assumptions for regression\nUnderstand connection between distribution of residuals and inferential procedures\nConduct inference on a single coefficient\nConduct inference on the overall regression model"
  },
  {
    "objectID": "slides/09-inference-pt2.html#computing-setup",
    "href": "slides/09-inference-pt2.html#computing-setup",
    "title": "Inference for regression",
    "section": "Computing setup",
    "text": "Computing setup\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(kableExtra)  \nlibrary(patchwork)   \n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/09-inference-pt2.html#data-ncaa-football-expenditures",
    "href": "slides/09-inference-pt2.html#data-ncaa-football-expenditures",
    "title": "Inference for regression",
    "section": "Data: NCAA Football expenditures",
    "text": "Data: NCAA Football expenditures\nToday’s data come from Equity in Athletics Data Analysis and includes information about sports expenditures and revenues for colleges and universities in the United States. This data set was featured in a March 2022 Tidy Tuesday.\nWe will focus on the 2019 - 2020 season expenditures on football for institutions in the NCAA - Division 1 FBS. The variables are :\n\ntotal_exp_m: Total expenditures on football in the 2019 - 2020 academic year (in millions USD)\nenrollment_th: Total student enrollment in the 2019 - 2020 academic year (in thousands)\ntype: institution type (Public or Private)\n\n\nfootball &lt;- read_csv(\"data/ncaa-football-exp.csv\")"
  },
  {
    "objectID": "slides/09-inference-pt2.html#univariate-eda",
    "href": "slides/09-inference-pt2.html#univariate-eda",
    "title": "Inference for regression",
    "section": "Univariate EDA",
    "text": "Univariate EDA"
  },
  {
    "objectID": "slides/09-inference-pt2.html#bivariate-eda",
    "href": "slides/09-inference-pt2.html#bivariate-eda",
    "title": "Inference for regression",
    "section": "Bivariate EDA",
    "text": "Bivariate EDA"
  },
  {
    "objectID": "slides/09-inference-pt2.html#regression-model",
    "href": "slides/09-inference-pt2.html#regression-model",
    "title": "Inference for regression",
    "section": "Regression model",
    "text": "Regression model\n\nexp_fit &lt;- lm(total_exp_m ~ enrollment_th + type, data = football)\ntidy(exp_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0\n\n\n\n\n\n\nFor every additional 1,000 students, we expect the institution’s total expenditures on football to increase by $780,000, on average, holding institution type constant."
  },
  {
    "objectID": "slides/09-inference-pt2.html#statistical-inference",
    "href": "slides/09-inference-pt2.html#statistical-inference",
    "title": "Inference for regression",
    "section": "Statistical inference",
    "text": "Statistical inference\n\n\n\nStatistical inference provides methods and tools so we can use the single observed sample to make valid statements (inferences) about the population it comes from\nFor our inferences to be valid, the sample should be representative (ideally random) of the population we’re interested in\n\n\n\n\n\nImage source: Eugene Morgan © Penn State"
  },
  {
    "objectID": "slides/09-inference-pt2.html#inference-for-linear-regression",
    "href": "slides/09-inference-pt2.html#inference-for-linear-regression",
    "title": "Inference for regression",
    "section": "Inference for linear regression",
    "text": "Inference for linear regression\n\nInference based on ANOVA\n\nHypothesis test for the statistical significance of the overall regression model\nHypothesis test for a subset of coefficients\n\nInference for a single coefficient \\(\\beta_j\\)\n\nHypothesis test for a coefficient \\(\\beta_j\\)\nConfidence interval for a coefficient \\(\\beta_j\\)"
  },
  {
    "objectID": "slides/09-inference-pt2.html#linear-regression-model",
    "href": "slides/09-inference-pt2.html#linear-regression-model",
    "title": "Inference for regression",
    "section": "Linear regression model",
    "text": "Linear regression model\n\\[\n\\begin{aligned}\n\\mathbf{y} &= Model + Error \\\\[5pt]\n&= f(\\mathbf{X}) + \\boldsymbol{\\epsilon} \\\\[5pt]\n&= E(\\mathbf{y}|\\mathbf{X}) + \\mathbf{\\epsilon} \\\\[5pt]\n&= \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon}\n\\end{aligned}\n\\]\n\n\n\nWe have discussed multiple ways to find the least squares estimates of \\(\\boldsymbol{\\beta} = \\begin{bmatrix}\\beta_0 \\\\\\beta_1\\end{bmatrix}\\)\n\nNone of these approaches depend on the distribution of \\(\\boldsymbol{\\epsilon}\\)\n\nNow we will use statistical inference to draw conclusions about \\(\\boldsymbol{\\beta}\\) that depend on particular assumptions about the distribution of \\(\\boldsymbol{\\epsilon}\\)"
  },
  {
    "objectID": "slides/09-inference-pt2.html#linear-regression-model-1",
    "href": "slides/09-inference-pt2.html#linear-regression-model-1",
    "title": "Inference for regression",
    "section": "Linear regression model",
    "text": "Linear regression model\n\\[\n\\mathbf{y}|\\mathbf{X} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma_\\epsilon^2\\mathbf{I})\n\\]\n\nImage source: Introduction to the Practice of Statistics (5th ed)"
  },
  {
    "objectID": "slides/09-inference-pt2.html#expected-value-of-mathbfy",
    "href": "slides/09-inference-pt2.html#expected-value-of-mathbfy",
    "title": "Inference for regression",
    "section": "Expected value of \\(\\mathbf{y}\\)",
    "text": "Expected value of \\(\\mathbf{y}\\)\nLet \\(\\mathbf{b} = \\begin{bmatrix}b_1 \\\\ \\vdots \\\\b_p\\end{bmatrix}\\) be a \\(p \\times 1\\) vector of random variables.\n\n\nThen \\(E(\\mathbf{b}) = E\\begin{bmatrix}b_1 \\\\ \\vdots \\\\ b_p\\end{bmatrix} = \\begin{bmatrix}E(b_1) \\\\ \\vdots \\\\ E(b_p)\\end{bmatrix}\\)\n\n\n\n\nUse this to find \\(E(\\mathbf{y}|\\mathbf{X})\\)."
  },
  {
    "objectID": "slides/09-inference-pt2.html#variance",
    "href": "slides/09-inference-pt2.html#variance",
    "title": "Inference for regression",
    "section": "Variance",
    "text": "Variance\nLet \\(\\mathbf{b} = \\begin{bmatrix}b_1 \\\\ \\vdots \\\\b_p\\end{bmatrix}\\) be a \\(p \\times 1\\) vector of independent random variables.\n\n\nThen \\(Var(\\mathbf{b}) = \\begin{bmatrix}Var(b_1) & 0 & \\dots & 0 \\\\ 0 & Var(b_2) & \\dots & 0 \\\\ \\vdots & \\vdots & \\dots & \\cdot \\\\ 0 & 0 & \\dots & Var(b_p)\\end{bmatrix}\\)\n\n\n\n\nUse this to find \\(Var(\\mathbf{y}|\\mathbf{X})\\)."
  },
  {
    "objectID": "slides/09-inference-pt2.html#assumptions-of-regression",
    "href": "slides/09-inference-pt2.html#assumptions-of-regression",
    "title": "Inference for regression",
    "section": "Assumptions of regression",
    "text": "Assumptions of regression\n\n\n\\[\n\\mathbf{y}|\\mathbf{X} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma_\\epsilon^2\\mathbf{I})\n\\]\n\n\n\nImage source: Introduction to the Practice of Statistics (5th ed)\n\n\n\n\nLinearity: There is a linear relationship between the response and predictor variables.\nConstant Variance: The variability about the least squares line is generally constant.\nNormality: The distribution of the residuals is approximately normal.\nIndependence: The residuals are independent from one another."
  },
  {
    "objectID": "slides/09-inference-pt2.html#estimating-sigma2_epsilon",
    "href": "slides/09-inference-pt2.html#estimating-sigma2_epsilon",
    "title": "Inference for regression",
    "section": "Estimating \\(\\sigma^2_{\\epsilon}\\)",
    "text": "Estimating \\(\\sigma^2_{\\epsilon}\\)\n\nOnce we fit the model, we can use the residuals to estimate \\(\\sigma_{\\epsilon}^2\\)\n\\(\\hat{\\sigma}^2_{\\epsilon}\\) is needed for hypothesis testing and constructing confidence intervals for regression\n\n\\[\n\\hat{\\sigma}^2_\\epsilon = \\frac{\\sum_\\limits{i=1}^n(y_i - \\hat{y}_i)^2}{n-p-1} = \\frac{\\sum_\\limits{i=1}^ne_i^2}{n - p - 1} = \\frac{SSR}{n - p - 1}\n\\]\n\nThe regression standard error \\(\\hat{\\sigma}_{\\epsilon}\\) is a measure of the average distance between the observations and regression line\n\n\\[\n\\hat{\\sigma}_\\epsilon = \\sqrt{\\frac{SSR}{n - p - 1}}\n\\]"
  },
  {
    "objectID": "slides/09-inference-pt2.html#inference-for-beta_j",
    "href": "slides/09-inference-pt2.html#inference-for-beta_j",
    "title": "Inference for regression",
    "section": "Inference for \\(\\beta_j\\)",
    "text": "Inference for \\(\\beta_j\\)\nWe often want to conduct inference on individual model coefficients\n\nHypothesis test: Is there a linear relationship between the response and \\(x_j\\)?\nConfidence interval: What is a plausible range of values \\(\\beta_j\\) can take?\n\nBut first we need to understand the distribution of \\(\\hat{\\beta}_j\\)"
  },
  {
    "objectID": "slides/09-inference-pt2.html#sampling-distribution-of-hatbeta_j",
    "href": "slides/09-inference-pt2.html#sampling-distribution-of-hatbeta_j",
    "title": "Inference for regression",
    "section": "Sampling distribution of \\(\\hat{\\beta}_j\\)",
    "text": "Sampling distribution of \\(\\hat{\\beta}_j\\)\n\\[\n\\hat{\\boldsymbol{\\beta}} \\sim N(\\boldsymbol{\\beta}, \\sigma^2_\\epsilon(\\mathbf{X}^T\\mathbf{X})^{-1})\n\\]\nLet \\(\\mathbf{C} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\). Then, for each coefficient \\(\\hat{\\beta}_j\\),\n\n\n\\(E(\\hat{\\beta}_j) = \\boldsymbol{\\beta}_j\\), the \\(j^{th}\\) element of \\(\\boldsymbol{\\beta}\\)\n\\(Var(\\hat{\\beta}_j) = \\sigma^2_{\\epsilon}C_{jj}\\)\n\\(Cov(\\hat{\\beta}_i, \\hat{\\beta}_j) = \\sigma^2_{\\epsilon}C_{ij}\\)"
  },
  {
    "objectID": "slides/09-inference-pt2.html#steps-for-a-hypothesis-test",
    "href": "slides/09-inference-pt2.html#steps-for-a-hypothesis-test",
    "title": "Inference for regression",
    "section": "Steps for a hypothesis test",
    "text": "Steps for a hypothesis test\n\nState the null and alternative hypotheses.\nCalculate a test statistic.\nCalculate the p-value.\nState the conclusion."
  },
  {
    "objectID": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-hypotheses",
    "href": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-hypotheses",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Hypotheses",
    "text": "Hypothesis test for \\(\\beta_j\\): Hypotheses\nWe will generally test the hypotheses:\n\nNull Hypothesis: \\(H_0: \\beta_j = 0\\)\n\nThere is no linear relationship between \\(\\beta_j\\) and \\(y\\) after accounting for the other variables in the model\n\nAlternative hypothesis: \\(H_a: \\beta_j \\neq 0\\)\n\nThere is a linear relationship between \\(\\beta_j\\) and \\(y\\) after accounting for the other variables in the model"
  },
  {
    "objectID": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-test-statistic",
    "href": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-test-statistic",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Test statistic",
    "text": "Hypothesis test for \\(\\beta_j\\): Test statistic\nTest statistic: Number of standard errors the estimate is away from the null hypothesized value\n\\[\n\\text{Test Statstic} = \\frac{\\text{Estimate - Null}}{\\text{Standard error}} \\\\\n\\]\n\n\n\\[T = \\frac{\\hat{\\beta}_j - 0}{SE(\\hat{\\beta}_j)} ~ = ~\\frac{\\hat{\\beta}_j - 0}{\\sqrt{\\hat{\\sigma}^2_\\epsilon C_{jj}}} ~\\sim ~ t_{n-p-1}\n\\]"
  },
  {
    "objectID": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-p-value",
    "href": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-p-value",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): P-value",
    "text": "Hypothesis test for \\(\\beta_j\\): P-value\nThe p-value is the probability of observing a test statistic at least as extreme (in the direction of the alternative hypothesis) from the null value as the one observed\n\\[\np-value = P(|t| &gt; |\\text{test statistic}|),\n\\]\ncalculated from a \\(t\\) distribution with \\(n- p - 1\\) degrees of freedom"
  },
  {
    "objectID": "slides/09-inference-pt2.html#understanding-the-p-value",
    "href": "slides/09-inference-pt2.html#understanding-the-p-value",
    "title": "Inference for regression",
    "section": "Understanding the p-value",
    "text": "Understanding the p-value\n\n\n\nMagnitude of p-value\nInterpretation\n\n\n\n\np-value &lt; 0.01\nstrong evidence against \\(H_0\\)\n\n\n0.01 &lt; p-value &lt; 0.05\nmoderate evidence against \\(H_0\\)\n\n\n0.05 &lt; p-value &lt; 0.1\nweak evidence against \\(H_0\\)\n\n\np-value &gt; 0.1\neffectively no evidence against \\(H_0\\)\n\n\n\nThese are general guidelines. The strength of evidence depends on the context of the problem."
  },
  {
    "objectID": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-conclusion",
    "href": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-conclusion",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Conclusion",
    "text": "Hypothesis test for \\(\\beta_j\\): Conclusion\nThere are two parts to the conclusion\n\nMake a conclusion by comparing the p-value to a predetermined decision-making threshold called the significance level ( \\(\\alpha\\) level)\n\nIf \\(\\text{p-value} &lt; \\alpha\\): Reject \\(H_0\\)\nIf \\(\\text{p-value} \\geq \\alpha\\): Fail to reject \\(H_0\\)\n\nState the conclusion in the context of the data"
  },
  {
    "objectID": "slides/09-inference-pt2.html#confidence-interval-for-beta_j-1",
    "href": "slides/09-inference-pt2.html#confidence-interval-for-beta_j-1",
    "title": "Inference for regression",
    "section": "Confidence interval for \\(\\beta_j\\)",
    "text": "Confidence interval for \\(\\beta_j\\)\n\n\nA plausible range of values for a population parameter is called a confidence interval\nUsing only a single point estimate is like fishing in a murky lake with a spear, and using a confidence interval is like fishing with a net\n\nWe can throw a spear where we saw a fish but we will probably miss, if we toss a net in that area, we have a good chance of catching the fish\nSimilarly, if we report a point estimate, we probably will not hit the exact population parameter, but if we report a range of plausible values we have a good shot at capturing the parameter"
  },
  {
    "objectID": "slides/09-inference-pt2.html#what-confidence-means",
    "href": "slides/09-inference-pt2.html#what-confidence-means",
    "title": "Inference for regression",
    "section": "What “confidence” means",
    "text": "What “confidence” means\n\n\nWe will construct \\(C\\%\\) confidence intervals.\n\nThe confidence level impacts the width of the interval\n\n\n\n\n“Confident” means if we were to take repeated samples of the same size as our data, fit regression lines using the same predictors, and calculate \\(C\\%\\) CIs for the coefficient of \\(x_j\\), then \\(C\\%\\) of those intervals will contain the true value of the coefficient \\(\\beta_j\\)\n\n\n\nBalance precision and accuracy when selecting a confidence level"
  },
  {
    "objectID": "slides/09-inference-pt2.html#confidence-interval-for-beta_j-2",
    "href": "slides/09-inference-pt2.html#confidence-interval-for-beta_j-2",
    "title": "Inference for regression",
    "section": "Confidence interval for \\(\\beta_j\\)",
    "text": "Confidence interval for \\(\\beta_j\\)\n\\[\n\\text{Estimate} \\pm \\text{ (critical value) } \\times \\text{SE}\n\\]\n\n\n\\[\n\\hat{\\beta}_1 \\pm t^* \\times SE({\\hat{\\beta}_j})\n\\]\nwhere \\(t^*\\) is calculated from a \\(t\\) distribution with \\(n-p-1\\) degrees of freedom"
  },
  {
    "objectID": "slides/09-inference-pt2.html#confidence-interval-critical-value",
    "href": "slides/09-inference-pt2.html#confidence-interval-critical-value",
    "title": "Inference for regression",
    "section": "Confidence interval: Critical value",
    "text": "Confidence interval: Critical value\n\n\n# confidence level: 95%\nqt(0.975, df = nrow(football) - 2 - 1)\n\n[1] 1.97928\n\n\n\n\n\n\n# confidence level: 90%\nqt(0.95, df = nrow(football) - 2 - 1)\n\n[1] 1.657235\n\n\n\n\n\n\n# confidence level: 99%\nqt(0.995, df = nrow(football) - 2 - 1)\n\n[1] 2.61606"
  },
  {
    "objectID": "slides/09-inference-pt2.html#ci-for-beta_j-calculation",
    "href": "slides/09-inference-pt2.html#ci-for-beta_j-calculation",
    "title": "Inference for regression",
    "section": "95% CI for \\(\\beta_j\\): Calculation",
    "text": "95% CI for \\(\\beta_j\\): Calculation\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0"
  },
  {
    "objectID": "slides/09-inference-pt2.html#ci-for-beta_j-in-r",
    "href": "slides/09-inference-pt2.html#ci-for-beta_j-in-r",
    "title": "Inference for regression",
    "section": "95% CI for \\(\\beta_j\\) in R",
    "text": "95% CI for \\(\\beta_j\\) in R\n\ntidy(exp_fit, conf.int = TRUE, conf.level = 0.95) |&gt; \n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n13.426\n25.239\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n0.562\n0.999\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0\n-19.466\n-6.986\n\n\n\n\n\n\nInterpretation: We are 95% confident that for each additional 1,000 students enrolled, the institution’s expenditures on football will be greater by $562,000 to $999,000, on average, holding institution type constant."
  },
  {
    "objectID": "slides/09-inference-pt2.html#test-for-overall-significance-hypotheses",
    "href": "slides/09-inference-pt2.html#test-for-overall-significance-hypotheses",
    "title": "Inference for regression",
    "section": "Test for overall significance: Hypotheses",
    "text": "Test for overall significance: Hypotheses\nWe can conduct a hypothesis test using the ANOVA table to determine if there is at least one non-zero coefficient in the model\n\\[\n\\begin{aligned}\n&H_0: \\beta_1 = \\dots = \\beta_p = 0\\\\\n&H_a: \\beta_j \\neq 0 \\text{ for at least one }j\n\\end{aligned}\n\\]\n\nFor the football data\n\\[\n\\begin{aligned}\n&H_0: \\beta_1 = \\beta_2 = 0\\\\\n&H_a: \\beta_j \\neq 0 \\text{ for at least one }j\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/09-inference-pt2.html#test-for-overall-significance-test-statistic",
    "href": "slides/09-inference-pt2.html#test-for-overall-significance-test-statistic",
    "title": "Inference for regression",
    "section": "Test for overall significance: Test statistic",
    "text": "Test for overall significance: Test statistic\n\n\n\n\n\nSource\nDf\nSum Sq\nMean Sq\nF Stat\nPr(&gt; F)\n\n\n\n\nModel\n2\n7138.591\n3569.296\n26.628\n0\n\n\nResiduals\n124\n16621.344\n134.043\n\n\n\n\nTotal\n126\n23759.935\n\n\n\n\n\n\n\n\n\nTest statistic: Ratio of explained to unexplained variability\n\\[\nF = \\frac{\\text{Mean Square Model}}{\\text{Mean Square Residuals}}\n\\]\nThe test statistic follows an \\(F\\) distribution with \\(p\\) and \\(n -  p - 1\\) degrees of freedom"
  },
  {
    "objectID": "slides/09-inference-pt2.html#test-for-overall-significance-p-value",
    "href": "slides/09-inference-pt2.html#test-for-overall-significance-p-value",
    "title": "Inference for regression",
    "section": "Test for overall significance: P-value",
    "text": "Test for overall significance: P-value\n\n\\[\n\\text{P-value} = \\text{Pr}(F &gt; \\text{F Stat})\n\\]"
  },
  {
    "objectID": "slides/09-inference-pt2.html#test-for-overall-significance-conclusion",
    "href": "slides/09-inference-pt2.html#test-for-overall-significance-conclusion",
    "title": "Inference for regression",
    "section": "Test for overall significance: Conclusion",
    "text": "Test for overall significance: Conclusion\n\\[\n\\begin{aligned}\n&H_0: \\beta_1 = \\beta_2 = 0\\\\\n&H_a: \\beta_j \\neq 0 \\text{ for at least one }j\n\\end{aligned}\n\\]\n\nfootball_anova |&gt;\n  kable(digits = 3)\n\n\n\n\nSource\nDf\nSum Sq\nMean Sq\nF Stat\nPr(&gt; F)\n\n\n\n\nModel\n2\n7138.591\n3569.296\n26.628\n0\n\n\nResiduals\n124\n16621.344\n134.043\n\n\n\n\nTotal\n126\n23759.935\n\n\n\n\n\n\n\n\n\nWhat is the conclusion from this hypothesis test?"
  },
  {
    "objectID": "slides/09-inference-pt2.html#recap",
    "href": "slides/09-inference-pt2.html#recap",
    "title": "Inference for regression",
    "section": "Recap",
    "text": "Recap\n\nIntroduced statistical inference in the context of regression\nDescribed the assumptions for regression\nConnected the distribution of residuals and inferential procedures\nConducted inference on a single coefficient\nConducted inference on the overall regression model\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#announcements",
    "href": "slides/07-mlr-pt3.html#announcements",
    "title": "ANOVA + Geometric interpretation",
    "section": "Announcements",
    "text": "Announcements\n\nLab 02 due on Thursday at 11:59pm\n\nPush work to GitHub repo\nSubmit final PDF on Gradescope + select all team members + mark pages for each question\n\nHW 01 due Thursday at 11:59pm\n\nNote submission instructions"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#homework-submission",
    "href": "slides/07-mlr-pt3.html#homework-submission",
    "title": "ANOVA + Geometric interpretation",
    "section": "Homework submission",
    "text": "Homework submission\nIf you write your responses to Exercises 1 - 4 by hand, you will need to combine your written work to the completed PDF for Exercises 5 - 10 before submitting on Gradescope.\nInstructions to combine PDFs:\n\nPreview (Mac): support.apple.com/guide/preview/combine-pdfs-prvw43696/mac\nAdobe (Mac or PC): helpx.adobe.com/acrobat/using/merging-files-single-pdf.html\n\nGet free access to Adobe Acrobat as a Duke student: oit.duke.edu/help/articles/kb0030141/"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#latex-in-this-class",
    "href": "slides/07-mlr-pt3.html#latex-in-this-class",
    "title": "ANOVA + Geometric interpretation",
    "section": "Latex in this class",
    "text": "Latex in this class\nFor this class you will need to be able to…\n\nProperly write mathematical symbols, e.g., \\(\\beta_1\\) not B1, \\(R^2\\) not R2\nWrite basic regression equations, e.g., \\(\\hat{y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2\\)\nWrite matrix equations: \\(\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\\)\nWrite hypotheses (we’ll start this next week), e.g., \\(H_0: \\beta = 0\\)\n\nYou are welcome to but not required to write math proofs using LaTex."
  },
  {
    "objectID": "slides/07-mlr-pt3.html#topics",
    "href": "slides/07-mlr-pt3.html#topics",
    "title": "ANOVA + Geometric interpretation",
    "section": "Topics",
    "text": "Topics\n\nCompare models using Adjusted \\(R^2\\)\nIntroduce the ANOVA table\nUse a geometric interpretation to find the least squares estimates"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#computing-setup",
    "href": "slides/07-mlr-pt3.html#computing-setup",
    "title": "ANOVA + Geometric interpretation",
    "section": "Computing setup",
    "text": "Computing setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(viridis) #adjust color palette\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#data-peer-to-peer-lender",
    "href": "slides/07-mlr-pt3.html#data-peer-to-peer-lender",
    "title": "ANOVA + Geometric interpretation",
    "section": "Data: Peer-to-peer lender",
    "text": "Data: Peer-to-peer lender\nToday’s data is a sample of 50 loans made through a peer-to-peer lending club. The data is in the loan50 data frame in the openintro R package.\n\n\n# A tibble: 50 × 4\n   annual_income_th debt_to_income verified_income interest_rate\n              &lt;dbl&gt;          &lt;dbl&gt; &lt;fct&gt;                   &lt;dbl&gt;\n 1             59           0.558  Not Verified            10.9 \n 2             60           1.31   Not Verified             9.92\n 3             75           1.06   Verified                26.3 \n 4             75           0.574  Not Verified             9.92\n 5            254           0.238  Not Verified             9.43\n 6             67           1.08   Source Verified          9.92\n 7             28.8         0.0997 Source Verified         17.1 \n 8             80           0.351  Not Verified             6.08\n 9             34           0.698  Not Verified             7.97\n10             80           0.167  Source Verified         12.6 \n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#variables",
    "href": "slides/07-mlr-pt3.html#variables",
    "title": "ANOVA + Geometric interpretation",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\n\nannual_income_th: Annual income (in $1000s)\ndebt_to_income: Debt-to-income ratio, i.e. the percentage of a borrower’s total debt divided by their total income\nverified_income: Whether borrower’s income source and amount have been verified (Not Verified, Source Verified, Verified)\n\n\nResponse: interest_rate: Interest rate for the loan"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#model-fit-in-r",
    "href": "slides/07-mlr-pt3.html#model-fit-in-r",
    "title": "ANOVA + Geometric interpretation",
    "section": "Model fit in R",
    "text": "Model fit in R\n\nint_fit &lt;- lm(interest_rate ~ debt_to_income + verified_income  + annual_income_th, data = loan50)\n\nint_fit2 &lt;- lm(interest_rate ~ debt_to_income + verified_income  + annual_income_th + verified_income * annual_income_th, data = loan50)"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#rmse-r2",
    "href": "slides/07-mlr-pt3.html#rmse-r2",
    "title": "ANOVA + Geometric interpretation",
    "section": "RMSE & \\(R^2\\)",
    "text": "RMSE & \\(R^2\\)\n\nRoot mean square error, RMSE: A measure of the average error (average difference between observed and predicted values of the outcome)\nR-squared, \\(R^2\\) : Percentage of variability in the outcome explained by the regression model"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#comparing-models",
    "href": "slides/07-mlr-pt3.html#comparing-models",
    "title": "ANOVA + Geometric interpretation",
    "section": "Comparing models",
    "text": "Comparing models\n\n\nThough we use \\(R^2\\) to assess the model fit, it is generally unreliable for comparing models with different number of predictors. Why?\n\n\\(R^2\\) will stay the same or increase as we add more variables to the model . Let’s show why this is true.\nIf we only use \\(R^2\\) to choose a best fit model, we will be prone to choose the model with the most predictor variables."
  },
  {
    "objectID": "slides/07-mlr-pt3.html#adjusted-r2",
    "href": "slides/07-mlr-pt3.html#adjusted-r2",
    "title": "ANOVA + Geometric interpretation",
    "section": "Adjusted \\(R^2\\)",
    "text": "Adjusted \\(R^2\\)\n\nAdjusted \\(R^2\\): measure that includes a penalty for unnecessary predictor variables\nSimilar to \\(R^2\\), it is a measure of the amount of variation in the response that is explained by the regression model"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#r2-and-adjusted-r2",
    "href": "slides/07-mlr-pt3.html#r2-and-adjusted-r2",
    "title": "ANOVA + Geometric interpretation",
    "section": "\\(R^2\\) and Adjusted \\(R^2\\)",
    "text": "\\(R^2\\) and Adjusted \\(R^2\\)\n\\[R^2 = \\frac{SSM}{SST} = 1 - \\frac{SSR}{SST}\\]\n\n\n\\[R^2_{adj} = 1 - \\frac{SSR/(n-p-1)}{SST/(n-1)}\\]\nwhere\n\n\\(n\\) is the number of observations used to fit the model\n\\(p\\) is the number of terms (not including the intercept) in the model"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#compare-models",
    "href": "slides/07-mlr-pt3.html#compare-models",
    "title": "ANOVA + Geometric interpretation",
    "section": "Compare models",
    "text": "Compare models\nWhich model would you select int_fit (main effects only) or int_fit2 (main effects + interaction) based on…\n\\(R^2\\)\n\nglance(int_fit)$r.squared\n\n[1] 0.279854\n\nglance(int_fit2)$r.squared\n\n[1] 0.2963437\n\n\n\n\\(Adj. R^2\\)\n\nglance(int_fit)$adj.r.squared\n\n[1] 0.215841\n\nglance(int_fit2)$adj.r.squared\n\n[1] 0.1981591"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#anova-table",
    "href": "slides/07-mlr-pt3.html#anova-table",
    "title": "ANOVA + Geometric interpretation",
    "section": "ANOVA table",
    "text": "ANOVA table\n\n\n\nSource\nSum of squares\nDF\nMean square\nF\n\n\n\n\nModel\n\\(\\sum_{i=1}^n(\\hat{y}_i - \\bar{y})^2\\)\n\\(p\\)\n\\(SSM / p\\)\n\\(MSM / MSR\\)\n\n\nResidual\n\\(\\sum_{i=1}^n(y_i- \\hat{y}_i)^2\\)\n\\(n - p - 1\\)\n\\(SSR / (n - p - 1)\\)\n\n\n\nTotal\n\\(\\sum_{i = 1}^n(y_i - \\bar{y})^2\\)\n\\(n - 1\\)\n\n\n\n\n\n\n\n\nThe degrees of freedom (df) are the number of independent pieces of information used to calculate a statistic.\nMean square (MS) is the sum of squares divided by the associated degrees of freedom."
  },
  {
    "objectID": "slides/07-mlr-pt3.html#using-r2-and-adjusted-r2",
    "href": "slides/07-mlr-pt3.html#using-r2-and-adjusted-r2",
    "title": "ANOVA + Geometric interpretation",
    "section": "Using \\(R^2\\) and Adjusted \\(R^2\\)",
    "text": "Using \\(R^2\\) and Adjusted \\(R^2\\)\n\nAdjusted \\(R^2\\) can be used as a quick assessment to compare the fit of multiple models; however, it should not be the only assessment!\nUse \\(R^2\\) when describing the relationship between the response and predictor variables"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#geometry-of-least-squares-regression",
    "href": "slides/07-mlr-pt3.html#geometry-of-least-squares-regression",
    "title": "ANOVA + Geometric interpretation",
    "section": "Geometry of least squares regression",
    "text": "Geometry of least squares regression\n\n\nLet \\(\\text{Col}(\\mathbf{X})\\) be the column space of \\(\\mathbf{X}\\): the set all possible linear combinations (span) of the columns of \\(\\mathbf{X}\\)\nThe vector of responses \\(\\mathbf{y}\\) is not in \\(\\text{Col}(\\mathbf{X})\\).\nGoal: Find another vector \\(\\mathbf{z} = \\mathbf{Xb}\\) that is in \\(\\text{Col}(\\mathbf{X})\\) and is as close as possible to \\(\\mathbf{y}\\).\n\n\\(\\mathbf{z}\\) is called a projection of \\(\\mathbf{y}\\) onto \\(\\text{Col}(\\mathbf{X})\\) ."
  },
  {
    "objectID": "slides/07-mlr-pt3.html#geometry-of-least-squares-regression-1",
    "href": "slides/07-mlr-pt3.html#geometry-of-least-squares-regression-1",
    "title": "ANOVA + Geometric interpretation",
    "section": "Geometry of least squares regression",
    "text": "Geometry of least squares regression\n\n\nFor any \\(\\mathbf{z} = \\mathbf{Xb}\\) in \\(\\text{Col}(\\mathbf{X})\\), the vector \\(\\mathbf{e} = \\mathbf{y} - \\mathbf{Xb}\\) is the difference between \\(\\mathbf{y}\\) and \\(\\mathbf{Xb}\\).\n\nIn other words, we want to minimize \\(||\\mathbf{e}||^2 = ||\\mathbf{y} - \\mathbf{Xb}||^2\\)\n\nThis is minimized for the \\(\\mathbf{b}\\) ( we’ll call it \\(\\hat{\\boldsymbol{\\beta}}\\) ) that makes \\(\\mathbf{e}\\) orthogonal to \\(\\text{Col}(\\mathbf{X})\\)\nRecall: If \\(\\mathbf{e}\\) is orthogonal to \\(\\text{Col}(\\mathbf{X})\\), then the inner product of any vector in \\(\\text{Col}(\\mathbf{X})\\) and \\(\\mathbf{e}\\) is 0 \\(\\Rightarrow \\mathbf{X}^T\\mathbf{e} = \\mathbf{0}\\)"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#geometry-of-least-squares-regression-2",
    "href": "slides/07-mlr-pt3.html#geometry-of-least-squares-regression-2",
    "title": "ANOVA + Geometric interpretation",
    "section": "Geometry of least squares regression",
    "text": "Geometry of least squares regression\n\nTherefore, we have\n\n\\[\n\\mathbf{X}^T(\\mathbf{y} - \\mathbf{Xb}) = \\mathbf{0}\n\\]\nLet’s solve for \\(\\mathbf{b}\\) to get the least squares estimate."
  },
  {
    "objectID": "slides/07-mlr-pt3.html#recap",
    "href": "slides/07-mlr-pt3.html#recap",
    "title": "ANOVA + Geometric interpretation",
    "section": "Recap",
    "text": "Recap\n\nCompared models using Adjusted \\(R^2\\)\nIntroduced the ANOVA table\nUsed a geometric interpretation to find the least squares estimates"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#next-class",
    "href": "slides/07-mlr-pt3.html#next-class",
    "title": "ANOVA + Geometric interpretation",
    "section": "Next class",
    "text": "Next class\n\nInference for regression\nSee Sep 19 prepare\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/13-mle.html#announcements",
    "href": "slides/13-mle.html#announcements",
    "title": "Maximum likelihood estimation",
    "section": "Announcements",
    "text": "Announcements\n\nOffice hours:\n\nThis week: Thursday - Friday\nNext week: Wednesday - Friday\n\nNo class next Monday or Tuesday\n\n\n\n🍁 Have a good Fall Break! 🍁"
  },
  {
    "objectID": "slides/13-mle.html#topics",
    "href": "slides/13-mle.html#topics",
    "title": "Maximum likelihood estimation",
    "section": "Topics",
    "text": "Topics\n\nLikelihood\nMaximum likelihood estimation\nMLE for linear regression\nProperties of maximum likelihood estimator"
  },
  {
    "objectID": "slides/13-mle.html#motivation",
    "href": "slides/13-mle.html#motivation",
    "title": "Maximum likelihood estimation",
    "section": "Motivation",
    "text": "Motivation\n\n\nWe can find the estimators of \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2_{\\epsilon}\\) for the model\n\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}, \\hspace{10mm} \\boldsymbol{\\epsilon} \\sim N(0, \\sigma^2_\\epsilon\\mathbf{I})\n\\]using least-squares estimation\n\nWe have also shown some nice properties of the least-squares estimator \\(\\hat{\\boldsymbol{\\beta}}\\), given \\(E(\\boldsymbol{\\epsilon}) = \\mathbf{0}\\) and \\(Var(\\boldsymbol{\\epsilon}) = \\sigma^2_{\\epsilon}\\mathbf{I}\\)\nToday we will introduce another way to find these estimators - maximum likelihood estimation. We will see…\n\nthe maximum likelihood estimators have nice properties\nthe least-squares estimator is equal to the maximum likelihood estimator when certain assumptions hold"
  },
  {
    "objectID": "slides/13-mle.html#example-shooting-free-throws",
    "href": "slides/13-mle.html#example-shooting-free-throws",
    "title": "Maximum likelihood estimation",
    "section": "Example: Shooting free throws",
    "text": "Example: Shooting free throws\nSuppose a basketball player shoots a single free throw, such that the probability of making a basket is \\(p\\)\n\n\n\nWhat is the probability distribution for this random phenomenon?\nSuppose the probability is \\(p = 0.5\\)? What is the probability the player makes a single shot, given this value of \\(p\\)?\nSuppose the probability is \\(p = 0.8\\)? What is the probability the player makes a single shot, given this value of \\(p\\)?"
  },
  {
    "objectID": "slides/13-mle.html#shooting-three-free-throws",
    "href": "slides/13-mle.html#shooting-three-free-throws",
    "title": "Maximum likelihood estimation",
    "section": "Shooting three free throws",
    "text": "Shooting three free throws\nSuppose the player shoots three free throws. They are all independent and the player has the same probability \\(p\\) of making each shot.\nLet \\(B\\) represent a made basket, and \\(M\\) represent a missed basket. The player shoots three free throws with the outcome \\(BBM\\).\n\n\n\nSuppose the probability is \\(p = 0.5\\)? What is the probability of observing the data \\(BBM\\), given this value of \\(p\\)?\nSuppose the probability is \\(p = 0.3\\)? What is the probability of observing the data \\(BBM\\), given this value of \\(p\\) ?"
  },
  {
    "objectID": "slides/13-mle.html#shooting-three-free-throws-1",
    "href": "slides/13-mle.html#shooting-three-free-throws-1",
    "title": "Maximum likelihood estimation",
    "section": "Shooting three free throws",
    "text": "Shooting three free throws\nSuppose the player shoots three free throws. They are all independent and the player has the same probability \\(p\\) of making each shot.\nThe player shoots three free throws with the outcome \\(BBM\\).\n\n\n\nHow would you describe in words the probabilities we previously calculated?\nNew question: What parameter value of \\(p\\) do you think maximizes the probability of observing this data?\nWe will use a likelihood function to answer this question."
  },
  {
    "objectID": "slides/13-mle.html#likelihood",
    "href": "slides/13-mle.html#likelihood",
    "title": "Maximum likelihood estimation",
    "section": "Likelihood",
    "text": "Likelihood\n\n\nA likelihood is a function that tells us how likely we are to observe our data for a given parameter value (or values). \nNote that this is not the same as the probability function.\nProbability function: Fixed parameter value(s) + input possible outcomes \\(\\Rightarrow\\) probability of seeing the different outcomes given the parameter value(s)\nLikelihood function: Fixed data + input possible parameter values \\(\\Rightarrow\\) probability of seeing the fixed data for each parameter value"
  },
  {
    "objectID": "slides/13-mle.html#likelihood-shooting-three-free-throws",
    "href": "slides/13-mle.html#likelihood-shooting-three-free-throws",
    "title": "Maximum likelihood estimation",
    "section": "Likelihood: shooting three free throws",
    "text": "Likelihood: shooting three free throws\nThe likelihood function for the probability of a basket \\(p\\) given we observed \\(BBM\\) when shooting three independent free throws is \\[\nL(p|BBM) = p \\times p \\times (1 - p)\n\\]\n\n\nThus, if the likelihood for \\(p = 0.8\\) is\n\\[\nL(p = 0.8|BBM) = 0.8 \\times 0.8 \\times (1 - 0.8) = 0.128\n\\]"
  },
  {
    "objectID": "slides/13-mle.html#likelihood-shooting-three-free-throws-1",
    "href": "slides/13-mle.html#likelihood-shooting-three-free-throws-1",
    "title": "Maximum likelihood estimation",
    "section": "Likelihood: shooting three free throws",
    "text": "Likelihood: shooting three free throws\n\nWhat is the general formula for the likelihood function for \\(p\\) given the observed data \\(BBM\\)?\nWhy do we need to assume independence?\nWhy does having identically distributed data simplify things?"
  },
  {
    "objectID": "slides/13-mle.html#likelihood-shooting-three-free-throws-2",
    "href": "slides/13-mle.html#likelihood-shooting-three-free-throws-2",
    "title": "Maximum likelihood estimation",
    "section": "Likelihood: shooting three free throws",
    "text": "Likelihood: shooting three free throws\nThe likelihood function for \\(p\\) given the data \\(BBM\\) is\n\\[\nL(p|BBM) = p \\times p \\times (1 - p) = p^2 \\times (1 - p)\n\\]\n\n\n\nWe want of the value of \\(p\\) that maximizes this likelihood function, i.e., the value of \\(p\\) that is most likely given the observed data.\nThe process of finding this value is maximum likelihood estimation.\nThere are three primary ways to find the maximum likelihood estimator\n\nApproximate using a graph\nUsing calculus\nNumerical approximation"
  },
  {
    "objectID": "slides/13-mle.html#finding-the-mle-using-graphs",
    "href": "slides/13-mle.html#finding-the-mle-using-graphs",
    "title": "Maximum likelihood estimation",
    "section": "Finding the MLE using graphs",
    "text": "Finding the MLE using graphs\n\n\nWhat do you think is the approximate value of the MLE of \\(p\\) given the data?"
  },
  {
    "objectID": "slides/13-mle.html#finding-the-mle-using-calculus",
    "href": "slides/13-mle.html#finding-the-mle-using-calculus",
    "title": "Maximum likelihood estimation",
    "section": "Finding the MLE using calculus",
    "text": "Finding the MLE using calculus\n\nFind the MLE using the first derivative of the likelihood function.\n\n\n\nThis can be tricky because of the Product Rule, so we can maximize the log(Likelihood) instead. The same value maximizes the likelihood and log(Likelihood).\n\n\nUse calculus to find the MLE of \\(p\\) given the data \\(BBM\\)."
  },
  {
    "objectID": "slides/13-mle.html#shooting-n-free-throws",
    "href": "slides/13-mle.html#shooting-n-free-throws",
    "title": "Maximum likelihood estimation",
    "section": "Shooting \\(n\\) free throws",
    "text": "Shooting \\(n\\) free throws\nSuppose the player shoots \\(n\\) free throws. They are all independent and the player has the same probability \\(p\\) of making each shot.\nSuppose the player makes \\(k\\) baskets out of the \\(n\\) free throws. This is the observed data.\n\n\n\nWhat is the formula for the probability distribution to describe this random phenomenon?\n\n\n\nWhat is the formula for the likelihood function for \\(p\\) given the observed data?\nFor what value of \\(p\\) do we maximize the likelihood given the observed data? Use calculus to find the response."
  },
  {
    "objectID": "slides/13-mle.html#why-maximum-likelihood-estimation",
    "href": "slides/13-mle.html#why-maximum-likelihood-estimation",
    "title": "Maximum likelihood estimation",
    "section": "Why maximum likelihood estimation?",
    "text": "Why maximum likelihood estimation?\n\n“Maximum likelihood estimation is, by far, the most popular technique for deriving estimators.” (Casella and Berger 2024, 315)\nMLEs have nice statistical properties. They are\n\nConsistent\nEfficient - Have the smallest MSE among all consistent estimators\nAsymptotically normal\n\n\n\n\n\n\n\n\n\nNote\n\n\nIf the normality assumption holds, the least squares estimator is the maximum likelihood estimator for \\(\\beta\\). Therefore, it has all these properties of the MLE."
  },
  {
    "objectID": "slides/13-mle.html#linear-regression",
    "href": "slides/13-mle.html#linear-regression",
    "title": "Maximum likelihood estimation",
    "section": "Linear regression",
    "text": "Linear regression\nRecall the linear model\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}, \\hspace{10mm} \\boldsymbol{\\epsilon} \\sim N(\\mathbf{0}, \\sigma^2_{\\epsilon}\\mathbf{I})\n\\]\n\n\n\nWe have discussed least-squares estimation to find \\(\\hat{\\boldsymbol{\\beta}}\\) and \\(\\hat{\\sigma}_\\epsilon^2\\)\nWe have discussed properties of \\(\\hat{\\boldsymbol{\\beta}}\\) that depend on \\(E(\\boldsymbol{\\epsilon}) = \\mathbf{0}\\) and \\(Var(\\boldsymbol{\\epsilon}) = \\sigma^2_{\\epsilon}\\mathbf{I}\\)\nWe have used the fact that \\(\\hat{\\boldsymbol{\\beta}} \\sim N(\\boldsymbol{\\beta}, \\sigma^2_{\\epsilon}(\\mathbf{X}^T\\mathbf{X})^{-1})\\) when doing hypothesis testing and confidence intervals.\nNow we will discuss how we know \\(\\hat{\\boldsymbol{\\beta}}\\) is normally distributed, as we introduce MLE for linear regression"
  },
  {
    "objectID": "slides/13-mle.html#simple-linear-regression-model",
    "href": "slides/13-mle.html#simple-linear-regression-model",
    "title": "Maximum likelihood estimation",
    "section": "Simple linear regression model",
    "text": "Simple linear regression model\nSuppose we have the simple linear regression (SLR) model\n\\[\ny_i = \\beta_0 + \\beta_1x_i + \\epsilon_i, \\hspace{10mm} \\epsilon_i \\sim N(0, \\sigma^2_{\\epsilon})\n\\]\nsuch that \\(\\epsilon_i\\) are independently and identically distributed.\n\n\nWe can write this model in the form below and use this to find the MLE\n\\[\ny_i | x_i \\sim N(\\beta_0 + \\beta_1 x_i, \\sigma^2_{\\epsilon})\n\\]"
  },
  {
    "objectID": "slides/13-mle.html#side-note-normal-distribution",
    "href": "slides/13-mle.html#side-note-normal-distribution",
    "title": "Maximum likelihood estimation",
    "section": "Side note: Normal distribution",
    "text": "Side note: Normal distribution\nLet \\(X\\) be a random variable, such that \\(X \\sim N(\\mu, \\sigma^2)\\). Then the probability function is\n\\[\nP(X = x | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\Big\\{-{\\frac{1}{2\\sigma^2}(x - \\mu)^2}\\Big\\}\n\\]"
  },
  {
    "objectID": "slides/13-mle.html#likelihood-for-slr",
    "href": "slides/13-mle.html#likelihood-for-slr",
    "title": "Maximum likelihood estimation",
    "section": "Likelihood for SLR",
    "text": "Likelihood for SLR\nThe likelihood function for \\(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon}\\) is\n\\[\n\\begin{aligned}\nL&(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon} | x_i, \\dots, x_n, y_i, \\dots, y_n) \\\\[5pt]\n&= \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma_\n\\epsilon^2}}\\exp\\Big\\{{-\\frac{1}{2\\sigma_\\epsilon^2}(y_i - [\\beta_0 + \\beta_1x_i])^2}\\Big\\} \\\\[10pt]\n& = (2\\pi\\sigma^2_{\\epsilon})^{-\\frac{n}{2}}\\exp\\Big\\{-\\frac{1}{2\\sigma^2_{\\epsilon}}\\sum_{i=1}^n(y_i - \\beta_0 - \\beta_1x_i)^2\\Big\\}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/13-mle.html#log-likelihood-for-slr",
    "href": "slides/13-mle.html#log-likelihood-for-slr",
    "title": "Maximum likelihood estimation",
    "section": "Log-likelihood for SLR",
    "text": "Log-likelihood for SLR\nThe log-likelihood function for \\(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon}\\) is\n\\[\n\\begin{aligned}\n\\log &L(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon} | x_i, \\dots, x_n, y_i, \\dots, y_n)\n  \\\\[8pt]\n& = -\\frac{n}{2}\\log(2\\pi\\sigma^2_{\\epsilon}) -\\frac{1}{2\\sigma^2_{\\epsilon}}\\sum_{i=1}^n(y_i - \\beta_0 - \\beta_1x_i)^2\n\\end{aligned}\n\\]\n\n\nWe will use the log-likelihood function to find the MLEs"
  },
  {
    "objectID": "slides/13-mle.html#mle-for-beta_0",
    "href": "slides/13-mle.html#mle-for-beta_0",
    "title": "Maximum likelihood estimation",
    "section": "MLE for \\(\\beta_0\\)",
    "text": "MLE for \\(\\beta_0\\)\n1️⃣ Take derivative of \\(\\log L\\) with respect to \\(\\beta_0\\) and set it equal to 0\n\\[\n\\frac{\\partial \\log L}{\\partial \\beta_0} = -\\frac{2}{2\\sigma^2_\\epsilon}\\sum_{i=1}^n (y_i - \\beta_0 - \\beta_1x_i)(-1) = 0\n\\]"
  },
  {
    "objectID": "slides/13-mle.html#mle-for-beta_0-1",
    "href": "slides/13-mle.html#mle-for-beta_0-1",
    "title": "Maximum likelihood estimation",
    "section": "MLE for \\(\\beta_0\\)",
    "text": "MLE for \\(\\beta_0\\)\n2️⃣ Find the \\(\\tilde{\\beta}_0\\) that satisfies the equality on the previous slide\n\nAfter a few steps…\n\\[\n\\begin{aligned}\n&\\Rightarrow \\sum_{i=1}^ny_i - n\\tilde{\\beta}_0 - \\tilde{\\beta}_1\\sum_{i=1}^n x_i = 0 \\\\\n&\\Rightarrow \\sum_{i=1}^ny_i  - \\tilde{\\beta}_1\\sum_{i=1}^n x_i = n\\tilde{\\beta}_0 \\\\\n&\\Rightarrow \\frac{1}{n}\\sum_{i=1}^ny_i  - \\frac{1}{n}\\tilde{\\beta}_1\\sum_{i=1}^n x_i = \\tilde{\\beta}_0\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/13-mle.html#mle-for-beta_0-2",
    "href": "slides/13-mle.html#mle-for-beta_0-2",
    "title": "Maximum likelihood estimation",
    "section": "MLE for \\(\\beta_0\\)",
    "text": "MLE for \\(\\beta_0\\)\n3️⃣ We can use the second derivative to show we’ve found the maximum\n\\[\n\\frac{\\partial^2 \\log L}{\\partial \\beta_0^2} = -\\frac{n}{2\\tilde{\\sigma}^2_\\epsilon}  &lt; 0\n\\]\n\n\nTherefore, we have found the maximum. Thus, MLE for \\(\\beta_0\\) is\n\\[\n\\tilde{\\beta}_0 = \\bar{y} - \\tilde{\\beta}_1\\bar{x}\n\\]\n$$$$"
  },
  {
    "objectID": "slides/13-mle.html#mle-for-beta_1-and-sigma2_epsilon",
    "href": "slides/13-mle.html#mle-for-beta_1-and-sigma2_epsilon",
    "title": "Maximum likelihood estimation",
    "section": "MLE for \\(\\beta_1\\) and \\(\\sigma^2_{\\epsilon}\\)",
    "text": "MLE for \\(\\beta_1\\) and \\(\\sigma^2_{\\epsilon}\\)\nWe can use a similar process to find the MLEs for \\(\\beta_1\\) and \\(\\sigma^2_{\\epsilon}\\)\n\\[\n\\tilde{\\beta}_1 = \\frac{\\sum_{i=1}^n y_i(x_i - \\bar{x})}{\\sum_{i=1}^n(x_i - \\bar{x})^2}\n\\]\n\n\\[\n\\tilde{\\sigma}^2_{\\epsilon} = \\frac{\\sum_{i=1}^n(y_i - \\tilde{\\beta}_0 - \\tilde{\\beta}_1x_i)^2}{n} = \\frac{\\sum_{i=1}^ne_i^2}{n}\n\\]"
  },
  {
    "objectID": "slides/13-mle.html#putting-it-all-together",
    "href": "slides/13-mle.html#putting-it-all-together",
    "title": "Maximum likelihood estimation",
    "section": "Putting it all together",
    "text": "Putting it all together\n\n\nThe MLEs \\(\\tilde{\\beta}_0\\) and \\(\\tilde{\\beta}_1\\) are equivalent to the least-squares estimators, when the errors follow independent and identical normal distributions\nThis means the least-squares estimators \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) and inherit all the nice properties of MLEs\n\nConsistency\nEfficiency - minimum variance among all consistent estimators\nAsymptotically normal"
  },
  {
    "objectID": "slides/13-mle.html#putting-it-all-together-1",
    "href": "slides/13-mle.html#putting-it-all-together-1",
    "title": "Maximum likelihood estimation",
    "section": "Putting it all together",
    "text": "Putting it all together\n\nFrom previous work, we also know estimators \\(\\tilde{\\beta}_0\\) and \\(\\tilde{\\beta}_1\\) are unbiased\nNote that the MLE \\(\\tilde{\\sigma}^2_{\\epsilon}\\) is asymptotically unbiased\n\nThe estimate from least-squares \\(\\hat{\\sigma}_{\\epsilon}^2\\) is unbiased"
  },
  {
    "objectID": "slides/13-mle.html#references",
    "href": "slides/13-mle.html#references",
    "title": "Maximum likelihood estimation",
    "section": "References",
    "text": "References\n\n\n\n\n🔗 STA 221 - Fall 2024\n\n\n\n\nCasella, George, and Roger Berger. 2024. Statistical Inference. CRC Press."
  },
  {
    "objectID": "slides/12-exam-01-review.html#announcements",
    "href": "slides/12-exam-01-review.html#announcements",
    "title": "Exam 01 review",
    "section": "Announcements",
    "text": "Announcements\n\nProject Proposal due TODAY at 11:59pm\nLab 03 due TODAY at 11:59pm\nHW 02 due TODAY at 11:59pm\nExam 01: Tuesday, October 8 (in class + take-home)\n\nLecture recordings available until the start of the in-class exam (Link on side bar of webpage)\nMonday’s lab: Exam office hours\nNo office hours while take-home exam is out"
  },
  {
    "objectID": "slides/12-exam-01-review.html#exam-01",
    "href": "slides/12-exam-01-review.html#exam-01",
    "title": "Exam 01 review",
    "section": "Exam 01",
    "text": "Exam 01\n\n20s% of final course grade\n50 points total\n\nin-class: 35-40 points\ntake-home: 10 - 15 points\n\nIn-class: 75 minutes during Tuesday, October 8 lecture\nTake-home: due October 10 at 11:30am (we will have class Thursday)\nIf you miss any part of the exam for an excused absence (with academic dean’s note), your Exam 02 score will be counted twice"
  },
  {
    "objectID": "slides/12-exam-01-review.html#content-weeks-1---6",
    "href": "slides/12-exam-01-review.html#content-weeks-1---6",
    "title": "Exam 01 review",
    "section": "Content: Weeks 1 - 6",
    "text": "Content: Weeks 1 - 6\n\n\n\nExploratory data analysis\nFitting and interpreting linear regression models\nModel assessment and comparison\nANOVA\nCategorical + interaction terms\nInference for model coefficients\n\n\n\nMatrix representation of regression\nHat matrix\nFinding the least-squares estimator (no geometric interpretation)\nAssumptions for least-squares regression\nProperties of the least-squares estimator"
  },
  {
    "objectID": "slides/12-exam-01-review.html#outline-of-in-class-portion",
    "href": "slides/12-exam-01-review.html#outline-of-in-class-portion",
    "title": "Exam 01 review",
    "section": "Outline of in-class portion",
    "text": "Outline of in-class portion\n\nClosed-book, closed-note.\n8 questions, some with multiple parts\nQuestion types:\n\nShort answer (show work / explain response)\nTrue/ False.\n\nIf false, write 1 - 2 sentence justification about why it is false.\n\nDerivations\n\nWill be provided all relevant R output and a page of math rules \nJust need a pencil or pen. No calculator permitted on exam."
  },
  {
    "objectID": "slides/12-exam-01-review.html#outline-of-take-home-portion",
    "href": "slides/12-exam-01-review.html#outline-of-take-home-portion",
    "title": "Exam 01 review",
    "section": "Outline of take-home portion",
    "text": "Outline of take-home portion\n\nReleased: Tuesday, October 8 ~ 1pm\nDue: Thursday, October 10 at 11:30 (we will have class Thursday)\nSimilar in format to a lab/ HW\n\nWill receive Exam questions in README of GitHub repo\nFormatting + using a reproducible workflow will be part of grade\n\nSubmit a PDF of responses to GitHub"
  },
  {
    "objectID": "slides/05-mlr.html#topics",
    "href": "slides/05-mlr.html#topics",
    "title": "Multiple linear regression (MLR)",
    "section": "Topics",
    "text": "Topics\n\nExploratory data analysis for multiple linear regression\nFitting the least squares line\nInterpreting coefficients for quantitative predictors\nPrediction"
  },
  {
    "objectID": "slides/05-mlr.html#computing-setup",
    "href": "slides/05-mlr.html#computing-setup",
    "title": "Multiple linear regression (MLR)",
    "section": "Computing setup",
    "text": "Computing setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))"
  },
  {
    "objectID": "slides/05-mlr.html#data-peer-to-peer-lender",
    "href": "slides/05-mlr.html#data-peer-to-peer-lender",
    "title": "Multiple linear regression (MLR)",
    "section": "Data: Peer-to-peer lender",
    "text": "Data: Peer-to-peer lender\nToday’s data is a sample of 50 loans made through a peer-to-peer lending club. The data is in the loan50 data frame in the openintro R package.\n\n\n# A tibble: 50 × 4\n   annual_income debt_to_income verified_income interest_rate\n           &lt;dbl&gt;          &lt;dbl&gt; &lt;fct&gt;                   &lt;dbl&gt;\n 1         59000         0.558  Not Verified            10.9 \n 2         60000         1.31   Not Verified             9.92\n 3         75000         1.06   Verified                26.3 \n 4         75000         0.574  Not Verified             9.92\n 5        254000         0.238  Not Verified             9.43\n 6         67000         1.08   Source Verified          9.92\n 7         28800         0.0997 Source Verified         17.1 \n 8         80000         0.351  Not Verified             6.08\n 9         34000         0.698  Not Verified             7.97\n10         80000         0.167  Source Verified         12.6 \n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/05-mlr.html#variables",
    "href": "slides/05-mlr.html#variables",
    "title": "Multiple linear regression (MLR)",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\n\nannual_income: Annual income\ndebt_to_income: Debt-to-income ratio, i.e. the percentage of a borrower’s total debt divided by their total income\nverified_income: Whether borrower’s income source and amount have been verified (Not Verified, Source Verified, Verified)\n\n\nOutcome: interest_rate: Interest rate for the loan"
  },
  {
    "objectID": "slides/05-mlr.html#outcome-interest_rate",
    "href": "slides/05-mlr.html#outcome-interest_rate",
    "title": "Multiple linear regression (MLR)",
    "section": "Outcome: interest_rate",
    "text": "Outcome: interest_rate\n\n\n\n\n\n\nMin\nMedian\nMax\nIQR\n\n\n\n\n5.31\n9.93\n26.3\n5.755"
  },
  {
    "objectID": "slides/05-mlr.html#predictors",
    "href": "slides/05-mlr.html#predictors",
    "title": "Multiple linear regression (MLR)",
    "section": "Predictors",
    "text": "Predictors"
  },
  {
    "objectID": "slides/05-mlr.html#data-manipulation-1-rescale-income",
    "href": "slides/05-mlr.html#data-manipulation-1-rescale-income",
    "title": "Multiple linear regression (MLR)",
    "section": "Data manipulation 1: Rescale income",
    "text": "Data manipulation 1: Rescale income\n\nloan50 &lt;- loan50 |&gt;\n  mutate(annual_income_th = annual_income / 1000)\n\n\n\n\nWhy did we rescale income?"
  },
  {
    "objectID": "slides/05-mlr.html#outcome-vs.-predictors",
    "href": "slides/05-mlr.html#outcome-vs.-predictors",
    "title": "Multiple linear regression (MLR)",
    "section": "Outcome vs. predictors",
    "text": "Outcome vs. predictors\n\n\nGoal: Use these predictors in a single model to understand variability in interest rate.\n\n\n\nWhy do we want to use a single model versus 3 separate simple linear regression models?"
  },
  {
    "objectID": "slides/05-mlr.html#multiple-linear-regression-mlr",
    "href": "slides/05-mlr.html#multiple-linear-regression-mlr",
    "title": "Multiple linear regression (MLR)",
    "section": "Multiple linear regression (MLR)",
    "text": "Multiple linear regression (MLR)\nBased on the analysis goals, we will use a multiple linear regression model of the following form\n\\[\n\\begin{aligned}\\text{interest_rate} ~ =\n\\beta_0 & + \\beta_1 ~ \\text{debt_to_income} \\\\ & + \\beta_2 ~ \\text{verified_income} \\\\ &+ \\beta_3~ \\text{annual_income_th} \\\\\n& +\\epsilon, \\quad \\epsilon \\sim N(0, \\sigma^2_{\\epsilon})\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/05-mlr.html#multiple-linear-regression-1",
    "href": "slides/05-mlr.html#multiple-linear-regression-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\nRecall: The simple linear regression model\n\\[\nY = \\beta_0 + \\beta_1~ X + \\epsilon, \\quad \\epsilon \\sim N(0, \\sigma^2_{\\epsilon})\n\\]\n\nThe form of the multiple linear regression model is\n\\[\nY = \\beta_0 + \\beta_1X_1 +  \\dots + \\beta_pX_p + \\epsilon, \\quad \\epsilon \\sim N(0, \\sigma^2_{\\epsilon})\n\\]\n\n\n\nTherefore,\n\\[\nE(Y|X_1, \\ldots, X_p) = \\beta_0 + \\beta_1X_1 +  \\dots + \\beta_pX_p\n\\]"
  },
  {
    "objectID": "slides/05-mlr.html#fitting-the-least-squares-line",
    "href": "slides/05-mlr.html#fitting-the-least-squares-line",
    "title": "Multiple linear regression (MLR)",
    "section": "Fitting the least squares line",
    "text": "Fitting the least squares line\nSimilar to simple linear regression, we want to find estimates for \\(\\beta_0, \\beta_1, \\ldots, \\beta_p\\) that minimize\n\\[\n\\sum_{i=1}^{n}e_i^2 = \\sum_{i=1}^n[y_i - \\hat{y}_i]^2 = \\sum_{i=1}^n[y_i - (\\beta_0 + \\beta_1x_{i1} + \\dots + \\beta_px_{ip})]^2\n\\]\n\n\nThe calculations can be very tedious, especially if \\(p\\) is large"
  },
  {
    "objectID": "slides/05-mlr.html#matrix-form-of-multiple-linear-regression",
    "href": "slides/05-mlr.html#matrix-form-of-multiple-linear-regression",
    "title": "Multiple linear regression (MLR)",
    "section": "Matrix form of multiple linear regression",
    "text": "Matrix form of multiple linear regression\nSuppose we have \\(n\\) observations, a quantitative response variable, and \\(p\\) &gt; 1 predictors \\[\n\\underbrace{\n\\begin{bmatrix}\ny_1 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix} }_\n{\\mathbf{y}} \\hspace{3mm}\n=\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n1 &x_{11} & \\dots & x_{1p}\\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\n1 &  x_{n1} & \\dots &x_{np}\n\\end{bmatrix}\n}_{\\mathbf{X}}\n\\hspace{2mm}\n\\underbrace{\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\vdots \\\\\n\\beta_p\n\\end{bmatrix}\n}_{\\boldsymbol{\\beta}}\n\\hspace{3mm}\n+\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n\\epsilon_1 \\\\\n\\vdots\\\\\n\\epsilon_n\n\\end{bmatrix}\n}_\\boldsymbol{\\epsilon}\n\\]\n\nWhat are the dimensions of \\(\\mathbf{y}\\), \\(\\mathbf{X}\\), \\(\\boldsymbol{\\beta}\\), \\(\\boldsymbol{\\epsilon}\\)?"
  },
  {
    "objectID": "slides/05-mlr.html#matrix-form-of-multiple-linear-regression-1",
    "href": "slides/05-mlr.html#matrix-form-of-multiple-linear-regression-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Matrix form of multiple linear regression",
    "text": "Matrix form of multiple linear regression\nAs with simple linear regression, we have\n\\[\n\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n\\]\n\nGeneralizing the derivations from SLR to \\(p &gt; 2\\), we have\n\\[\n\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}\n\\]\nas before."
  },
  {
    "objectID": "slides/05-mlr.html#model-fit-in-r",
    "href": "slides/05-mlr.html#model-fit-in-r",
    "title": "Multiple linear regression (MLR)",
    "section": "Model fit in R",
    "text": "Model fit in R\n\nint_fit &lt;- lm(interest_rate ~ debt_to_income + verified_income  + annual_income_th,\n              data = loan50)\n\ntidy(int_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n10.726\n1.507\n7.116\n0.000\n\n\ndebt_to_income\n0.671\n0.676\n0.993\n0.326\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n\n\nannual_income_th\n-0.021\n0.011\n-1.804\n0.078"
  },
  {
    "objectID": "slides/05-mlr.html#model-equation",
    "href": "slides/05-mlr.html#model-equation",
    "title": "Multiple linear regression (MLR)",
    "section": "Model equation",
    "text": "Model equation\n\\[\n\\begin{align}\\hat{\\text{interest_rate}} =  10.726 &+0.671 \\times \\text{debt_to_income}\\\\\n&+ 2.211 \\times \\text{source_verified}\\\\  \n&+ 6.880 \\times \\text{verified}\\\\\n& -0.021 \\times \\text{annual_income_th}\n\\end{align}\n\\]\n\n\n\n\n\n\nNote\n\n\nWe will talk about why there are two terms in the model for verified_income soon!"
  },
  {
    "objectID": "slides/05-mlr.html#interpreting-hatbeta_j",
    "href": "slides/05-mlr.html#interpreting-hatbeta_j",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting \\(\\hat{\\beta}_j\\)",
    "text": "Interpreting \\(\\hat{\\beta}_j\\)\n\nThe estimated coefficient \\(\\hat{\\beta}_j\\) is the expected change in the mean of \\(Y\\) when \\(X_j\\) increases by one unit, holding the values of all other predictor variables constant.\n\n\n\nExample: The estimated coefficient for debt_to_income is 0.671. This means for each point in an borrower’s debt to income ratio, the interest rate on the loan is expected to be greater by 0.671%, holding annual income and income verification constant."
  },
  {
    "objectID": "slides/05-mlr.html#interpreting-hatbeta_j-1",
    "href": "slides/05-mlr.html#interpreting-hatbeta_j-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting \\(\\hat{\\beta}_j\\)",
    "text": "Interpreting \\(\\hat{\\beta}_j\\)\n\nThe estimated coefficient for annual_income_th is -0.021. Interpret this coefficient in the context of the data.\n\n\n\n\nWhy do we need to include a statement about holding all other predictors constant?"
  },
  {
    "objectID": "slides/05-mlr.html#interpreting-hatbeta_0",
    "href": "slides/05-mlr.html#interpreting-hatbeta_0",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting \\(\\hat{\\beta}_0\\)",
    "text": "Interpreting \\(\\hat{\\beta}_0\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n10.726\n1.507\n7.116\n0.000\n7.690\n13.762\n\n\ndebt_to_income\n0.671\n0.676\n0.993\n0.326\n-0.690\n2.033\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n-0.606\n5.028\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n3.253\n10.508\n\n\nannual_income_th\n-0.021\n0.011\n-1.804\n0.078\n-0.043\n0.002\n\n\n\n\n\n\n\n\nDescribe the subset of borrowers who are expected to get an interest rate of 10.726% based on our model. Is this interpretation meaningful? Why or why not?"
  },
  {
    "objectID": "slides/05-mlr.html#prediction",
    "href": "slides/05-mlr.html#prediction",
    "title": "Multiple linear regression (MLR)",
    "section": "Prediction",
    "text": "Prediction\n\nWhat is the predicted interest rate for an borrower with an debt-to-income ratio of 0.558, whose income is not verified, and who has an annual income of $59,000?\n\n\n\n10.726 + 0.671 * 0.558 + 2.211 * 0 + 6.880 * 0 - 0.021 * 59\n\n[1] 9.861418\n\n\n\nThe predicted interest rate for an borrower with with an debt-to-income ratio of 0.558, whose income is not verified, and who has an annual income of $59,000 is 9.86%."
  },
  {
    "objectID": "slides/05-mlr.html#prediction-in-r",
    "href": "slides/05-mlr.html#prediction-in-r",
    "title": "Multiple linear regression (MLR)",
    "section": "Prediction in R",
    "text": "Prediction in R\nJust like with simple linear regression, we can use the predict() function in R to calculate the appropriate intervals for our predicted values:\n\nnew_borrower &lt;- tibble(\n  debt_to_income  = 0.558, \n  verified_income = \"Not Verified\", \n  annual_income_th = 59\n)\n\npredict(int_fit, new_borrower)\n\n       1 \n9.890888 \n\n\n\n\n\n\n\n\nNote\n\n\nDifference in predicted value due to rounding the coefficients on the previous slide."
  },
  {
    "objectID": "slides/05-mlr.html#cautions",
    "href": "slides/05-mlr.html#cautions",
    "title": "Multiple linear regression (MLR)",
    "section": "Cautions",
    "text": "Cautions\n\nDo not extrapolate! Because there are multiple predictor variables, there is the potential to extrapolate in many directions\nThe multiple regression model only shows association, not causality\n\nTo show causality, you must have a carefully designed experiment or carefully account for confounding variables in an observational study"
  },
  {
    "objectID": "slides/05-mlr.html#recap",
    "href": "slides/05-mlr.html#recap",
    "title": "Multiple linear regression (MLR)",
    "section": "Recap",
    "text": "Recap\n\nShowed exploratory data analysis for multiple linear regression\nUsed least squares to fit the regression line\nInterpreted the coefficients for quantitative predictors\nPredicted the response for new observations"
  },
  {
    "objectID": "slides/05-mlr.html#next-class",
    "href": "slides/05-mlr.html#next-class",
    "title": "Multiple linear regression (MLR)",
    "section": "Next class",
    "text": "Next class\n\nMore on multiple linear regression\n\nCategorical predictors\nModel assessment\nGeometric interpretation (as time permits)\n\nSee Sep 12 prepare\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#announcements",
    "href": "slides/11-prop-of-estimators-pt2.html#announcements",
    "title": "Properties of estimators",
    "section": "Announcements",
    "text": "Announcements\n\nProject Proposal due Thursday, October 3 at 11:59pm\nLab 03 due Thursday, October 3 at 11:59pm\nHW 02 due Thursday, October 3 at 11:59pm (released after class)\nExam 01: Tuesday, October 8 (in class + take-home)\n\nLecture recordings available until the start of the in-class exam (Link on side bar of webpage)\nExam review on Thursday\nMonday’s lab: Exam office hours\nNo office hours while take-home exam is out"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#topics",
    "href": "slides/11-prop-of-estimators-pt2.html#topics",
    "title": "Properties of estimators",
    "section": "Topics",
    "text": "Topics\n\nProperties of the least squares estimator\n\n\n\n\n\n\n\nNote\n\n\nThis is not a mathematical statistics class. There are semester-long courses that will go into these topics in much more detail; we will barely scratch the surface in this course.\nOur goals are to understand\n\nEstimators have properties\nA few properties of the least squares estimator and why they are useful"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#motivation",
    "href": "slides/11-prop-of-estimators-pt2.html#motivation",
    "title": "Properties of estimators",
    "section": "Motivation",
    "text": "Motivation\n\n\nWe have discussed how to use least squares to find an estimator of \\(\\hat{\\boldsymbol{\\beta}}\\)\nHow do we know whether our least-squares estimator is a “good” estimator?\nWhen we consider what makes an estimator “good”, we’ll look at three criteria:\n\nBias\nVariance\nMean squared error\n\nWe’ll take a look at these and motivate why we might prefer using least squares to compute \\(\\hat{\\boldsymbol{\\beta}}\\) versus other methods"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#bias-and-variance",
    "href": "slides/11-prop-of-estimators-pt2.html#bias-and-variance",
    "title": "Properties of estimators",
    "section": "Bias and variance",
    "text": "Bias and variance\nSuppose you are throwing darts at a target\n\n\n\n\n\n\nImage source: Analytics Vidhya\n\n\n\n\nIdeal scenario: Darts are clustered around the target (unbiased and low variance)\nWorst case scenario: Darts are widely spread out and systematically far from the target (high bias and high variance)\nAcceptable scenario: There’s some trade-off between the bias and variance."
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#properties-of-hatboldsymbolbeta-1",
    "href": "slides/11-prop-of-estimators-pt2.html#properties-of-hatboldsymbolbeta-1",
    "title": "Properties of estimators",
    "section": "Properties of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Properties of \\(\\hat{\\boldsymbol{\\beta}}\\)\nFinite sample ( \\(n\\) ) properties\n\nUnbiased estimator\nBest Linear Unbiased Estimator (BLUE)\n\n\nInfinite sample ( \\(n \\rightarrow \\infty\\) ) properties\n\nConsistent estimator\nEfficient estimator"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#unbiased-estimator",
    "href": "slides/11-prop-of-estimators-pt2.html#unbiased-estimator",
    "title": "Properties of estimators",
    "section": "Unbiased estimator",
    "text": "Unbiased estimator\nThe bias of an estimator is the difference between the estimator’s expected value and the true value of the parameter\nLet \\(\\hat{\\theta}\\) be an estimator of the parameter \\(\\theta\\). Then\n\\[\nBias(\\hat{\\theta}) = E(\\hat{\\theta}) - \\theta\n\\]\nAn estimator is unbiased if the bias is 0 and thus \\(E(\\hat{\\theta}) = \\theta\\)"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#unbiased-estimator-1",
    "href": "slides/11-prop-of-estimators-pt2.html#unbiased-estimator-1",
    "title": "Properties of estimators",
    "section": "Unbiased estimator",
    "text": "Unbiased estimator\n\\[\n\\begin{aligned}\nE(\\hat{\\boldsymbol{\\beta}}) &= E[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}] \\\\[8pt]\n& = E[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T(\\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon})] \\\\[8pt]\n& = E[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}] + E[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\boldsymbol{\\epsilon}]\\\\[8pt]\n& = \\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^TE(\\boldsymbol{\\epsilon}) \\\\[8pt]\n& = \\boldsymbol{\\beta}\n\\end{aligned}\n\\]\nThe least-squares estimator \\(\\hat{\\boldsymbol{\\beta}}\\) is an unbiased estimator of \\(\\boldsymbol{\\beta}\\)"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#variance-of-hatboldsymbolbeta",
    "href": "slides/11-prop-of-estimators-pt2.html#variance-of-hatboldsymbolbeta",
    "title": "Properties of estimators",
    "section": "Variance of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Variance of \\(\\hat{\\boldsymbol{\\beta}}\\)\n\\[\n\\begin{aligned}\nVar(\\hat{\\boldsymbol{\\beta}}) &= Var((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}) \\\\[8pt]\n& = [(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T]Var(\\mathbf{y})[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T]^T \\\\[8pt]\n& = [(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T]\\sigma^2_{\\epsilon}\\mathbf{I}[\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}] \\\\[8pt]\n& = \\sigma^2_{\\epsilon}[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}] \\\\[8pt]\n& = \\sigma^2_{\\epsilon}(\\mathbf{X}^T\\mathbf{X})^{-1}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#linear-regression-model",
    "href": "slides/11-prop-of-estimators-pt2.html#linear-regression-model",
    "title": "Properties of estimators",
    "section": "“Linear” regression model",
    "text": "“Linear” regression model\nWhat does it mean for a model to be a “linear” regression model?\n\nLinear regression models are linear in the parameters, i.e. given an observation \\(y_i\\)\n\\[\ny_i = \\beta_0 + \\beta_1f_1(x_{i1}) +  \\dots + \\beta_pf_p(x_{ip}) + \\epsilon_i\n\\]\nThe functions \\(f_1, \\ldots, f_p\\) can be non-linear as long as \\(\\beta_0, \\beta_1, \\ldots, \\beta_p\\) are linear in \\(Y\\)"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#gauss-markov-theorem-proof",
    "href": "slides/11-prop-of-estimators-pt2.html#gauss-markov-theorem-proof",
    "title": "Properties of estimators",
    "section": "Gauss-Markov Theorem Proof",
    "text": "Gauss-Markov Theorem Proof\nSuppose \\(\\tilde{\\boldsymbol{\\beta}}\\) is another linear unbiased estimator of \\(\\boldsymbol{\\beta}\\) that can be expressed as \\(\\tilde{\\boldsymbol{\\beta}} = \\mathbf{Cy}\\) , such that \\(\\hat{\\mathbf{y}} = \\mathbf{X}\\tilde{\\boldsymbol{\\beta}} = \\mathbf{XCy}\\)\n\nLet \\(\\mathbf{C} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T + \\mathbf{B}\\) for a non-zero matrix \\(\\mathbf{B}\\).\n\n\nWhat is the dimension of \\(\\mathbf{B}\\)?"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#gauss-markov-theorem-proof-1",
    "href": "slides/11-prop-of-estimators-pt2.html#gauss-markov-theorem-proof-1",
    "title": "Properties of estimators",
    "section": "Gauss-Markov Theorem Proof",
    "text": "Gauss-Markov Theorem Proof\n\\[\n\\tilde{\\boldsymbol{\\beta}} = \\mathbf{Cy} = ((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T + \\mathbf{B})\\mathbf{y}\n\\]\nWe need to show\n\n\\(\\tilde{\\boldsymbol{\\beta}}\\) is unbiased\n\\(Var(\\tilde{\\boldsymbol{\\beta}}) &gt; Var(\\hat{\\boldsymbol{\\beta}})\\)"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#gauss-markov-theorem-proof-2",
    "href": "slides/11-prop-of-estimators-pt2.html#gauss-markov-theorem-proof-2",
    "title": "Properties of estimators",
    "section": "Gauss-Markov Theorem Proof",
    "text": "Gauss-Markov Theorem Proof\n\\[\n\\begin{aligned}\nE(\\tilde{\\boldsymbol{\\beta}}) & = E[((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T + \\mathbf{B})\\mathbf{y}] \\\\\n& = E[((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T + \\mathbf{B})(\\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon})] \\\\\n& = E[((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T + \\mathbf{B})(\\mathbf{X}\\boldsymbol{\\beta})] \\\\\n& = ((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T + \\mathbf{B})(\\mathbf{X}\\boldsymbol{\\beta}) \\\\\n& = (\\mathbf{I} + \\mathbf{BX})\\boldsymbol{\\beta}\n\\end{aligned}\n\\]\n\n\nWhat assumption(s) of the Gauss-Markov Theorem did we use?\nWhat must be true for \\(\\tilde{\\boldsymbol{\\beta}}\\) to be unbiased?"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#gauss-markov-theorem-proof-3",
    "href": "slides/11-prop-of-estimators-pt2.html#gauss-markov-theorem-proof-3",
    "title": "Properties of estimators",
    "section": "Gauss-Markov Theorem Proof",
    "text": "Gauss-Markov Theorem Proof\n\n\\(\\mathbf{BX}\\) must be the \\(\\mathbf{0}\\) matrix (dimension = \\((p+1) \\times (p+1)\\)) in order for \\(\\tilde{\\boldsymbol{\\beta}}\\) to be unbiased\nNow we need to find \\(Var(\\tilde{\\boldsymbol{\\beta}})\\) and see how it compares to \\(Var(\\hat{\\boldsymbol{\\beta}})\\)"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#gauss-markov-theorem-proof-4",
    "href": "slides/11-prop-of-estimators-pt2.html#gauss-markov-theorem-proof-4",
    "title": "Properties of estimators",
    "section": "Gauss-Markov Theorem Proof",
    "text": "Gauss-Markov Theorem Proof\n\\[\n\\begin{aligned}\nVar(\\tilde{\\boldsymbol{\\beta}}) &= Var[((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T + \\mathbf{B})\\mathbf{y}] \\\\[8pt]\n& = ((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T + \\mathbf{B})Var(\\mathbf{y})((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T + \\mathbf{B})^T \\\\[8pt]\n& = \\small{\\sigma^2_{\\epsilon}[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1} + (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T \\mathbf{B}^T + \\mathbf{BX}(\\mathbf{X}^T\\mathbf{X})^{-1} + \\mathbf{BB}^T]}\\\\[8pt]\n& = \\sigma^2_\\epsilon(\\mathbf{X}^T\\mathbf{X})^{-1} + \\sigma^2_{\\epsilon}\\mathbf{BB}^T\\end{aligned}\n\\]\n\nWhat assumption(s) of the Gauss-Markov Theorem did we use?"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#gauss-markov-theorem-proof-5",
    "href": "slides/11-prop-of-estimators-pt2.html#gauss-markov-theorem-proof-5",
    "title": "Properties of estimators",
    "section": "Gauss-Markov Theorem Proof",
    "text": "Gauss-Markov Theorem Proof\nWe have\n\\[\nVar(\\tilde{\\boldsymbol{\\beta}}) = \\sigma^2_{\\epsilon}(\\mathbf{X}^T\\mathbf{X})^{-1} + \\sigma^2_\\epsilon \\mathbf{BB}^T\n\\]\n\nWe know that \\(\\sigma^2_{\\epsilon}\\mathbf{BB}^T \\geq \\mathbf{0}\\).\n\n\n\n\nWhen is \\(\\sigma^2_{\\epsilon}\\mathbf{BB}^T = \\mathbf{0}\\)?\n\n\n\nTherefore, we have shown that \\(Var(\\tilde{\\boldsymbol{\\beta}}) &gt; Var(\\hat{\\boldsymbol{\\beta}})\\) and have completed the proof."
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#properties-of-hatboldsymbolbeta-2",
    "href": "slides/11-prop-of-estimators-pt2.html#properties-of-hatboldsymbolbeta-2",
    "title": "Properties of estimators",
    "section": "Properties of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Properties of \\(\\hat{\\boldsymbol{\\beta}}\\)\nFinite sample ( \\(n\\) ) properties\n\nUnbiased estimator ✅\nBest Linear Unbiased Estimator (BLUE) ✅\n\n\nInfinite sample ( \\(n \\rightarrow \\infty\\) ) properties\n\nConsistent estimator\nEfficient estimator"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#mean-squared-error",
    "href": "slides/11-prop-of-estimators-pt2.html#mean-squared-error",
    "title": "Properties of estimators",
    "section": "Mean squared error",
    "text": "Mean squared error\nThe mean squared error (MSE) is the squared difference between the estimator and parameter.\n\nLet \\(\\hat{\\theta}\\) be an estimator of the parameter \\(\\theta\\). Then\n\\[\n\\begin{aligned}\nMSE(\\hat{\\theta}) &= E[(\\hat{\\theta} - \\theta)^2] \\\\\n& = E(\\hat{\\theta}^2 - 2\\hat{\\theta}\\theta + \\theta^2) \\\\\n& = E(\\hat{\\theta}^2) - 2\\theta E(\\hat{\\theta}) + \\theta^2 \\\\\n& = \\underbrace{E(\\hat{\\theta}^2) -  E(\\hat{\\theta})^2}_{Var(\\hat{\\theta})} + \\underbrace{E(\\hat{\\theta})^2 - 2\\theta E(\\hat{\\theta}) + \\theta^2}_{Bias(\\theta)^2}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#mean-squared-error-1",
    "href": "slides/11-prop-of-estimators-pt2.html#mean-squared-error-1",
    "title": "Properties of estimators",
    "section": "Mean squared error",
    "text": "Mean squared error\n\\[\nMSE(\\hat{\\theta}) = Var(\\hat{\\theta}) + Bias(\\hat{\\theta})^2\n\\]\n\n\nThe least-squares estimator \\(\\hat{\\boldsymbol{\\beta}}\\) is unbiased, so \\[MSE(\\hat{\\boldsymbol{\\beta}}) = Var(\\hat{\\boldsymbol{\\beta}})\\]"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#consistency",
    "href": "slides/11-prop-of-estimators-pt2.html#consistency",
    "title": "Properties of estimators",
    "section": "Consistency",
    "text": "Consistency\nAn estimator \\(\\hat{\\theta}\\) is a consistent estimator of a parameter \\(\\theta\\) if it converges in probability to \\(\\theta\\). Given a sequence of estimators \\(\\hat{\\theta}_1, \\hat{\\theta}_2, . . .\\), then for every \\(\\epsilon &gt; 0\\),\n\\[\n\\displaystyle \\lim_{n\\to\\infty} P(|\\hat{\\theta}_n - \\theta| \\geq \\epsilon) = 0\n\\]\n\nThis means that as the sample size goes to \\(\\infty\\) (and thus the sample information gets better and better), the estimator will be arbitrarily close to the parameter with high probability.\n\n\n\nWhy is this a useful property of an estimator?"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#consistency-1",
    "href": "slides/11-prop-of-estimators-pt2.html#consistency-1",
    "title": "Properties of estimators",
    "section": "Consistency",
    "text": "Consistency\n\n\n\n\n\nImportant\n\n\nTheorem\nAn estimator \\(\\hat{\\theta}\\) is a consistent estimator of the parameter \\(\\theta\\) if the sequence of estimators \\(\\hat{\\theta}_1, \\hat{\\theta}_2, \\ldots\\) satisfies\n\n\\(\\lim_{n \\to \\infty} Var(\\hat{\\theta}) = 0\\)\n\\(\\lim_{n \\to \\infty} Bias(\\hat{\\theta}) = 0\\)"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#consistency-of-hatboldsymbolbeta",
    "href": "slides/11-prop-of-estimators-pt2.html#consistency-of-hatboldsymbolbeta",
    "title": "Properties of estimators",
    "section": "Consistency of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Consistency of \\(\\hat{\\boldsymbol{\\beta}}\\)\n\\(Bias(\\hat{\\boldsymbol{\\beta}}) = \\mathbf{0}\\), so \\(\\lim_{n \\to \\infty} Bias(\\hat{\\boldsymbol{\\beta}}) = \\mathbf{0}\\)\n\n\nNow we need to show that \\(\\lim_{n \\to \\infty} Var(\\hat{\\boldsymbol{\\beta}}) = \\mathbf{0}\\)\n\n\nWhat is \\(Var(\\hat{\\boldsymbol{\\beta}})\\)?\nDoes \\(Var(\\hat{\\boldsymbol{\\beta}}) \\to \\mathbf{0}\\) as \\(n \\to \\infty\\)?"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#efficiency",
    "href": "slides/11-prop-of-estimators-pt2.html#efficiency",
    "title": "Properties of estimators",
    "section": "Efficiency",
    "text": "Efficiency\n\nThe efficiency of an estimator is concerned with the asymptotic variance of an estimator.\nThe estimator with the smallest variance is considered the most efficient.\nBy the Gauss-Markov Theorem, we have shown that the least-squares estimator is the most efficient among linear unbiased estimators."
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#recap",
    "href": "slides/11-prop-of-estimators-pt2.html#recap",
    "title": "Properties of estimators",
    "section": "Recap",
    "text": "Recap\nFinite sample ( \\(n\\) ) properties\n\nUnbiased estimator ✅\nBest Linear Unbiased Estimator (BLUE) ✅\n\n\nInfinite sample ( \\(n \\rightarrow \\infty\\) ) properties\n\nConsistent estimator ✅\nEfficient estimator ✅\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#announcements",
    "href": "slides/10-prop-of-estimators.html#announcements",
    "title": "Properties of estimators",
    "section": "Announcements",
    "text": "Announcements\n\nProject\n\nResearch questions due TODAY\nProposal due Thursday, October 3 at 11:59pm\n\nLab 03 due Thursday, October 3 at 11:59pm\nHW 02 due Thursday, October 3 at 11:59pm (released after class)\nStatistics experience due Tue, Nov 26 at 11:59pm"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#topics",
    "href": "slides/10-prop-of-estimators.html#topics",
    "title": "Properties of estimators",
    "section": "Topics",
    "text": "Topics\n\nCompute and interpret confidence interval for a single coefficient\nProperties of \\(\\hat{\\boldsymbol{\\beta}}\\)\nDefine “linear” model"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#computing-setup",
    "href": "slides/10-prop-of-estimators.html#computing-setup",
    "title": "Properties of estimators",
    "section": "Computing setup",
    "text": "Computing setup\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(kableExtra)  \nlibrary(patchwork)   \n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#data-ncaa-football-expenditures",
    "href": "slides/10-prop-of-estimators.html#data-ncaa-football-expenditures",
    "title": "Properties of estimators",
    "section": "Data: NCAA Football expenditures",
    "text": "Data: NCAA Football expenditures\nToday’s data come from Equity in Athletics Data Analysis and includes information about sports expenditures and revenues for colleges and universities in the United States. This data set was featured in a March 2022 Tidy Tuesday.\nWe will focus on the 2019 - 2020 season expenditures on football for institutions in the NCAA - Division 1 FBS. The variables are :\n\ntotal_exp_m: Total expenditures on football in the 2019 - 2020 academic year (in millions USD)\nenrollment_th: Total student enrollment in the 2019 - 2020 academic year (in thousands)\ntype: institution type (Public or Private)"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#regression-model",
    "href": "slides/10-prop-of-estimators.html#regression-model",
    "title": "Properties of estimators",
    "section": "Regression model",
    "text": "Regression model\n\nexp_fit &lt;- lm(total_exp_m ~ enrollment_th + type, data = football)\ntidy(exp_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#inference-for-beta_j",
    "href": "slides/10-prop-of-estimators.html#inference-for-beta_j",
    "title": "Properties of estimators",
    "section": "Inference for \\(\\beta_j\\)",
    "text": "Inference for \\(\\beta_j\\)\nWe often want to conduct inference on individual model coefficients\n\nHypothesis test: Is there a linear relationship between the response and \\(x_j\\)?\nConfidence interval: What is a plausible range of values \\(\\beta_j\\) can take?"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#confidence-interval-for-beta_j-1",
    "href": "slides/10-prop-of-estimators.html#confidence-interval-for-beta_j-1",
    "title": "Properties of estimators",
    "section": "Confidence interval for \\(\\beta_j\\)",
    "text": "Confidence interval for \\(\\beta_j\\)\n\n\nA plausible range of values for a population parameter is called a confidence interval\nUsing only a single point estimate is like fishing in a murky lake with a spear, and using a confidence interval is like fishing with a net\n\nWe can throw a spear where we saw a fish but we will probably miss, if we toss a net in that area, we have a good chance of catching the fish\nSimilarly, if we report a point estimate, we probably will not hit the exact population parameter, but if we report a range of plausible values we have a good shot at capturing the parameter"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#what-confidence-means",
    "href": "slides/10-prop-of-estimators.html#what-confidence-means",
    "title": "Properties of estimators",
    "section": "What “confidence” means",
    "text": "What “confidence” means\n\n\nWe will construct \\(C\\%\\) confidence intervals\n\nThe confidence level impacts the width of the interval\n\n“Confidence” means if we were to take repeated samples of the same size as our data, fit regression lines using the same predictors, and calculate \\(C\\%\\) CIs for the coefficient of \\(x_j\\), then \\(C\\%\\) of those intervals will contain the true value of the coefficient \\(\\beta_j\\)\nNeed to balance precision and accuracy when selecting a confidence level"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#confidence-interval-for-beta_j-2",
    "href": "slides/10-prop-of-estimators.html#confidence-interval-for-beta_j-2",
    "title": "Properties of estimators",
    "section": "Confidence interval for \\(\\beta_j\\)",
    "text": "Confidence interval for \\(\\beta_j\\)\n\\[\n\\text{Estimate} \\pm \\text{ (critical value) } \\times \\text{SE}\n\\]\n\n\n\\[\n\\hat{\\beta}_1 \\pm t^* \\times SE({\\hat{\\beta}_j})\n\\]\nwhere \\(t^*\\) is calculated from a \\(t\\) distribution with \\(n-p-1\\) degrees of freedom"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#computing-t-in-r",
    "href": "slides/10-prop-of-estimators.html#computing-t-in-r",
    "title": "Properties of estimators",
    "section": "Computing \\(t^*\\) in R",
    "text": "Computing \\(t^*\\) in R\n\n\n# confidence level: 95%\nqt(0.975, df = nrow(football) - 2 - 1)\n\n[1] 1.97928\n\n\n\n\n\n\n# confidence level: 90%\nqt(0.95, df = nrow(football) - 2 - 1)\n\n[1] 1.657235\n\n\n\n\n\n\n# confidence level: 99%\nqt(0.995, df = nrow(football) - 2 - 1)\n\n[1] 2.61606"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#ci-for-coefficient-of-enrollment",
    "href": "slides/10-prop-of-estimators.html#ci-for-coefficient-of-enrollment",
    "title": "Properties of estimators",
    "section": "95% CI for coefficient of enrollment",
    "text": "95% CI for coefficient of enrollment\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0\n\n\n\n\n\n\n\n\\[\n\\hat{\\beta}_j \\pm t^* \\times SE(\\hat{\\beta}_j)\n\\]\n\n\n\\[\n0.7804 \\pm 1.9793 \\times 0.1103\n\\]\n\n\n\\[\n[0.562, 0.999]\n\\]"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#interpreting-the-ci",
    "href": "slides/10-prop-of-estimators.html#interpreting-the-ci",
    "title": "Properties of estimators",
    "section": "Interpreting the CI",
    "text": "Interpreting the CI\n🔗 edstem.org/us/courses/62513/discussion/648045"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#computing-ci-in-r",
    "href": "slides/10-prop-of-estimators.html#computing-ci-in-r",
    "title": "Properties of estimators",
    "section": "Computing CI in R",
    "text": "Computing CI in R\n\ntidy(exp_fit, conf.int = TRUE, conf.level = 0.95) |&gt; \n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n13.426\n25.239\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n0.562\n0.999\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0\n-19.466\n-6.986"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#motivation",
    "href": "slides/10-prop-of-estimators.html#motivation",
    "title": "Properties of estimators",
    "section": "Motivation",
    "text": "Motivation\n\n\nWe have discussed how to use least squares to find an estimator of \\(\\hat{\\boldsymbol{\\beta}}\\)\nHow do we know whether our least squares estimator is a “good” estimator?\nWhen we consider what makes an estimator “good”, we’ll look at three criteria:\n\nBias\nVariance\nMean squared error\n\nWe’ll take a look at these over the course of a few lectures and motivate why we might prefer using least squares to compute \\(\\hat{\\boldsymbol{\\beta}}\\) versus other methods"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#bias-and-variance",
    "href": "slides/10-prop-of-estimators.html#bias-and-variance",
    "title": "Properties of estimators",
    "section": "Bias and variance",
    "text": "Bias and variance\nSuppose you are throwing darts at a target\n\n\n\n\n\n\nImage source: Analytics Vidhya\n\n\n\n\nUnbiased: Darts distributed around the target\nBiased: Darts systematically away from the target\nVariance: Darts could be widely spread (high variance) or generally clustered together (low variance)"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#bias-and-variance-1",
    "href": "slides/10-prop-of-estimators.html#bias-and-variance-1",
    "title": "Properties of estimators",
    "section": "Bias and variance",
    "text": "Bias and variance\n\nIdeal scenario: Darts are clustered around the target (unbiased and low variance)\nWorst case scenario: Darts are widely spread out and systematically far from the target (high bias and high variance)\nAcceptable scenario: There’s some trade-off between the bias and variance. For example, it may be acceptable for the darts to be clustered around a point that is close to the target (low bias and low variance)"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#bias-and-variance-2",
    "href": "slides/10-prop-of-estimators.html#bias-and-variance-2",
    "title": "Properties of estimators",
    "section": "Bias and variance",
    "text": "Bias and variance\n\n\nEach time we take a sample of size \\(n\\), we can find the least squares estimator (throw dart at target)\nSuppose we take many independent samples of size \\(n\\) and find the least squares estimator for each sample (throw many darts at the target). Ideally,\n\nThe estimators are centered at the true parameter (unbiased)\nThe estimators are clustered around the true parameter (unbiased with low variance)\n\n\n\n\nLet’s take a look at the mean and variance of the least squares estimator"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#expected-value-of-hatboldsymbolbeta",
    "href": "slides/10-prop-of-estimators.html#expected-value-of-hatboldsymbolbeta",
    "title": "Properties of estimators",
    "section": "Expected value of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Expected value of \\(\\hat{\\boldsymbol{\\beta}}\\)\nThe bias of an estimator is the difference between the estimator’s expected value and the true value of the parameter\n\nLet \\(\\hat{\\theta}\\) be an estimator of the parameter \\(\\theta\\). Then\n\\[\nBias(\\hat{\\theta}) = E(\\hat{\\theta}) - \\theta\n\\]\n\n\nAn estimator is unbiased if the bias is 0 and thus \\(E(\\hat{\\theta}) = \\theta\\)"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#finding-expected-value-and-variance",
    "href": "slides/10-prop-of-estimators.html#finding-expected-value-and-variance",
    "title": "Properties of estimators",
    "section": "Finding expected value and variance",
    "text": "Finding expected value and variance\nLet \\(\\mathbf{A}\\) be a \\(n \\times p\\) matrix of constants and \\(\\mathbf{b}\\) a \\(p \\times 1\\) vector of random variables. Then\n\\[\nE(\\mathbf{Ab}) = \\mathbf{A}E(\\mathbf{b})\n\\]\n\\[\nVar(\\mathbf{Ab}) = \\mathbf{A}Var(\\mathbf{b})\\mathbf{A}^T\n\\]"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#expected-value-of-hatboldsymbolbeta-1",
    "href": "slides/10-prop-of-estimators.html#expected-value-of-hatboldsymbolbeta-1",
    "title": "Properties of estimators",
    "section": "Expected value of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Expected value of \\(\\hat{\\boldsymbol{\\beta}}\\)\nLet’s take a look at the expected value of the least squares estimator. Given \\(E(\\boldsymbol{\\epsilon}) = \\mathbf{0}\\),\n\\[\n\\begin{aligned}\nE(\\hat{\\boldsymbol{\\beta}}) &= E[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}] \\\\[8pt]\n& = \\class{fragment}{E[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T(\\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon})]} \\\\[8pt]\n& = \\class{fragment}{E[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}] + E[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\boldsymbol{\\epsilon}]}\\\\[8pt]\n& = \\class{fragment}{\\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^TE(\\boldsymbol{\\epsilon})} \\\\[8pt]\n& = \\class{fragment}{\\boldsymbol{\\beta}}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#expected-value-of-hatboldsymbolbeta-2",
    "href": "slides/10-prop-of-estimators.html#expected-value-of-hatboldsymbolbeta-2",
    "title": "Properties of estimators",
    "section": "Expected value of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Expected value of \\(\\hat{\\boldsymbol{\\beta}}\\)\nThe least squares estimator \\(\\hat{\\boldsymbol{\\beta}}\\) is an unbiased estimator of \\(\\boldsymbol{\\beta}\\)\n\\[\nE(\\hat{\\boldsymbol{\\beta}}) = \\boldsymbol{\\beta}\n\\]\n\n\nNow let’s take a look at the variance"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#variance-of-hatboldsymbolbeta",
    "href": "slides/10-prop-of-estimators.html#variance-of-hatboldsymbolbeta",
    "title": "Properties of estimators",
    "section": "Variance of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Variance of \\(\\hat{\\boldsymbol{\\beta}}\\)\n\\[\n\\begin{aligned}\nVar(\\hat{\\boldsymbol{\\beta}}) &= Var((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}) \\\\[8pt]\n& = \\class{fragment}{[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T]Var(\\mathbf{y})[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T]^T }\\\\[8pt]\n& = \\class{fragment}{[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T]\\sigma^2_{\\epsilon}\\mathbf{I}[\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}]} \\\\[8pt]\n& = \\class{fragment}{\\sigma^2_{\\epsilon}[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}]} \\\\[8pt]\n& = \\class{fragment}{\\sigma^2_{\\epsilon}(\\mathbf{X}^T\\mathbf{X})^{-1}}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#variance-of-hatboldsymbolbeta-1",
    "href": "slides/10-prop-of-estimators.html#variance-of-hatboldsymbolbeta-1",
    "title": "Properties of estimators",
    "section": "Variance of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Variance of \\(\\hat{\\boldsymbol{\\beta}}\\)\n\\[\nVar(\\hat{\\boldsymbol{\\beta}}) =  \\sigma^2_{\\epsilon}(\\mathbf{X}^T\\mathbf{X})^{-1}\n\\]\nWe will show that \\(\\hat{\\boldsymbol{\\beta}}\\) is the “best” estimator (has the lowest variance) among the class of linear unbiased estimators"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#linear-regression-model",
    "href": "slides/10-prop-of-estimators.html#linear-regression-model",
    "title": "Properties of estimators",
    "section": "“Linear” regression model",
    "text": "“Linear” regression model\nWhat does it mean for a model to be a “linear” regression model?\n\n\nLinear regression models are linear in the parameters, i.e. given an observation \\(y_i\\)\n\\[\ny_i = \\beta_0 + \\beta_1f_1(x_{i1}) +  \\dots + \\beta_pf_p(x_{ip}) + \\epsilon_i\n\\]\nThe functions \\(f_1, \\ldots, f_p\\) can be non-linear as long as \\(\\beta_0, \\beta_1, \\ldots, \\beta_p\\) are linear in \\(Y\\)"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#identify-the-linear-regression-model",
    "href": "slides/10-prop-of-estimators.html#identify-the-linear-regression-model",
    "title": "Properties of estimators",
    "section": "Identify the linear regression model",
    "text": "Identify the linear regression model\n🔗 edstem.org/us/courses/62513/discussion/648051"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#identify-the-linear-regression-model-1",
    "href": "slides/10-prop-of-estimators.html#identify-the-linear-regression-model-1",
    "title": "Properties of estimators",
    "section": "Identify the linear regression model",
    "text": "Identify the linear regression model\n\n\n\\(y_i = \\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i1}^2 + \\beta_3x_{i2}  + \\epsilon_i\\)\n\\(y_i = \\beta_1x_{i1} + \\beta_2x_{i2} + \\beta_3x_{i1}x_{i2} + \\epsilon_i\\)\n\\(y_i = \\beta_0  + \\beta_1\\sin(x_{i1} + \\beta_2x_{i2}) + \\beta_3x_{i3} + \\epsilon_i\\)\n\\(y_i = \\beta_0 + \\beta_1e^{x_{i1}} + \\beta_2e^{x_{i2}} + \\epsilon_i\\)\n\\(y_i = \\exp(\\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i2} + \\beta_3x_{i3}) + \\epsilon_i\\)"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#recap",
    "href": "slides/10-prop-of-estimators.html#recap",
    "title": "Properties of estimators",
    "section": "Recap",
    "text": "Recap\n\nComputed and interpreted confidence interval for a single coefficient\nShowed some properties of \\(\\hat{\\boldsymbol{\\beta}}\\)\nDefined “linear” model\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Useful links",
    "section": "",
    "text": "RStudio containers\n🔗 for Duke Container Manager\n\n\nCourse GitHub organization\n🔗 for GitHub\n\n\nCourse Canvas site\n🔗 for Canvas\n\n\nDiscussion forum\n🔗 to Ed Discussion\n\n\nAssignment submission\n🔗 to Gradescope\n\n\nZoom links\n🔗 on Canvas",
    "crumbs": [
      "Useful links"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "STA 221 Syllabus",
    "section": "",
    "text": "Lecture\nTue & Thu 11:45am - 1pm\nOld Chemistry 116\n\n\nLab 01\nMon 11:45am - 1pm\nLSRC A247\n\n\nLab 02\nMon 4:40 - 5:55pm\nOld Chemistry 101\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nRole\nOffice Hours\n\n\n\n\nProf. Maria Tackett\nInstructor\nMon 1:30 - 2:30pm, Old Chem 118B\nThu 3 - 4pm, Old Chem 118B\nor by appointment\n\n\nKat Husar\nHead TA\nLab 02L leader\nTue 1:30 - 3:30pm, Old Chem 220\n\n\nJon Campbell\nLab 01L leader\nTue & Thu 9 - 10am, Old Chem 025\n\n\nIshrit Gupta\nLab 01L helper\nFri 1- 3pm, Old Chem 203B\n\n\nAlan Wang\nLab 02L helper\nMon & Wed 10 - 11am, Old Chem 203B",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-info",
    "href": "syllabus.html#course-info",
    "title": "STA 221 Syllabus",
    "section": "",
    "text": "Lecture\nTue & Thu 11:45am - 1pm\nOld Chemistry 116\n\n\nLab 01\nMon 11:45am - 1pm\nLSRC A247\n\n\nLab 02\nMon 4:40 - 5:55pm\nOld Chemistry 101\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nRole\nOffice Hours\n\n\n\n\nProf. Maria Tackett\nInstructor\nMon 1:30 - 2:30pm, Old Chem 118B\nThu 3 - 4pm, Old Chem 118B\nor by appointment\n\n\nKat Husar\nHead TA\nLab 02L leader\nTue 1:30 - 3:30pm, Old Chem 220\n\n\nJon Campbell\nLab 01L leader\nTue & Thu 9 - 10am, Old Chem 025\n\n\nIshrit Gupta\nLab 01L helper\nFri 1- 3pm, Old Chem 203B\n\n\nAlan Wang\nLab 02L helper\nMon & Wed 10 - 11am, Old Chem 203B",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "STA 221 Syllabus",
    "section": "Course description",
    "text": "Course description\nIn STA 221, students will learn how linear and logistic regression models are used to explore multivariable relationships, apply these methods to answer relevant and engaging questions using a data-driven approach, and learn the mathematical underpinnings of the models. Students will develop computing skills to implement a reproducible data analysis workflow and gain experience communicating statistical results. Throughout the semester, students will work on a team project where they will develop a research question, answer it using methods learned in the course, and share results through a written report and presentation.\nTopics include applications of linear and logistic regression, analysis of variance, model diagnostics, and model selection. Regression parameter estimation via maximum likelihood least squares will also be discussed. Students will gain experience using the computing tools R and GitHub to analyze real-world data from a variety of fields.\n\nPrerequisites\nEither any STA 100-level course or STA 230, 231, or 240L and MATH 216, 218, or 221. The recommended co-requisite is STA 230, 231, or 240L. Interested students with different backgrounds should seek instructor consent.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-learning-objectives",
    "href": "syllabus.html#course-learning-objectives",
    "title": "STA 221 Syllabus",
    "section": "Course learning objectives",
    "text": "Course learning objectives\nBy the end of the semester, you will be able to…\n\nanalyze data to explore real-world multivariable relationships.\nfit, interpret, and draw conclusions from linear and logistic regression models.\nimplement a reproducible analysis workflow using R for analysis, Quarto to write reports and GitHub for version control and collaboration.\nexplain the mathematical foundations of linear and logistic regression.\neffectively communicate statistical results to a general audience.\nassess the ethical considerations and implications of analysis decisions.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-materials",
    "href": "syllabus.html#course-materials",
    "title": "STA 221 Syllabus",
    "section": "Course materials",
    "text": "Course materials\nWhile there is no official textbook for the course; readings will primarily be made available as they are assigned. We will use the statistical software R. Students will be able to access R through Docker containers provided by Duke Office of Information Technology. See the computing page for more information.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-community",
    "href": "syllabus.html#course-community",
    "title": "STA 221 Syllabus",
    "section": "Course community",
    "text": "Course community\n\nInclusive community\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Duke’s Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nPronouns\nPronouns are meaningful tools to communicate identities and experiences, and using pronouns supports a campus environment where all community members can thrive. Please update your gender pronouns in Duke Hub. You can find instructions to do so here. You can learn more at the Center for Sexual and Gender Diversity’s website.\n\n\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the Student Disability Access Office to request or update accommodations under these circumstances.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website, sta221-fa24.netlify.app.\nLinks to Zoom meetings may be found in Canvas. Periodic announcements will be sent via email and will also be available through Ed Discussion and Canvas Announcements. Please check your email regularly to ensure you have the latest announcements for the course.\n\n\nEmail\nIf you have questions about assignment extensions, accommodations, or any other matter not appropriate for the class discussion forum, please email me directly at maria.tackett@duke.edu. If you email me, please include “STA 221” in the subject line. Barring extenuating circumstances, I will respond to STA 221 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#five-tips-for-success",
    "href": "syllabus.html#five-tips-for-success",
    "title": "STA 221 Syllabus",
    "section": "Five tips for success",
    "text": "Five tips for success\nYour success on this course depends very much on you and the effort you put into it. Your TAs and I will help you be providing you with materials and answering questions and setting a pace, but for this to work you must do the following:\n\nComplete all the preparation work before class.\nAsk questions. As often as you can. In class, out of class. Ask me, ask the TAs, ask your friends, ask the person sitting next to you. This will help you more than anything else. If you get a question wrong on an assessment, ask us why. If you’re not sure about the homework, ask. If you hear something on the news that sounds related to what we discussed, ask. If the reading is confusing, ask.\nDo the readings and other preparation work.\nDo the homework and lab.The earlier you start, the better. It’s not enough to just mechanically plow through the exercises. You should ask yourself how these exercises relate to earlier material, and imagine how they might be changed (to make questions for an exam, for example.)\nDon’t procrastinate. The content builds upon what was taught in previous weeks, so if something is confusing to you in Week 2, Week 3 will become more confusing, Week 4 even worse, etc. Don’t let the week end with unanswered questions. But if you find yourself falling behind and not knowing where to begin asking, come to office hours and work with a member of the teaching team to help you identify a good (re)starting point.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#getting-help-in-the-course",
    "href": "syllabus.html#getting-help-in-the-course",
    "title": "STA 221 Syllabus",
    "section": "Getting help in the course",
    "text": "Getting help in the course\n\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours1 to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. You are encouraged to use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on the class discussion forum Ed Discussion. There is a chance another student has already asked a similar question, so please check the other posts in Ed Discussion before adding a new question. If you know the answer to a question posted in the discussion forum, you are encouraged to respond!\n\nCheck out the Support page for more resources.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#what-to-expect-in-the-course",
    "href": "syllabus.html#what-to-expect-in-the-course",
    "title": "STA 221 Syllabus",
    "section": "What to expect in the course",
    "text": "What to expect in the course\n\nLectures and labs\nLectures and labs are designed to be interactive, so you gain experience applying new concepts and learning from each other. My role as instructor is to introduce you to new methods, tools, and techniques, but it is up to you to take them and make use of them. A lot of what you do in this course will involve writing code, and coding is a skill that is best learned by doing. Therefore, as much as possible, you will be working on a variety of tasks and activities during the lectures and labs. You are expected to prepare for class by completing assigned readings, attend all lecture and lab sessions, and meaningfully contribute to in-class exercises and discussion. Additionally, some lectures will feature application exercises that will be graded based on completing what we do in class.\nYou are expected to bring a laptop, tablet, or any device with internet and a keyboard to each class so that you can participate in the in-class exercises. Please make sure your device is fully charged before you come to class, as the number of outlets in the classroom will not be sufficient to accommodate everyone.\n\n\nTeams\nYou will be assigned to a team at the beginning of the semester. You are encouraged to sit with your teammates in lecture and you will also work with them in the lab sessions. All team members are expected to contribute equally to the completion of the group activities, labs and the final project. You will be asked to complete teamwork evaluations and self-reflections throughout the semester. Failure to adequately contribute to an assignment can result in a penalty to your score relative to the team’s overall mark.\nYou are expected to make use of the provided GitHub repository as the central collaborative platform. Commits to this repository will be used as one of several metrics of each team member’s relative contribution for each project.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#activities-assessment",
    "href": "syllabus.html#activities-assessment",
    "title": "STA 221 Syllabus",
    "section": "Activities & Assessment",
    "text": "Activities & Assessment\nYou will be assessed based on six components: application exercises, homework, labs, exams, project, and teamwork.\n\nLabs\nIn labs, you will apply the concepts discussed in lecture to various data analysis scenarios, with a focus on the computation and communication. Most lab assignments will be completed in teams, and all team members are expected to contribute equally to the completion of each assignment. You are expected to use the team’s Git repository in the course’s GitHub organization as the central platform for collaboration. Commits to this repository will be used as a metric of each team member’s relative contribution for each lab, and there will be periodic peer evaluation on the team collaboration. Lab assignments will be completed using Quarto, correspond to an appropriate GitHub repository, and submitted for grading in Gradescope.\nThe lowest lab grade will be dropped at the end of the semester.\n\n\nHomework\nIn homework, you will apply what you’ve learned during lecture and lab to complete data analysis tasks and explain the underlying mathematics. You may discuss homework assignments with other students; however, homework should be completed and submitted individually. Similar to lab assignments, homework must be typed up using Quarto and GitHub and submitted as a PDF in Gradescope.\nOne homework assignment will be dedicated to a statistics experience. The statistics experience is an opportunity to engage with statistics and data science outside of the classroom through podcasts, books, seminars, data analysis competitions, and other activities. As you complete these experiences, the goal is to consider how the material you’re learning in the course connects with society more broadly.\nThe lowest homework grade will be dropped at the end of the semester.\n\n\nExams\nThere will be two exams in this course. Each exam will include a closed-notes in-class component and an open-note take-home component. Through these exams you have the opportunity to demonstrate what you’ve learned in the course thus far. The exams will focus on both conceptual understanding of the applied and mathematical content and application through analysis and computational tasks. The exams will be based on content in reading assignments, lectures, application exercises, homework, and lab assignments. More detail about the exams will be given during the semester.\n\n\nProject\nThe purpose of the final project is to apply what you’ve learned to analyze an interesting data-driven research question. The project will be completed with your lab teams, and each team will present their work through a written report and presentation. More information about the project will be provided during the semester. You can learn more on the final project page.\n\n\nParticipation (Application exercises + teamwork)\n\nApplication exercises\nYou will get the most out of the course if you actively participate in class and when working with your team. Parts of some lectures will be dedicated to working on Application Exercises (AEs). AEs are submitted by pushing your work to the relevant GitHub repo. AEs from Tuesday lectures should be submitted by Friday by 11:59p ET, and AEs from Thursday lectures are should be submitted by Sunday at 11:59p ET. Because AEs are intended for in-class activities, there are no extensions given on AEs.\nAEs will be graded based on making a good-faith effort to attempt all questions covered in class. You are welcome to, but not required, to work on AEs beyond lecture.\nSuccessful on-time effort on at least 80% of AEs will result in full credit for AEs in the final course grade.\n\n\nTeamwork\nGiven the collaborative nature of statistics and data science work, teamwork will be a key part of this course. You will work in teams for in-class activities, lab assignments, and the final course project. There will be periodic peer and self-evaluations to reflect on the team’s collaboration. These evaluations will be counted as part of the participation grade.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#grading",
    "href": "syllabus.html#grading",
    "title": "STA 221 Syllabus",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\n\nCategory\nPercentage\n\n\n\n\nHomework\n25%\n\n\nFinal project\n15%\n\n\nLabs\n15%\n\n\nExam 01\n20%\n\n\nExam 02\n20%\n\n\nParticipation (AEs + Teamwork)\n5%\n\n\n\n\n\nThe final letter grade will be determined based on the following thresholds:\n\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n&gt;= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n&lt; 60",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-policies",
    "href": "syllabus.html#course-policies",
    "title": "STA 221 Syllabus",
    "section": "Course policies",
    "text": "Course policies\n\nDuke Community Standard\nAll students must adhere to the Duke Community Standard(DCS): Duke University is a community dedicated to scholarship, leadership, and service and to the principles of honesty, fairness, and accountability. Citizens of this community commit to reflect upon these principles in all academic and non-academic endeavors, and to protect and promote a culture of integrity.\nTo uphold the Duke Community Standard, students agree:\n\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors;and\nI will act if the Standard is compromised.\n\n\n\n\n\n\nAcademic honesty\nTL;DR: Don’t cheat!\n\nThe homework assignments must be completed individually and you are welcomed to discuss the assignment with classmates at a high level (e.g., discuss what’s the best way for approaching a problem, what functions are useful for accomplishing a particular task, etc.). However you may not directly share answers to homework questions (including any code) with anyone other than myself and the teaching assistants.\nYou may not discuss or otherwise work with others on the exams. Unauthorized collaboration or using unauthorized materials will be considered a violation for all students involved. More details will be given closer to the exam date.\nFor the projects and team labs, collaboration within teams is not only allowed, but expected. Communication between teams at a high level is also allowed however you may not share code or components of the project or team labs across teams.\nReusing code: Unless explicitly stated otherwise, you may make use of online resources (e.g. StackOverflow) for coding examples on assignments. If you directly use code from an outside source (or use it as inspiration), you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\nUse of artificial intelligence (AI): You should treat AI tools, such as ChatGPT, the same as other online resources. There are two guiding principles that govern how you can use AI in this course:2 (1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. We will practice using AI to facilitate—rather than hinder—learning. (2) Ethical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\nAI tools for code: You may make use of the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. You may use these guidelines for citing AI-generated content.\nNo AI tools for narrative: Unless instructed otherwise, AI is not permitted for writing narrative on assignments. In general, you may use AI as a resource as you complete assignments but not to answer the exercises for you. You are ultimately responsible for the work you turn in; it should reflect your understanding of the course content.\n\n\nIf you are unsure if the use of a particular resource complies with the academic honesty policy, please ask a member of the teaching team.\nRegardless of course delivery format, it is the responsibility of all students to understand and follow all Duke policies, including academic integrity (e.g., completing one’s own work, following proper citation of sources, adhering to guidance around group work projects,and more).Ignoring these requirements is a violation of the Duke Community Standard. Any questions and/or concerns regarding academic integrity can be directed to the Office of Student Conduct and Community Standards at conduct@duke.edu.\n\n\nLate work policy\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback in a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline. Note that the lowest homework and lab assignment will be dropped to accommodate such circumstances.\n\nHomework and labs may be submitted up to 2 days late. There will be a 5% deduction for each 24-hour period the assignment is late.\nThe late work policy for exams will be provided with the exam instructions.\nThe late work policy for the project will be provided with the project instructions.\n\n\n\nWaiver for extenuating circumstances\nIf there are circumstances that prevent you from completing a lab or homework assignment by the stated due date, you may email me at maria.tackett@duke.edu before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide explanation. This waiver may only be used once in the semester, so only use it for a truly extenuating circumstance.\nIf there are circumstances that are having a longer-term impact on your academic performance, please let your academic dean know, as they can be a resource. Please let me know if you need help contacting your academic dean.\n\n\nRegrade Requests\nRegrade requests must be submitted on Gradescope within a week of when an assignment is returned. Regrade requests will be considered if there was an error in the grade calculation or if you feel a correct answer was mistakenly marked as incorrect. Requests to dispute the number of points deducted for an incorrect response will not be considered. Note that by submitting a regrade request, the entire question will be graded which could potentially result in losing points.\nNo grades will be changed after the final project presentations.\n\n\nAttendance policy\nEvery student is expected to attend and participate in lecture and labs. There may be times, however, when you cannot attend class. Lecture recordings are available upon request for students who have an excused absence. See the Lecture recording request policy for more detail. If you miss a lecture, make sure to review the material and complete the application exercise, if applicable, before the next lecture. Labs dedicated to completing the lab assignment and collaborating with your lab team. If you miss a lab session, make sure to communicate with your lab TA and teammates about how you can make up your contribution. If you know you’re going to miss a lab session and you’re feeling well enough to do so, notify your lab TA and teammates ahead of time.\nMore details on Trinity attendance policies are available here.\n\n\n\n\n\nLecture recording request\nLectures will be recorded on Panopto and will be made available to students with an excused absence upon request. Videos shared with such students will be available for a week after the lecture date. To request a particular lecture’s video, please fill out the form at the link below. Please submit the form within 24 hours of missing lecture to ensure you have sufficient time to watch the recording. Please also make sure that any official documentation, such as STINFs, Dean’s excuses, NOVAPs, and quarantine/removal from class notices from student health are also uploaded to the form.\n🔗 https://forms.office.com/r/Y46k4dqRLY\nAbout one week before each exam, the class recordings will be available to all students. These recordings will be available until the start of the exam.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#accommodations",
    "href": "syllabus.html#accommodations",
    "title": "STA 221 Syllabus",
    "section": "Accommodations",
    "text": "Accommodations\n\nAcademic accommodations\nIf you need accommodations for this class, you will need to register with the Student Disability Access Office (SDAO) and provide them with documentation related to your needs. SDAO will work with you to determine what accommodations are appropriate for your situation. Please note that accommodations are not retroactive and disability accommodations cannot be provided until a Faculty Accommodation Letter has been given to me. Please contact SDAO for more information: sdao@duke.edu or access.duke.edu.\n\n\nReligious accommodations\nStudents are permitted by university policy to be absent from class to observe a religious holiday. Accordingly, Trinity College of Arts & Sciences and the Pratt School of Engineering have established procedures to be followed by students for notifying their instructors of an absence necessitated by the observance of a religious holiday. Please submit requests for religious accommodations at the beginning of the semester so that we can work to make suitable arrangements well ahead of time. You can find the policy and relevant notification form here: trinity.duke.edu/undergraduate/academic-policies/religious-holidays",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#academic-and-wellness-support",
    "href": "syllabus.html#academic-and-wellness-support",
    "title": "STA 221 Syllabus",
    "section": "Academic and wellness support",
    "text": "Academic and wellness support\n\nAcademic Resource Center\nThere are times may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917.\n\n\nCAPS\nDuke Counseling & Psychological Services (CAPS) helps Duke Students enhance strengths and develop abilities to successfully live, grow and learn in their personal and academic lives. CAPS recognizes that we are living in unprecedented times and that the changes, challenges and stressors brought on by the COVID-19 pandemic have impacted everyone, often in ways that are tax our well-being. CAPS offers many services to Duke undergraduate students, including brief individual and group counseling, couples counseling and more. CAPS staff also provides outreach to student groups, particularly programs supportive of at-risk populations, on a wide range of issues impacting them in various aspects of campus life. CAPS provides services to students via Telehealth. To initiate services, you can contact their front desk at 919-660-1000.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#important-dates",
    "href": "syllabus.html#important-dates",
    "title": "STA 221 Syllabus",
    "section": "Important dates",
    "text": "Important dates\n\nAugust 26: Classes begin\nSeptember 2: Labor Day. No classes\nSeptember 6: Drop/Add ends\nOctober 14 - 15: Fall Break. No classes\nNovember 8: Last day to withdraw with “W”\nNovember 27 - 29: Thanksgiving recess\nDecember 6: Classes end\nDecember 7 - 10: Reading period\nDecember 11 - 16: Final exam period\n\nClick here for the full Duke academic calendar.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#footnotes",
    "href": "syllabus.html#footnotes",
    "title": "STA 221 Syllabus",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOffice hours are times the teaching team set aside each week to meet with students. Click here to learn more about how to effectively use office hours.↩︎\nThese guiding principles are based on Course Policies related to ChatGPT and other AI Tools developed by Joel Gladd, Ph.D.↩︎↩︎",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "computing-troubleshooting.html",
    "href": "computing-troubleshooting.html",
    "title": "Computing troubleshooting",
    "section": "",
    "text": "If you’re having difficulty launching an RStudio session from your reserved container, go to status.oit.duke.edu and scroll down to Teaching and Learning Tools. Under this heading you’ll find an entry called Container Manager (CMGR Coursework Containers).\n\nIf the status shows something other than Operational, this means there is a known incident with the containers. Check back later to see if it’s been resolved. If there’s a deadline coming up soon, post on the course forum to let us know that there’s an issue. We can look into how quickly it might get resolved and decide on what to do about the deadline accordingly. Note: We don’t anticipate this to happen regularly, the systems are Operational a huge majority of the time!\nIf the status shows Operational, this means the system is expected to be working. Check your internet connection, if need be, restart your computer to ensure a fresh new connection. If your issue persists, post on the course forum with details on what you’ve tried and the errors you see (including verbatim errors and/or screenshots).",
    "crumbs": [
      "Computing",
      "Troubleshooting"
    ]
  }
]