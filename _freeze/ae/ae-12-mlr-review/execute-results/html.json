{
  "hash": "8c335f8cffc481b884095049a8045fb8",
  "result": {
    "markdown": "---\ntitle: \"AE 12: Multiple linear regression review\"\nsubtitle: \"LEGO Sets\"\ndate: \"Oct 31, 2022\"\neditor: visual\nexecute: \n  warning: false\n  message: false\n---\n\n\n::: callout-important\nGo to the [course GitHub organization](https://github.com/sta210-fa22) and locate your `ae-12`- to get started.\n\nThe AE is due on GitHub by Thursday, November 03, 11:59pm.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(patchwork)\nlibrary(rms)\nlibrary(knitr)\n```\n:::\n\n\nThe data for this analysis includes information about LEGO sets from themes produced January 1, 2018 and September 11, 2020. The data were originally scraped from Brickset.com, an online LEGO set guide.\n\nYou will work with data on about 400 randomly selected LEGO sets produced during this time period. The primary variables are interest in this analysis are\n\n-   `Pieces`: Number of pieces in the set from brickset.com.\n-   `Amazon_Price`: Amazon price of the set scraped from brickset.com (in U.S. dollars)\n-   `Size`: General size of the interlocking bricks (Large = LEGO Duplo sets - which include large brick pieces safe for children ages 1 to 5, Small = LEGO sets which- include the traditional smaller brick pieces created for age groups 5 and - older, e.g., City, Friends)\n-   `Theme`: Theme of the LEGO set\n\nThe goal of this analysis is to predict the Amazon price based on the number of pieces, theme, and size of pieces. We will only include observations that have recorded values for all relevant variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlegos <- read_csv(\"data/lego-sample.csv\") |>\n  select(Size, Pieces, Theme, Amazon_Price) |>\n  drop_na()\n```\n:::\n\n\n-   What is a disadvantage of dropping observations that have missing values, instead of using a method to impute, i.e., fill in, the missing data? How might dropping these observations impact the generalizability of conclusions?\n\n## Exploratory data analysis\n\n### Response variable\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = legos, aes(x = Amazon_Price)) +\n  geom_histogram() + \n    labs(title = \"Price of Lego sets on Amazon\",\n         x = \"Price in US dollars\")\n```\n\n::: {.cell-output-display}\n![](ae-12-mlr-review_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n### Predictor variables\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_pieces <- ggplot(data = legos, aes(x = Pieces)) +\n  geom_histogram() + \n    labs(title = \"Number of pieces\",\n         x = \"\")\n\np_size <- ggplot(data = legos, aes(x = Size)) +\n  geom_bar() + \n    labs(title = \"Piece size\",\n         x = \"\") + \n  coord_flip()\n\np_pieces /  p_size\n```\n\n::: {.cell-output-display}\n![](ae-12-mlr-review_files/figure-html/eda-predictors-1.png){width=672}\n:::\n:::\n\n\n-   What (if any) feature engineering might we want to include in a recipe for a model for `Pieces` and `Size`?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlegos |>\n  count(Theme) |>\nggplot(aes(x = fct_reorder(Theme, n), y = n)) +\n  geom_col() + \n    labs(title = \"Lego Set Theme\", \n         x = \"Theme\", \n         y = \"Number of LEGO sets\") + \n  coord_flip()\n```\n\n::: {.cell-output-display}\n![](ae-12-mlr-review_files/figure-html/eda-predictors-theme-1.png){width=672}\n:::\n:::\n\n\n-   Why should we avoid putting `Theme` in a model as is?\n\n-   How can we use [`step_other()`](https://recipes.tidymodels.org/reference/step_other.html) in the recipe to make `Theme` more usable in the model?\n\n## Model Fitting\n\n### Training and test sets\n\nWrite code to data into training (75%) and testing (25%) sets.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1031)\n\n# add code to make training and test sets\n```\n:::\n\n\n### Model workflow\n\nFit the model using `Pieces`, `Size`, and `Theme` to understand variability in `Amazon_Price`. To do so, specify the model and use training data to create a recipe applying the feature engineering steps mentioned above. Then, build the model workflow and fit the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code to specify model \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code to create recipe\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# This is an optional step to see the outcome of the recipe\n\n# add code to prep and bake \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code to build workflow\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code to fit model\n```\n:::\n\n\n## Check conditions + multicollinearity\n\nWhen we fit a model using `recipe` and `workflow`, we need to extract the model object before using the augment function. Fill in the name of the model fit in the code below.\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\nUpdate the option to `eval: true`, so the code chunk evaluates when the document is rendered.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlego_fit_model <- extract_fit_parsnip(______)\nlego_aug <- augment(lego_fit_model)\n```\n:::\n\n\n### Residuals vs predicted values\n\nUse the code below to make a plot of residuals vs. predicted values\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\nUpdate the option to `eval: true`, so the code chunk evaluates when the document is rendered.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = lego_aug, aes(x = .fitted, y= .resid)) +\n  geom_point() + \n  geom_hline(yintercept = 0, color = \"red\", linetype = \"dashed\") + \n  labs(x = \"Predicted\", \n       y = \"Residuals\", \n       title = \"Residuals vs. Predicted\")\n```\n:::\n\n\n### Distribution of residuals\n\nFill in the code below to make a histogram of the residuals with an overlay of the normal distribution.\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\nUpdate the option to `eval: true`, so the code chunk evaluates when the document is rendered.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(lego_aug, aes(.resid)) +\n  geom_histogram(aes(y = after_stat(density))) +\n  stat_function(\n    fun = dnorm, \n    args = list(mean = mean(lego_aug$_____), sd = sd(_____)), \n    color = \"red\"\n  )\n```\n:::\n\n\nUse the plots and information about the data to comment on whether each condition is satisfied.\n\n-   Linearity: \\[Add response\\]\n\n-   Constant variance: \\[Add response\\]\n\n-   Normality: \\[Add response\\]\n\n-   Independence: \\[Add response\\]\n\n### Multicollinearity\n\nFun the code to use the `vif()` function from the **rms** package to check multicollinearity.\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\nUpdate the option to `eval: true`, so the code chunk evaluates when the document is rendered.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvif(lego_fit_model$fit)\n```\n:::\n\n\n-   Are there issues with multicollinearity in the model?\n\n## Next steps\n\n-   Based on the assessment of the model conditions and multicollinearity, what is the next step you might take in the model building process?\n\n::: callout-important\nTo submit the AE:\n\n-   Render the document to produce the PDF with all of your work from today's class.\n-   Push all your work to your `ae-12-` repo on GitHub. (You do not submit AEs on Gradescope).\n:::\n",
    "supporting": [
      "ae-12-mlr-review_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}