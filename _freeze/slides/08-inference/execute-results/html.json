{
  "hash": "7fd41b6ef5a0dd3be1d0003c361d2f6a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Inference for regression\"\nauthor: \"Prof. Maria Tackett\"\ndate: \"2025-02-04\"\ndate-format: \"MMM DD, YYYY\"\nfooter: \"[ðŸ”— STA 221 - Spring 2025](https://sta221-sp25.netlify.app)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs: \n    theme: slides.scss\n    multiplex: false\n    transition: fade\n    slide-number: true\n    incremental: false \n    chalkboard: true\n    include-before: [ '<script type=\"text/x-mathjax-config\">MathJax.Hub.Config({tex2jax: {enableAssistiveMml: false}});</script>']\n  html: \n    output-file: 08-inference-notes.html\nhtml-math-method:\n  method: mathjax\n  url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\nexecute:\n  freeze: auto\n  echo: true\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\nbibliography: references.bib\n---\n\n\n\n\n\n\n## Announcements\n\n-   Lab 03 due **TODAY** at 11:59pm\n\n-   [Click here](https://prodduke.sharepoint.com/:p:/s/ARCStaff839/EZ4PKTRTlCVMpFZiR6XoRycB4UUlRMuI2_Rda9hKxNZtsA) to learn more about the Academic Resource Center\n\n-   [Statistics experience](../hw/stats-experience.html) due **Tuesday, April 22**\n\n## Poll: Office hours availability \n\n<center>\n\n\n\n\n```{=html}\n<iframe width=\"640px\" height=\"480px\" src=\"https://forms.office.com/r/DL8rBQ988y?embed=true\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" style=\"border: none; max-width:100%; max-height:100vh\" allowfullscreen webkitallowfullscreen mozallowfullscreen msallowfullscreen> </iframe>\n```\n\n\n\n\nðŸ”— <https://forms.office.com/r/DL8rBQ988y>\n\n</center>\n\n## Topics\n\n-   Understand statistical inference in the context of regression\n\n-   Describe the assumptions for regression\n\n-   Understand connection between distribution of residuals and inferential procedures\n\n-   Conduct inference on a single coefficient\n\n## Computing setup\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(kableExtra)  \nlibrary(patchwork)   \n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())\n```\n:::\n\n\n\n\n## Data: NCAA Football expenditures {.midi}\n\nToday's data come from [Equity in Athletics Data Analysis](https://ope.ed.gov/athletics/#/datafile/list) and includes information about sports expenditures and revenues for colleges and universities in the United States. This data set was featured in a [March 2022 Tidy Tuesday](https://github.com/rfordatascience/tidytuesday/blob/master/data/2022/2022-03-29/readme.md).\n\nWe will focus on the 2019 - 2020 season expenditures on football for institutions in the NCAA - Division 1 FBS. The variables are :\n\n-   `total_exp_m`: Total expenditures on football in the 2019 - 2020 academic year (in millions USD)\n\n-   `enrollment_th`: Total student enrollment in the 2019 - 2020 academic year (in thousands)\n\n-   `type`: institution type (Public or Private)\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfootball <- read_csv(\"data/ncaa-football-exp.csv\")\n```\n:::\n\n\n\n\n## Univariate EDA\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](08-inference_files/figure-revealjs/unnamed-chunk-3-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n## Bivariate EDA\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](08-inference_files/figure-revealjs/unnamed-chunk-4-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n## Regression model\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nexp_fit <- lm(total_exp_m ~ enrollment_th + type, data = football)\ntidy(exp_fit) |>\n  kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|term          | estimate| std.error| statistic| p.value|\n|:-------------|--------:|---------:|---------:|-------:|\n|(Intercept)   |   19.332|     2.984|     6.478|       0|\n|enrollment_th |    0.780|     0.110|     7.074|       0|\n|typePublic    |  -13.226|     3.153|    -4.195|       0|\n\n\n:::\n:::\n\n\n\n\n<br>\n\nFor every additional 1,000 students, we expect an institution's total expenditures on football to increase by \\$780,000, on average, holding institution type constant.\n\n## From sample to population {.midi}\n\n> For every additional 1,000 students, we expect an institution's total expenditures on football to increase by \\$780,000, on average, holding institution type constant.\n\n. . .\n\n::: incremental\n-   This estimate is valid for the single sample of 127 higher education institutions in the 2019 - 2020 academic year.\n-   But what if we're not interested quantifying the relationship between student enrollment, institution type, and football expenditures for this single sample?\n-   What if we want to say something about the relationship between these variables for all colleges and universities with football programs and across different years?\n:::\n\n# Inference for regression\n\n## Statistical inference\n\n:::::: columns\n:::: {.column width=\"40%\"}\n::: midi\n-   **Statistical inference** provides methods and tools so we can use the single observed sample to make valid statements (inferences) about the population it comes from\n\n-   For our inferences to be valid, the sample should be representative (ideally random) of the population we're interested in\n:::\n::::\n\n::: {.column width=\"60%\"}\n![Image source: Eugene Morgan Â© Penn State](images/08/inference.png){fig-align=\"center\"}\n:::\n::::::\n\n## Inference for linear regression\n\n-   **Inference based on ANOVA**\n\n    -   Hypothesis test for the statistical significance of the overall regression model\n\n    -   Hypothesis test for a subset of coefficients\n\n-   **Inference for a single coefficient** $\\beta_j$ (today's focus)\n\n    -   Hypothesis test for a coefficient $\\beta_j$\n\n    -   Confidence interval for a coefficient $\\beta_j$\n\n## Linear regression model {.midi}\n\n$$\n\\begin{aligned}\n\\mathbf{y} &= \\text{Model} + \\text{Error} \\\\[5pt]\n&= f(\\mathbf{X}) + \\boldsymbol{\\epsilon} \\\\[5pt]\n&= E(\\mathbf{y}|\\mathbf{X}) + \\mathbf{\\epsilon} \\\\[5pt]\n&= \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon}\n\\end{aligned}\n$$\n\n. . .\n\n::: incremental\n-   We have discussed multiple ways to find the least squares estimates of $\\boldsymbol{\\beta} = \\begin{bmatrix}\\beta_0 \\\\\\beta_1\\end{bmatrix}$\n\n    -   None of these approaches depend on the distribution of $\\boldsymbol{\\epsilon}$\n\n-   Now we will use statistical inference to draw conclusions about $\\boldsymbol{\\beta}$ that depend on particular assumptions about the distribution of $\\boldsymbol{\\epsilon}$\n:::\n\n## Linear regression model\n\n$$\\begin{aligned}\n\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}, \\hspace{8mm} \\boldsymbol{\\epsilon} \\sim N(\\mathbf{0}, \\sigma^2_{\\epsilon}\\mathbf{I})\n\\end{aligned}\n$$\n\nsuch that the errors are independent and normally distributed.\n\n. . .\n\n-   **Independent**: Knowing the error term for one observation doesn't tell us about the error term for another observation\n-   **Normally distributed**: The distribution follows a particular mathematical model that is unimodal and symmetric\n\n## Distribution of error terms\n\nThe error terms follow a (multivariate) normal distribution with mean $\\mathbf{0}$ and variance $\\sigma^2\\mathbf{I}$\n\n$$f(\\boldsymbol{\\epsilon}) = \\frac{1}{(2\\pi)^{n/2}|\\sigma^2_{\\epsilon}\\mathbf{I}|^{1/2}}\\exp\\Big\\{-\\frac{1}{2}(\\boldsymbol{\\epsilon} - \\mathbf{0})^\\mathsf{T}(\\sigma^2_{\\epsilon}\\mathbf{I})^{-1}(\\boldsymbol{\\epsilon}- \\mathbf{0})\\Big\\}$$\n\n<br>\n\nThis probability density function is a mathematical function that tells us about the shape of the distribution.\n\n## Describing random phenomena {.midi}\n\n::: incremental\n-   There is some uncertainty in the error terms (and thus the response variable), so we use mathematical models to describe that uncertainty.\n\n-   Some terminology:\n\n    -   **Sample space**: Set of all possible outcomes\n\n    -   **Random variable**: Function (mapping) from the sample space onto real numbers\n\n    -   **Event:** Subset of the sample space, i.e., a set of possible outcomes (possible values the random variable can take)\n\n    -   **Probability density function:** Mathematical function that produces probability of occurrences for events in the sample space for a continuous random variable\n:::\n\n## Visualizing distribution of $\\mathbf{y}|\\mathbf{X}$  {.midi}\n\n$$\n\\mathbf{y}|\\mathbf{X} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma_\\epsilon^2\\mathbf{I})\n$$\n\n![Image source: *Introduction to the Practice of Statistics (5th ed)*](images/08/regression.png){fig-align=\"center\"}\n\n## Expected value  {background-color=\"#ccddeb\"}\n\nLet $\\mathbf{z} = \\begin{bmatrix}z_1 \\\\ \\vdots \\\\z_p\\end{bmatrix}$ be a $p \\times 1$ vector of random variables.\n\n<br>\n\n. . .\n\nThen $E(\\mathbf{z}) = E\\begin{bmatrix}z_1 \\\\ \\vdots \\\\ z_p\\end{bmatrix} = \\begin{bmatrix}E(z_1) \\\\ \\vdots \\\\ E(z_p)\\end{bmatrix}$\n\n## Expected value  {background-color=\"ccddeb\"}\n\nLet $\\mathbf{A}$ and $\\mathbf{C}$ be $n \\times p$ matrices of constants and $\\mathbf{z}$ a $p \\times 1$ vector of random variables. Then\n\n$$\nE(\\mathbf{Az}) = \\mathbf{A}E(\\mathbf{z})\n$$\n\n<br>\n\n. . .\n\n$$\nE(\\mathbf{Az} + \\mathbf{C}) = E(\\mathbf{Az}) + E(\\mathbf{C}) = \\mathbf{A}E(\\mathbf{z}) + \\mathbf{C}\n$$\n\n## Expected value of the response\n\n::: question\nShow $$\nE(\\mathbf{y}|\\mathbf{X}) = \\mathbf{X}\\boldsymbol{\\beta}\n$$\n:::\n\n## Variance {background-color=\"#ccddeb\"}\n\n\\\nLet $\\mathbf{z} = \\begin{bmatrix}z_1 \\\\ \\vdots \\\\z_p\\end{bmatrix}$ be a $p \\times 1$ vector of random variables.\n\n<br>\n\n. . .\n\nThen $Var(\\mathbf{z}) = \\begin{bmatrix}Var(z_1) & Cov(z_1, z_2) & \\dots & Cov(z_1, z_p)\\\\ Cov(z_2, z_1) & Var(z_2) & \\dots & Cov(z_2, z_p) \\\\ \\vdots & \\vdots & \\dots & \\cdot \\\\ Cov(z_p, z_1) & Cov(z_p, z_2) & \\dots & Var(z_p)\\end{bmatrix}$\n\n## Variance  {background-color=\"#ccddeb\"}\n\nLet $\\mathbf{A}$ be an $n \\times p$ matrix of constants and $\\mathbf{z}$ a $p \\times 1$ vector of random variables. Then\n\n$$\nVar(\\mathbf{z}) = E[(\\mathbf{z} - E(\\mathbf{z}))(\\mathbf{z} - E(\\mathbf{z}))^\\mathsf{T}]\n$$\n\n<br>\n\n. . .\n\n$$\n\\begin{aligned}\nVar(\\mathbf{Az}) &= E[(\\mathbf{Az} - E(\\mathbf{Az}))(\\mathbf{Az} - E(\\mathbf{Az}))^\\mathsf{T}] \\\\[8pt]\n& = \\mathbf{A}Var(\\mathbf{z})\\mathbf{A}^\\mathsf{T}\n\\end{aligned}\n$$\n\n## Variance of  the response\n\n::: question\nShow\n\n$$\nVar(\\mathbf{y}|\\mathbf{X}) = \\sigma^2_\\epsilon\\mathbf{I}\n$$\n:::\n\n## Linear transformation of normal random variable {background-color=\"#ccddeb\"}\n\nSuppose $\\mathbf{z}$ is (multivariate) normal random variable such that $\\mathbf{z} \\sim N(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$\n\n<br>\n\nA linear transformation of $\\mathbf{z}$ is also multivariate normal, such that\n\n$$\n\\mathbf{A}\\mathbf{z} + \\mathbf{B} \\sim N(\\mathbf{A}\\boldsymbol{\\mu} + \\mathbf{B}, \\mathbf{A}\\boldsymbol{\\Sigma}\\mathbf{A}^\\mathsf{T})\n$$\n\n::: question\nExplain why $\\mathbf{y}|\\mathbf{X}$ is normally distributed.\n:::\n\n## Assumptions for regression\n\n::::: columns\n::: {.column width=\"50%\"}\n$$\n\\mathbf{y}|\\mathbf{X} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma_\\epsilon^2\\mathbf{I})\n$$\n\n![Image source: *Introduction to the Practice of Statistics (5th ed)*](images/08/regression.png){fig-align=\"center\"}\n:::\n\n::: {.column width=\"50%\"}\n1.  **Linearity:** There is a linear relationship between the response and predictor variables.\n2.  **Constant Variance:** The variability about the least squares line is generally constant.\n3.  **Normality:** The distribution of the residuals is approximately normal.\n4.  **Independence:** The residuals are independent from one another.\n:::\n:::::\n\n## Estimating $\\sigma^2_{\\epsilon}$ {.midi}\n\n-   Once we fit the model, we can use the residuals to estimate $\\sigma_{\\epsilon}^2$\n\n-   The estimated value $\\hat{\\sigma}^2_{\\epsilon}$ is needed for hypothesis testing and constructing confidence intervals for regression\n\n$$\n\\hat{\\sigma}^2_\\epsilon = \\frac{SSR}{n - p - 1} = \\frac{\\mathbf{e}^\\mathsf{T}\\mathbf{e}}{n-p-1} \n$$\n\n. . .\n\n-   The **regression standard error** $\\hat{\\sigma}_{\\epsilon}$ is a measure of the average distance between the observations and regression line\n\n$$\n\\hat{\\sigma}_\\epsilon = \\sqrt{\\frac{SSR}{n - p - 1}} \n$$\n\n# Inference for a single coefficient\n\n## Inference for $\\beta_j$\n\nWe often want to conduct inference on individual model coefficients\n\n-   **Hypothesis test:** Is there a linear relationship between the response and $x_j$?\n\n-   **Confidence interval**: What is a plausible range of values $\\beta_j$ can take?\n\n. . .\n\nBut first we need to understand the distribution of $\\hat{\\beta}_j$\n\n## Sampling distribution of $\\hat{\\beta}$ {.midi}\n\n-   A **sampling distribution** is the probability distribution of a statistic for a large number of random samples of size $n$ from a population\n\n-   The sampling distribution of $\\hat{\\boldsymbol{\\beta}}$ is the probability distribution of the estimated coefficients if we repeatedly took samples of size $n$ and fit the regression model\n\n$$\n\\hat{\\boldsymbol{\\beta}} \\sim N(\\boldsymbol{\\beta}, \\sigma^2_\\epsilon(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1})\n$$\n\n. . .\n\nThe estimated coefficients $\\hat{\\boldsymbol{\\beta}}$ are **normally distributed** with\n\n$$\nE(\\hat{\\boldsymbol{\\beta}}) = \\boldsymbol{\\beta} \\hspace{10mm} Var(\\hat{\\boldsymbol{\\beta}}) = \\sigma^2_{\\epsilon}(\\boldsymbol{X}^\\mathsf{T}\\boldsymbol{X})^{-1}\n$$\n\n## Expected value of $\\boldsymbol{\\hat{\\beta}}$\n\n::: question\nShow\n\n$$E(\\hat{\\boldsymbol{\\beta}}) = \\boldsymbol{\\beta}$$\n:::\n\n## Sampling distribution of $\\hat{\\beta}_j$\n\n$$\n\\hat{\\boldsymbol{\\beta}} \\sim N(\\boldsymbol{\\beta}, \\sigma^2_\\epsilon(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1})\n$$\n\nLet $\\mathbf{C} = (\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1}$. Then, for each coefficient $\\hat{\\beta}_j$,\n\n::: incremental\n-   $E(\\hat{\\beta}_j) = \\boldsymbol{\\beta}_j$, the $j^{th}$ element of $\\boldsymbol{\\beta}$\n\n-   $Var(\\hat{\\beta}_j) = \\sigma^2_{\\epsilon}C_{jj}$\n\n-   $Cov(\\hat{\\beta}_i, \\hat{\\beta}_j) = \\sigma^2_{\\epsilon}C_{ij}$\n:::\n\n## $SE(\\hat{\\boldsymbol{\\beta}})$ for NCAA data\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nX <- model.matrix(total_exp_m ~ enrollment_th + type, data = football)\nsigma_sq <- glance(exp_fit)$sigma^2\n\nvar_beta <- sigma_sq * solve(t(X) %*% X)\nvar_beta\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              (Intercept) enrollment_th typePublic\n(Intercept)     8.9054556   -0.13323338 -6.0899556\nenrollment_th  -0.1332334    0.01216984 -0.1239408\ntypePublic     -6.0899556   -0.12394079  9.9388370\n```\n\n\n:::\n:::\n\n\n\n\n## $SE(\\hat{\\boldsymbol{\\beta}})$ for NCAA data\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n|term          | estimate| std.error| statistic| p.value|\n|:-------------|--------:|---------:|---------:|-------:|\n|(Intercept)   |   19.332|     2.984|     6.478|       0|\n|enrollment_th |    0.780|     0.110|     7.074|       0|\n|typePublic    |  -13.226|     3.153|    -4.195|       0|\n\n\n:::\n:::\n\n\n\n\n<br>\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsqrt(diag(var_beta))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  (Intercept) enrollment_th    typePublic \n     2.984201      0.110317      3.152592 \n```\n\n\n:::\n:::\n\n\n\n\n# Hypothesis test for $\\beta_j$\n\n## Steps for a hypothesis test\n\n1.  State the null and alternative hypotheses.\n2.  Calculate a test statistic.\n3.  Calculate the p-value.\n4.  State the conclusion.\n\n## Hypothesis test for $\\beta_j$: Hypotheses\n\nWe will generally test the hypotheses:\n\n$$\n\\begin{aligned}\n&H_0: \\beta_j = 0 \\\\\n&H_a: \\beta_j \\neq 0\n\\end{aligned}\n$$\n\n::: question\nState these hypotheses in words.\n:::\n\n## Hypothesis test for $\\beta_j$: Test statistic {.midi}\n\n**Test statistic:** Number of standard errors the estimate is away from the null\n\n$$\n\\text{Test Statstic} = \\frac{\\text{Estimate - Null}}{\\text{Standard error}} \\\\\n$$\n\n. . .\n\nIf $\\sigma^2_{\\epsilon}$ was known, the test statistic would be\n\n$$Z = \\frac{\\hat{\\beta}_j - 0}{SE(\\hat{\\beta}_j)} ~ = ~\\frac{\\hat{\\beta}_j - 0}{\\sqrt{\\sigma^2_\\epsilon C_{jj}}} ~\\sim ~ N(0, 1)\n$$\n\n. . .\n\nIn general, $\\sigma^2_{\\epsilon}$ is [**not**]{.underline} known, so we use $\\hat{\\sigma}_{\\epsilon}^2$ to calculate $SE(\\hat{\\beta}_j)$\n\n$$T = \\frac{\\hat{\\beta}_j - 0}{SE(\\hat{\\beta}_j)} ~ = ~\\frac{\\hat{\\beta}_j - 0}{\\sqrt{\\hat{\\sigma}^2_\\epsilon C_{jj}}} ~\\sim ~ t_{n-p-1}\n$$\n\n## Hypothesis test for $\\beta_j$: Test statistic\n\n-   The test statistic $T$ follows a $t$ distribution with $n - p -1$ degrees of freedom.\n\n-   We need to account for the additional variability introduced by calculating $SE(\\hat{\\beta}_j)$ using an estimated value instead of a constant\n\n## *t* vs. N(0,1)\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Standard normal vs. t distributions](08-inference_files/figure-revealjs/fig-normal-t-curves-1.png){#fig-normal-t-curves fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n## Hypothesis test for $\\beta_j$: P-value\n\nThe **p-value** is the probability of observing a test statistic at least as extreme (in the direction of the alternative hypothesis) from the null value as the one observed\n\n$$\np-value = P(|t| > |\\text{test statistic}|),\n$$\n\ncalculated from a $t$ distribution with $n- p - 1$ degrees of freedom\n\n. . .\n\n::: question\nWhy do we take into account \"extreme\" on both the high and low ends?\n:::\n\n## Understanding the p-value\n\n| Magnitude of p-value    | Interpretation                        |\n|:------------------------|:--------------------------------------|\n| p-value \\< 0.01         | strong evidence against $H_0$         |\n| 0.01 \\< p-value \\< 0.05 | moderate evidence against $H_0$       |\n| 0.05 \\< p-value \\< 0.1  | weak evidence against $H_0$           |\n| p-value \\> 0.1          | effectively no evidence against $H_0$ |\n\n<br>\n\n**These are general guidelines. The strength of evidence depends on the context of the problem.**\n\n## Hypothesis test for $\\beta_j$: Conclusion\n\n**There are two parts to the conclusion**\n\n-   Make a conclusion by comparing the p-value to a predetermined decision-making threshold called the significance level ( $\\alpha$ level)\n\n    -   If $\\text{P-value} < \\alpha$: Reject $H_0$\n\n    -   If $\\text{P-value} \\geq \\alpha$: Fail to reject $H_0$\n\n-   State the conclusion in the context of the data\n\n# Application exercise\n\n::: appex\nðŸ“‹ [https://sta221-sp25.netlify.app/ae/ae-03-inference](../ae/ae-03-inference){.uri}\n:::\n\n## Recap\n\n-   Introduced statistical inference in the context of regression\n\n-   Described the assumptions for regression\n\n-   Connected the distribution of residuals and inferential procedures\n\n-   Conducted inference on a single coefficient\n",
    "supporting": [
      "08-inference_files/figure-revealjs"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}