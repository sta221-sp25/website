{
  "hash": "e8971dff22ec4c92748c98dc0362c87f",
  "result": {
    "markdown": "---\ntitle: \"Logistic regression\"\nsubtitle: \"Introduction\"\nauthor: \"Prof. Maria Tackett\"\ndate: \"2022-11-02\"\ndate-format: \"MMM DD, YYYY\"\nfooter: \"[ðŸ”— Week 10](https://sta210-fa22.netlify.app/weeks/week-10.html)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    multiplex: false\n    transition: fade\n    slide-number: true\n    incremental: false \n    chalkboard: true\nexecute:\n  freeze: auto\n  echo: true\n  warning: false\n  message: false\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\n---\n\n\n\n\n## Announcements\n\n-   Project proposal due Fri, Nov 04 at 11:59pm\n\n-   HW 03 due Mon, Nov 07 at 11:59pm\n\n-   Team Feedback #1 due Tue, Nov 08 at 11:59pm\n\n    -   Received email from Teammates around 10am\n    -   Check your junk/spam folder if you do not see the email.\n    -   Email me if you still don't see it.\n\n-   See [Week 10](../weeks/week-10.html) activities\n\n## Topics\n\n-   Logistic regression for binary response variable\n\n-   Relationship between odds and probabilities\n\n-   Use logistic regression model to calculate predicted odds and probabilities\n\n## Computational setup\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(Stat2Data)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 20))\n```\n:::\n\n\n# Predicting categorical outcomes\n\n## Types of outcome variables\n\n**Quantitative outcome variable**:\n\n-   Sales price of a house in Levittown, NY\n-   **Model**: Expected sales price given the number of bedrooms, lot size, etc.\n\n. . .\n\n**Categorical outcome variable**:\n\n-   High risk of coronary heart disease\n-   **Model**: Probability an adult is high risk of heart disease given their age, total cholesterol, etc.\n\n## Models for categorical outcomes\n\n::: columns\n::: {.column width=\"50%\"}\n**Logistic regression**\n\n2 Outcomes\n\n1: Yes, 0: No\n:::\n\n::: {.column width=\"50%\"}\n**Multinomial logistic regression**\n\n3+ Outcomes\n\n1: Democrat, 2: Republican, 3: Independent\n:::\n:::\n\n## 2022 election forecasts\n\n![](images/19/fivethirtyeight-2022-senate.png){fig-align=\"center\"}\n\nSource: [FiveThirtyEight 2022 Election Forecasts](https://projects.fivethirtyeight.com/2022-election-forecast/)\n\n## 2020 NBA finals predictions\n\n![](images/19/nba-predictions.png){fig-align=\"center\"}\n\nSource: [FiveThirtyEight 2019-20 NBA Predictions](https://projects.fivethirtyeight.com/2020-nba-predictions/games/?ex_cid=rrpromo)\n\n## Do teenagers get 7+ hours of sleep? {.smaller}\n\n::: columns\n::: {.column width=\"40%\"}\nStudents in grades 9 - 12 surveyed about health risk behaviors including whether they usually get 7 or more hours of sleep.\n\n`Sleep7`\n\n1: yes\n\n0: no\n:::\n\n::: {.column width=\"60%\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata(YouthRisk2009) #from Stat2Data package\nsleep <- YouthRisk2009 |>\n  as_tibble() |>\n  filter(!is.na(Age), !is.na(Sleep7))\nsleep |>\n  relocate(Age, Sleep7)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 446 Ã— 6\n     Age Sleep7 Sleep           SmokeLife SmokeDaily MarijuaEver\n   <int>  <int> <fct>           <fct>     <fct>            <int>\n 1    16      1 8 hours         Yes       Yes                  1\n 2    17      0 5 hours         Yes       Yes                  1\n 3    18      0 5 hours         Yes       Yes                  1\n 4    17      1 7 hours         Yes       No                   1\n 5    15      0 4 or less hours No        No                   0\n 6    17      0 6 hours         No        No                   0\n 7    17      1 7 hours         No        No                   0\n 8    16      1 8 hours         Yes       No                   0\n 9    16      1 8 hours         No        No                   0\n10    18      0 4 or less hours Yes       Yes                  1\n# â€¦ with 436 more rows\n```\n:::\n:::\n\n:::\n:::\n\n## Plot the data\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(sleep, aes(x = Age, y = Sleep7)) +\n  geom_point() + \n  labs(y = \"Getting 7+ hours of sleep\")\n```\n\n::: {.cell-output-display}\n![](19-logistic-intro_files/figure-revealjs/unnamed-chunk-4-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n## Let's fit a linear regression model\n\n**Outcome:** $Y$ = 1: yes, 0: no\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](19-logistic-intro_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n## Let's use proportions\n\n**Outcome:** Probability of getting 7+ hours of sleep\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](19-logistic-intro_files/figure-revealjs/unnamed-chunk-6-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n## What happens if we zoom out?\n\n**Outcome:** Probability of getting 7+ hours of sleep\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](19-logistic-intro_files/figure-revealjs/unnamed-chunk-7-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\nðŸ›‘ *This model produces predictions outside of 0 and 1.*\n\n## Let's try another model\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](19-logistic-intro_files/figure-revealjs/logistic-model-plot-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n*âœ… This model (called a **logistic regression model**) only produces predictions between 0 and 1.*\n\n## The code\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(sleep_age, aes(x = Age, y = prop)) +\n  geom_point() + \n  geom_hline(yintercept = c(0,1), lty = 2) + \n  stat_smooth(method =\"glm\", method.args = list(family = \"binomial\"), \n              fullrange = TRUE, se = FALSE) +\n  labs(y = \"P(7+ hours of sleep)\") +\n  xlim(1, 40) +\n  ylim(-0.5, 1.5)\n```\n:::\n\n\n## Different types of models\n\n| Method                          | Outcome      | Model                                                     |\n|---------------------------------|--------------|-----------------------------------------------------------|\n| Linear regression               | Quantitative | $Y = \\beta_0 + \\beta_1~ X$                                |\n| Linear regression (transform Y) | Quantitative | $\\log(Y) = \\beta_0 + \\beta_1~ X$                          |\n| Logistic regression             | Binary       | $\\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\beta_0 + \\beta_1 ~ X$ |\n\n## Application exercise\n\n::: appex\nðŸ“‹ [AE 13: Logistic Regression Intro](../ae/ae-13-logistic-intro)\n\nLinear Regression vs. Logistic Regression\n:::\n\n# Odds and probabilities\n\n## Binary response variable\n\n::: incremental\n-   $Y = 1: \\text{ yes}, 0: \\text{ no}$\n-   $\\pi$: **probability** that $Y=1$, i.e., $P(Y = 1)$\n-   $\\frac{\\pi}{1-\\pi}$: **odds** that $Y = 1$\n-   $\\log\\big(\\frac{\\pi}{1-\\pi}\\big)$: **log odds**\n-   Go from $\\pi$ to $\\log\\big(\\frac{\\pi}{1-\\pi}\\big)$ using the **logit transformation**\n:::\n\n## Odds\n\n::: incremental\nSuppose there is a **70% chance** it will rain tomorrow\n\n-   Probability it will rain is $\\mathbf{p = 0.7}$\n-   Probability it won't rain is $\\mathbf{1 - p = 0.3}$\n-   Odds it will rain are **7 to 3**, **7:3**, $\\mathbf{\\frac{0.7}{0.3} \\approx 2.33}$\n:::\n\n## Are teenagers getting enough sleep?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsleep |>\n  count(Sleep7) |>\n  mutate(p = round(n / sum(n), 3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 Ã— 3\n  Sleep7     n     p\n   <int> <int> <dbl>\n1      0   150 0.336\n2      1   296 0.664\n```\n:::\n:::\n\n\n. . .\n\n$P(\\text{7+ hours of sleep}) = P(Y = 1) = p = 0.664$\n\n. . .\n\n$P(\\text{< 7 hours of sleep}) = P(Y = 0) = 1 - p = 0.336$\n\n. . .\n\n$P(\\text{odds of 7+ hours of sleep}) = \\frac{0.664}{0.336} = 1.976$\n\n## From odds to probabilities\n\n::: columns\n::: {.column width=\"50%\"}\n**odds**\n\n\n$$\\omega = \\frac{\\pi}{1-\\pi}$$\n\n:::\n\n::: {.column width=\"50%\"}\n**probability**\n\n\n$$\\pi = \\frac{\\omega}{1 + \\omega}$$\n\n:::\n:::\n\n# Logistic regression\n\n## From odds to probabilities\n\n::: incremental\n(1) **Logistic model**: log odds = $\\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\beta_0 + \\beta_1~X$\n(2) **Odds =** $\\exp\\big\\{\\log\\big(\\frac{\\pi}{1-\\pi}\\big)\\big\\} = \\frac{\\pi}{1-\\pi}$\n(3) Combining (1) and (2) with what we saw earlier\n\n\n$$\\text{probability} = \\pi = \\frac{\\exp\\{\\beta_0 + \\beta_1~X\\}}{1 + \\exp\\{\\beta_0 + \\beta_1~X\\}}$$\n\n:::\n\n## Logistic regression model\n\n**Logit form**: $$\\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\beta_0 + \\beta_1~X$$\n\n. . .\n\n**Probability form**:\n\n\n$$\n\\pi = \\frac{\\exp\\{\\beta_0 + \\beta_1~X\\}}{1 + \\exp\\{\\beta_0 + \\beta_1~X\\}}\n$$\n\n\n## Risk of coronary heart disease\n\nThis dataset is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. We want to use `age` to predict if a randomly selected adult is high risk of having coronary heart disease in the next 10 years.\n\n<br>\n\n`high_risk`:\n\n::: nonincremental\n-   1: High risk of having heart disease in next 10 years\n-   0: Not high risk of having heart disease in next 10 years\n:::\n\n`age`: Age at exam time (in years)\n\n## Data: `heart_disease`\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4,240 Ã— 2\n     age high_risk\n   <dbl> <fct>    \n 1    39 0        \n 2    46 0        \n 3    48 0        \n 4    61 1        \n 5    46 0        \n 6    43 0        \n 7    63 1        \n 8    45 0        \n 9    52 0        \n10    43 0        \n# â€¦ with 4,230 more rows\n```\n:::\n:::\n\n\n## High risk vs. age\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(heart_disease, aes(x = high_risk, y = age)) +\n  geom_boxplot(fill = \"steelblue\") +\n  labs(x = \"High risk - 1: yes, 0: no\",\n       y = \"Age\", \n       title = \"Age vs. High risk of heart disease\")\n```\n\n::: {.cell-output-display}\n![](19-logistic-intro_files/figure-revealjs/unnamed-chunk-12-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n## Let's fit the model\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"1|2|3\"}\nheart_disease_fit <- logistic_reg() |>\n  set_engine(\"glm\") |>\n  fit(high_risk ~ age, data = heart_disease, family = \"binomial\")\n\ntidy(heart_disease_fit) |> kable(digits = 3)\n```\n\n::: {.cell-output-display}\n|term        | estimate| std.error| statistic| p.value|\n|:-----------|--------:|---------:|---------:|-------:|\n|(Intercept) |   -5.561|     0.284|   -19.599|       0|\n|age         |    0.075|     0.005|    14.178|       0|\n:::\n:::\n\n\n## The model\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy(heart_disease_fit) |> kable(digits = 3)\n```\n\n::: {.cell-output-display}\n|term        | estimate| std.error| statistic| p.value|\n|:-----------|--------:|---------:|---------:|-------:|\n|(Intercept) |   -5.561|     0.284|   -19.599|       0|\n|age         |    0.075|     0.005|    14.178|       0|\n:::\n:::\n\n\n\\\n\n$$\\log\\Big(\\frac{\\hat{\\pi}}{1-\\hat{\\pi}}\\Big) = -5.561 + 0.075 \\times \\text{age}$$ where $\\hat{\\pi}$ is the predicted probability of being high risk of heart disease\n\n## Predicted log odds {.midi}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\naugment(heart_disease_fit$fit) |> select(.fitted, .resid)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4,240 Ã— 2\n   .fitted .resid\n     <dbl>  <dbl>\n 1  -2.65  -0.370\n 2  -2.13  -0.475\n 3  -1.98  -0.509\n 4  -1.01   1.62 \n 5  -2.13  -0.475\n 6  -2.35  -0.427\n 7  -0.858  1.56 \n 8  -2.20  -0.458\n 9  -1.68  -0.585\n10  -2.35  -0.427\n# â€¦ with 4,230 more rows\n```\n:::\n:::\n\n. . .\n\n**For observation 1**\n\n\n$$\\text{predicted odds} = \\hat{\\omega} = \\frac{\\hat{\\pi}}{1-\\hat{\\pi}} = \\exp\\{-2.650\\} = 0.071$$\n\n\n## Predicted probabilities {.midi}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredict(heart_disease_fit, new_data = heart_disease, type = \"prob\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4,240 Ã— 2\n   .pred_0 .pred_1\n     <dbl>   <dbl>\n 1   0.934  0.0660\n 2   0.894  0.106 \n 3   0.878  0.122 \n 4   0.733  0.267 \n 5   0.894  0.106 \n 6   0.913  0.0870\n 7   0.702  0.298 \n 8   0.900  0.0996\n 9   0.843  0.157 \n10   0.913  0.0870\n# â€¦ with 4,230 more rows\n```\n:::\n:::\n\n. . .\n\n\n$$\\text{predicted probabilities} = \\hat{\\pi} = \\frac{\\exp\\{-2.650\\}}{1 + \\exp\\{-2.650\\}} = 0.066$$\n\n\n## Predicted classes\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredict(heart_disease_fit, new_data = heart_disease, type = \"class\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4,240 Ã— 1\n   .pred_class\n   <fct>      \n 1 0          \n 2 0          \n 3 0          \n 4 0          \n 5 0          \n 6 0          \n 7 0          \n 8 0          \n 9 0          \n10 0          \n# â€¦ with 4,230 more rows\n```\n:::\n:::\n\n## Default prediction\n\nFor a logistic regression, the default prediction is the `class`.\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredict(heart_disease_fit, new_data = heart_disease)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4,240 Ã— 1\n   .pred_class\n   <fct>      \n 1 0          \n 2 0          \n 3 0          \n 4 0          \n 5 0          \n 6 0          \n 7 0          \n 8 0          \n 9 0          \n10 0          \n# â€¦ with 4,230 more rows\n```\n:::\n:::\n\n## Observed vs. predicted\n\n::: question\nWhat does the following table show?\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredict(heart_disease_fit, new_data = heart_disease) |>\n  bind_cols(heart_disease) |>\n  count(high_risk, .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 Ã— 3\n  high_risk .pred_class     n\n  <fct>     <fct>       <int>\n1 0         0            3596\n2 1         0             644\n```\n:::\n:::\n\n. . .\n\n::: question\nThe `.pred_class` is the class with the highest predicted probability. What is a limitation to using this method to determine the predicted class?\n:::\n\n## Recap\n\n-   Logistic regression for binary response variable\n\n-   Relationship between odds and probabilities\n\n-   Used logistic regression model to calculate predicted odds and probabilities\n\n# Application exercise\n\n::: appex\nðŸ“‹ [AE 13: Logistic Regression Intro](../ae/ae-13-logistic-intro)\n:::\n",
    "supporting": [
      "19-logistic-intro_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    function fireSlideChanged(previousSlide, currentSlide) {\n\n      // dispatch for htmlwidgets\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for reveal\n    if (window.Reveal) {\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\n        fireSlideChanged(event.previousSlide, event.currentSlide);\n      });\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}