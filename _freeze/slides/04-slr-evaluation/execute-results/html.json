{
  "hash": "835a23259a02f903223a5c9759803856",
  "result": {
    "markdown": "---\ntitle: \"SLR: Prediction + model evaluation\"\nauthor: \"Prof. Maria Tackett\"\ndate: \"2022-09-07\"\ndate-format: \"MMM DD, YYYY\"\nfooter: \"[🔗 STA 210 - Fall 2023 -  Schedule](https://sta210-fa23.netlify.app/schedule)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    multiplex: false\n    transition: fade\n    slide-number: false\n    incremental: false \n    chalkboard: true\nhtml-math-method:\n  method: mathjax\n  url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\nexecute:\n  freeze: auto\n  echo: true\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\nbibliography: references.bib\n---\n\n\n\n\n\n## Announcements\n\n-   Office hours have started. [Click here](https://docs.google.com/spreadsheets/d/1Ay1GxqU2HDpFwnNLZxv0baIAa1lJwUVdtvmprPdkefk/edit?usp=sharing) for full schedule.\n\n-   Accept the email invitation to join the sta210-fa22 GitHub organization by **today at 11:59pm.**\n\n    -   You may also go to the [course organization](https://github.com/sta210-fa22) and click to accept on the banner at the top of the page.\n\n    -   If you don't see the email or banner invitation, please email Prof. Tackett (maria.tackett\\@duke.edu).\n\n-   Lab 01 this week - will need access to RStudio and to be a member of the course GitHub organization.\n\n-   See [Week 02](https://sta210-fa22.netlify.app/weeks/week-02.html) for this week's activities.\n\n## Topics\n\n-   Motivate the importance of model evaluation\n\n-   Describe how $R^2$ and RMSE are used to evaluate models\n\n-   Assess model's predictive importance using data splitting and bootstrapping\n\n## Computational setup\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(usdata)      # for the county_2019 dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))\n```\n:::\n\n\n\n## Application exercise\n\n::: appex\n📋 [github.com/sta210-fa22/ae-02-bikeshare](https://github.com/sta210-fa22/ae-02-bikeshare)\n:::\n\n# Uninsurance and high school graduation rates in NC\n\n## Data source\n\n-   The data come from [`usdata::county_2019`](https://openintrostat.github.io/usdata/reference/county_2019.html)\n-   These data have been compiled from the 2019 American Community Survey\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(region, subregion)`\n```\n:::\n:::\n\n\n\n## Uninsurance rate\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04-slr-evaluation_files/figure-html/unnamed-chunk-1-1.png){width=100%}\n:::\n:::\n\n\n\n## High school graduation rate\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04-slr-evaluation_files/figure-html/unnamed-chunk-2-1.png){width=100%}\n:::\n:::\n\n\n\n## Examining the relationship\n\n::: midi\n-   The [NC Labor and Economic Analysis Division (LEAD)](https://www.nccommerce.com/about-us/divisions-programs/labor-economic-analysis-division) \"collects data, conducts research and analysis and publishes reports about the state's economy and labor market. Information and data produced by LEAD help stakeholders make more informed decisions on business recruitment, education and workforce policies and career development, as well as gain a more extensive view of North Carolina's economy.\"\n\n-   Suppose that an analyst working for LEAD is interested in the relationship between uninsurance and high school graduation rates in NC counties.\n:::\n\n. . .\n\n::: question\nWhat type of visualization should the analyst make to examine the relationship between these two variables?\n:::\n\n## Data prep\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncounty_2019_nc <- county_2019 |>\n  as_tibble() |>\n  filter(state == \"North Carolina\") |>\n  select(name, hs_grad, uninsured)\n\ncounty_2019_nc\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 100 × 3\n   name             hs_grad uninsured\n   <chr>              <dbl>     <dbl>\n 1 Alamance County     86.3      11.2\n 2 Alexander County    82.4       8.9\n 3 Alleghany County    77.5      11.3\n 4 Anson County        80.7      11.1\n 5 Ashe County         85.1      12.6\n 6 Avery County        83.6      15.9\n 7 Beaufort County     87.7      12  \n 8 Bertie County       78.4      11.9\n 9 Bladen County       81.3      12.9\n10 Brunswick County    91.3       9.8\n# ℹ 90 more rows\n```\n:::\n:::\n\n\n\n## Uninsurance vs. HS graduation rates\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(county_2019_nc,\n       aes(x = hs_grad, y = uninsured)) +\n  geom_point() +\n  scale_x_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  scale_y_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  labs(\n    x = \"High school graduate\", y = \"Uninsured\",\n    title = \"Uninsurance vs. HS graduation rates\",\n    subtitle = \"North Carolina counties, 2015 - 2019\"\n  ) +\n  geom_point(data = county_2019_nc |> filter(name == \"Durham County\"), aes(x = hs_grad, y = uninsured), shape = \"circle open\", color = \"#8F2D56\", size = 4, stroke = 2) +\n  geom_text(data = county_2019_nc |> filter(name == \"Durham County\"), aes(x = hs_grad, y = uninsured, label = name), color = \"#8F2D56\", fontface = \"bold\", nudge_y = 3, nudge_x = 2)\n```\n\n::: {.cell-output-display}\n![](04-slr-evaluation_files/figure-html/nc-uninsured-hsgrad-scatter-1.png){width=80%}\n:::\n:::\n\n\n\n## Modeling the relationship\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(county_2019_nc, aes(x = hs_grad, y = uninsured)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"#8F2D56\") +\n  scale_x_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  scale_y_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  labs(\n    x = \"High school graduate\", y = \"Uninsured\",\n    title = \"Uninsurance vs. HS graduation rates\",\n    subtitle = \"North Carolina counties, 2015 - 2019\"\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](04-slr-evaluation_files/figure-html/nc-uninsured-hsgrad-scatter-line-1.png){width=80%}\n:::\n:::\n\n\n\n## Fitting the model\n\nWith `fit()`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnc_fit <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(uninsured ~ hs_grad, data = county_2019_nc)\n\ntidy(nc_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)   33.9      3.99        8.50 2.12e-13\n2 hs_grad       -0.262    0.0468     -5.61 1.88e- 7\n```\n:::\n:::\n\n\n\n## Augmenting the data\n\nWith `augment()` to add columns for predicted values (`.fitted`), residuals (`.resid`), etc.:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnc_aug <- augment(nc_fit$fit)\nnc_aug\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 100 × 8\n   uninsured hs_grad .fitted  .resid   .hat .sigma    .cooksd .std.resid\n       <dbl>   <dbl>   <dbl>   <dbl>  <dbl>  <dbl>      <dbl>      <dbl>\n 1      11.2    86.3   11.3  -0.0633 0.0107   2.10 0.00000501    -0.0305\n 2       8.9    82.4   12.3  -3.39   0.0138   2.07 0.0186        -1.63  \n 3      11.3    77.5   13.6  -2.27   0.0393   2.09 0.0252        -1.11  \n 4      11.1    80.7   12.7  -1.63   0.0199   2.09 0.00633       -0.790 \n 5      12.6    85.1   11.6   1.02   0.0100   2.10 0.00122        0.492 \n 6      15.9    83.6   12.0   3.93   0.0112   2.06 0.0203         1.89  \n 7      12      87.7   10.9   1.10   0.0133   2.10 0.00191        0.532 \n 8      11.9    78.4   13.3  -1.44   0.0328   2.09 0.00830       -0.700 \n 9      12.9    81.3   12.6   0.324  0.0174   2.10 0.000218       0.157 \n10       9.8    91.3    9.95 -0.151  0.0291   2.10 0.0000806     -0.0734\n# ℹ 90 more rows\n```\n:::\n:::\n\n\n\n## Visualizing the model I {.smaller}\n\n::: columns\n::: {.column width=\"25%\"}\n::: nonincremental\n-   **Black circles:** Observed values (`y = uninsured`)\n:::\n:::\n\n::: {.column width=\"75%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04-slr-evaluation_files/figure-html/unnamed-chunk-6-1.png){width=100%}\n:::\n:::\n\n\n:::\n:::\n\n## Visualizing the model II {.smaller}\n\n::: columns\n::: {.column width=\"25%\"}\n::: nonincremental\n-   Black circles: Observed values (`y = uninsured`)\n-   **Pink solid line:** Least squares regression line\n:::\n:::\n\n::: {.column width=\"75%\"}\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](04-slr-evaluation_files/figure-html/unnamed-chunk-7-1.png){width=100%}\n:::\n:::\n\n\n:::\n:::\n\n## Visualizing the model III {.smaller}\n\n::: columns\n::: {.column width=\"25%\"}\n::: nonincremental\n-   Black circles: Observed values (`y = uninsured`)\n-   Pink solid line: Least squares regression line\n-   **Maroon triangles:** Predicted values (`y = .fitted`)\n:::\n:::\n\n::: {.column width=\"75%\"}\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](04-slr-evaluation_files/figure-html/unnamed-chunk-8-1.png){width=100%}\n:::\n:::\n\n\n:::\n:::\n\n## Visualizing the model IV {.smaller}\n\n::: columns\n::: {.column width=\"25%\"}\n::: nonincremental\n-   Black circles: Observed values (`y = uninsured`)\n-   Pink solid line: Least squares regression line\n-   Maroon triangles: Predicted values (`y = .fitted`)\n-   **Gray dashed lines:** Residuals\n:::\n:::\n\n::: {.column width=\"75%\"}\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](04-slr-evaluation_files/figure-html/unnamed-chunk-9-1.png){width=100%}\n:::\n:::\n\n\n:::\n:::\n\n## Evaluating the model fit\n\n::: question\nHow can we evaluate whether the model for predicting uninsurance rate from high school graduation rate for NC counties is a good fit?\n:::\n\n# Model evaluation\n\n## Two statistics {.small}\n\n::: incremental\n-   **R-squared**, $R^2$ : Percentage of variability in the outcome explained by the regression model (in the context of SLR, the predictor)\n\n    $$\n    R^2 = Cor(x,y)^2 = Cor(y, \\hat{y})^2\n    $$\n\n-   **Root mean square error, RMSE**: A measure of the average error (average difference between observed and predicted values of the outcome)\n\n    $$\n    RMSE = \\sqrt{\\frac{\\sum_{i = 1}^n (y_i - \\hat{y}_i)^2}{n}}\n    $$\n:::\n\n. . .\n\n::: question\nWhat indicates a good model fit? Higher or lower $R^2$? Higher or lower RMSE?\n:::\n\n## $R^2$\n\n::: incremental\n-   Ranges between 0 (terrible predictor) and 1 (perfect predictor)\n\n-   Has no units\n\n-   Calculate with `rsq()` using the augmented data:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrsq(nc_aug, truth = uninsured, estimate = .fitted)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rsq     standard       0.243\n```\n:::\n:::\n\n\n:::\n\n## Interpreting $R^2$ {.smaller}\n\n\n\n::: {.cell}\n\n:::\n\n\n\n::: poll\n🗳️ **Vote on Ed Discussion**\n\n::: midi\n::: poll\nThe $R^2$ of the model for predicting uninsurance rate from high school graduation rate for NC counties is 24.3%. Which of the following is the correct interpretation of this value?\n:::\n\n-   High school graduation rates correctly predict 24.3% of uninsurance rates in NC counties.\n-   24.3% of the variability in uninsurance rates in NC counties can be explained by high school graduation rates.\n-   24.3% of the variability in high school graduation rates in NC counties can be explained by uninsurance rates.\n-   24.3% of the time uninsurance rates in NC counties can be predicted by high school graduation rates.\n:::\n:::\n\n[Vote - Section 001](https://edstem.org/us/courses/26900/discussion/1738486)\n\n[Vote - Section 002](https://edstem.org/us/courses/26900/discussion/1738497)\n\n## Alternative approach for $R^2$\n\nAlternatively, use `glance()` to construct a single row summary of the model fit, including $R^2$:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglance(nc_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic     p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>       <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     0.243         0.235  2.09      31.5 0.000000188     1  -214.  435.  443.\n# ℹ 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n```\n:::\n:::\n\n\n\n. . .\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglance(nc_fit)$r.squared\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2430694\n```\n:::\n:::\n\n\n\n## RMSE\n\n::: incremental\n-   Ranges between 0 (perfect predictor) and infinity (terrible predictor)\n\n-   Same units as the response variable\n\n-   Calculate with `rmse()` using the augmented data:\n\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    rmse(nc_aug, truth = uninsured, estimate = .fitted)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    # A tibble: 1 × 3\n      .metric .estimator .estimate\n      <chr>   <chr>          <dbl>\n    1 rmse    standard        2.07\n    ```\n    :::\n    :::\n\n\n\n-   The value of RMSE is not very meaningful on its own, but it's useful for comparing across models (more on this when we get to regression with multiple predictors)\n:::\n\n## Obtaining $R^2$ and RMSE\n\n::: incremental\n-   Use `rsq()` and `rmse()`, respectively\n\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    rsq(nc_aug, truth = uninsured, estimate = .fitted)\n    rmse(nc_aug, truth = uninsured, estimate = .fitted)\n    ```\n    :::\n\n\n\n-   First argument: data frame containing `truth` and `estimate` columns\n\n-   Second argument: name of the column containing `truth` (observed outcome)\n\n-   Third argument: name of the column containing `estimate` (predicted outcome)\n:::\n\n## Purpose of model evaluation\n\n-   $R^2$ tells us how our model is doing to predict the data we *already have*\n-   But generally we are interested in prediction for a new observation, not for one that is already in our sample, i.e. **out-of-sample prediction**\n-   We have a couple ways of *simulating* out-of-sample prediction before actually getting new data to evaluate the performance of our models\n\n<!--Ended here in class-->\n\n# Splitting data\n\n## Spending our data\n\n::: incremental\n-   There are several steps to create a useful model: parameter estimation, model selection, performance assessment, etc.\n-   Doing all of this on the entire data we have available leaves us with no other data to assess our choices\n-   We can allocate specific subsets of data for different tasks, as opposed to allocating the largest possible amount to the model parameter estimation only (which is what we've done so far)\n:::\n\n## Simulation: data splitting {.smaller}\n\n::: columns\n::: {.column width=\"30%\"}\n::: nonincremental\n-   Take a random sample of 10% of the data and set aside (testing data)\n-   Fit a model on the remaining 90% of the data (training data)\n-   Use the coefficients from this model to make predictions for the testing data\n-   Repeat 10 times\n:::\n:::\n\n::: {.column width=\"70%\"}\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](04-slr-evaluation_files/figure-html/unnamed-chunk-16-1.png){width=100%}\n:::\n:::\n\n\n:::\n:::\n\n## Predictive performance {.smaller}\n\n::: columns\n::: {.column width=\"25%\"}\n::: question\n::: nonincremental\n-   How consistent are the predictions for different testing datasets?\n-   How consistent are the predictions for counties with high school graduation rates in the middle of the plot vs. in the edges?\n:::\n:::\n:::\n\n::: {.column width=\"75%\"}\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](04-slr-evaluation_files/figure-html/unnamed-chunk-17-1.png){width=100%}\n:::\n:::\n\n\n:::\n:::\n\n# Bootstrapping\n\n## Bootstrapping our data\n\n::: incremental\n-   The idea behind bootstrapping is that if a given observation exists in a sample, there may be more like it in the population\n-   With bootstrapping, we simulate resampling from the population by resampling from the sample we observed\n-   Bootstrap samples are the sampled *with replacement* from the original sample and same size as the original sample\n    -   For example, if our sample consists of the observations {A, B, C}, bootstrap samples could be {A, A, B}, {A, C, A}, {B, C, C}, {A, B, C}, etc.\n:::\n\n## Simulation: bootstrapping {.smaller}\n\n::: columns\n::: {.column width=\"25%\"}\n::: nonincremental\n-   Take a bootstrap sample -- sample with replacement from the original data, same size as the original data\n-   Fit model to the sample and make predictions for that sample\n-   Repeat many times\n:::\n:::\n\n::: {.column width=\"75%\"}\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](04-slr-evaluation_files/figure-html/unnamed-chunk-18-1.png){width=100%}\n:::\n:::\n\n\n:::\n:::\n\n## Predictive performance {.smaller}\n\n::: columns\n::: {.column width=\"25%\"}\n::: question\n::: nonincremental\n-   How consistent are the predictions for different bootstrap datasets?\n-   How consistent are the predictions for counties with high school graduation rates in the middle of the plot vs. in the edges?\n:::\n:::\n:::\n\n::: {.column width=\"75%\"}\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](04-slr-evaluation_files/figure-html/unnamed-chunk-19-1.png){width=100%}\n:::\n:::\n\n\n:::\n:::\n\n## Recap\n\n-   Motivated the importance of model evaluation\n\n-   Described how $R^2$ and RMSE are used to evaluate models\n\n-   Assessed model's predictive importance using data splitting and bootstrapping\n\n## Next week\n\nInference on the slope using\n\n-   Simulation-based methods\n\n-   Mathematical models\n",
    "supporting": [
      "04-slr-evaluation_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}