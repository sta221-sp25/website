{
  "hash": "1087916928e4c16259d6249cbb10bae0",
  "result": {
    "markdown": "---\ntitle: \"MLR Inference\"\nauthor: \"Prof. Maria Tackett\"\ndate: \"2022-10-26\"\ndate-format: \"MMM DD, YYYY\"\nfooter: \"[ðŸ”— Week 09](https://sta210-fa22.netlify.app/weeks/week-09.html)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    multiplex: false\n    transition: fade\n    slide-number: true\n    incremental: false \n    chalkboard: true\nexecute:\n  freeze: auto\n  echo: true\n  warning: false\n  message: false\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\n---\n\n\n\n\n## Announcements\n\n-   See Gradescope for feedback on project topic ideas.\n\n    -   Read comments carefully. Even if a data set is marked \"usable\", there may be suggestions about extensive data cleaning required to make it appropriate for the project.\n    -   Attend office hours or talk with TAs in lab if you have questions.\n\n-   See [Week 09](https://sta210-fa22.netlify.app/weeks/week-09.html) activities.\n\n## Topics\n\n-   Conduct a hypothesis test for $\\beta_j$\n\n-   Calculate a confidence interval for $\\beta_j$\n\n-   Inference pitfalls\n\n## Computational setup\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)      # for tables\nlibrary(patchwork)  # for laying out plots\nlibrary(rms)        # for vif\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 20))\n```\n:::\n\n\n## Modeling workflow\n\n-   Split data into training and test sets.\n\n-   Use cross validation on the training set to fit, evaluate, and compare candidate models. Choose a final model based on summary of cross validation results.\n\n-   Refit the model using the entire training set and do \"final\" evaluation on the test set (make sure you have not overfit the model).\n\n    -   Adjust as needed if there is evidence of overfit.\n\n-   Use model fit on training set for inference and prediction.\n\n## Data: `rail_trail` {.smaller}\n\n::: nonincremental\n-   The Pioneer Valley Planning Commission (PVPC) collected data for ninety days from April 5, 2005 to November 15, 2005.\n-   Data collectors set up a laser sensor, with breaks in the laser beam recording when a rail-trail user passed the data collection station.\n:::\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 90 Ã— 7\n   volume hightemp avgtemp season cloudcover precip day_type\n    <dbl>    <dbl>   <dbl> <chr>       <dbl>  <dbl> <chr>   \n 1    501       83    66.5 Summer       7.60 0      Weekday \n 2    419       73    61   Summer       6.30 0.290  Weekday \n 3    397       74    63   Spring       7.5  0.320  Weekday \n 4    385       95    78   Summer       2.60 0      Weekend \n 5    200       44    48   Spring      10    0.140  Weekday \n 6    375       69    61.5 Spring       6.60 0.0200 Weekday \n 7    417       66    52.5 Spring       2.40 0      Weekday \n 8    629       66    52   Spring       0    0      Weekend \n 9    533       80    67.5 Summer       3.80 0      Weekend \n10    547       79    62   Summer       4.10 0      Weekday \n# â€¦ with 80 more rows\n```\n:::\n:::\n\n\nSource: [Pioneer Valley Planning Commission](http://www.fvgreenway.org/pdfs/Northampton-Bikepath-Volume-Counts%20_05_LTA.pdf) via the **mosaicData** package.\n\n## Variables {.smaller}\n\n**Outcome**:\n\n`volume` estimated number of trail users that day (number of breaks recorded)\n\n. . .\n\n**Predictors**\n\n::: nonincremental\n-   `hightemp` daily high temperature (in degrees Fahrenheit)\n-   `avgtemp` average of daily low and daily high temperature (in degrees Fahrenheit)\n-   `season` one of \"Fall\", \"Spring\", or \"Summer\"\n-   `cloudcover` measure of cloud cover (in oktas)\n-   `precip` measure of precipitation (in inches)\n-   `day_type` one of \"weekday\" or \"weekend\"\n:::\n\n# Conduct a hypothesis test for $\\beta_j$\n\n## Review: Simple linear regression (SLR)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(rail_trail, aes(x = hightemp, y = volume)) + \n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(x = \"High temp (F)\", y = \"Number of riders\")\n```\n\n::: {.cell-output-display}\n![](17-mlr-inference_files/figure-revealjs/unnamed-chunk-4-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n## SLR model summary\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrt_slr_fit <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(volume ~ hightemp, data = rail_trail)\n\ntidy(rt_slr_fit) |> kable()\n```\n\n::: {.cell-output-display}\n|term        |   estimate|  std.error|  statistic|   p.value|\n|:-----------|----------:|----------:|----------:|---------:|\n|(Intercept) | -17.079280| 59.3953040| -0.2875527| 0.7743652|\n|hightemp    |   5.701878|  0.8480074|  6.7238541| 0.0000000|\n:::\n:::\n\n\n## SLR hypothesis test {.midi}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n|term        | estimate| std.error| statistic| p.value|\n|:-----------|--------:|---------:|---------:|-------:|\n|(Intercept) |   -17.08|     59.40|     -0.29|    0.77|\n|hightemp    |     5.70|      0.85|      6.72|    0.00|\n:::\n:::\n\n\n1.  **Set hypotheses:** $H_0: \\beta_1 = 0$ vs. $H_A: \\beta_1 \\ne 0$\n\n. . .\n\n2.  **Calculate test statistic and p-value:** The test statistic is $t= 6.72$ . The p-value is calculated using a $t$ distribution with 88 degrees of freedom. The p-value is $\\approx 0$ .\n\n. . .\n\n3.  **State the conclusion:** The p-value is small, so we reject $H_0$. The data provide strong evidence that high temperature is a helpful predictor for the number of daily riders, i.e. there is a linear relationship between high temperature and number of daily riders.\n\n## Multiple linear regression\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrt_mlr_main_fit <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(volume ~ hightemp + season, data = rail_trail)\n\ntidy(rt_mlr_main_fit) |> kable(digits = 2)\n```\n\n::: {.cell-output-display}\n|term         | estimate| std.error| statistic| p.value|\n|:------------|--------:|---------:|---------:|-------:|\n|(Intercept)  |  -125.23|     71.66|     -1.75|    0.08|\n|hightemp     |     7.54|      1.17|      6.43|    0.00|\n|seasonSpring |     5.13|     34.32|      0.15|    0.88|\n|seasonSummer |   -76.84|     47.71|     -1.61|    0.11|\n:::\n:::\n\n\n## MLR hypothesis test: hightemp {.midi}\n\n1.  **Set hypotheses:** $H_0: \\beta_{hightemp} = 0$ vs. $H_A: \\beta_{hightemp} \\ne 0$, given `season` is in the model\n\n. . .\n\n2.  **Calculate test statistic and p-value:** The test statistic is $t = 6.43$. The p-value is calculated using a $t$ distribution with 86 (n - p - 1) degrees of freedom. The p-value is $\\approx 0$.\n\n. . .\n\n3.  **State the conclusion:** The p-value is small, so we reject $H_0$. The data provide strong evidence that high temperature for the day is a useful predictor in a model that already contains the season as a predictor for number of daily riders.\n\n## The model for `season = Spring` {.smaller}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n|term         | estimate| std.error| statistic| p.value|\n|:------------|--------:|---------:|---------:|-------:|\n|(Intercept)  |  -125.23|     71.66|     -1.75|    0.08|\n|hightemp     |     7.54|      1.17|      6.43|    0.00|\n|seasonSpring |     5.13|     34.32|      0.15|    0.88|\n|seasonSummer |   -76.84|     47.71|     -1.61|    0.11|\n:::\n:::\n\n\n<br>\n\n. . .\n\n\n$$\n\\begin{aligned}\n\\widehat{volume} &= -125.23 + 7.54 \\times \\texttt{hightemp} + 5.13 \\times \\texttt{seasonSpring} - 76.84 \\times \\texttt{seasonSummer} \\\\\n&= -125.23 + 7.54 \\times \\texttt{hightemp} + 5.13 \\times 1 - 76.84 \\times 0 \\\\\n&= -120.10 + 7.54 \\times \\texttt{hightemp}\n\\end{aligned}\n$$\n\n\n## The model for `season = Summer` {.smaller}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n|term         | estimate| std.error| statistic| p.value|\n|:------------|--------:|---------:|---------:|-------:|\n|(Intercept)  |  -125.23|     71.66|     -1.75|    0.08|\n|hightemp     |     7.54|      1.17|      6.43|    0.00|\n|seasonSpring |     5.13|     34.32|      0.15|    0.88|\n|seasonSummer |   -76.84|     47.71|     -1.61|    0.11|\n:::\n:::\n\n\n<br>\n\n. . .\n\n\n$$\n\\begin{aligned}\n\\widehat{volume} &= -125.23 + 7.54 \\times \\texttt{hightemp} + 5.13 \\times \\texttt{seasonSpring} - 76.84 \\times \\texttt{seasonSummer} \\\\\n&= -125.23 + 7.54 \\times \\texttt{hightemp} + 5.13 \\times 0 - 76.84 \\times 1 \\\\\n&= -202.07 + 7.54 \\times \\texttt{hightemp}\n\\end{aligned}\n$$\n\n\n## The model for `season = Fall` {.smaller}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n|term         | estimate| std.error| statistic| p.value|\n|:------------|--------:|---------:|---------:|-------:|\n|(Intercept)  |  -125.23|     71.66|     -1.75|    0.08|\n|hightemp     |     7.54|      1.17|      6.43|    0.00|\n|seasonSpring |     5.13|     34.32|      0.15|    0.88|\n|seasonSummer |   -76.84|     47.71|     -1.61|    0.11|\n:::\n:::\n\n\n<br>\n\n. . .\n\n\n$$\n\\begin{aligned}\n\\widehat{volume} &= -125.23 + 7.54 \\times \\texttt{hightemp} + 5.13 \\times \\texttt{seasonSpring} - 76.84 \\times \\texttt{seasonSummer} \\\\\n&= -125.23 + 7.54 \\times \\texttt{hightemp} + 5.13 \\times 0 - 76.84 \\times 0 \\\\\n&= -125.23 + 7.54 \\times \\texttt{hightemp}\n\\end{aligned}\n$$\n\n\n## The models\n\nSame slope, different intercepts\n\n-   `season = Spring`: $-120.10 + 7.54 \\times \\texttt{hightemp}$\n-   `season = Summer`: $-202.07 + 7.54 \\times \\texttt{hightemp}$\n-   `season = Fall`: $-125.23 + 7.54 \\times \\texttt{hightemp}$\n\n## Application exercise\n\n::: appex\nðŸ“‹ [AE 11: MLR Inference](../ae/ae-11-mlr-inference.html)\n:::\n\n::: question\n**Ex 1.** Add an interaction effect between `hightemp` and `season` to the model. Do the data provide evidence of a significant interaction effect? Comment on the significance of the interaction terms.\n:::\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_6359418b\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">08</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n\n# Confidence interval for $\\beta_j$\n\n## Confidence interval for $\\beta_j$ {.midi}\n\n-   The $C%$ confidence interval for $\\beta_j$ $$\\hat{\\beta}_j \\pm t^* SE(\\hat{\\beta}_j)$$ where $t^*$ follows a $t$ distribution with $n - p - 1$ degrees of freedom.\n\n-   Generically, we are $C%$ confident that the interval LB to UB contains the population coefficient of $x_j$.\n\n-   In context, we are $C%$ confident that for every one unit increase in $x_j$, we expect $y$ to change by LB to UB units, holding all else constant.\n\n## Confidence interval for $\\beta_j$\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy(rt_mlr_main_fit, conf.int = TRUE) |>\n  kable(digits= 2)\n```\n\n::: {.cell-output-display}\n|term         | estimate| std.error| statistic| p.value| conf.low| conf.high|\n|:------------|--------:|---------:|---------:|-------:|--------:|---------:|\n|(Intercept)  |  -125.23|     71.66|     -1.75|    0.08|  -267.68|     17.22|\n|hightemp     |     7.54|      1.17|      6.43|    0.00|     5.21|      9.87|\n|seasonSpring |     5.13|     34.32|      0.15|    0.88|   -63.10|     73.36|\n|seasonSummer |   -76.84|     47.71|     -1.61|    0.11|  -171.68|     18.00|\n:::\n:::\n\n\n## CI for `hightemp` {.midi}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n|term         | estimate| std.error| statistic| p.value| conf.low| conf.high|\n|:------------|--------:|---------:|---------:|-------:|--------:|---------:|\n|(Intercept)  |  -125.23|     71.66|     -1.75|    0.08|  -267.68|     17.22|\n|hightemp     |     7.54|      1.17|      6.43|    0.00|     5.21|      9.87|\n|seasonSpring |     5.13|     34.32|      0.15|    0.88|   -63.10|     73.36|\n|seasonSummer |   -76.84|     47.71|     -1.61|    0.11|  -171.68|     18.00|\n:::\n:::\n\n\n<br>\n\nWe are 95% confident that for every degree Fahrenheit the day is warmer, the number of riders increases by 5.21 to 9.87, on average, holding season constant.\n\n## CI for `seasonSpring` {.midi}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n|term         | estimate| std.error| statistic| p.value| conf.low| conf.high|\n|:------------|--------:|---------:|---------:|-------:|--------:|---------:|\n|(Intercept)  |  -125.23|     71.66|     -1.75|    0.08|  -267.68|     17.22|\n|hightemp     |     7.54|      1.17|      6.43|    0.00|     5.21|      9.87|\n|seasonSpring |     5.13|     34.32|      0.15|    0.88|   -63.10|     73.36|\n|seasonSummer |   -76.84|     47.71|     -1.61|    0.11|  -171.68|     18.00|\n:::\n:::\n\n\n<br>\n\nWe are 95% confident that the number of riders on a Spring day is lower by 63.1 to higher by 73.4 compared to a Fall day, on average, holding high temperature for the day constant.\n\n. . .\n\n::: question\nIs `season` a significant predictor of the number of riders, after accounting for high temperature?\n:::\n\n# Inference pitfalls\n\n## Large sample sizes\n\n::: callout-caution\nIf the sample size is large enough, the test will likely result in rejecting $H_0: \\beta_j = 0$ even $x_j$ has a very small effect on $y$.\n\n::: nonincremental\n-   Consider the **practical significance** of the result not just the statistical significance.\n\n-   Use the confidence interval to draw conclusions instead of relying only p-values.\n:::\n:::\n\n## Small sample sizes\n\n::: callout-caution\nIf the sample size is small, there may not be enough evidence to reject $H_0: \\beta_j=0$.\n\n::: nonincremental\n-   When you fail to reject the null hypothesis, **DON'T** immediately conclude that the variable has no association with the response.\n\n-   There may be a linear association that is just not strong enough to detect given your data, or there may be a non-linear association.\n:::\n:::\n",
    "supporting": [
      "17-mlr-inference_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/countdown-0.3.5/countdown.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/countdown-0.3.5/countdown.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    function fireSlideChanged(previousSlide, currentSlide) {\n\n      // dispatch for htmlwidgets\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for reveal\n    if (window.Reveal) {\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\n        fireSlideChanged(event.previousSlide, event.currentSlide);\n      });\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}