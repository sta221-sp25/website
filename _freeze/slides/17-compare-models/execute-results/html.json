{
  "hash": "50539cdfb54dd47ded3cf0d9de98373a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Model comparison\"\nauthor: \"Prof. Maria Tackett\"\ndate: \"2024-10-29\"\ndate-format: \"MMM DD, YYYY\"\nfooter: \"[ðŸ”— STA 221 - Fall 2024](https://sta221-fa24.netlify.app)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    multiplex: false\n    transition: fade\n    slide-number: true\n    incremental: false \n    chalkboard: true\n    include-before: [ '<script type=\"text/x-mathjax-config\">MathJax.Hub.Config({tex2jax: {enableAssistiveMml: false}});</script>']\nhtml-math-method:\n  method: mathjax\n  url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\nexecute:\n  freeze: auto\n  echo: true\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\nfilters:\n  - parse-latex\nbibliography: references.bib\n---\n\n\n\n## Announcements {.midi}\n\n-   HW 03 due Thursday at 11:59pm (released after class)\n\n-   Project: Exploratory data analysis due Thursday at 11:59pm\n\n-   Looking ahead\n\n    -   Project presentations November 11\n\n    -   Statistics experience due Tuesday, November 26\n\n## Computing set up\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)\nlibrary(kableExtra) # for formatting tables\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())\n```\n:::\n\n\n\n## Topics\n\n-   ANOVA for Multiple Linear Regression\n\n-   Nested (Partial) F Test\n\n-   AIC & BIC\n\n## Restaurant tips\n\nWhat affects the amount customers tip at a restaurant?\n\n-   **Response:**\n    -   `Tip`: amount of the tip\n-   **Predictors:**\n    -   `Party`: number of people in the party\n    -   `Meal`: time of day (Lunch, Dinner, Late Night)\n    -   `Age`: age category of person paying the bill (Yadult, Middle, SenCit)\n\n\n\n::: {.cell}\n\n:::\n\n\n\n## Response Variable\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-compare-models_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n\n## Predictor Variables\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-compare-models_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n\n## Response vs. Predictors\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-compare-models_files/figure-revealjs/unnamed-chunk-5-1.png){width=960}\n:::\n:::\n\n\n\n## Restaurant tips: model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel1 <- lm(Tip ~ Party +  Age , data = tips)\ntidy(model1, conf.int = TRUE) |>\n  kable(format = \"markdown\", digits=3)\n```\n\n::: {.cell-output-display}\n\n\n|term        | estimate| std.error| statistic| p.value| conf.low| conf.high|\n|:-----------|--------:|---------:|---------:|-------:|--------:|---------:|\n|(Intercept) |    0.838|     0.397|     2.112|   0.036|    0.055|     1.622|\n|Party       |    1.837|     0.124|    14.758|   0.000|    1.591|     2.083|\n|AgeSenCit   |    0.379|     0.410|     0.925|   0.356|   -0.430|     1.189|\n|AgeYadult   |   -1.009|     0.408|    -2.475|   0.014|   -1.813|    -0.204|\n\n\n:::\n:::\n\n\n\n<center>**Is this the best model to explain variation in Tips?**</center>\n\n# Test for overall significance\n\n## Test for overall significance: Hypotheses\n\nWe can conduct a hypothesis test using the ANOVA table to determine if there is at least one non-zero coefficient in the model\n\n$$\n\\begin{aligned}\n&H_0: \\beta_1 = \\dots = \\beta_p = 0\\\\\n&H_a: \\beta_j \\neq 0 \\text{ for at least one }j \n\\end{aligned}\n$$\n\n. . .\n\n**For the tips data:**$$\n\\begin{aligned}\n&H_0: \\beta_1 = \\beta_2 = \\beta_3 = 0\\\\\n&H_a: \\beta_j \\neq 0 \\text{ for at least one }j \n\\end{aligned}\n$$\n\n## Test for overall significance: Test statistic {.midi}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|Source    |  Df|   Sum Sq|Mean Sq |F Stat |Pr(> F) |\n|:---------|---:|--------:|:-------|:------|:-------|\n|Model     |   3| 1226.664|408.888 |98.284 |0       |\n|Residuals | 165|  686.444|4.16    |       |        |\n|Total     | 168| 1913.108|        |       |        |\n\n\n:::\n:::\n\n\n\n<br>\n\n**Test statistic**: Ratio of explained to unexplained variability\n\n$$\nF = \\frac{\\text{Mean Square Model}}{\\text{Mean Square Residuals}}\n$$\n\nThe test statistic follows an $F$ distribution with $p$ and $n -  p - 1$ degrees of freedom\n\n## Test for overall significance: P-value\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-compare-models_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n\n$$\n\\text{P-value} = \\text{Pr}(F > \\text{F Stat})\n$$\n\n## Test for overall significance: Conclusion {.midi}\n\n$$\n\\begin{aligned}\n&H_0: \\beta_1 = \\beta_2 = \\beta_3 = 0\\\\\n&H_a: \\beta_j \\neq 0 \\text{ for at least one }j \n\\end{aligned}\n$$\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|Source    |  Df|   Sum Sq|Mean Sq |F Stat |Pr(> F) |\n|:---------|---:|--------:|:-------|:------|:-------|\n|Model     |   3| 1226.664|408.888 |98.284 |0       |\n|Residuals | 165|  686.444|4.16    |       |        |\n|Total     | 168| 1913.108|        |       |        |\n\n\n:::\n:::\n\n\n\n<br>\n\n::: question\nWhat is the conclusion from this hypothesis test?\n:::\n\n## Testing subset of coefficients\n\n-   Sometimes we want to test whether a **subset of coefficients** are all equal to 0\n\n-   This is often the case when we want test\n\n    -   whether a categorical variable with $k$ levels is a significant predictor of the response\n    -   whether the interaction between a categorical and quantitative variable is significant\n\n-   To do so, we will use the **Nested (Partial) F-test**\n\n## Nested (Partial) F Test {#nested-partial-f-test}\n\n-   Suppose we have a full and reduced model:\n\n$$\\begin{aligned}&\\text{Full}: y = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_q x_q + \\beta_{q+1} x_{q+1} + \\dots \\beta_p x_p \\\\\n&\\text{Reduced}: y = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_q x_q\\end{aligned}$$\n\n. . .\n\n-   We want to test whether any of the variables $x_{q+1}, x_{q+2}, \\ldots, x_p$ are significant predictors. To do so, we will test the hypothesis:\n\n    $$\\begin{aligned}&H_0: \\beta_{q+1} =  \\beta_{q+2} = \\dots = \\beta_p = 0 \\\\ \n    &H_a: \\text{at least one }\\beta_j \\text{ is not equal to 0}\\end{aligned}$$\n\n## Nested F Test\n\n-   The test statistic for this test is\n\n$$F = \\frac{(SSR_{reduced} - SSR_{full})\\big/\\text{# predictors tested}}{SSR_{full}\\big/(n-p_{full}-1)}$$ <br>\n\n-   Calculate the p-value using the F distribution with df1 = \\# predictors tested and df2 = $(n-p_{full}-1)$\n\n## Is `Meal` a significant predictor of tips?\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:right;\"> estimate </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 1.254 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Party </td>\n   <td style=\"text-align:right;\"> 1.808 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> AgeSenCit </td>\n   <td style=\"text-align:right;\"> 0.390 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> AgeYadult </td>\n   <td style=\"text-align:right;\"> -0.505 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;background-color: rgba(220, 229, 178, 255) !important;\"> MealLate Night </td>\n   <td style=\"text-align:right;background-color: rgba(220, 229, 178, 255) !important;\"> -1.632 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;background-color: rgba(220, 229, 178, 255) !important;\"> MealLunch </td>\n   <td style=\"text-align:right;background-color: rgba(220, 229, 178, 255) !important;\"> -0.612 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n## Tips: Nested F test\n\n$$\\begin{aligned}&H_0: \\beta_{late night} = \\beta_{lunch} = 0\\\\\n&H_a: \\text{ at least one }\\beta_j \\text{ is not equal to 0}\\end{aligned}$$\n\n. . .\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreduced <- lm(Tip ~ Party + Age, data = tips)\n```\n:::\n\n\n\n. . .\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull <- lm(Tip ~ Party + Age + Meal, data = tips)\n```\n:::\n\n\n\n<br>\n\n. . .\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Nested F test in R\nanova(reduced, full)\n```\n:::\n\n\n\n## Tips: Nested F test\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> Res.Df </th>\n   <th style=\"text-align:right;\"> RSS </th>\n   <th style=\"text-align:right;\"> Df </th>\n   <th style=\"text-align:right;\"> Sum of Sq </th>\n   <th style=\"text-align:right;\"> F </th>\n   <th style=\"text-align:right;\"> Pr(&gt;F) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 165 </td>\n   <td style=\"text-align:right;\"> 686.444 </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;background-color: rgba(220, 229, 178, 255) !important;\"> 163 </td>\n   <td style=\"text-align:right;background-color: rgba(220, 229, 178, 255) !important;\"> 622.979 </td>\n   <td style=\"text-align:right;background-color: rgba(220, 229, 178, 255) !important;\"> 2 </td>\n   <td style=\"text-align:right;background-color: rgba(220, 229, 178, 255) !important;\"> 63.465 </td>\n   <td style=\"text-align:right;background-color: rgba(220, 229, 178, 255) !important;\"> 8.303 </td>\n   <td style=\"text-align:right;background-color: rgba(220, 229, 178, 255) !important;\"> 0 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n. . .\n\nF Stat: $\\frac{(686.444 - 622.979)/2}{622.979/(169 - 5 - 1)} = 8.303$\n\n. . .\n\nP-value: P(F \\> 8.303) = 0.0003 - calculated using an F distribution with 2 and 163 degrees of freedom\n\n. . .\n\nThe data provide sufficient evidence to conclude that at least one coefficient associated with `Meal` is not zero. Therefore, `Meal` is a significant predictor of `Tips`.\n\n## Model with `Meal`\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:right;\"> estimate </th>\n   <th style=\"text-align:right;\"> std.error </th>\n   <th style=\"text-align:right;\"> statistic </th>\n   <th style=\"text-align:right;\"> p.value </th>\n   <th style=\"text-align:right;\"> conf.low </th>\n   <th style=\"text-align:right;\"> conf.high </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 1.254 </td>\n   <td style=\"text-align:right;\"> 0.394 </td>\n   <td style=\"text-align:right;\"> 3.182 </td>\n   <td style=\"text-align:right;\"> 0.002 </td>\n   <td style=\"text-align:right;\"> 0.476 </td>\n   <td style=\"text-align:right;\"> 2.032 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Party </td>\n   <td style=\"text-align:right;\"> 1.808 </td>\n   <td style=\"text-align:right;\"> 0.121 </td>\n   <td style=\"text-align:right;\"> 14.909 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> 1.568 </td>\n   <td style=\"text-align:right;\"> 2.047 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> AgeSenCit </td>\n   <td style=\"text-align:right;\"> 0.390 </td>\n   <td style=\"text-align:right;\"> 0.394 </td>\n   <td style=\"text-align:right;\"> 0.990 </td>\n   <td style=\"text-align:right;\"> 0.324 </td>\n   <td style=\"text-align:right;\"> -0.388 </td>\n   <td style=\"text-align:right;\"> 1.168 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> AgeYadult </td>\n   <td style=\"text-align:right;\"> -0.505 </td>\n   <td style=\"text-align:right;\"> 0.412 </td>\n   <td style=\"text-align:right;\"> -1.227 </td>\n   <td style=\"text-align:right;\"> 0.222 </td>\n   <td style=\"text-align:right;\"> -1.319 </td>\n   <td style=\"text-align:right;\"> 0.308 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> MealLate Night </td>\n   <td style=\"text-align:right;\"> -1.632 </td>\n   <td style=\"text-align:right;\"> 0.407 </td>\n   <td style=\"text-align:right;\"> -4.013 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> -2.435 </td>\n   <td style=\"text-align:right;\"> -0.829 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> MealLunch </td>\n   <td style=\"text-align:right;\"> -0.612 </td>\n   <td style=\"text-align:right;\"> 0.402 </td>\n   <td style=\"text-align:right;\"> -1.523 </td>\n   <td style=\"text-align:right;\"> 0.130 </td>\n   <td style=\"text-align:right;\"> -1.405 </td>\n   <td style=\"text-align:right;\"> 0.181 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n## Including interactions\n\nDoes the effect of `Party` differ based on the `Meal` time?\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|term                 | estimate|\n|:--------------------|--------:|\n|(Intercept)          |    1.276|\n|Party                |    1.795|\n|AgeSenCit            |    0.401|\n|AgeYadult            |   -0.470|\n|MealLate Night       |   -1.845|\n|MealLunch            |   -0.461|\n|Party:MealLate Night |    0.111|\n|Party:MealLunch      |   -0.050|\n\n\n:::\n:::\n\n\n\n## Nested F test for interactions\n\nLet's use a Nested F test to determine if `Party*Meal` is statistically significant.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreduced <- lm(Tip ~ Party + Age + Meal, data = tips)\n```\n:::\n\n\n\n. . .\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull <- lm(Tip ~ Party + Age + Meal + Meal * Party, \n           data = tips)\n```\n:::\n\n\n\n. . .\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkable(anova(reduced, full), format = \"markdown\", digits = 3) |>\n  row_spec(2, background = \"#dce5b2\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> Res.Df </th>\n   <th style=\"text-align:right;\"> RSS </th>\n   <th style=\"text-align:right;\"> Df </th>\n   <th style=\"text-align:right;\"> Sum of Sq </th>\n   <th style=\"text-align:right;\"> F </th>\n   <th style=\"text-align:right;\"> Pr(&gt;F) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 163 </td>\n   <td style=\"text-align:right;\"> 622.979 </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;background-color: rgba(220, 229, 178, 255) !important;\"> 161 </td>\n   <td style=\"text-align:right;background-color: rgba(220, 229, 178, 255) !important;\"> 621.965 </td>\n   <td style=\"text-align:right;background-color: rgba(220, 229, 178, 255) !important;\"> 2 </td>\n   <td style=\"text-align:right;background-color: rgba(220, 229, 178, 255) !important;\"> 1.014 </td>\n   <td style=\"text-align:right;background-color: rgba(220, 229, 178, 255) !important;\"> 0.131 </td>\n   <td style=\"text-align:right;background-color: rgba(220, 229, 178, 255) !important;\"> 0.877 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n## Final model for now\n\nWe conclude that the effect of **`Party`** does not differ based **`Meal`**. Therefore, we will use the original model that only included main effects.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:right;\"> estimate </th>\n   <th style=\"text-align:right;\"> std.error </th>\n   <th style=\"text-align:right;\"> statistic </th>\n   <th style=\"text-align:right;\"> p.value </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 1.254 </td>\n   <td style=\"text-align:right;\"> 0.394 </td>\n   <td style=\"text-align:right;\"> 3.182 </td>\n   <td style=\"text-align:right;\"> 0.002 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Party </td>\n   <td style=\"text-align:right;\"> 1.808 </td>\n   <td style=\"text-align:right;\"> 0.121 </td>\n   <td style=\"text-align:right;\"> 14.909 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> AgeSenCit </td>\n   <td style=\"text-align:right;\"> 0.390 </td>\n   <td style=\"text-align:right;\"> 0.394 </td>\n   <td style=\"text-align:right;\"> 0.990 </td>\n   <td style=\"text-align:right;\"> 0.324 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> AgeYadult </td>\n   <td style=\"text-align:right;\"> -0.505 </td>\n   <td style=\"text-align:right;\"> 0.412 </td>\n   <td style=\"text-align:right;\"> -1.227 </td>\n   <td style=\"text-align:right;\"> 0.222 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> MealLate Night </td>\n   <td style=\"text-align:right;\"> -1.632 </td>\n   <td style=\"text-align:right;\"> 0.407 </td>\n   <td style=\"text-align:right;\"> -4.013 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> MealLunch </td>\n   <td style=\"text-align:right;\"> -0.612 </td>\n   <td style=\"text-align:right;\"> 0.402 </td>\n   <td style=\"text-align:right;\"> -1.523 </td>\n   <td style=\"text-align:right;\"> 0.130 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n# Model comparison using AIC and BIC\n\n## Tips: Comparing models\n\nLet's compare two models:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel1 <- lm(Tip ~ Party + Age + Meal, data = tips)\nglance(model1) |> select(r.squared, adj.r.squared)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã— 2\n  r.squared adj.r.squared\n      <dbl>         <dbl>\n1     0.674         0.664\n```\n\n\n:::\n:::\n\n\n\n<br>\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2 <- lm(Tip ~ Party + Age + Meal + Day, data = tips)\nglance(model2) |> select(r.squared, adj.r.squared)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã— 2\n  r.squared adj.r.squared\n      <dbl>         <dbl>\n1     0.683         0.662\n```\n\n\n:::\n:::\n\n\n\n## AIC & BIC\n\n**Akaike's Information Criterion (AIC):** $$AIC = n\\log(SSR)  + 2(p+1)$$ <br>\n\n**Schwarz's Bayesian Information Criterion (BIC)** $$BIC = n\\log(SSR) + log(n)\\times(p+1)$$\n\n## AIC & BIC\n\n$$\\begin{aligned} & AIC = \\color{blue}{n\\log(SSR)} \\color{black}{ + 2(p+1)} \\\\\n& BIC = \\color{blue}{n\\log(SSR)}  \\color{black}{+ \\log(n)\\times(p+1) }\\end{aligned}$$\n\n. . .\n\n<br>\n\nFirst Term: Generally decreases as *p* increases\n\n## AIC & BIC\n\n$$\\begin{aligned} & AIC = n\\log(SSR)  + \\color{blue}{2(p+1)} \\\\\n& BIC = n\\log(SSR) + \\color{blue}{\\log(n)\\times(p+1)} \\end{aligned}$$\n\n<br>\n\nSecond Term: Increases as *p* increases\n\n## Using AIC & BIC\n\n$$\\begin{aligned} & AIC = n\\log(SSR)  + \\color{red}{2(p+1)} \\\\\n& BIC = n\\log(SSR) + \\color{red}{\\log(n)\\times(p+1)} \\end{aligned}$$ <br> <br>\n\n-   Choose model with the smaller value of AIC or BIC\n\n-   If $n \\geq 8$, the <font color=\"red\">penalty</font> for BIC is larger than that of AIC, so BIC tends to favor *more parsimonious* models (i.e. models with fewer terms)\n\n## Tips: AIC & BIC\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel1 <- lm(Tip ~ Party + Age + Meal, data = tips)\nglance(model1) |> select(AIC, BIC)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã— 2\n    AIC   BIC\n  <dbl> <dbl>\n1  714.  736.\n```\n\n\n:::\n:::\n\n\n\n<br>\n\n. . .\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2 <- lm(Tip ~ Party + Age + Meal + Day, data = tips)\nglance(model2) |> select(AIC, BIC)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã— 2\n    AIC   BIC\n  <dbl> <dbl>\n1  720.  757.\n```\n\n\n:::\n:::\n\n\n\n. . .\n\n::: question\nWhich model do you choose?\n:::\n\n## Parsimony and Occamâ€™s razor {.small}\n\n-   The principle of **parsimony** is attributed to William of Occam (early 14th-century English nominalist philosopher), who insisted that, given a set of equally good explanations for a given phenomenon, *the correct explanation is the simplest explanation*[^1]\n\n-   Called **Occamâ€™s razor** because he â€œshavedâ€ his explanations down to the bare minimum\n\n-   Parsimony in modeling:\n\n    -   models should have as few parameters as possible\n\n    -   linear models should be preferred to non-linear models\n\n    -   experiments relying on few assumptions should be preferred to those relying on many\n\n    -   models should be pared down until they are *minimal adequate*\n\n    -   simple explanations should be preferred to complex explanations\n\n[^1]: Source: The R Book by Michael J. Crawley\n\n## In pursuit of Occamâ€™s razor\n\n-   Occamâ€™s razor states that among competing hypotheses that predict equally well, the one with the fewest assumptions should be selected\n\n-   Model selection follows this principle\n\n-   We only want to add another variable to the model if the addition of that variable brings something valuable in terms of predictive power to the model\n\n-   In other words, we prefer the simplest best model, i.e.Â **parsimonious** model\n\n## In pursuit of Occam's razor\n\n-   Occam's razor states that among competing hypotheses that predict equally well, the one with the fewest assumptions should be selected\n\n-   Model selection follows this principle\n\n-   We only want to add another variable to the model if the addition of that variable brings something valuable in terms of predictive power to the model\n\n-   In other words, we prefer the simplest best model, i.e. **parsimonious** model\n\n## Alternate views {.midi}\n\n> Sometimes a simple model will outperform a more complex model . . . Nevertheless, I believe that deliberately limiting the complexity of the model is not fruitful when the problem is evidently complex. Instead, if a simple model is found that outperforms some particular complex model, the appropriate response is to define a different complex model that captures whatever aspect of the problem led to the simple model performing well.\n>\n> <br>\n>\n> Radford Neal - Bayesian Learning for Neural Networks[^2]\n\n[^2]: Suggested blog post: [Occam](https://statmodeling.stat.columbia.edu/2012/06/26/occam-2/) by Andrew Gelman\n\n## Recap\n\n-   ANOVA for Multiple Linear Regression\n\n-   Nested F Test\n\n-   AIC & BIC\n",
    "supporting": [
      "17-compare-models_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}