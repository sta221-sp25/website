---
title: "Multiple linear regression (MLR)"
subtitle: "Categorical predictors + Assessment"
author: "Prof. Maria Tackett"
date: "2024-09-12"
date-format: "MMM DD, YYYY"
footer: "[üîó STA 221 - Fall 2024](https://sta221-fa24.netlify.app)"
logo: "../images/logo.png"
format: 
  revealjs:
    theme: slides.scss
    multiplex: false
    transition: fade
    slide-number: true
    incremental: false 
    chalkboard: true
    include-before: [ '<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {enableAssistiveMml: false}});</script>']
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
execute:
  freeze: auto
  echo: true
knitr:
  opts_chunk: 
    R.options:      
    width: 200
bibliography: references.bib
---

## Announcements

-   Lab 01 due on **TODAY at 11:59pm**

    -   Push work to GitHub repo

    -   Submit final PDF on Gradescope + mark pages for each question

-   HW 01 due **Thursday, September 19 at 11:59pm**

    -   Will be released after class

-   Team labs start on Monday

## Homework

Homework will generally be split into two sections:

<br>

1Ô∏è‚É£ **Conceptual exercises**

The conceptual exercises are focused on explaining concepts and showing results mathematically. Show your work for each question.\
\
**You may write the answers and associated work for conceptual exercises by hand or type them in your Quarto document.**

## Homework

2Ô∏è‚É£ **Applied exercises**

The applied exercises are focused on applying the concepts to analyze data.

**All work for the applied exercises must be typed in your Quarto document following a reproducible workflow.**

Write all narrative using complete sentences and include informative axis labels / titles on visualizations.

## Topics

-   Categorical predictors and interaction terms

-   Assess model fit using RSME and $R^2$

-   Compare models using $Adj. R^2$

-   Introduce LaTex

## Computing setup

```{r packages}
#| echo: true
#| message: false

# load packages
library(tidyverse)
library(tidymodels)
library(openintro)
library(patchwork)
library(knitr)
library(kableExtra)
library(viridis) #adjust color palette

# set default theme and larger font size for ggplot2
ggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))
```

## Data: Peer-to-peer lender

Today's data is a sample of 50 loans made through a peer-to-peer lending club. The data is in the `loan50` data frame in the **openintro** R package.

```{r}
#| echo: false

loan50 <- loan50 |>
  mutate(annual_income_th = annual_income / 1000)

loan50 |>
  select(annual_income_th, debt_to_income, verified_income, interest_rate)
```

## Variables

**Predictors**:

::: nonincremental
-   `annual_income_th`: Annual income (in \$1000s)
-   `debt_to_income`: Debt-to-income ratio, i.e. the percentage of a borrower's total debt divided by their total income
-   `verified_income`: Whether borrower's income source and amount have been verified (`Not Verified`, `Source Verified`, `Verified`)
:::

**Response**: `interest_rate`: Interest rate for the loan

## Response vs. predictors {.small}

```{r}
#| echo: false
p4 <- ggplot(loan50, aes(x = verified_income, y = interest_rate)) +
  geom_boxplot(fill = "steelblue") +
  labs(
    y = "Interest rate",
    x = "Income verification"
  )

p5 <- ggplot(loan50, aes(x = debt_to_income, y = interest_rate)) +
  geom_point(color = "steelblue") +
  labs(
    y = NULL,
    x = "Debt to income ratio"
  )


p6 <- ggplot(loan50, aes(x = annual_income_th, y = interest_rate)) +
  geom_point(color = "steelblue") +
  labs(
    y = NULL,
    x = "Annual income (in $1000s)"
  )

p4 + p5 / p6
```

**Goal**: Use these predictors in a single model to understand variability in interest rate.

## Model fit in R

```{r}
#| echo: true

int_fit <- lm(interest_rate ~ debt_to_income + verified_income  + annual_income_th,
              data = loan50)

tidy(int_fit) |>
  kable(digits = 3)
```

# Categorical predictors

## Matrix form of multiple linear regression

$$
\underbrace{
\begin{bmatrix}
y_1 \\
\vdots \\
y_n
\end{bmatrix} }_
{\mathbf{y}} \hspace{3mm}
= 
\hspace{3mm}
\underbrace{
\begin{bmatrix}
1 &x_{11} & \dots & x_{1p}\\
\vdots & \vdots &\ddots & \vdots \\
1 &  x_{n1} & \dots &x_{np}
\end{bmatrix}
}_{\mathbf{X}}
\hspace{2mm}
\underbrace{
\begin{bmatrix}
\beta_0 \\
\beta_1 \\
\vdots \\
\beta_p
\end{bmatrix}
}_{\boldsymbol{\beta}}
\hspace{3mm}
+
\hspace{3mm}
\underbrace{
\begin{bmatrix}
\epsilon_1 \\
\vdots\\
\epsilon_n
\end{bmatrix}
}_\boldsymbol{\epsilon}
$$

<center>How might we include a categorical predictor with $k$ levels in the design matrix, $\mathbf{X}$ ?</center>

## Indicator variables {.midi}

Suppose we want to predict the amount of sleep a Duke student gets based on whether they are in Pratt (Pratt Yes/ No are the only two options). Consider the model

$$
Sleep_i = \beta_0 + \beta_1\mathbf{1}(Pratt_i = \texttt{Yes}) + \beta_2\mathbf{1}(Pratt_i = \texttt{No})
$$

::: question
-   Write out the design matrix for this hypothesized linear model.

-   Demonstrate that the design matrix is not of full column rank (that is, affirmatively provide one of the columns in terms of the others).

-   Use this intuition to explain why when we include categorical predictors, we cannot include both indicators for every level of the variable *and* an intercept.
:::

## Indicator variables

-   Suppose there is a categorical variable with $k$ levels

-   We can make $k$ indicator variables from the data - one indicator for each level

-   An **indicator (dummy) variable** takes values 1 or 0

    -   1 if the observation belongs to that level

    -   0 if the observation does not belong to that level

## Indicator variables for `verified_income`

```{r}
#| echo: true

loan50 <- loan50 |>
  mutate(
    not_verified = if_else(verified_income == "Not Verified", 1, 0),
    source_verified = if_else(verified_income == "Source Verified", 1, 0),
    verified = if_else(verified_income == "Verified", 1, 0)
  )
```

. . .

```{r}
#| echo: false
loan50 |>
  select(verified_income, not_verified, source_verified, verified) |>
  slice(1, 3, 6)
```

## Indicator variables in the model {.midi}

-   We will use $k-1$ of the indicator variables in the model.
-   The **baseline** is the category that doesn't have a term in the model.
-   The coefficients of the indicator variables in the model are interpreted as the expected change in the response compared to the baseline, holding all other variables constant.

. . .

```{r}
loan50 |>
  select(verified_income, source_verified, verified) |>
  slice(1, 3, 6)
```

::: appex
Take a look at the design matrix in [AE 02](https://sta221-fa24.netlify.app/ae/ae-02-mlr)
:::

## Interpreting `verified_income` {.small}

```{r}
#| echo: false
tidy(int_fit
, conf.int  = T) |>
  kable(digits = 3) |>
  row_spec(c(3,4), background = "#dce5b2")
```

. . .

::: incremental
-   The baseline level is `Not verified`.
-   People with source verified income are expected to take a loan with an interest rate that is 2.211% higher, on average, than the rate on loans to those whose income is not verified, holding all else constant.
:::

. . .

::: question
What is the expected interest rate for someone whose income is `Verified`, who has a debt-to-income ratio of 0 and annual income of \$0?
:::

# Interaction terms

## Interaction terms

-   Sometimes the relationship between a predictor variable and the response depends on the value of another predictor variable.
-   This is an **interaction effect**.
-   To account for this, we can include **interaction terms** in the model.

## Interest rate vs. annual income

The lines are not parallel indicating there is a potential **interaction effect**. The slope of annual income differs based on the income verification.

```{r}
#| echo: false

p1 <- ggplot(loan50, 
             aes(x = annual_income_th, y = interest_rate)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    x = "Annual income (in $1000s)",
    y = "Interest rate"
  )

p2 <- ggplot(loan50, 
             aes(x = annual_income_th, y = interest_rate,
                 color = verified_income)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Annual income (in $1000s)", y = NULL, color = NULL) +
  theme(legend.position = c(0.6, 0.9)) +
  scale_color_viridis_d(end = 0.9)

p1 + p2 +
  plot_annotation(title = "Interest rate vs. annual income")
```

# Application exercise

::: appex
üìã <https://sta221-fa24.netlify.app/ae/ae-02-mlr>
:::

## Interaction term in model {.smaller}

```{r}
#| echo: true
int_fit_2 <- lm(interest_rate ~ debt_to_income + verified_income + annual_income_th + verified_income * annual_income_th,
      data = loan50)
```

```{r}
#| echo: false
tidy(int_fit_2) |>
  kable(digits = 3) |>
  row_spec(c(6,7), background = "#dce5b2")
```

## Interpreting interaction terms

-   What the interaction means: The effect of annual income on the interest rate differs by -0.016 when the income is source verified compared to when it is not verified, holding all else constant.
-   Interpreting `annual_income` for source verified: If the income is source verified, we expect the interest rate to decrease by 0.023% (-0.007 + -0.016) for each additional thousand dollars in annual income, holding all else constant.

# Model assessment and comparison

## RMSE & $R^2$

-   **Root mean square error, RMSE**: A measure of the average error (average difference between observed and predicted values of the outcome)

-   **R-squared**, $R^2$ : Percentage of variability in the outcome explained by the regression model

## Comparing models

::: incremental
-   When comparing models, do we prefer the model with the lower or higher RMSE?

-   Though we use $R^2$ to assess the model fit, it is generally unreliable for comparing models with different number of predictors. Why?

    -   $R^2$ will stay the same or increase as we add more variables to the model . Let's show why this is true.

    -   If we only use $R^2$ to choose a best fit model, we will be prone to choose the model with the most predictor variables.
:::

## Adjusted $R^2$

-   **Adjusted** $R^2$: measure that includes a penalty for unnecessary predictor variables
-   Similar to $R^2$, it is a measure of the amount of variation in the response that is explained by the regression model

## $R^2$ and Adjusted $R^2$

$$R^2 = \frac{SSM}{SST} = 1 - \frac{SSR}{SST}$$

<br>

. . .

$$R^2_{adj} = 1 - \frac{SSR/(n-p-1)}{SST/(n-1)}$$

where

-   $n$ is the number of observations used to fit the model

-   $p$ is the number of terms (not including the intercept) in the model

## Using $R^2$ and Adjusted $R^2$

-   Adjusted $R^2$ can be used as a quick assessment to compare the fit of multiple models; however, it should not be the only assessment!
-   Use $R^2$ when describing the relationship between the response and predictor variables

. . .

::: appex
üìã <https://sta221-fa24.netlify.app/ae/ae-02-mlr>
:::

# LaTex

## Latex in this class

For this class you will need to be able to...

-   Properly write mathematical symbols, e.g., $\beta_1$ not *B1,* $R^2$ not *R2*

-   Write basic regression equations, e.g., $\hat{y} = \beta_0 + \beta_1x_1 + \beta_2x_2$

-   Write matrix equations: $\mathbf{y} = \mathbf{X}\boldsymbol{\beta} + \boldsymbol{\epsilon}$

-   Write hypotheses (we'll start this next week), e.g., $H_0: \beta = 0$

You are welcome to but <u>not</u> required to write math proofs using LaTex.

# Application exercise

::: appex
üìã <https://sta221-fa24.netlify.app/ae/ae-02-mlr>
:::

## Recap

-   Interpreted categorical predictors and interaction terms

-   Assessed model fit using RSME and $R^2$

-   Compared models using $Adj. R^2$

-   Introduced LaTex

## Next class

-   Geometric interpretation

-   Inference for regression

-   See Sep 17 prepare
