---
title: "Logistic Regression: Assumptions + Estimation"
author: "Prof. Maria Tackett"
date: "2025-04-10"
date-format: "MMM DD, YYYY"
footer: "[ðŸ”— STA 221 - Spring 2025](https://sta221-sp25.netlify.app)"
logo: "../images/logo.png"
format: 
  revealjs: 
    theme: slides.scss
    multiplex: false
    transition: fade
    slide-number: true
    incremental: false 
    chalkboard: true
    include-before: [ '<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {enableAssistiveMml: false}});</script>']
  html: 
    output-file: 23-logistic-assumptions-notes.html
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
execute:
  freeze: auto
  echo: true
knitr:
  opts_chunk: 
    R.options:      
    width: 200
bibliography: references.bib
---

```{r setup, include=FALSE, echo=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
	fig.align = "center",
	fig.height =5,
	fig.width = 8,
	message = FALSE,
	warning = FALSE
)
```

## Announcements

-   HW 04 due TODAY at 11:59pm

-   Project draft due at beginning of lab tomorrow

    -   Peer review in lab

-   Exam 02 - April 17 (same format as Exam 01)

    -   Exam 02 practice + lecture recordings available

-   Statistics experience due April 22

## Questions from this week's content?

<center>

```{=html}
<iframe width="640px" height="480px" src="https://forms.office.com/Pages/ResponsePage.aspx?id=TsVyyzFKnk2xSh6jbfrJTBw0r2_bKCVMs9lST1_-2sxUQ1JTSFBZNlFMWUJZSDcwTUdaVzgwWUhBMC4u&embed=true" frameborder="0" marginwidth="0" marginheight="0" style="border: none; max-width:100%; max-height:100vh" allowfullscreen webkitallowfullscreen mozallowfullscreen msallowfullscreen> </iframe>
```

</center>

## Topics

-   Confidence intervals for logistic regression

-   Conditions for logistic regression

-   Estimating coefficients for logistic regression model

## Computational setup

```{r}
#| echo: true
#| warning: false
#| message: false


library(tidyverse)
library(tidymodels)
library(knitr)
library(kableExtra)
library(Stat2Data)  #empirical logit plots
library(patchwork)

# set default theme in ggplot2
ggplot2::theme_set(ggplot2::theme_bw())
```

## COVID-19 infection prevention practices at food establishments

Researchers at Wollo University in Ethiopia conducted a study in July and August 2020 to understand factors associated with good COVID-19 infection prevention practices at food establishments. Their study is published in @andualem2022covid.

They were particularly interested in the understanding implementation of prevention practices at food establishments, given the workersâ€™ increased risk due to daily contact with customers.

## Access to personal protective equipment {.midi}

We will use the data from @andualem2022covid to explore the association between age, sex, years of service, and whether someone works at a food establishment with access to personal protective equipment (PPE) as of August 2020. We will use access to PPE as a proxy for wearing PPE.

The study participants were selected using a simple random sampling at the selected establishments.

```{r echo = F}
covid_df <- read_csv("data/covid-prevention-study.csv") |>
  rename(age = "Age of food handlers", 
         years = "Years of service", 
         ppe_access = "Availability of PPEs") |>
  mutate(sex = factor(if_else(Sex == 2, "Female", "Male"))) |>
  select(age, sex, years, ppe_access) |>
  mutate(ppe_access = as_factor(ppe_access))

covid_df |> slice(1:5) |> kable()
```

## Full model results

![](images/22/logistic-output.PNG){fig-align="center"}

## Confidence interval for $\beta_j$

We can calculate the **C% confidence interval** for $\beta_j$ as the following:

$$
\Large{\hat{\beta}_j \pm z^* \times SE(\hat{\beta}_j)}
$$

where $z^*$ is calculated from the $N(0,1)$ distribution

. . .

This is an interval for the change in the log-odds for every one unit increase in $x_j$

## Interpretation in terms of the odds

The change in **odds** for every one unit increase in $x_j$.

$$
\Large{\exp\{\hat{\beta}_j \pm z^* \times SE(\hat{\beta}_j)\}}
$$

. . .

**Interpretation:** We are $C\%$ confident that for every one unit increase in $x_j$, the odds multiply by a factor of $\exp\{\hat{\beta}_j - z^* \times SE(\hat{\beta}_j)\}$ to $\exp\{\hat{\beta}_j + z^* \times SE(\hat{\beta}_j)\}$, holding all else constant.

## PPE Access: Interpret CI

![](images/22/logistic-output.PNG){fig-align="center"}

::: question
Interpret the 95% confidence interval for \> 5 years experience in terms of the odds of having access to PPE.
:::

<!--# see these notes for empirical logit: https://sta210-fa23.netlify.app/slides/20-logistic-inf.html#/calculating-empirical-logit-categorical-predictor-->

# Visualizations

## Bivariate EDA: categorical predictor

```{r}
#| fig-align: center
#| echo: false

library(viridis)
ggplot(data = covid_df, aes(x = sex, fill = ppe_access)) + 
  geom_bar(position = "fill")  +
  labs(x = "Sex", 
       fill = "PPE Access", 
       title = "PPE Access by Sex") + 
  scale_fill_viridis_d()
```

## Bivariate EDA: quantitative predictor

```{r}
#| echo: false
#| fig-align: center

ggplot(data = covid_df, aes(x = ppe_access, y = age)) + 
  geom_boxplot(fill = "steelblue", color = "black")  +
  labs(x = "PPE Access",
       y = "Age (in years)", 
       title = "PPE Access vs. Age") + 
  coord_flip()
```

## EDA: Potential interaction effect

```{r}
#| echo: false
#| fig-align: center

ggplot(data = covid_df, aes(x = ppe_access, y = age)) + 
  geom_boxplot(fill = "steelblue", color = "black")  +
  labs(x = "PPE Access",
       y = "Age (in years)", 
       title = "PPE Access vs. Age",
       subtitle = "by Sex") + 
  coord_flip() + 
  facet_wrap(~ sex)
```

## Empirical logit

The **empirical logit** is the log of the observed odds:

$$
\text{logit}(\hat{p}) = \log\Big(\frac{\hat{p}}{1 - \hat{p}}\Big) = \log\Big(\frac{\# \text{Yes}}{\# \text{No}}\Big)
$$

## Calculating empirical logit (categorical predictor) {.midi}

If the predictor is categorical, we can calculate the empirical logit for each level of the predictor.

```{r}
covid_df |>
  count(sex, ppe_access) |>
  group_by(sex) |>
  mutate(prop = n/sum(n)) |>
  mutate(emp_logit = log(prop/(1-prop)))
```

## Calculating empirical logit (quantitative predictor)

1.  Divide the range of the predictor into intervals with approximately equal number of cases. (If you have enough observations, use 5 - 10 intervals.)

2.  Compute the empirical logit for each interval

. . .

You can then calculate the mean value of the predictor in each interval and create a plot of the empirical logit versus the mean value of the predictor in each interval.

## Empirical logit plot in R (quantitative predictor)

Created using `dplyr` and `ggplot` functions.

```{r}
#| echo: false
covid_df |> 
  mutate(age_bin = cut_number(age, n = 10)) |>
  group_by(age_bin) |>
  mutate(mean_age = mean(age)) |>
  count(mean_age, ppe_access) |>
  mutate(prop = n/sum(n)) |>
  filter(ppe_access == "1") |>
  mutate(emp_logit = log(prop/(1-prop))) |>
  ggplot(aes(x = mean_age, y = emp_logit)) + 
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Mean Age", 
       y = "Empirical logit", 
       title = "Empirical logit of PPE Access vs. Age")
```

## Empirical logit plot in R (quantitative predictor)

Created using `dplyr` and `ggplot` functions.

```{r}
#| eval: false
#| echo: true


covid_df |> 
  mutate(age_bin = cut_number(age, n = 10)) |>
  group_by(age_bin) |>
  mutate(mean_age = mean(age)) |>
  count(mean_age, ppe_access) |>
  mutate(prop = n/sum(n)) |>
  filter(ppe_access == "1") |>
  mutate(emp_logit = log(prop/(1-prop))) |>
  ggplot(aes(x = mean_age, y = emp_logit)) + 
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Mean Age", 
       y = "Empirical logit", 
       title = "Empirical logit of PPE Access vs. Age")
```

## Empirical logit plot in R (quantitative predictor)

Using the `emplogitplot1` function from the **Stat2Data** R package

```{r}
emplogitplot1(ppe_access ~ age,  data = covid_df, ngroups = 10)
```

## Empirical logit plot in R (interactions)

Using the `emplogitplot2` function from the **Stat2Data** R package

```{r}
emplogitplot2(ppe_access ~ age + sex, data = covid_df, 
              ngroups = 10, 
              putlegend = "bottomright")
```

## Logistic regression model {.midi}

```{r}
ppe_model <- glm(ppe_access ~ age + sex + years, 
                 data = covid_df, family = binomial)
tidy(ppe_model, conf.int = TRUE) |>
  kable(digits = 3)
```

## Visualizing coefficient estimates {.midi}

```{r}
model_odds_ratios <- tidy(ppe_model, exponentiate = TRUE, conf.int = TRUE)
```

```{r, out.width = "55%"}
ggplot(data = model_odds_ratios, aes(x = term, y = estimate)) +
  geom_point() +
  geom_hline(yintercept = 1, lty = 2) + 
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high))+
  labs(title = "Adjusted odds ratios",
       x = "",
       y = "Estimated AOR") +
  coord_flip()
```

# Assumptions for logistic regression

## Assumptions for logistic regression

<!--# https://bookdown.org/roback/bookdown-BeyondMLR/ch-logreg.html#logistic-regression-assumptions-->

-   **Linearity:** The log-odds have a linear relationship with the predictors.

-   **Randomness:** The data were obtained from a random process

-   **Independence:** The observations are independent from one another.

## Checking linearity

Check the empirical logit plots for the <u>quantitative </u>predictors

::::: columns
::: {.column width="50%"}
```{r}
emplogitplot1(ppe_access ~ age, data = covid_df, 
              ngroups = 10)
```
:::

::: {.column width="50%"}
```{r}
emplogitplot1(ppe_access ~ years, data = covid_df, 
              ngroups = 5)
```
:::
:::::

. . .

::: midi
âœ… The linearity condition is satisfied. There is generally a linear relationship between the empirical logit and the quantitative predictor variables
:::

## Checking randomness

We can check the randomness condition based on the context of the data and how the observations were collected.

-   Was the sample randomly selected?

-   If the sample was not randomly selected, the condition is still satisfied if the sample is representative of the population

. . .

âœ… The randomness condition is satisfied. The paper states the participants were selected using simple random sampling at selected establishments. We can reasonably treat this sample as representative of the population.

## Checking independence

-   We can check the independence condition based on the context of the data and how the observations were collected.

-   Independence is most often violated if the data were collected over time or there is a strong spatial relationship between the observations.

. . .

âœ… We will treat this sample as independent. If given the data, we may want to further investigate potential correlation within an establishment.

# Estimating $\boldsymbol{\beta}$

## Estimating $\boldsymbol{\beta}$

Recall that the coefficients for logistic regression are estimated using maximum likelihood estimation.

$$
\begin{aligned}\log &L(\boldsymbol\beta | x_1, \dots, x_n, y_1, \dots, y_n) \\
&= \sum_{i=1}^n y_i \mathbf{x}_i^\mathsf{T} \boldsymbol\beta - \sum_{i=1}^n \log(1+ \exp\{\mathbf{x}_i^\mathsf{T} \boldsymbol{\beta}\})
\end{aligned}
$$

## Estimating $\boldsymbol{\beta}$

Take the derivative and set it equal to 0 to solve for $\boldsymbol{\beta}$. ([Click here](https://canvas.duke.edu/courses/51767/discussion_topics/176837) for the full derivation.)\
$$
\begin{aligned}
\frac{\partial \log L}{\partial \boldsymbol\beta} =\sum_{i=1}^n y_i \mathbf{x}_i^\mathsf{T}
&- \sum_{i=1}^n \frac{\exp\{\mathbf{x}_i^\mathsf{T} \boldsymbol\beta\} x_i^\mathsf{T}}{1+\exp\{\mathbf{x}_i^\mathsf{T} \boldsymbol\beta\}} = 0
\end{aligned}
$$

. . .

There is no closed form solution. We can find the solution numerically using the **Newton-Raphson method**.

## Newton-Raphson method

Newton-Raphson is a numerical method for finding solutions to $f(x) = 0$ . Steps of the Newton-Raphson method:

1.  Start with an initial guess $\theta^{(0)}$ .

2.  For each iteration,

    $$
    \theta^{(t+1)} = \theta^{(t)} - \frac{f(\theta^{(t)})}{f^{\prime}(\theta^{(t)})}
    $$

3.  Stop when the convergence criteria is satisfied.

## Newton-Raphson method

![](images/22/newton-raphson.jpeg){fig-align="center" width="75%"}

Image source: [LibreTexts-Mathematics](https://math.libretexts.org/Bookshelves/Calculus/Map%3A_Calculus__Early_Transcendentals_%28Stewart%29/04%3A_Applications_of_Differentiation/4.08%3A_Newton%27s_Method)

## Example {.midi}

Let's find the solution (root) of the function $$f(x) = x^3 - 20$$

```{r}
#| echo: false
#| fig-align: center


eq = function(x){x*x*x - 20}
eq_deriv = function(x){3 * x * x}

ggplot(data.frame(x=c(1, 5)), aes(x=x)) + 
  stat_function(fun=eq) +
  labs(title = "Original function") +
  geom_hline(yintercept = 0, linetype = 2, color = "red")
```

## Example

Suppose the convergence criteria be $\Delta = |\theta^{(t+1)} - \theta^{(t)}| < 0.001$ . We'll start with an initial guess of $\theta^{(0)} = 3$

. . .

$$
\theta^{(1)} = 3 - \frac{3^3 - 20}{3*3^2} = 2.740741
$$

. . .

$$\Delta = |2.740741 - 3| = 0.259259
$$

. . .

$$
\theta^{(2)} = 2.740741 - \frac{2.740741^3 - 20}{3*2.740741^2} = 2.71467
$$

. . .

$$\Delta = |2.71467 - 2.740741| = 0.026071
$$

## 

## Example

$$
\theta^{(3)} = 2.71467 - \frac{2.71467^3 - 20}{3*2.71467^2} = 2.714418
$$

. . .

$$
\Delta = |2.714418 - 2.71467| = 0.000252 < 0.001
$$

::: center
**The solution is** $\mathbf{\approx 2.714418}$
:::

## Score vector & Hessian {.midi}

Given parameter $\boldsymbol{\theta} = [\theta_1, \ldots, \theta_p]^\mathsf{T}$ and log-likelihood, $\log L (\boldsymbol{\theta}|\mathbf{X})$ , then

. . .

$$
\text{Score vector } =\nabla_{\boldsymbol{\theta}} \log L = \begin{bmatrix}\frac{\partial \log L}{\partial \theta_1} \\ \vdots \\ \frac{\partial \log L}{\partial \theta_p} \end{bmatrix}
$$

$$
\text{Hessian} = \nabla^2_{\boldsymbol{\theta}} \log L = \begin{bmatrix}\frac{\partial^2 \log L}{\partial \theta_1^2} &\frac{\partial^2 \log L}{\partial \theta_1\theta_2} & \dots & \frac{\partial^2 \log L}{\partial \theta_1\theta_p} \\
\frac{\partial^2 \log L}{\partial \theta_2\theta_1} & \frac{\partial^2 \log L}{\partial \theta_2^2}  & \dots & \frac{\partial^2 \log L}{\partial \theta_2\theta_p} \\
\vdots & \vdots & \dots & \vdots \\ 
\frac{\partial^2 \log L}{\partial \theta_p\theta_1} & \frac{\partial^2 \log L}{\partial \theta_p\theta_2} & \dots & \frac{\partial^2 \log L}{\partial \theta_p^2}\end{bmatrix}
$$

## Newton-Raphson for logistic regression

1.  Start with an initial guess $\boldsymbol{\beta}^{(0)}$ .

2.  For each iteration,

    $$
    \boldsymbol{\beta}^{(t+1)} = \boldsymbol{\beta}^{(t)} - \big(\nabla_{\boldsymbol{\beta}}^2 \log L(\boldsymbol{\beta}^{(t)}|\mathbf{X})\big)^{-1}\big(\nabla_{\boldsymbol{\beta}} \log L(\boldsymbol{\beta}^{(t)}|\mathbf{X})\big)
    $$

3.  Stop when the convergence criteria is satisfied.

## Newton-Raphson for logistic regression {.midi}

$$
\log L = \sum_{i=1}^n y_i \mathbf{x}_i^\mathsf{T} \boldsymbol\beta - \sum_{i=1}^n \log(1+ \exp\{\mathbf{x}_i^\mathsf{T} \boldsymbol{\beta}\})
$$

<br>

$$
\nabla_{\boldsymbol{\beta}} \log L = \sum_{i=1}^n \Bigg[y_i
- \frac{\exp\{\mathbf{x}_i^\mathsf{T} \boldsymbol\beta\}}{1+\exp\{\mathbf{x}_i^\mathsf{T} \boldsymbol\beta\}}\Bigg]\mathbf{x}_i
$$

<br>

$$
\nabla^2_{\boldsymbol{\beta}} \log L = \
- \sum_{i=1}^n \Big(\frac{1}{1+\exp\{\mathbf{x}_i^\mathsf{T} \boldsymbol\beta\}}\Big)\Big(\frac{\exp\{\mathbf{x}_i^\mathsf{T} \boldsymbol\beta\}}{1+\exp\{\mathbf{x}_i^\mathsf{T} \boldsymbol\beta\}}\Big)\mathbf{x}_i\mathbf{x}_i^\mathsf{T}
$$

# PPE access example

::: appex
ðŸ“‹ [https://sta221-sp25.netlify.app/ae/ae-06-newton-raphson.html](../ae/ae-06-newton-raphson.html){.uri}
:::

## Questions from this week's content?

<center>

```{=html}
<iframe width="640px" height="480px" src="https://forms.office.com/Pages/ResponsePage.aspx?id=TsVyyzFKnk2xSh6jbfrJTBw0r2_bKCVMs9lST1_-2sxUQ1JTSFBZNlFMWUJZSDcwTUdaVzgwWUhBMC4u&embed=true" frameborder="0" marginwidth="0" marginheight="0" style="border: none; max-width:100%; max-height:100vh" allowfullscreen webkitallowfullscreen mozallowfullscreen msallowfullscreen> </iframe>
```

</center>

## References
