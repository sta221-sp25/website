---
title: "Probabilites, odds, odds ratios"
author: "Prof. Maria Tackett"
date: "2024-10-31"
date-format: "MMM DD, YYYY"
footer: "[ðŸ”— STA 221 - Fall 2024](https://sta221-fa24.netlify.app)"
logo: "../images/logo.png"
format: 
  revealjs:
    theme: slides.scss
    multiplex: false
    transition: fade
    slide-number: true
    incremental: false 
    chalkboard: true
    include-before: [ '<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {enableAssistiveMml: false}});</script>']
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
execute:
  freeze: auto
  echo: true
knitr:
  opts_chunk: 
    R.options:      
    width: 200
filters:
  - parse-latex
bibliography: references.bib
---

```{r}
#| include: false

# figure options
knitr::opts_chunk$set(
  fig.width = 10, fig.asp = 0.618, out.width = "90%",
  fig.retina = 3, dpi = 300, fig.align = "center"
)

library(countdown)
```

## Announcements {.midi}

-   HW 03 due TODAY 11:59pm

-   Project: Exploratory data analysis due TODAY at 11:59pm

-   Tuesday, November 5: Wellness Day (no lecture)

-   Looking ahead

    -   Project presentations November 11

    -   Statistics experience due Tuesday, November 26

## Topics

-   Logistic regression for binary response variable

-   Relationship between odds and probabilities

-   Odds ratios and connection to logistic model

## Computational setup

```{r}
#| warning: false

# load packages
library(tidyverse)
library(tidymodels)
library(knitr)
library(Stat2Data) #contains data set

# set default theme in ggplot2
ggplot2::theme_set(ggplot2::theme_bw())
```

# Predicting categorical outcomes

## Types of outcome variables

**Quantitative outcome variable**:

-   Sales price of a house in Duke Forest
-   **Model**: Expected sales price given the number of bedrooms, lot size, etc.

. . .

**Categorical outcome variable**:

-   Indicator of being high risk of getting coronary heart disease in the next 10 years
-   **Model**: Probability an adult is high risk of heart disease in the next 10 years given their age, total cholesterol, etc.

## Models for categorical outcomes

::: columns
::: {.column width="50%"}
**Logistic regression**

2 Outcomes

1: Yes, 0: No
:::

::: {.column width="50%"}
**Multinomial logistic regression (in STA 310)**

3+ Outcomes

1: Democrat, 2: Republican, 3: Independent
:::
:::

## Do teenagers get 7+ hours of sleep? {.smaller}

::: columns
::: {.column width="40%"}
Students in grades 9 - 12 surveyed about health risk behaviors including whether they usually get 7 or more hours of sleep.

`Sleep7`

1: yes

0: no
:::

::: {.column width="60%"}
```{r}
#| echo: false
data(YouthRisk2009) #from Stat2Data package
sleep <- YouthRisk2009 |>
  as_tibble() |>
  filter(!is.na(Age), !is.na(Sleep7))
sleep |>
  relocate(Age, Sleep7)
```
:::
:::

## Plot the data

```{r}
ggplot(sleep, aes(x = Age, y = Sleep7)) +
  geom_point() + 
  labs(y = "Getting 7+ hours of sleep")
```

## Let's fit a linear regression model

**Outcome:** $Y$ = 1: yes, 0: no

```{r}
#| echo: false

ggplot(sleep, aes(x = Age, y = Sleep7)) +
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  labs(y = "Getting 7+ hours of sleep")
```

## Let's use proportions

**Outcome:** Probability of getting 7+ hours of sleep

```{r}
#| echo: false

sleep_age <- sleep |>
  group_by(Age) |>
  summarise(prop = mean(Sleep7))

ggplot(sleep_age, aes(x = Age, y = prop)) +
  geom_point() + 
  geom_hline(yintercept = c(0,1), lty = 2) + 
  stat_smooth(method = "lm",fullrange = TRUE, se = FALSE) +
  labs(y = "P(7+ hours of sleep)")
```

## What happens if we zoom out?

**Outcome:** Probability of getting 7+ hours of sleep

```{r}
#| echo: false

ggplot(sleep_age, aes(x = Age, y = prop)) +
  geom_point() + 
  geom_hline(yintercept = c(0,1), lty = 2) + 
  stat_smooth(method = "lm",fullrange = TRUE, se = FALSE) +
  labs(y = "P(7+ hours of sleep)") +
  xlim(1, 40) +
  ylim(-1, 2)
```

ðŸ›‘ *This model produces predictions outside of 0 and 1.*

## Let's try another model

```{r}
#| label: logistic-model-plot
#| echo: false

ggplot(sleep_age, aes(x = Age, y = prop)) +
  geom_point() + 
  geom_hline(yintercept = c(0,1), lty = 2) + 
  stat_smooth(method ="glm", method.args = list(family = "binomial"), 
              fullrange = TRUE, se = FALSE) +
  labs(y = "P(7+ hours of sleep)") +
  xlim(1, 40) +
  ylim(-0.5, 1.5)
```

*âœ… This model (called a **logistic regression model**) only produces predictions between 0 and 1.*

## The code

```{r}
#| ref.label: logistic-model-plot
#| echo: true
#| fig-show: hide
```

## Different types of models

| Method                          | Outcome      | Model                                                           |
|---------------------------------|--------------|-----------------------------------------------------------------|
| Linear regression               | Quantitative | $y_i = \beta_0 + \beta_1~ x_i$                                  |
| Linear regression (transform Y) | Quantitative | $\log(y_i) = \beta_0 + \beta_1~ x_i$                            |
| Logistic regression             | Binary       | $\log\big(\frac{\pi_i}{1-\pi_i}\big) = \beta_0 + \beta_1 ~ x_i$ |

## Linear vs. logistic regression

::: question
State whether a linear regression model or logistic regression model is more appropriate for each scenario.

1.  Use age and education to predict if a randomly selected person will vote in the next election.

2.  Use budget and run time (in minutes) to predict a movie's total revenue.

3.  Use age and sex to calculate the probability a randomly selected adult will visit Duke Health in the next year.
:::

# Probabilities and odds

## Binary response variable

::: incremental
-   $Y = 1: \text{ yes}, 0: \text{ no}$
-   $\pi$: **probability** that $Y=1$, i.e., $P(Y = 1)$
-   $\frac{\pi}{1-\pi}$: **odds** that $Y = 1$
-   $\log\big(\frac{\pi}{1-\pi}\big)$: **log odds**
-   Go from $\pi$ to $\log\big(\frac{\pi}{1-\pi}\big)$ using the **logit transformation**
:::

## Odds

::: incremental
Suppose there is a **70% chance** it will rain tomorrow

-   Probability it will rain is $\mathbf{p = 0.7}$
-   Probability it won't rain is $\mathbf{1 - p = 0.3}$
-   Odds it will rain are **7 to 3**, **7:3**, $\mathbf{\frac{0.7}{0.3} \approx 2.33}$
:::

## Are teenagers getting enough sleep?

```{r}
sleep |>
  count(Sleep7) |>
  mutate(p = round(n / sum(n), 3))
```

. . .

$P(\text{7+ hours of sleep}) = P(Y = 1) = p = 0.664$

. . .

$P(\text{< 7 hours of sleep}) = P(Y = 0) = 1 - p = 0.336$

. . .

$P(\text{odds of 7+ hours of sleep}) = \frac{0.664}{0.336} = 1.976$

## From odds to probabilities

::: columns
::: {.column width="50%"}
**odds**

$$\omega = \frac{\pi}{1-\pi}$$
:::

::: {.column width="50%"}
**probability**

$$\pi = \frac{\omega}{1 + \omega}$$
:::
:::

# Odds ratios

## Risk of coronary heart disease {.midi}

This data set is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. We want to examine the relationship between various health characteristics and the risk of having heart disease. These notes focus on the following variables:

-   `high_risk`:

    -   1: High risk of having heart disease in next 10 years
    -   0: Not high risk of having heart disease in next 10 year

-   `education`: 1 = Some High School, 2 = High School or GED, 3 = Some College or Vocational School, 4 = College

```{r}
#| echo: false

heart_disease <- read_csv(here::here("slides", "data/framingham.csv")) |>
  select(age, education, TenYearCHD) |>
  drop_na() |>
  mutate(high_risk = as_factor(TenYearCHD), 
         education = as_factor(education))
```

## High risk vs. education

```{r}
#| label: mutate-level-names
#| echo: false

heart_disease <- heart_disease |>
  mutate(
    high_risk_names = if_else(high_risk == "1", "High risk", "Not high risk"),
    education_names = case_when(
      education == "1" ~ "Some high school",
      education == "2" ~ "High school or GED",
      education == "3" ~ "Some college or vocational school",
      education == "4" ~ "College"
    ),
    education_names = fct_relevel(education_names, "Some high school", "High school or GED", "Some college or vocational school", "College")
  )
```

```{r}
#| label: education-high-risk-table
#| echo: false

heart_disease |>
  count(education_names, high_risk_names) |>
  pivot_wider(names_from = high_risk_names, values_from = n) |>
  kable(col.names = c("Education", "High risk", "Not high risk"))
```

## Compare the odds for two groups {.midi}

```{r}
#| ref.label: education-high-risk-table
#| echo: false
```

. . .

-   We want to compare the risk of heart disease for those with a High School diploma/GED and those with a college degree.

-   We'll use the **odds** to compare the two groups

$$
\text{odds} = \frac{P(\text{success})}{P(\text{failure})} = \frac{\text{# of successes}}{\text{# of failures}}
$$

## Compare the odds for two groups {.midi}

```{r}
#| ref.label: education-high-risk-table
#| echo: false
```

-   Odds of being high risk for the **High school or GED** group: $\frac{147}{1106} = 0.133$

-   Odds of being high risk for the **College** group: $\frac{70}{403} = 0.174$

-   Based on this, we see those with a college degree had higher odds of being high risk for heart disease than those with a high school diploma or GED.

## Odds ratio (OR) {.midi}

```{r}
#| ref.label: education-high-risk-table
#| echo: false
```

Let's summarize the relationship between the two groups. To do so, we'll use the **odds ratio (OR)**.

$$
OR = \frac{\text{odds}_1}{\text{odds}_2} = \frac{\omega_1}{\omega_2}
$$

## OR: College vs. High school or GED {.midi}

```{r}
#| ref.label: education-high-risk-table
#| echo: false
```

$$OR = \frac{\text{odds}_{College}}{\text{odds}_{HS}} = \frac{0.174}{0.133} = \mathbf{1.308}$$

. . .

The odds of being high risk for heart disease are 1.30 times higher for those with a college degree than those with a high school diploma or GED.

## OR: College vs. Some high school {.midi}

```{r}
#| ref.label: education-high-risk-table
#| echo: false
```

$$OR = \frac{\text{odds}_{College}}{\text{odds}_{Some HS}} = \frac{70/403}{323/1397} = 0.751$$

. . .

The odds of being high risk for having heart disease for those with a college degree are 0.751 times the odds of being high risk for heart disease for those with some high school.

## More natural interpretation

-   It's more natural to interpret the odds ratio with a statement with the odds ratio greater than 1.

-   The odds of being high risk for heart disease are 1.33 times higher for those with some high school than those with a college degree.

## Making the table 1

First, rename the levels of the categorical variables:

```{r}
#| ref.label: mutate-level-names
```

## Making the table 2

Then, make the table:

```{r}
#| ref.label: education-high-risk-table
#| results: hide
```

## Deeper look into the code

```{r}
heart_disease |>
  count(education_names, high_risk_names)
```

## Deeper look into the code

```{r}
#| code-line-numbers: "3"

heart_disease |>
  count(education_names, high_risk_names) |>
  pivot_wider(names_from = high_risk_names, values_from = n)
```

## Deeper look into the code

```{r}
#| code-line-numbers: "4"

heart_disease |>
  count(education_names, high_risk_names) |>
  pivot_wider(names_from = high_risk_names, values_from = n) |>
  kable()
```

## Deeper look into the code

```{r}
#| code-line-numbers: "4"

heart_disease |>
  count(education_names, high_risk_names) |>
  pivot_wider(names_from = high_risk_names, values_from = n) |>
  kable(col.names = c("Education", "High risk", "Not high risk"))
```

# Application exercise

::: appex
ðŸ“‹ <https://sta221-fa24.netlify.app/ae/ae-06-prob-odds.html>
:::

If your group is selected, [click here](https://docs.google.com/presentation/d/1GQWIYYnJY1zRg_iukcZMnTXWlwuq9k3DoRE8GrsyuF4/edit?usp=sharing) to add your response to the Google Slide.

## Recap

-   Introduced logistic regression for binary response variable

-   Showed the relationship between odds and probabilities

-   Introduced odds ratios and their connection to logistic model
