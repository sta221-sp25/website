---
title: "Model comparison"
author: "Prof. Maria Tackett"
date: "2024-10-29"
date-format: "MMM DD, YYYY"
footer: "[🔗 STA 221 - Fall 2024](https://sta221-fa24.netlify.app)"
logo: "../images/logo.png"
format: 
  revealjs:
    theme: slides.scss
    multiplex: false
    transition: fade
    slide-number: true
    incremental: false 
    chalkboard: true
    include-before: [ '<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {enableAssistiveMml: false}});</script>']
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
execute:
  freeze: auto
  echo: true
  execute: false
  message: false
knitr:
  opts_chunk: 
    R.options:      
    width: 200
filters:
  - parse-latex
bibliography: references.bib
---

## Announcements {.midi}

-   HW 03 due Thursday at 11:59pm

-   Project: Exploratory data analysis due Thursday at 11:59pm

-   Looking ahead

    -   Project presentations November 11

    -   Statistics experience due Tuesday, November 26

## Computing set up

```{r}
#| echo: true
#| message: false

# load packages
library(tidyverse)  
library(tidymodels)  
library(knitr)       
library(patchwork)
library(kableExtra) # for formatting tables

# set default theme in ggplot2
ggplot2::theme_set(ggplot2::theme_bw())
```

## Topics

-   ANOVA for Multiple Linear Regression

-   Nested (Partial) F Test

-   AIC & BIC

## Restaurant tips

What affects the amount customers tip at a restaurant?

-   **Response:**
    -   `Tip`: amount of the tip
-   **Predictors:**
    -   `Party`: number of people in the party
    -   `Meal`: time of day (Lunch, Dinner, Late Night)
    -   `Age`: age category of person paying the bill (Yadult, Middle, SenCit)

```{r echo = F}
tips <- read_csv("data/tip-data.csv") |>
  filter(!is.na(Party))
```

## Response Variable

```{r echo = F}
ggplot(data = tips, aes(x = Tip)) +
  geom_histogram() +
  labs("Distribution of Tips")
```

## Predictor Variables

```{r echo = F}
p1 <- ggplot(data = tips, aes(x = Party)) +
  geom_histogram() + 
  labs(title = "Party Size", 
       x = "", y = "")

p2 <- ggplot(data = tips, aes(x = Meal)) +
  geom_bar() + 
  labs(title = "Meal Time", 
       x = "", y = "")

p3 <- ggplot(data = tips, aes(x = Age)) +
  geom_bar() + 
  labs(title = "Age of Payer", 
       x = "", y = "")

p1 + p2 + p3
```

## Response vs. Predictors

```{r echo = F}
p1 <- ggplot(data = tips, aes(x = Party, y = Tip)) +
  geom_point() +
  labs(title = "Tips vs. Party")

p2 <- ggplot(data = tips, aes(x = Meal, y = Tip)) +
  geom_boxplot(fill = "steelblue", color = "black") +
  labs(title = "Tips vs. Meal Time", 
       x = "Time of Day")

p3 <- ggplot(data = tips, aes(x = Age, y = Tip)) +
  geom_boxplot(fill = "steelblue", color = "black") +
  labs(title = "Tips vs. Age", 
       x = "Age")

p1 + p2  + p3
```

## Restaurant tips: model

```{r}
model1 <- lm(Tip ~ Party +  Age , data = tips)
tidy(model1, conf.int = TRUE) |>
  kable(format = "markdown", digits=3)
```

<center>**Is this the best model to explain variation in Tips?**</center>

# Test for overall significance

## Test for overall significance: Hypotheses

We can conduct a hypothesis test using the ANOVA table to determine if there is at least one non-zero coefficient in the model

$$
\begin{aligned}
&H_0: \beta_1 = \dots = \beta_p = 0\\
&H_a: \beta_j \neq 0 \text{ for at least one }j 
\end{aligned}
$$

. . .

**For the tips data:**$$
\begin{aligned}
&H_0: \beta_1 = \beta_2 = \beta_3 = 0\\
&H_a: \beta_j \neq 0 \text{ for at least one }j 
\end{aligned}
$$

## Test for overall significance: Test statistic {.midi}

```{r}
#| echo: false

tips_anova <- anova(lm(Tip ~ Party + Age, data = tips)) |>
  tidy() |>
  mutate(term = if_else(term %in% c("Party", "Age"), "Model", term))

ssm <- round(tips_anova$sumsq[1] + tips_anova$sumsq[2], 3)
dfm <- tips_anova$df[1] + tips_anova$df[2]
msm <- ssm / dfm
ssr <- round(tips_anova$sumsq[3], 3)
sst <- ssm + ssr
stat <- msm / tips_anova$meansq[3]


#replace model row with total model values 
tips_anova$df[1] = dfm
tips_anova$sumsq[1] = ssm
tips_anova$meansq[1] = msm
tips_anova$statistic[1] = stat
tips_anova$p.value[1] = pf(stat, dfm, tips_anova$df[3], lower.tail = FALSE)


tips_anova <- tips_anova |>
  slice(-2) |> # remove extra row for model variable
  add_row(term = "Total", df = nrow(tips) - 1, sumsq = sst, meansq = NA, statistic = NA, p.value = NA) 

tips_anova <- tips_anova |>
  mutate(meansq = round(meansq,3), 
         statistic = round(statistic, 3), 
         p.value = round(p.value, 3), 
         meansq = as.character(meansq), 
         statistic = as.character(statistic), 
         p.value = as.character(p.value),
         meansq = if_else(is.na(meansq), "", meansq), 
         statistic = if_else(is.na(statistic), "", statistic), 
         p.value = if_else(is.na(p.value), "", p.value))

tips_anova <- tips_anova |>
  rename("Source" = term, 
         "Df" = df,
         "Sum Sq" = sumsq, 
         "Mean Sq" = meansq, 
         "F Stat" = statistic, 
         "Pr(> F)" = p.value) 



tips_anova |>
  kable(digits = 3)
```

<br>

**Test statistic**: Ratio of explained to unexplained variability

$$
F = \frac{\text{Mean Square Model}}{\text{Mean Square Residuals}}
$$

The test statistic follows an $F$ distribution with $p$ and $n -  p - 1$ degrees of freedom

## Test for overall significance: P-value

```{r}
#| echo: false

## F distribution 
ggplot() +
  stat_function(fun = df, 
                geom = "line", 
                args = list(df1 = 3, df2 = 165), 
                color = "steelblue2", lwd = 2, 
                xlim = c(0, 6)) +
  labs(x = "F", 
       y = "density", 
       title = "F distribution with 3 and 165 df") + 
  theme_classic()
```

$$
\text{P-value} = \text{Pr}(F > \text{F Stat})
$$

## Test for overall significance: Conclusion {.midi}

$$
\begin{aligned}
&H_0: \beta_1 = \beta_2 = \beta_3 = 0\\
&H_a: \beta_j \neq 0 \text{ for at least one }j 
\end{aligned}
$$

```{r}
#| echo: false
tips_anova |>
  kable(digits = 3)
```

<br>

::: question
What is the conclusion from this hypothesis test?
:::

## Why use overall F test? {.midi}

Why do we use overall F test instead of just looking at the test for individual coefficients?[^1]

[^1]: Example from *Introduction to Statistical Learning*

Suppose we have a model such that $p = 100$ and $H_0: \beta_1 = \dots = \beta_{100} = 0$ is true

. . .

::: incremental
-   About 5% of the p-values for individual coefficients will be below 0.05 by chance.

-   So we expect to see 5 small p-values if even no linear association actually exists.

-   Therefore, it is very likely we will see at least one small p-value by chance.

-   The F-test does not have this problem, because it accounts for the number of predictors. There is only a 5% chance we will get a p-value below 0.05, if a linear relationship truly does not exist.
:::

## Testing subset of coefficients

-   Sometimes we want to test whether a **subset of coefficients** are all equal to 0

-   This is often the case when we want test

    -   whether a categorical variable with $k$ levels is a significant predictor of the response
    -   whether the interaction between a categorical and quantitative variable is significant

-   To do so, we will use the **Nested (Partial) F-test**

## Nested (Partial) F Test {#nested-partial-f-test}

-   Suppose we have a full and reduced model:

$$\begin{aligned}&\text{Full}: y = \beta_0 + \beta_1 x_1 + \dots + \beta_q x_q + \beta_{q+1} x_{q+1} + \dots \beta_p x_p \\
&\text{Reduced}: y = \beta_0 + \beta_1 x_1 + \dots + \beta_q x_q\end{aligned}$$

. . .

-   We want to test whether any of the variables $x_{q+1}, x_{q+2}, \ldots, x_p$ are significant predictors. To do so, we will test the hypothesis:

    $$\begin{aligned}&H_0: \beta_{q+1} =  \beta_{q+2} = \dots = \beta_p = 0 \\ 
    &H_a: \text{at least one }\beta_j \text{ is not equal to 0}\end{aligned}$$

## Nested F Test

-   The test statistic for this test is

$$F = \frac{(SSR_{reduced} - SSR_{full})\big/\text{# predictors tested}}{SSR_{full}\big/(n-p_{full}-1)}$$ <br>

-   Calculate the p-value using the F distribution with df1 = \# predictors tested and df2 = $(n-p_{full}-1)$

## Is `Meal` a significant predictor of tips?

```{r echo=F}
model.tips <- lm(Tip ~ Party + Age + Meal, data = tips)
tidy(model.tips) |>
  select(term, estimate) |>
  kable(format="html", digits=3) |>
  row_spec(c(5,6), background = "#dce5b2")
```

## Tips: Nested F test

$$\begin{aligned}&H_0: \beta_{late night} = \beta_{lunch} = 0\\
&H_a: \text{ at least one }\beta_j \text{ is not equal to 0}\end{aligned}$$

. . .

```{r echo = T}
reduced <- lm(Tip ~ Party + Age, data = tips)
```

. . .

```{r echo = T}
full <- lm(Tip ~ Party + Age + Meal, data = tips)
```

<br>

. . .

```{r echo = T, eval = F}
#Nested F test in R
anova(reduced, full)
```

## Tips: Nested F test

```{r echo = F}
kable(anova(reduced, full), format="markdown", digits = 3) |>
 row_spec(2, background = "#dce5b2")
```

. . .

F Stat: $\frac{(686.444 - 622.979)/2}{622.979/(169 - 5 - 1)} = 8.303$

. . .

P-value: P(F \> 8.303) = 0.0003 - calculated using an F distribution with 2 and 163 degrees of freedom

. . .

The data provide sufficient evidence to conclude that at least one coefficient associated with `Meal` is not zero. Therefore, `Meal` is a significant predictor of `Tips`.

## Model with `Meal`

```{r echo=F}
model.tips <- lm(Tip ~ Party + Age + Meal, data = tips)
tidy(model.tips, conf.int = TRUE) |>
  kable(format="html", digits=3)
```

## Including interactions {.midi}

Does the effect of `Party` differ based on the `Meal` time?

```{r echo=F}
full <- lm(Tip ~ Party + Age + Meal + Meal*Party, data = tips)
tidy(full) |>
  select(term, estimate) |>
  kable(format = "markdown", digits = 3)
```

## Nested F test for interactions

Let's use a Nested F test to determine if `Party*Meal` is statistically significant.

```{r echo = T}
reduced <- lm(Tip ~ Party + Age + Meal, data = tips)
```

. . .

```{r echo = T}
full <- lm(Tip ~ Party + Age + Meal + Meal * Party, 
           data = tips)
```

. . .

```{r}
kable(anova(reduced, full), format = "markdown", digits = 3) |>
  row_spec(2, background = "#dce5b2")
```

## Final model for now

We conclude that the effect of **`Party`** does not differ based **`Meal`**. Therefore, we will use the original model that only included main effects.

```{r echo  =F}
model.tips <- lm(Tip ~ Party + Age + Meal,data=tips)
kable(tidy(model.tips),format="html", digits=3)
```

# Model comparison using AIC and BIC

## Tips: Comparing models

Let's compare two models:

```{r echo = T}
model1 <- lm(Tip ~ Party + Age + Meal, data = tips)
glance(model1) |> select(r.squared, adj.r.squared)
```

<br>

```{r echo = T}
model2 <- lm(Tip ~ Party + Age + Meal + Day, data = tips)
glance(model2) |> select(r.squared, adj.r.squared)
```

## AIC & BIC

**Akaike's Information Criterion (AIC):** $$AIC = n\log(SSR)  + 2(p+1)$$ <br>

**Schwarz's Bayesian Information Criterion (BIC)** $$BIC = n\log(SSR) + log(n)\times(p+1)$$

## AIC & BIC

$$\begin{aligned} & AIC = \color{blue}{n\log(SSR)} \color{black}{ + 2(p+1)} \\
& BIC = \color{blue}{n\log(SSR)}  \color{black}{+ \log(n)\times(p+1) }\end{aligned}$$

. . .

<br>

First Term: Generally decreases as *p* increases

## AIC & BIC

$$\begin{aligned} & AIC = n\log(SSR)  + \color{blue}{2(p+1)} \\
& BIC = n\log(SSR) + \color{blue}{\log(n)\times(p+1)} \end{aligned}$$

<br>

Second Term: Increases as *p* increases

## Using AIC & BIC

$$\begin{aligned} & AIC = n\log(SSR)  + \color{red}{2(p+1)} \\
& BIC = n\log(SSR) + \color{red}{\log(n)\times(p+1)} \end{aligned}$$ <br> <br>

-   Choose model with the smaller value of AIC or BIC

-   If $n \geq 8$, the <font color="red">penalty</font> for BIC is larger than that of AIC, so BIC tends to favor *more parsimonious* models (i.e. models with fewer terms)

## Tips: AIC & BIC

```{r echo = T}
model1 <- lm(Tip ~ Party + Age + Meal, data = tips)
glance(model1) |> select(AIC, BIC)
```

<br>

. . .

```{r echo = T}
model2 <- lm(Tip ~ Party + Age + Meal + Day, data = tips)
glance(model2) |> select(AIC, BIC)
```

. . .

::: question
Which model do you choose?
:::

## Parsimony and Occam’s razor {.small}

-   The principle of **parsimony** is attributed to William of Occam (early 14th-century English nominalist philosopher), who insisted that, given a set of equally good explanations for a given phenomenon, *the correct explanation is the simplest explanation*[^2]

-   Called **Occam’s razor** because he “shaved” his explanations down to the bare minimum

-   Parsimony in modeling:

    -   models should have as few parameters as possible

    -   linear models should be preferred to non-linear models

    -   experiments relying on few assumptions should be preferred to those relying on many

    -   models should be pared down until they are *minimal adequate*

    -   simple explanations should be preferred to complex explanations

[^2]: Source: The R Book by Michael J. Crawley

## In pursuit of Occam’s razor

-   Occam’s razor states that among competing hypotheses that predict equally well, the one with the fewest assumptions should be selected

-   Model selection follows this principle

-   We only want to add another variable to the model if the addition of that variable brings something valuable in terms of predictive power to the model

-   In other words, we prefer the simplest best model, i.e. **parsimonious** model

## In pursuit of Occam's razor

-   Occam's razor states that among competing hypotheses that predict equally well, the one with the fewest assumptions should be selected

-   Model selection follows this principle

-   We only want to add another variable to the model if the addition of that variable brings something valuable in terms of predictive power to the model

-   In other words, we prefer the simplest best model, i.e. **parsimonious** model

## Alternate views {.midi}

> Sometimes a simple model will outperform a more complex model . . . Nevertheless, I believe that deliberately limiting the complexity of the model is not fruitful when the problem is evidently complex. Instead, if a simple model is found that outperforms some particular complex model, the appropriate response is to define a different complex model that captures whatever aspect of the problem led to the simple model performing well.
>
> <br>
>
> Radford Neal - Bayesian Learning for Neural Networks[^3]

[^3]: Suggested blog post: [Occam](https://statmodeling.stat.columbia.edu/2012/06/26/occam-2/) by Andrew Gelman

## Recap

-   ANOVA for Multiple Linear Regression

-   Nested F Test

-   AIC & BIC
